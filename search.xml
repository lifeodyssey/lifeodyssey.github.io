<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2020</title>
    <url>/posts/94a46e7b.html</url>
    <content><![CDATA[<p>2020，马上就要过去了。</p>
<a id="more"></a>
<h1 id="section">2020.12.13</h1>
<p>大概这个会到最后放到博客里面吧，也许不会，也许放到博客以后不会发朋友圈。</p>
<p>2020年的第一天，我和朋友一起去看了名古屋第一天的日出。当时我就在想，我2020年唯一的目标就是，找到像今天的太阳一样，能让我在在天没亮时起床，在寒风中赶路的东西。</p>
<p>2020就这么快结束了，而我感觉我似乎还没有找到它。</p>
<p>我似乎没有什么足够感兴趣的、想研究的问题。</p>
<p>这一年极大的锻炼了我的心态，从年初夜晚回家路上听着《疯狂世界》想躺在马路中间，到现在即使研究做不出来，还能厚着脸皮跟老板讲我不行然后按时下班。虽然也还会焦虑，但总归是好多了。</p>
<p>“能够看到这个领域的一些核心问题，并且自己的能力能够解决这个问题”</p>
<p>这句话一直是我决定读博，或者说不读博的核心准则。</p>
<p>虽然兴趣也很重要，但是能毕业的博士才是好博士。我不认为自己是什么能解决重大问题的天之骄子，只是因为做研究更倾向于我喜欢的生活方式才会想往这方面尝试。</p>
<p>回到那句话来，我确实能够看到本领域的很多核心问题，比如大气校正，比如IOP inversion，比如PFT-DA，比如SST trade-off，比如biological responce。</p>
<p>但是我始终感觉我并没有足够的能力来解决这些问题 ；或者说做不到核心的去解决，只是在缝缝补补碰运气。</p>
<p>就像小时候家里电视机坏了，修理师傅就会拆开以后庖丁解牛，但是我只会这儿砸砸那儿拍拍，祈求我还能看上今晚的动画片。有些时候我能意识到问题出在电视机的某一侧，所以我每次都拍那儿，但是我却无法真正的解决电视机的问题——这才是在我眼里一个博士生真正该做的事情。</p>
<p>我不否认我是还有许多东西需要学习，就比如怎么去把电视机拆开检查。问题是，我擅长这个吗？</p>
<p>我擅长什么？</p>
<p>编程写代码？就算是我发邮件怼的那两个印度人或者我老板都比我厉害一点。</p>
<p>数据统计分析？我连手推APTRK都做不到。</p>
<p>辐射传输？自己毕业的时候就拿到了好多参考资料，但是到现在还不能推出来这一套公式。</p>
<p>发现问题的能力？是的我好像是能发现问题在电视的哪个地方，但是我并不擅长去解决他。</p>
<p>也许是我要求太高，每一条都和这方面最厉害的人去比较。但是科研就是这样，你在你这方面比不上你最厉害的那个人，你永远成不了气候。</p>
<p>自己在读研后，也很少因为自己研究有什么进展而获得快乐。我只会在做出来的结果受到别人表扬时获得者快乐，就像一个因为考试成绩好而获得别人表扬的小孩的那种快乐，但是其实我也并不喜欢考试。更别说小时候的考试满分只有100分考到90多分或者考到100分，那就很快乐，就算是没有别人的表扬，但是做科研，满分，那是没有满分，你做不到你当前最好的，那你就是0分。</p>
<p>如果做这件事不快乐，我又怎么能把他当成一生的事业呢？科研本就是依赖于自己的兴趣的，否则一个月几千块钱谁能坚持的下去。</p>
<p>那我自己到底喜欢什么呢？有什么事情能把我从寒冷的被窝里叫出来呢？</p>
<p>星空，算一个。除此之外，好像再也没有了。</p>
<p>虽然这样，但是我可能还是会选择读博吧，因为我真的很喜欢那种生活方式，每天都可以和比自己聪明的人进行交流，每天都可以知道这个世界对前年的知识范围在哪里，同时还有足够的时间进行摸鱼，而且，做出来的成果都是自己的，虽然他有着各种各样的坏处，比如压力大，收入少，考核要求高，但是哪行不是这样呢。</p>
<p>只是我可能不会成为我心目中的那种博士生了，而是一个划水摸鱼的混子。</p>
<p>希望我这个混子不会在未来被淘汰吧。</p>
<p>虽然今年还没有结束，但是我还是先把它发出来吧，等到我生日的时候我再看看，再重新写一篇24岁的展望，看看这么短的时间里，我会不会发生什么变化呢？</p>
<h1 id="section-1">2020.12.26</h1>
<p>终于讲完了我人生的首次报告。</p>
<p>我为什么会不想读博呢？</p>
<p>老板不好？老板简直好的不能再好了，给我TA，帮我改材料，让我参加日本内部的研讨会，几乎是他能想到的能给我的资源都会给我。</p>
<p>所以我为什么不想读博呢？</p>
<p>压力。</p>
<p>非升即走，发paper，申请funding，自己毕业之后甚至都不知道能不能找到一个有编制的工作，也不知道要做几期博后才能谋到一个讲师🧟‍♂️的职位。看到自己隔壁的四十多还是单身的研究员放佛就看到了自己。人家好歹还是东大毕业的JSPS DC2，我连人家的十分之一都没有。等我毕业国内不知道是不是也会变成日本这样。</p>
<p>黑暗。</p>
<p>看不到有什么办法能够解决自己这个方向所面临的问题。自己进入这个学科也快两年了，大大小小的问题总结起来其实也就那么几个，但是似乎真的没有什么东西能够解决它们，很多文献都是到了there are more effort for XXX，然后关于XXX的好文献一年都不一定能有那么几篇。</p>
<p>看不到这个学科有什么问题需要我。我感觉不到我自己的能力、技能和知识和那些处在领域前沿的人相比，看不到自己究竟有什么优点，看不到有什么问题是能够靠自己的能力解决的，甚至应该学哪些知识都不知道。</p>
<p>看不到自己的研究到底有什么真正实际的用处。正像老板那次组会讲的'We have been working here for decades, but we can't do anything for this area'.</p>
<p>菜。</p>
<p>日语不会，英语不好，行动力不行-不然我好歹有个中文了，做事不细心，三分钟热度，流于表面，眼高于顶，三分钟热度，坐不住。</p>
<p>所以我是真的开始不想读博了。</p>
<p>‘科研是最糟糕的职业，你会与最聪明的人竞争，你会与最勤奋的人竞争，你得不断学习新的东西，挣得也不多’</p>
<p>在工业界第一名风光无限，但是第二第三第四第五凭着差异化竞争也有肉吃。但是科研，你不是第一，你就输了。</p>
<p>所以我真的开始不想读了。虽然真的让我读我也会读得下去，读得出来。</p>
<p>自己真的很热爱吗？不是。</p>
<p>我想了很久我所期待的生活会是什么样的，我也想了很久如果让我像我老板一样工作会不会开心。</p>
<p>我可能只会把他当成工作而已吧。</p>
<p>那我为什么非要做这份工作呢，或者说，我为什么非要读博呢？</p>
<p>我觉得我也不需要博士学位来证明自己，选择罢了。</p>
<p>可能想法有些极端吧，但是这就是我现在的想法。</p>
<p>我想放弃这份站在人类知识最前沿的工作，因为站在那里代表了你要承受你背后所有人的压力和期待。</p>
<h1 id="section-2">2020.12.28</h1>
<p>我想读博吗？</p>
<blockquote>
<p>承认自己的平庸，并且去改变</p>
<p>积极地谋求转行，积极地寻找自己的钥匙。不要一边站在坑里向坑外大声地呼喊“我要出去”，一边一遍又一遍地重复自己挖坑的动作，让自己在坑里陷得更深。</p>
<p>对于重大的付出，和关系未来的重大事情上，一定要极其注意一些最基础的存在想象成分的信念是否合理，就像数学中的公理一样，公理错了，那么建立在公理上的一切的东西，都是虚无缥缈的。因此，必须经常检验反思，想象的部分是否合情合理。</p>
<p>疯狂就是不断地重复做同样的事情，却期待不同的结果。</p>
<p>问题不可能由导致问题的思维方式解决。</p>
<p>if you keep doing what you have been doing，you will keep getting what you have been getting</p>
</blockquote>
<p>自己能不能接受这份选择所带来的一切，想清楚对应的后果，降低对于收获的期待。</p>
<p>成年的三大特质</p>
<blockquote>
<ol type="1">
<li><p>接受自己对自己该负起的责任（have been accepting responsibility for one's self）</p></li>
<li><p>独立地做出决定（making independent decisions）。</p></li>
<li><p>实现经济独立（becoming financially independent）。</p></li>
</ol>
</blockquote>
<p>抛去所有的情绪问题（比如不读博可能会不甘心这种）来写一下support和oppose</p>
<p>读博。</p>
<p>support</p>
<ul>
<li>主观上来讲，我确实是有想做的课题，想做的研究，现在集中在PFT model/assimilation to ecosystem和portable devices water quality 这两块，确实这两块没有多少人做而且我也很感兴趣，并且前者我觉得我似乎是目前极少数能集合ecosystem /physical/optical三方面背景的人。</li>
<li>如果是从事和专业相关的工作的话，博士学位的出路一定会比硕士学位好很多，各种方面来讲。</li>
<li>拥有globally 移民的权利，在日本可以获得永驻。</li>
<li>能更方便的让我实现极光和银河的两个梦想。</li>
</ul>
<p>似乎除此之外我再也没有什么必须要读的原因了。</p>
<p>oppose</p>
<ul>
<li>读博期间的情绪压力大，有很大的概率抑郁。</li>
<li>可能会一口气单身到30岁。</li>
<li>读博毕业之后的教职市场并不明朗，可能会像小老板一样，四十多才安定下来。</li>
<li>读博之后收入也很低，30-35这一段最需要用钱的阶段可能月薪只有5000（在国内的话）。</li>
<li>长期的远离家人独自生活。</li>
<li>缺少去周杰伦/五月天等演唱会的机会。</li>
</ul>
<p>不读博。</p>
<p>support</p>
<ul>
<li>可预见的在三到五年之内成家立业。</li>
<li>能够有更多的机会去看周杰伦/五月天的演唱会。</li>
<li>更多的和家人团聚的机会。</li>
</ul>
<p>oppose</p>
<ul>
<li>不可预见的加班以及自己讨厌的重复性繁重工作。</li>
<li>几乎与两个梦想在可预见的时间内无缘。</li>
<li>讨厌的墙。</li>
<li>毕业3-5年内几乎超不了6000的工资，以及可预见的天花板</li>
<li>不可预见的频繁出海工作（年均2-3个月，且与自己的兴趣无关）</li>
<li>几乎这一辈子都在十八线/三十六线生活了。</li>
</ul>
<p>自己真的那么在意那三条吗？</p>
<p>虽然但是，我的确想找个女朋友。</p>
<p>自己能按时毕业吗？我有信心。我相信我的能力和技能能让我按时毕业，这是我为数不多的自信。</p>
<p>我有信心面对情绪压力吗？</p>
<p>回想我读研期间面对的情绪压力，几乎都是来自于我老板的。</p>
<p>而且自己也曾经解决过情绪压力。</p>
<p>比如今年年初题目做不出来，六月份因为经济问题，准备会议和proposal。</p>
<p>最简单的方式就是 和老板沟通。</p>
<p>自己既然能够解决，老板既然这么好。</p>
<p>那你有信心面对接下来的三年吗？</p>
<p>我 有。</p>
<p>我 读。</p>
<h1 id="最后的总结">最后的总结</h1>
<p>自己似乎最后也没有找到那个能让我在寒风中起来的东西。</p>
<p>但是至少 我算是做出了 我明晰后果并且愿意承担后果的抉择。</p>
<p>那么，在享受成果之前，先承担这份后果吧。</p>
<p>虽然我还是并不清楚我想要什么样的生活，但是显然我更喜欢读博那条路上的生活。有梦想就要去做。</p>
<p>享受每一天的进步，而不是和别人比来比去，才能真正的放下焦虑，自己就是想的太多，比较的太多。</p>
<p>跟自己的小初高同学相比，自己已经好很多了。自己肯定不愿意过上他们的生活。</p>
<p>而不是跟天生含着金钥匙的人相比，他们在同样的处境之下也不一定能做的比你更好，这不是自己之前用来安慰别人的话吗？</p>
<p>以后就少列Task list，多列accomplishment list吧。</p>
<p>以及自己还有好多博客的坑没填，我保证4月前一定会把它补完的。</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>A Ph.D is not enough</title>
    <url>/posts/13a77735.html</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>自动机器学习代码详解</title>
    <url>/posts/4668cbbb.html</url>
    <content><![CDATA[<p>毕业论文基于auto-sklearn做了一些自动机器学习模型的应用，模型的原理可以点击<span class="exturl" data-url="aHR0cDovL2NvZGV3aXRoemhhbmd5aS5jb20vMjAxOC8wNy8yNi9BdXRvTUwv">这里<i class="fa fa-external-link-alt"></i></span>，我这儿讲一下我的代码怎么用，相当于是一个详细版的注释。</p>
<p>代码地址见<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5L0FNRg==">https://github.com/lifeodyssey/AMF<i class="fa fa-external-link-alt"></i></span>。</p>
<a id="more"></a>
<p>进入到服务器amf目录下，输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> py3/bin/activate</span><br></pre></td></tr></table></figure>
<p>之后每一行的开头会显示(py3)字样，即代表进入虚拟环境。</p>
<p>之后直接输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python code.py</span><br></pre></td></tr></table></figure>
<p>即可开始运行程序。</p>
<p>以下是程序的详细说明，如果要修改代码，可以在服务器中直接使用vim进行修改，也可以在本地修改好之后用PSFTP推送到服务器上。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> autosklearn.regression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#前面这四行是引入相应的环境包</span></span><br><span class="line">rawdata=pd.read_excel(<span class="string">&#x27;rawdata.xlsx&#x27;</span>)<span class="comment">#单引号输入要读入文件的路径，文件的格式参考服务器中的rawdata.xlsx</span></span><br><span class="line">Y=rawdata[[<span class="string">&#x27;cpue&#x27;</span>]]<span class="comment">#单引号内写要预测的变量名</span></span><br><span class="line"></span><br><span class="line">Y=np.log10(Y+<span class="number">1</span>)<span class="comment">#这里采用了对数变换，可以去掉</span></span><br><span class="line">X=rawdata[[<span class="string">&#x27;lon&#x27;</span>,<span class="string">&#x27;lat&#x27;</span>,<span class="string">&#x27;sst&#x27;</span>,<span class="string">&#x27;chla&#x27;</span>,<span class="string">&#x27;doy&#x27;</span>]]<span class="comment">#单引号内输入要使用的变量名</span></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=<span class="number">0.3</span>,random_state=<span class="number">7</span>)<span class="comment">#test size代表了测试集在整个数据集中的占比，这里选取的是0.3即30%</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">automl = autosklearn.regression.AutoSklearnRegressor(</span><br><span class="line">    include_estimators=[<span class="string">&quot;random_forest&quot;</span>,<span class="string">&quot;decision_tree&quot;</span>,<span class="string">&quot;gradient_boosting&quot;</span>,<span class="string">&quot;xgradient_boosting&quot;</span>],</span><br><span class="line">    <span class="comment">#这里只放了几个我认为效果比较好的模型，模型种类参见https://github.com/automl/auto-sklearn/tree/master/autosklearn/pipeline/components/regression，如果想换用模型，把双引号内的名称更改即可；如果想删除或者添加，直接去掉相应的名称即可</span></span><br><span class="line">    exclude_estimators=<span class="literal">None</span>,</span><br><span class="line">    include_preprocessors=[<span class="string">&quot;no_preprocessing&quot;</span>, ],</span><br><span class="line">    exclude_preprocessors=<span class="literal">None</span>,</span><br><span class="line">    resampling_strategy=<span class="string">&#x27;cv&#x27;</span>,</span><br><span class="line">    resampling_strategy_arguments=&#123;<span class="string">&#x27;folds&#x27;</span>: <span class="number">10</span>&#125;,<span class="comment">#这里选了十折交叉验证来确定最优参数</span></span><br><span class="line">    )</span><br><span class="line">automl.fit(x_train, y_train.values.ravel())</span><br><span class="line"></span><br><span class="line">automl.sprint_statistics()</span><br><span class="line">automl.show_models()</span><br><span class="line">automl.refit(x_train, y_train.values.ravel())</span><br><span class="line"><span class="comment">#如果想输入新的自变量来做预测的话,将下面几句前面的#去除即可</span></span><br><span class="line"><span class="comment">#predata=pd.read_excel(&#x27;rawdata.xlsx&#x27;)#单引号内输入文件路径</span></span><br><span class="line"><span class="comment">#X=predata[[&#x27;lon&#x27;,&#x27;lat&#x27;,&#x27;sst&#x27;,&#x27;chla&#x27;,&#x27;doy&#x27;]]#单引号内输入选取的变量名</span></span><br><span class="line">y_pre = automl.predict(X)</span><br><span class="line">ypre=np.power(<span class="number">10</span>,ypre)<span class="number">-1</span><span class="comment">#变换回来</span></span><br><span class="line">ypre=pd.DataFrame(ypre)</span><br><span class="line">result=pd.concat([rawdata,ypre])<span class="comment">#如果输入新的自变量来做预测，将rawdata改为predata</span></span><br><span class="line">result.to_excel(<span class="string">&#x27;result.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Papers And Thesis</category>
      </categories>
      <tags>
        <tag>Automatic Machine Learning</tag>
        <tag>Fishery Forecasting</tag>
        <tag>Undergraduate Thesis</tag>
      </tags>
  </entry>
  <entry>
    <title>AWOC/KJWOC Online 2020 Presentation</title>
    <url>/posts/7c5b3027.html</url>
    <content><![CDATA[<p>Laster year I attended The <span class="math inline">\(\rm 8^{th} Asian/17^{th}\)</span> Korea-Japan Workshop on Ocean Color and gave a presentation.</p>
<a id="more"></a>
<h1 id="spectral-spatial-fusion-between-sgli-and-modis-in-the-ariake-sea">Spectral-spatial fusion between SGLI and MODIS in the Ariake Sea</h1>
<p><span class="math inline">\(\rm Zhenjia\ ZHOU^{1*}, Joji\ ISHIZAKA^{2}, Chi\ FENG^{3}\)</span></p>
<p>1 Graduate School of Environmental Studies, Nagoya University, Nagoya, Japan</p>
<p>2 Institute for Space-Earth Environmental Research, Nagoya University, Nagoya, Japan</p>
<p>3 Graduate School of Environmental Studies, Nagoya University, Nagoya, Japan</p>
<p>* e-mail: zhenjiazhou0127@gmail.com</p>
<p>Harmful algal bloom (HAB) is an environmental problem in both freshwater and marine systems. In Japan, HAB always appears in the western part, such as the Ariake Sea. Some toxic species, like raphidophytes, could reduce fishery production and thus cause economic loss. Therefore, it is essential to know the dynamic of the toxic and non-toxic HAB in Japan's coastal area.</p>
<p>The discrimination between different phytoplankton is based on the optical properties difference, such as remote sensing reflectance (Rrs), and derived backscattering and absorption in the visible light range. Nevertheless, there are two main restrictions from ocean color satellites in this field; spectral resolution and spatial resolution.</p>
<p>Currently, ocean color satellites could only carry a multi-spectral spectroradiometer, which could only get the optical properties in a few specific wavelengths. For example, the MODerate Resolution Imaging Spectroradiometer (MODIS) and the Second generation GLobal Imager (SGLI) measure only ten and six visible ocean bands, respectively. Such spectral resolution makes it hard to get unique optical properties of different phytoplankton.</p>
<p>Another restriction from the satellite is spatial resolution. MODIS takes 1 km spatial resolution data, and it may not be satisfactory to catch small HAB patches. Currently, SGLI is the highest spatial resolution (250 m) ocean color satellite in the Japanese coastal region.</p>
<p>This research aims to develop a method for the fusion between SGLI and MODIS in the Ariake Sea. The fusion product has high spatial (250 m)-spectral (14 wavelengths) resolution Rrs. First, we will adjust SGLI wavelength to MODIS wavelength to generate a reference image only from SGLI Rrs. Then the same wavelength MODIS Rrs will be used to calibrate the reference image through regression and interpolation. The spatial and optical properties will be investigated as a basis of the fusion process. Further evaluation will be done by in-situ data and the Aerosol Robotic Network-Ocean Color (AERONET-OC) established in the Ariake Sea. This is the first research that increases the spectral resolution of SGLI by image fusion. Moreover, this research could provide more spatial and spectral optical characteristic details of phytoplankton bloom than a single satellite.</p>
]]></content>
      <categories>
        <category>Papers And Thesis</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Data Fusion</tag>
        <tag>International Conference</tag>
        <tag>Presensentation</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 11.24-11.29</title>
    <url>/posts/d1210079.html</url>
    <content><![CDATA[<p>最近没有一点科研的状态</p>
<p>鸽了好多博客没写，文章没看</p>
<p>我好累 我好想放弃</p>
<p>我想 回家</p>
<p>好像那个被我找到的目标 又走远了</p>
<a id="more"></a>
<h1 id="phytoplankton-fluorescence-theory-current-literature-and-in-situ-measurement">Phytoplankton fluorescence: theory, current literature and <em>in situ</em> measurement</h1>
<p>Book 'Real-time Coastal Observing Systems <em>for</em> Marine Ecosystem Dynamics <em>and</em> Harmful Algal Blooms', Chapter 7, 'Phytoplankton fluorescence: theory, current literature and <em>in situ</em> measurement' edited by Marcel Baiin.</p>
<h1 id="fluorescence-component-in-the-reflectance-spectra-from-coastal-waters.-dependence-on-water-composition">Fluorescence component in the reflectance spectra from coastal waters. Dependence on water composition</h1>
<ol type="1">
<li>Based on HYDROLIGHT simulations of more than 2000 reflectance spectra from datasets typical of coastal waters with highly variable optically active constituents as well as on intercomparisons with field measurements, the magnitude of chlorophyll fluorescence was analyzed and parameterized as a function of phytoplankton, CDOM, and suspended inorganic matter concentrations. Using</li>
<li>Using the parameterizations developed, we show that variations in the fluorescence component of water leaving radiance in coastal waters are due more to the variability of attenuation in the water than to the variability of the fluorescence quantum yield, which we estimate to be relatively stable at around 1%</li>
<li>Finally, the ranges of water conditions where fluorescence plays a significant role in the reflectance NIR peak and where it is effectively undetectable are also determined.</li>
</ol>
<p>我可真喜欢这篇文章，写得真好，看着就舒服。</p>
<p>But it is still a very informative paper for me. Honestly, I do not know a lot about the fluorescence theories and elastic/inelastic scattering before I read this paper.</p>
<h1 id="fluorescence-component-in-the-reflectance-spectra-from-coastal-waters.-ii.-performance-of-retrieval-algorithms">Fluorescence component in the reflectance spectra from coastal waters. II. Performance of retrieval algorithms</h1>
<p>This is a analyse of NFLH algorithm.</p>
<h1 id="impact-of-sub-pixel-variations-on-ocean-color-remote-sensing-products">Impact of sub-pixel variations on ocean color remote sensing products</h1>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Inherent Optical Properties</tag>
        <tag>Fluorescence</tag>
        <tag>Ocean Optics</tag>
        <tag>Sub-pixel</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 11.30-12.6</title>
    <url>/posts/adc0cb59.html</url>
    <content><![CDATA[<p>重新加油</p>
<p>这周可以说是IOP专题了</p>
<a id="more"></a>
<h1 id="variations-of-light-absorption-by-suspended-particles-with-chlorophyll-a-concentration-in-oceanic-case-1-waters-analysis-and-implications-for-bio-optical-models">Variations of light absorption by suspended particles with chlorophyll a concentration in oceanic (case 1) waters: Analysis and implications for bio-optical models</h1>
<p>This is a fairly old paper.</p>
<p>The importance of this paper for my research is these figures.</p>
<figure>
<img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00021201104954518.png" alt="image-00021201104954518"><figcaption aria-hidden="true">image-00021201104954518</figcaption>
</figure>
<p>Although the data is obtained from oceanic(case 1) water, but we can see that the range of chlorophyll is relative high. So the parameteration of <span class="math inline">\(a_{ph}\)</span> might also could be used for case 2 water.</p>
<p>This is the parameteration for <span class="math inline">\(a_{ph}\)</span></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021201105305213.png" alt="image-00021201105305213"><figcaption aria-hidden="true">image-00021201105305213</figcaption>
</figure>
<p>Compared with former Bricaud 1995, the r2 is better.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021201105504185.png" alt="image-00021201105504185"><figcaption aria-hidden="true">image-00021201105504185</figcaption>
</figure>
<p>The author put the data here https://doi.pangaea.de/10.1594/PANGAEA.739879</p>
<p>But I use the data from herehttps://github.com/BrandonSmithJ/MDN/blob/abad4338f495f801b88a32c141b6639e7b7989ad/IOP/bricaud_1998_aph.txt</p>
<p>But when I tried this parameteratzation, this actually also produce some strange shape.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/Bricaud1998.png" alt="Bricaud1998"><figcaption aria-hidden="true">Bricaud1998</figcaption>
</figure>
<p>I think this is not only the problem of QAA, because when I use in-situ chia, the aph shape is also strange.</p>
<p>I think the reparameterazation is needed.</p>
<h1 id="inversion-of-in-situ-light-absorption-and-attenuation-measurements-to-estimate-constituent-concentrations-in-optically-complex-shelf-seas">Inversion of In Situ Light Absorption and Attenuation Measurements to Estimate Constituent Concentrations in Optically Complex Shelf Seas</h1>
<p>Packaging effect:</p>
<p>It is well known that the chlorophyll-specific phytoplankton absorption coefficient decreases with increasing Chl concentration due to the pigment packaging effect (Bricaud et al., 1995).</p>
<p>This paper suggest that 'linear regression can be performed for the ranges of chlorophyll concentration values that are relevant for shelf seas as the effect of pigment packaging will be relatively limited for these values'</p>
<p>It just assumes that the <span class="math inline">\(a^*_{ph}\)</span> is constant.</p>
<p>So it could fix the value...</p>
<p>But one thing for me is that may be I can try water classification.</p>
<p>There are a lot of things I think.</p>
<p>By now, especially before AWOC. I do not want to solving these problems.</p>
<h1 id="light-scattering-and-chlorophyll-concentration-in-case-1-waters-a-reexamination">Light scattering and chlorophyll concentration in case 1 waters: A reexamination</h1>
<h2 id="intro-and-mm">Intro and MM</h2>
<p>This analysis, restricted to case 1 waters, aims at reassessing a previous nonlinear relationship established between the particle scattering coefficient, <span class="math inline">\(b_p\)</span> (very close to the particle attenuation coefficient, <span class="math inline">\(c_p\)</span>), and the chlorophyll concentration, [Chl]. This paper also suggested a modified criterion for turbid case 2 water.</p>
<p>In Gordon and Morel 1983, <span class="math display">\[
b_{p}(550)=A[Chl]^{0.62}
\]</span> A, which is on average 0.30 within the upper oceanic layer, may vary between 0.12 and 0.45 to account for the lowest and highest particle scattering coefficients found at various depths in waters sat- isfying the criterion for belonging to case 1 waters</p>
<p>The importance of Gordon and Morel 1983 is the finding of this nolinear characteristics. But is lacks tightness expressed by the wide possible variation of A.</p>
<p>The Chl is measured by HPLC. The whole dataset has been seperated into several subsets for different purpose. For my research, I just need to focus on the surface, which is the <span class="math inline">\(N_{sat}/Z_{90}\)</span></p>
<figure>
<img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00021130141721276.png" alt="image-00021130141721276"><figcaption aria-hidden="true">image-00021130141721276</figcaption>
</figure>
<p>The author also use Bricaud 1995 to model phytoplankton absorption in order to study the contribution of absorption to attenuation coefficient. <span class="math display">\[
a_{ph}(660)=0.012[Chl]^{0.878}
\]</span></p>
<p><span class="math display">\[
a_{p}(660)=0.014[Chl]^{0.817}
\]</span></p>
<p>But the coefficient of determination(<span class="math inline">\(r^2=0.27\)</span>) is relative low.</p>
<p>They found the contribution is negligible. <span class="math inline">\(c_p\)</span> could be considered as same as <span class="math inline">\(b_p\)</span></p>
<h2 id="result-and-discussion">Result and discussion</h2>
<p>For the near surface layer, <span class="math display">\[
c_{p}(660)=0.347[Chl]^{0.766}(r^2=0.89, N_{sat}=435)
\]</span></p>
<h1 id="particulate-backscattering-ratio-at-leo-15-and-its-use-to-study-particle-composition-and-distribution">Particulate backscattering ratio at LEO 15 and its use to study particle composition and distribution</h1>
<h2 id="intro">Intro</h2>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Inherent Optical Properties</tag>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 9.28-10.4</title>
    <url>/posts/e4bb9d98.html</url>
    <content><![CDATA[<p>Annotated Bibliography 2020 9.28-10.4</p>
<p>I will try to read three or four papers every week and update my annotation.</p>
<p>Update 2020 9.30: At least two paper.</p>
<a id="more"></a>
<h1 id="downscaling-modis-images-with-area-to-point-regression-kriging">Downscaling MODIS images with area-to-point regression kriging</h1>
<p>Wang, Qunming, et al. "Downscaling MODIS images with area-to-point regression kriging." <em>Remote Sensing of Environment</em> 166 (2015): 191-204.</p>
<h2 id="method-description">Method description</h2>
<h3 id="problem-description">Problem description</h3>
<p><span class="math inline">\(Z_V^l(x_i)\)</span>: random variable of pixel V centered at xi (i =1,…,M,where M is the number of pixels) in coarse band l.</p>
<p><span class="math inline">\(Z_v^k(x_j)\)</span>: random variable of pixel v centered at xj (j =1,…,MF^2,where F is the spatial resolution (zoom) ratio between the coarse and fine bands) in fine band k</p>
<p>The notations v and Vdenote fine and coarse pixels, respectively.</p>
<p>Aim:predict <span class="math inline">\(Z_v^k(x)\)</span> for all fine pixels in all coarse bands.</p>
<p>Prediction: <span class="math display">\[
Z_v^l(x)=Z_{v1}^l(x)+Z_{v2}^l(x)
\]</span> <span class="math inline">\(Z_{v1}^l(x)\)</span>: regression</p>
<p><span class="math inline">\(Z_{v2}^l(x)\)</span> : ATPK</p>
<h3 id="regression">Regression</h3>
<p>For coarse band <span class="math inline">\(Z_V^l\)</span> , its corresponding fine band used as covariate is denoted as <span class="math inline">\(Z_v^{lk}\)</span></p>
<p>The regression prediction <span class="math inline">\(Z_{v1}^l(x)\)</span> is calculated as <span class="math display">\[
Z_{v1}^l(x)=a_lZ_v^{lk}(x)+b_l
\]</span> Key issue is to estimate <span class="math inline">\(a_l\)</span> and <span class="math inline">\(bl\)</span></p>
<p>The relationship in Eq. (2) is assumed to be uni- versal at different spatial resolutions, and the relationship built at coarse spatial resolutions can be applied at fine spatial resolution.</p>
<p>Based on this hypothesis, we get Eq.(3): <span class="math display">\[
Z_V^l(x)=a_lZ_V^{lk}x+b_l
\]</span> in which <span class="math inline">\(Z_V^{lk}\)</span> is the coarse image produced by upscaling the ancillary fine band <span class="math inline">\(Z_v^{lk}\)</span> to the same spatial resolution of the l-th coarse band, that is <span class="math display">\[
Z_V^{lk}=h_V^{l}(x)*Z_v^{lk}(x)=\int h_V^l(x-y)Z_v^{lk}(y)dy
\]</span> where <span class="math inline">\(h_V^l (y)\)</span> is the point spread function (PSF) for the l-th band and ∗ is the convolution operator</p>
<p>PSF:https://www.youtube.com/watch?v=Tkc_GOCjx7E</p>
<p>ordinary least squares (OLS) is applied for estimate <span class="math inline">\(a_l\)</span> and <span class="math inline">\(b_l\)</span></p>
<p>The ancillary information fromother data, such as elevation data and field measurement correlated to the observation, can also be favorably incorporated in regression modeling. Given T groups of covariates, <span class="math inline">\(Z_v^t(x)(t =1,…,T)\)</span>, the regression prediction <span class="math inline">\(Z_{v1} ^l (x)\)</span> in this more general case then becomes <span class="math display">\[
Z_{v1}^{l}(x)=\sum_{t=0}^Ta_{lt}Z_v^t(x),Z_{v}^{0}(x)=1\forall x
\]</span></p>
<h3 id="atpk">ATPK</h3>
<p>Residuals, denoted as <span class="math inline">\(Z_{V2}^l(x)\)</span>,from the regression process, that it, <span class="math display">\[
Z_{V2}^{l}(x)=Z_{V}^{l}-[a_l Z_V^{lk}(x)+b_l]
\]</span> The results ofregression cannot reproduce the spectral properties of the observed coarse data. Thus, regression alone is not sufficient for downscaling. The residuals at fine spatial resolution should be compen- sated for the regression prediction to honor the spectral properties. In the proposed ATPRK approach, based on the strong assumption <strong>that the residual is an intrinsically stationary process</strong>, ATPK acts as the second phase to downscale the residuals <span class="math inline">\(Z_{V2}^l (x)\)</span> to fine spatial resolution residuals <span class="math inline">\(Z_{v2} ^l (x)\)</span>.</p>
<p>Based on ATPK, the fine residual <span class="math inline">\(Z_{v2} ^l (x)\)</span> is a linear combination of N coarse residuals of band l <span class="math display">\[
Z_{v2}^{l}(x)=\sum_{i=1}^{N}\lambda_i Z_{V2}^l(x_i),s.t.\sum_{i=1}^N\lambda_i=1
\]</span> in which <span class="math inline">\(λ_i\)</span> is theweight for the <span class="math inline">\(i\)</span> th residual of the coarse pixel centered at <span class="math inline">\(x_i\)</span>.</p>
<p>The <span class="math inline">\(N\)</span> coarse residuals are from the <span class="math inline">\(N\)</span> coarse pixels surrounding the pixel center at <span class="math inline">\(x\)</span>,such as <span class="math inline">\(N\)</span>=5×5 window of coarse pixels.</p>
<p>As observed from Eq. (7), the ATPK part accounts for the spatial correlation between coarse pixels, which is not utilized in the regression part.</p>
<p>The objective of the ATPK part is to obtain the <span class="math inline">\(N\)</span> weights <span class="math inline">\({λ_1,…,λ_N}\)</span>. The weights are estimated by minimizing the prediction error variance. The corresponding kriging system is <span class="math display">\[
\begin{bmatrix}
C_{VV}^l(x_1,x_1) &amp; \cdots C_{VV}^l(x_1,x_N)&amp;1\\\\
\vdots&amp;\vdots&amp;\vdots \\\\
C_{VV}^l(x_N,x_1) &amp; \cdots C_{VV}^l(x_N,x_N)&amp;1\\\\
1 \cdots &amp;1 &amp; 0
\end{bmatrix}
\begin{bmatrix}
\lambda_1\\\\
\vdots\\\\
\lambda_N\\\\
\mu
\end{bmatrix}
=
\begin{bmatrix}
C_{vV}^l(x,x_1)\\\\
\vdots\\\\
C_{vV}^l(x,x_N)\\\\
1
\end{bmatrix}
\]</span> The term <span class="math inline">\(C_{VV} ^l (x_i, x_j)\)</span> is the coarse-to-coarse residual covariance between coarse pixels centered at <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> in band l, <span class="math inline">\(C_{vV}^ l (x, x_j)\)</span> is the fine-to-coarse residual covariance between fine and coarse pixels centered at <span class="math inline">\(x\)</span> and <span class="math inline">\(x_j\)</span>, respectively, and <span class="math inline">\(μ\)</span> is the Lagrange multiplier. The <span class="math inline">\(N\)</span> weights can be calculated according to Eq. (8). For this purpose, the two types of covariance in Eq. (8) need to be obtained in advance</p>
<p>Suppose <span class="math inline">\(s\)</span> is the Euclidean distance between centroids of any two pixels, and <span class="math inline">\(C_{vv} ^l (s)\)</span>is the fine-to-fine (called “punctual” in this paper, by assuming each fine pixel as a point) residual covariance between two fine pixels. The fine-to-coarse covariance $C_{vV}l (s) $and coarse-to-coarse covariance <span class="math inline">\(C_{VV}^ l (s)\)</span> are calculated by convoluting <span class="math inline">\(C_{vv}^ l (s)\)</span> with the PSF <span class="math inline">\(h_V ^l (s)\)</span>as follows <span class="math display">\[
C_{vV}^l(s)=C_{vv}^l(s)*h_V^l(s)
\]</span></p>
<p><span class="math display">\[
C_{VV}^l(s)=C_{VV}^l(s)*h_V^l(s)*h_V^l(-s)
\]</span></p>
<p>In Eq. (10), <span class="math inline">\(−s\)</span> means that the distance from point A within a pixel to point B within another pixel, denoted as <span class="math inline">\(−s\)</span>, is opposite to that from point B to point A (i.e., <span class="math inline">\(s\)</span>)</p>
<p>Note that the variable in the PSF should be a location, as indicated earlier in Eq. (4). However, s in Eqs. (9) and (10) is originally defined as a distance. Actually, in Eqs. (9) and (10), <span class="math inline">\(s\)</span> is defined for covariance <span class="math inline">\(C_{vv}^l\)</span>, which can be recognized as a 2-D image centered at {0,0}, with values in all directions and at multiple lag dis- tances. Thus, <span class="math inline">\(s\)</span> in Eqs. (9) and (10) is essentially a location in the image (e.g., <span class="math inline">\(s\)</span> = {1,1} means a point along the northeast direction with lag 1.414).</p>
<p>If we assume that the coarse pixel value is the average of the fine pixel values within it, then the PSF is <span class="math display">\[
h_V^l(x)=\begin{cases}\frac{1}{S_v},\quad if\quad x\in V(x)\\
0, \quad otherwise
\end{cases}
\]</span> where <span class="math inline">\(S_V\)</span> is the size of pixel <span class="math inline">\(V\)</span>,and <span class="math inline">\(V(x)\)</span> is the spatial support of pixel <span class="math inline">\(V\)</span> centered at <span class="math inline">\(x\)</span>. If the area of pixel <span class="math inline">\(v\)</span> is defined as 1, then <span class="math inline">\(S_V=F^2\)</span>.Given the PSF in Eq. (11), the computation of <span class="math inline">\(C_{vV}^l (x, x_j)\)</span>and <span class="math inline">\(C_{VV}^l(x_i, x_j)\)</span> are further simplified as <span class="math display">\[
C_{vV}^l(x,x_j)=\frac{1}{S_V}\int_\limits{u\in V(x_j)}C_{vv}^l(\boldsymbol{x}-\boldsymbol{u})d\boldsymbol{u}=\frac{1}{F^2}\sum_{m=1}^{F^2}C_{vv}^{l}(S_m)
\]</span></p>
<p><span class="math display">\[
C_{VV}^l(x_i,x_j)=\frac{1}{S_V}\int_\limits{u\in V(x_i)}C_{vV}^l(u,x_j)d\boldsymbol{u}\\\\
=\frac{1}{ {S_V}^2}\int_\limits{u\in V(x_i)}\int_\limits{u^\prime\in V(x_j)}C_{vv}^l(u-u^{\prime})d\boldsymbol{u}d\boldsymbol{u}^{\prime}\\\\
=\frac{1}{F^4}\sum_{m=1}^{F^2}\sum_{m=1}^{F^2}C_{vv}^l(s_{mm^\prime})
\]</span> In Eq. (12), <span class="math inline">\(s_m\)</span> is the distance between the centroid <span class="math inline">\(x\)</span> of fine pixel <span class="math inline">\(v\)</span> and the centroid of any fine pixel within the coarse pixel <span class="math inline">\(V\)</span> centered at <span class="math inline">\(x_j\)</span>,and <span class="math inline">\(s_{mm^\prime}\)</span>is the distance between the centroid of any fine pixel within the coarse pixel centered at <span class="math inline">\(x_i\)</span> and the centroid of any fine pixel within the coarse pixel centered at <span class="math inline">\(x_j\)</span>.</p>
<p>The critical problem of kriging weight estimation in ATPK becomes the estimation of punctual residual covariance <span class="math inline">\(C_{vv} ^l (s)\)</span>. It is derived by deconvolution (also termed deregularization in geostatistics) of the areal covariance, denoted as <span class="math inline">\(C_V ^l (s)\)</span>, of the known coarse residual image <span class="math inline">\(Z_{v2}^l\)</span>. Deconvolution aims to estimate the optimal punctual covariance, the regularized covariance of which approximates the known areal covariance.</p>
<p>Given a candidate pool of punctual covariances, each <span class="math inline">\(C_{vv}^l (s)\)</span> is convolved to the regularized areal covariance (denoted as <span class="math inline">\(C_V^{l\_R}(s)\)</span>). The optimal punctual covariance is determined as the one with the smallest difference between <span class="math inline">\(C_V^{l\_R}(s)\)</span> and CV l (s). The covariance, which is closely related to the semivariogram (their sum is a constant), can generally be characterized by three parameters, nugget, sill and range. The essence of punctual covariance estimation is the optimal parameter combination estimation. Note that in Eq. (8), the covariance matrix can be replaced by the semivariogram matrix and both give the same kriging weights. Therefore, the covariance modeling, including deconvolution and convolution, is essentially the semivariogram modeling</p>
<p>The candidate pool ofpunctual covariances is generated by referring to the known areal covariance <span class="math inline">\(C_V ^l (s)\)</span>. Specifically, for each of the three parameters of$ C_{vv}^ l (s)$, two multipliers are defined empirically to generate an interval for selecting the corresponding optimal parameter of <span class="math inline">\(C_{vv}^l (s)\)</span>. In this paper, the interval for punctual sill selection is set to between 1 and 3 times that of the areal sill, while the interval for punctual range selection is set to between 0.5 and 2.5 times that of the areal range. The step is set to 0.1. Regarding the punctual nugget, 21 × 21 = 441 steps of convolution need to be implemented to test each given nugget value. The computational cost increases linearly with the number of nugget candidates. To ease the computational burden, the assumption made in Atkinson et al. (2008) and Pardo-Igúzquiza et al. (2006, 2011) is adopted in this paper: there is zero nugget effect in the punctual covariance. As a result, the optimal punctual parameter combination is selected from the candidate pool containing 441 groups of parameters.</p>
<h3 id="atprk">ATPRK</h3>
<p>After both regression and ATPK are completed , their outputs (i.e., <span class="math inline">\(Z_{v1}^ l (x)\)</span>and <span class="math inline">\(Z_{v2}^ l (x))\)</span> are combined to produce the final downscaled result, as indicated in Eq. (1).The whole flowchart of the proposed ATPRK approach for downscaling MODIS imagery is shown in Fig. 1. For each coarse band l,ATPRK is performed in turn, and the final result is a fine spatial resolution seven-band MODIS image. The flowchart in Fig. 1 is easy to implement and can be revised by adding other available covariates, as illustrated in Eq. (5). <img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00020930132948176.png" alt="image-00020930132948176"></p>
<p>An important advantage of ATPK is the coherence characteristic (Kyriakidis, 2004; Kyriakidis &amp; Yoo, 2005) <span class="math display">\[
\int h_V^l(x-y)Z_{v2}^l(y)dy=Z_{V2}^l(x)
\]</span> This has been proved theoretically and demonstrated practically.</p>
<p>By compensating the downscaled residuals for regression prediction, we have that <span class="math display">\[
\int h_V^l(x-y)Z_v^l(y)dy=Z_V^l(x)
\]</span></p>
<h4 id="appendix-preserve-of-spectral-properties">Appendix: Preserve of spectral properties</h4>
<p>Without loss of generality, we consider the case of <span class="math inline">\(T\)</span> groups of ancillary variables, that is, the case in Eq. (5). According to Eq. (4), when building the regression model, each group of ancillary data <span class="math inline">\(Z_v^t(x)\)</span> is upscaled to <span class="math inline">\(Z_V ^t(x)\)</span>as follows <span class="math display">\[
Z_V^t(x)=\int h_V^l(x-y)Z_v^t(y)dy
\]</span> In APTK prediction <span class="math display">\[
\int h_V^l(x-y)Z_{v2}^l(y)dy=Z_{V2}^l(x)=Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)
\]</span> Therefore, we have <span class="math display">\[
\int h_V^l(x-y)Z_v^l(y)dy\\\\
=\int h_V^l(x-y)[Z_{v1}^l(y)+Z_{v2}^{l}(y)]dy\\\\
=\int h_V^l(x-y)Z_{v1}^l(y)dy+\int h_V^l(x-y)Z_{v2}^l(y)dy\\\\
=\int h_V^l(x-y)Z_{v1}^l(y)dy+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=\int h_V^l(x-y)\sum _{t=0}^{T}a_{lt}Z_{v}^l(y)dy+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=\sum_{t=0}^{T}a_{lt}\int h_V^l(x-y)Z_{v}^l(y)dy+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=\sum_{t=0}^{T}a_{lt}Z_V^t(x)+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=Z_V^l(x)
\]</span> This means that when the downscaled result <span class="math inline">\(Z_v^ l (x)\)</span> produced by the ATPRK approach is upscaled to the original coarse spatial resolution, it is identical to the original observed coarse image$ Z_V^l (x)$. Thus, the spectral properties of the coarse data are precisely preserved by ATPRK. This is a significant advantage of the new method ATPRK in image fusion.</p>
<h2 id="summary-and-annotation">Summary and Annotation</h2>
<p>To be honest, I didn't really understand it in detail, especially the deduction part. But fortunately, the author provided the source code in Matlab(https://github.com/qunmingwang), I can try to rewrite in the python and try to understand it more.</p>
<p>It might be the best method that could preserve the spectral properties(2020.9.30). Of course I need to do more literature review.</p>
<p>Another strength of this paper is that I now clearly undetstand what do I need to do for writing such kind of articles, including methods comparison(all most all the state-of-art and frequently used method), metrics(the most metrics I have seen) and classification(the essens of spectral resolution ).</p>
<p>In summary, ATPRK includes two parts: regression and ATPK. The former uses fine spatial resolution information from the fine band and the latter down- scales the residuals from regression that are then added back to the regression prediction.</p>
<h2 id="note-for-atprk-matlab-code">Note for ATPRK matlab code</h2>
<p>code repository:https://github.com/qunmingwang/Code-for-S2-fusion</p>
<p>This code is for Q. Wang, W. Shi, Z. Li, P. M. Atkinson. Fusion of Sentinel-2 images. Remote Sensing of Environment, 2016, 187: 241�C252.</p>
<p>This paper aims to downscale 20m Sentinel-2 band to 10m. And it compared the result with eight CS and MRA-based approaches.</p>
<p>This code chnage PSF to Gaussian filter. But it is proofed that the coherence characteristics of ATPK and ATPRK is not affected by the specific form of PSF.</p>
<h3 id="band-selection">Band Selection</h3>
<p>This paper extended the ATPRK using the synthesized and selected band schemes.</p>
<p>For accommodation of fine spatial reso- lution information from multiple fine bands, two schemes were proposed in Selva et al. (2015), that is, the synthesized band scheme and the selected band scheme.</p>
<p>The selected band scheme selects a fine band from the fine band set for each coarse band, which is determined as the one with the largest correlation with the visited coarse band.</p>
<p>The synthesized band scheme synthesizes a single fine band from the fine band set (i.e., fine multispectral image), such as averaging all fine multispectral bands (Selva et al. 2015).</p>
<p>However, the synthesized band scheme based on the simple averaging process fails to consider the relation between the visited coarse band and the four fine bands. In this paper, to fully account for the information in the four finebands, the synthesized band for each coarse band is determined adap- tively as a linear combination ofthe four fine bands.</p>
<p>So this is the why there exist the 'Selected band scheme.m' and 'Synthesized band scheme.m' as the first two file.</p>
<p>After band selection, as the selected band scheme only use panchromatic band and synthesized use multispectral bands, so the function are called 'ATPRK_PANsharpen' and 'ATPRK_MSsharpen', respectively.</p>
<h1 id="deriving-consistent-ocean-biological-and-biogeochemical-products-from-multiple-satellite-ocean-color-sensors">Deriving consistent ocean biological and biogeochemical products from multiple satellite ocean color sensors</h1>
<p>Menghua Wang, Lide Jiang, SeungHyun Son, Xiaoming Liu, and Kenneth J. Voss, "Deriving consistent ocean biological and biogeochemical products from multiple satellite ocean color sensors," Opt. Express <strong>28</strong>, 2661-2682 (2020)</p>
<p>This paper proposed a method that could derive consistent product from different new.</p>
<p>I need to consider sensor response function.</p>
<p>Consistency evaluation by scatter plot and density plot</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Data Fusion</tag>
        <tag>Remote Sensing</tag>
      </tags>
  </entry>
  <entry>
    <title>Chla retrieval</title>
    <url>/posts/a31ba57b.html</url>
    <content><![CDATA[<p>A note for Chla algorithm.</p>
<a id="more"></a>
<h1 id="chla-algorithms-review">Chla Algorithms Review</h1>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 48%">
<col style="width: 24%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Formula</th>
<th>Reference</th>
<th>Water type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OC</td>
<td><span class="math inline">\(log_{10}(Chl)=a_0+a_1X+a_2X^2+a_3X^3+a_4X^4,X=log_{10}(\frac{Rrs_(\lambda_b)}{Rrs_(\lambda_g)})\)</span>(Example)</td>
<td>O'Reilly 2019</td>
<td>Clear</td>
</tr>
<tr class="even">
<td>OCI</td>
<td><img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00030312152124019.png" alt="image-00030312152124019"></td>
<td>Wang 2016;Hu 2011</td>
<td>Coastal</td>
</tr>
<tr class="odd">
<td>Band ration</td>
<td><span class="math inline">\(Rrs(751)/Rrs(672)\)</span></td>
<td>Gurlin 2011</td>
<td>Coastal</td>
</tr>
<tr class="even">
<td>Tang/Tassan</td>
<td><img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00030312152233703.png" alt="image-00030312152233703"></td>
<td>Tang 2004;Tassan,1994;Sun 2010</td>
<td>Coastal</td>
</tr>
<tr class="odd">
<td>Gitelson</td>
<td><img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00030312152341386.png" alt="image-00030312152341386"></td>
<td>Gitelson 2008</td>
<td>Coastal</td>
</tr>
<tr class="even">
<td>RLH</td>
<td>Rrs(672)-Rrs(555)-{[Rrs(751)-Rrs(555)] × [(672-555)/(751-555)]}</td>
<td>Schalles,1998</td>
<td>Coastal</td>
</tr>
<tr class="odd">
<td>RDR</td>
<td>[Rrs(555)-Rrs(488)]/[Rrs(555) + Rrs(488)]</td>
<td>Gitelson,1993</td>
<td>Coastal</td>
</tr>
<tr class="even">
<td>NDCI</td>
<td>[Rrs(751)-Rrs(672)]/[Rrs(751) + Rrs(672)]</td>
<td>Mishra, 2012</td>
<td>Coastal</td>
</tr>
<tr class="odd">
<td>SCI</td>
<td>HChla = {Rrs(751) + (751-672)/(751-555) × [Rrs(555)-Rrs(751)]}-Rrs(672), H∆ = Rrs(555)-{Rrs(751) + (751-555)/(751-488) × [Rrs(488)-Rrs(751)]}, SCI = HChla-H∆</td>
<td>Shen, 2010</td>
<td>Coastal</td>
</tr>
<tr class="even">
<td>ASA</td>
<td><img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00030312152813412.png" alt="image-00030312152813412"></td>
<td>Jiang, 2020</td>
<td>Coastal</td>
</tr>
<tr class="odd">
<td>TC2</td>
<td><img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00030312152928782.png" alt="image-00030312152928782"></td>
<td>Liu,2020</td>
<td>Coastal, inversion based</td>
</tr>
<tr class="even">
<td>NIR-Red</td>
<td><img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00030312153111284.png" alt="image-00030312153111284"></td>
<td>Gons,2005</td>
<td>Cosatal</td>
</tr>
<tr class="odd">
<td>MDN</td>
<td>NN</td>
<td>Pahlevan 2020</td>
<td>Hyperspectral,Coastal</td>
</tr>
<tr class="even">
<td>OWT</td>
<td><img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00030312153858028.png" alt="image-00030312153858028"></td>
<td>Neil, 2019</td>
<td>Coastal</td>
</tr>
</tbody>
</table>
<p>There are a lot of Chla algorithm.</p>
<p>Possibly, it is almost out of date.</p>
<p>Just JO I think hhh.</p>
<h2 id="an-interesting-paper">An interesting paper</h2>
<p>Progressive scheme for blending empirical ocean color retrievals of absorption coefficient and chlorophyll concentration from open oceans to highly turbid waters</p>
<p>Former Classification scheme is based on value or shape. It is a hard transaction, not smoothly.</p>
<p>One way is use fuzzy c-mean, given隶属度(MD，这还是这么久了我第一次见到不会用英语的专业名词).But it is statistically based, don't have any implicit physics.</p>
<p>This is a paper have implicit physics.</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Chla Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第一周笔记 Machine Learning Foundation Week 1 Note in Cousera</title>
    <url>/posts/bc80cb40.html</url>
    <content><![CDATA[<p>An introduction for Machine learning</p>
<a id="more"></a>
<h1 id="what-is-machine-learning">What is machine learning</h1>
<h2 id="what-is-learning">What is learning</h2>
<p>learning: acquiring skill with experience accumulated from observations</p>
<p>machine learning: acquiring skill with experience accumulated/computed from data</p>
<p>skill: improve some performance measure(e.g.prediction accuracy)</p>
<h2 id="why-use-machine-learning">Why use machine learning</h2>
<ul>
<li>'define' trees and hand-program: difficult</li>
<li>learn from data(observations) and recognize: a 3-year-old can do so</li>
<li>'ML-based tree recognition system' can be easier to build than hand-programmed system</li>
</ul>
<p>ML: an alternative route to build complicated systems</p>
<h2 id="some-use-scenarios">Some Use Scenarios</h2>
<ul>
<li><p>when human cannot program the system manually</p>
<p>——navigation on Mars</p></li>
<li><p>when human cannot 'define the solution' easily</p>
<p>——speech/visual recognition</p></li>
<li><p>when needing rapid decisions that human cannot do</p>
<p>——high-frequency trading</p></li>
<li><p>when needing to be user-oriented in massive sacle</p>
<p>——consumer-targeted marketing</p></li>
</ul>
<h2 id="key-essence-of-ml">Key Essence of ML</h2>
<p>1. exists some 'underlying pattern' to be learned</p>
<p>——so 'performance measure' can be improved</p>
<p>2. but no programmable(easy) definition</p>
<p>——so 'ML' is needed</p>
<p>3. somehow there is data about the pattern</p>
<p>——so ML has some 'inputs' to learn from</p>
<p># Application of ML</p>
<h1 id="components-of-learning">Components of Learning:</h1>
<h2 id="basic-notations">Basic Notations</h2>
<ul>
<li><p>input: x $ $ <em>X</em></p></li>
<li><p>output: y $ $ <em>Y</em></p></li>
<li><p>unknow pattern to be learned $ $ target function: <em>f</em>: <em>X</em> $ $ <em>Y</em></p></li>
<li><p>data <span class="math inline">\(\Leftrightarrow\)</span> training examples: <span class="math inline">\(D =\{(x_1,y_1),(x_2.y_2),...,(x_n,y_n)\}\)</span></p></li>
<li><p>hypothesis <span class="math inline">\(\Leftrightarrow\)</span> skill with hopefully good performance :</p>
<p>$ g:X Y$</p></li>
</ul>
<h1 id="machine-learning-and-other-fields">Machine Learning and Other Fields</h1>
<h2 id="machine-learning-and-data-mining">Machine Learning and Data Mining</h2>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>Machine Learning</th>
<th>Data Mining</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>use data to compute hypothesis <em>g</em> that approximates target <em>f</em></td>
<td>use <strong>huge</strong> data to find <strong>property that</strong> is interesting</td>
</tr>
</tbody>
</table>
<ul>
<li><p>if 'interesting property' same as 'hypothesis' that approximate target——ML=DM</p></li>
<li><p>if 'interesting property' related to 'hypothesis ' that approximate target——DM can help ML,and vice versa(often,but not always)</p></li>
<li><p>traditional DM also focuses on efficient computation in large database</p></li>
</ul>
<h2 id="machine-learning-and-artificial-intelligence">Machine Learning and Artificial Intelligence</h2>
<table>
<colgroup>
<col style="width: 53%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Machine Learning</th>
<th>Artificial Intelligence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>use data to compute hypothesis <em>g</em> that approximates target <em>f</em></td>
<td>compute <strong>something that shows intelligent behavior</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>$ gf$ is something that shows intelligent behavior——ML can realize AI,among other routes</li>
<li>e.g. chess playing
<ul>
<li>traditional AI: game tree</li>
<li>ML for AI :learning from board data</li>
</ul></li>
</ul>
<p><strong>ML is one possible route to realize AI</strong></p>
<h2 id="machine-learning-and-statistics">Machine Learning and Statistics</h2>
<table>
<colgroup>
<col style="width: 52%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Machine Learning</th>
<th>Statistics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>use data to compute hypothesis <em>g</em> that approximates target <em>f</em></td>
<td>use data to <strong>make inference about an unknown process</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><em>g</em> is an inference outcome,<em>f</em> is something unknown——statistics <strong>can be used to achieve ML</strong></li>
<li>traditional statistics also focus on <strong>provable results with math assumptions</strong>,and care less about computation</li>
</ul>
<p><strong>statistics:many useful tools for ML</strong></p>
<h1 id="summary">Summary</h1>
<p>1. What is ML</p>
<p>-use data to approximate target</p>
<p>2. Application of ML</p>
<p>-alomost everywhere</p>
<p>3. Components of ML</p>
<p>-$ A$ takes <span class="math inline">\(D\)</span> and <span class="math inline">\(H\)</span> to get <span class="math inline">\(g\)</span></p>
<p>4. ML and other fields</p>
<p>-related to DM,AI and Stats</p>
<p># Appendix</p>
<p>預備知識</p>
<p>作業零 (機率統計、線性代數、微分之基本知識)</p>
<p>參考書籍</p>
<p>Learning from Data: A Short Course , Abu-Mostafa, Magdon-Ismail, Lin, 2013.</p>
<p>經典文獻</p>
<p>F. Rosenblatt. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, 65(6):386-408, 1958. (第二講：Perceptron 的出處)</p>
<p>W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58(301):13–30, 1963. (第四講：Hoeffding's Inequality)</p>
<p>Y. S. Abu-Mostafa, X. Song , A. Nicholson, M. Magdon-ismail. The bin model, 1995. (第四講：bin model 的出處)</p>
<p>V. Vapnik. The nature of statistical learning theory, 2nd edition, 2000. (第五到八講：VC dimension 與 VC bound 的完整數學推導及延伸)</p>
<p>Y. S. Abu-Mostafa. The Vapnik-Chervonenkis dimension: information versus complexity in learning. Neural Computation, 1(3):312-317, 1989. (第七講：VC Dimension 的概念與重要性)</p>
<p>參考文獻</p>
<p>A. Sadilek, S. Brennan, H. Kautz, and V. Silenzio. nEmesis: Which restaurants should you avoid today? First AAAI Conference on Human Computation and Crowdsourcing, 2013. (第一講：ML 在「食」的應用)</p>
<p>Y. S. Abu-Mostafa. Machines that think for themselves. Scientific American, 289(7):78-81, 2012. (第一講：ML 在「衣」的應用)</p>
<p>A. Tsanas, A. Xifara. Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools. Energy and Buildings, 49: 560-567, 2012. (第一講：ML 在「住」的應用)</p>
<p>J. Stallkamp, M. Schlipsing, J. Salmen, C. Igel. Introduction to the special issue on machine learning for traffic sign recognition. IEEE Transactions on Intelligent Transportation Systems 13(4): 1481-1483, 2012. (第一講：ML 在「行」的應用)</p>
<p>R. Bell, J. Bennett, Y. Koren, and C. Volinsky. The million dollar programming prize. IEEE Spectrum, 46(5):29-33, 2009. (第一講：Netflix 大賽)</p>
<p>S. I. Gallant. Perceptron-based learning algorithms. IEEE Transactions on Neural Networks, 1(2):179-191, 1990. (第二講：pocket 的出處，注意到實際的 pocket 演算法比我們介紹的要複雜)</p>
<p>R. Xu, D. Wunsch II. Survey of clustering algorithms. IEEE Transactions on Neural Networks 16(3), 645-678, 2005. (第三講：Clustering)</p>
<p>X. Zhu. Semi-supervised learning literature survey. University of Wisconsin Madison, 2008. (第三講：Semi-supervised)</p>
<p>Z. Ghahramani. Unsupervised learning. In Advanced Lectures in Machine Learning (MLSS ’03), pages 72–112, 2004. (第三講：Unsupervised)</p>
<p>L. Kaelbling, M. Littman, A. Moore. reinforcement learning: a survey. Journal of Artificial Intelligence Research, 4: 237-285. (第三講：Reinforcement)</p>
<p>A. Blum. On-Line algorithms in machine learning. Carnegie Mellon University,1998. (第三講：Online)</p>
<p>B. Settles. Active learning literature survey. University of Wisconsin Madison, 2010. (第三講：Active)</p>
<p>D. Wolpert. The lack of a priori distinctions between learning algorithms. Neural Computation, 8(7): 1341-1390. (第四講：No free lunch 的正式版)</p>
<p>T. M. Cover. Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition. IEEE Transactions on Electronic Computers, 14(3):326–334, 1965. (第五到六講：Growth Function)</p>
<p>B. Zadrozny, J. Langford, N. Abe. Cost sensitive learning by cost-proportionate example weighting. IEEE International Conference on Data Mining, 2003. (第八講：Weighted Classification)</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第三周笔记 Machine Learning Foundation Week 3 Note in Cousera</title>
    <url>/posts/4df973c2.html</url>
    <content><![CDATA[<p><strong>Types of Learning</strong></p>
<a id="more"></a>
<h1 id="learning-with-different-output-space">Learning with Different Output Space</h1>
<h2 id="credit-approval-problem-revisited">Credit Approval Problem Revisited</h2>
<h2 id="more-binary-classification-problems">More Binary Classification Problems</h2>
<h2 id="multiclass-classification-coin-recognition-problem">Multiclass Classification: Coin Recognition Problem</h2>
<h2 id="regression-patient-recovery-prediction-problem">Regression: Patient Recovery Prediction Problem</h2>
<h2 id="structured-learning-sequence-tagging-problem">Structured Learning: Sequence Tagging Problem</h2>
<h1 id="learning-with-different-data-label">Learning With Different Data Label</h1>
<h2 id="supervised-coin-recognition-revisited">Supervised: Coin Recognition Revisited</h2>
<p>##　Unsupervised: Coin Recognition without <span class="math inline">\(y_n\)</span></p>
<p>unsupervised multiclass classification <span class="math inline">\(\Leftrightarrow\)</span>‘Clustering’:a challenging but useful problem</p>
<h2 id="unsupervised-learning-without-y_n">Unsupervised: Learning without <span class="math inline">\(y_n\)</span></h2>
<ul>
<li>Clustering</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGVuc2l0eV9lc3RpbWF0aW9u">Density estimation<i class="fa fa-external-link-alt"></i></span></li>
<li>Outlier Detection</li>
</ul>
<h2 id="semi-supervisedcoin-recognition-with-some-y_n">Semi-supervised:Coin Recognition with Some <span class="math inline">\(y_n\)</span></h2>
<p>avoid expensive labeling</p>
<h2 id="reinforcement-learning">Reinforcement Learning</h2>
<h1 id="learning-with-different-protocol">Learning with Different Protocol</h1>
<h2 id="batch-learning">Batch Learning</h2>
<p>a very common protocol</p>
<h2 id="online-spam-filter-that-improves">Online: Spam Filter that ‘improves’</h2>
<h2 id="active-learning-learning-by-asking">Active Learning: Learning by ‘Asking’</h2>
<h1 id="learning-with-different-input-space">Learning with Different Input Space</h1>
<h2 id="concrete-features">Concrete Features</h2>
<p>human intelligence</p>
<h2 id="raw-features">Raw Features</h2>
<p>need human or machines to convert to concrete ones(feature engineering)</p>
<h2 id="abstract-features">Abstract Features</h2>
<p>again need feature conversion/extraction/construction</p>
<h1 id="summary">Summary</h1>
<ul>
<li>Learning with Different Output Space:classification,regression,structured</li>
<li>Learning with Different Data Label<span class="math inline">\(y_n\)</span>:supervised,un/semi-supervised,reinforecement</li>
<li>Learning with Different Protocol:batch,online,active</li>
<li>Learning with Different Input Space:concrete,raw,abstract</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第五周笔记-Machine-Learning-Foundation-Week-5-Note-in-Cousera</title>
    <url>/posts/fbd0b1b0.html</url>
    <content><![CDATA[<p><strong>Traning versus Testing</strong></p>
<p>Actually,I didn’t fully understand this part of course.However I don’t focus on the theory but application.</p>
<p>I will update this note if possible.</p>
<a id="more"></a>
<h1 id="recap-and-preview">Recap and Preview</h1>
<h2 id="recap-the-statistical-learning-flow">Recap: The ‘Statistical’ Learning Flow</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554528606498.png"></p>
<h2 id="two-central-questions">Two Central Questions</h2>
<p>1. can we make sure that <span class="math inline">\(E_{out}(g)\)</span> is close enough to <span class="math inline">\(E_{in}(g)\)</span>?</p>
<p>2. can we make <span class="math inline">\(E_{in}(g)\)</span> small enough?</p>
<p><span class="math inline">\(\Rightarrow\)</span> What role does <span class="math inline">\(\underbrace{M}\\{|\mathscr{H}|}\)</span> play for the two questions?</p>
<p>##　Trade-off on *M</p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>small M</th>
<th>large M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Yes <span class="math inline">\(\mathbb{P}[BAD]\leq2\cdot M\cdot exp(...)\)</span></td>
<td>1. No!<span class="math inline">\(\mathbb{P}[BAD]\leq2\cdot M\cdot exp(...)\)</span></td>
</tr>
<tr class="even">
<td>2. <span class="math inline">\(\color{Maroon}No!\)</span>,two few choices</td>
<td>2. Yes!many choices</td>
</tr>
</tbody>
</table>
<p>using the right M is important</p>
<h2 id="preview">Preview</h2>
<ul>
<li>Know: <span class="math inline">\(\mathbb{P}[|E_{in}(g)-E_{out}(g)|&gt;\epsilon]\leq 2 \cdot M\cdot exp(-2\epsilon^2N)\)</span></li>
<li>To do
<ul>
<li>establish a finite quantity that replaces M<span class="math inline">\(\mathbb{P}[|E_{in}(g)-E_{out}(g)|&gt;\epsilon]\leq 2 \cdot m_{\mathscr{H}}\cdot exp(-2\epsilon^2N)\)</span></li>
<li>justify the feasibility of learning for infinite M</li>
<li>study $m_{} <span class="math inline">\(to understand its trade-off for ‘right’\)</span>$,just like M</li>
</ul></li>
</ul>
<h1 id="effective-number-of-lines">Effective Number of Lines</h1>
<h2 id="where-did-m-come-from">Where Did <em>M</em> Come From</h2>
<p>The BAD event ：uniform bound fail<span class="math inline">\(\rightarrow\)</span> M<span class="math inline">\(\approx\infty\)</span></p>
<h2 id="where-did-uniform-bound-fail">Where Did Uniform Bound Fail</h2>
<p>overlapping for similar hypotheses</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509150052.png"></p>
<p>union bound over-estimating</p>
<p><strong>To acoount for overlap,can we group similar hypotheses by kind?</strong></p>
<h2 id="how-many-lines-are-there">How Many Lines Are There?</h2>
<p>In 2D,we can get smaller than <span class="math inline">\(2^N\)</span>lines</p>
<h2 id="effective-number-of-lines-1">Effective Number of Lines</h2>
<p>maximun kind of lines with respect to N inputs <span class="math inline">\(x_1\)</span>,<span class="math inline">\(x_2\)</span>,.....,<span class="math inline">\(x_N\)</span></p>
<p><span class="math inline">\(\iff\)</span>==effctive number of lines==</p>
<p>In 2D,the effective number of lines</p>
<ul>
<li><p>must be <span class="math inline">\(\leq 2^N\)</span></p></li>
<li><p>finite ‘grouping’ of infinitely-many lines <span class="math inline">\(\in H\)</span></p></li>
<li><p>wish:</p>
<p><span class="math inline">\(\mathbb{P}[|E_{in}(g)-E_{out}(g)|&gt;\epsilon]\leq 2 \cdot effctive(N)\cdot exp(-2\epsilon^2N)\)</span></p></li>
</ul>
<p>If</p>
<ol type="1">
<li><p>effective(N) can replace M and</p></li>
<li><p>effective(N) <span class="math inline">\(\ll 2^N\)</span></p>
<p>==learning possible with infinitie lines==</p></li>
</ol>
<h1 id="effective-number-of-hypotheses">Effective Number of Hypotheses</h1>
<h2 id="dichotomiesmini-hypotheses">Dichotomies:Mini-hypotheses</h2>
<h1 id="break-points">Break Points</h1>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第四周笔记-Machine-Learning-Foundation-Week-4-Note-in-Cousera</title>
    <url>/posts/c7f63b06.html</url>
    <content><![CDATA[<p><strong>Feasibility of Learning</strong></p>
<a id="more"></a>
<h1 id="learning-is-impossible">Learning is Impossible?</h1>
<h1 id="probability-to-the-rescue">Probability to the Rescue</h1>
<h2 id="inferring-something-unknow">Inferring Something Unknow</h2>
<p>in sample<span class="math inline">\(\rightarrow\)</span>out sample</p>
<h2 id="possible-versus-probable">Possible versus Probable</h2>
<h2 id="hoeffdings-inequality">Hoeffding’s Inequality</h2>
<p>In big sample(<em>N</em> large),<span class="math inline">\(\boldsymbol{\upsilon}\)</span> is probably close to <span class="math inline">\(\boldsymbol{u}\)</span> (within <span class="math inline">\(\boldsymbol{\epsilon}\)</span>) <span class="math display">\[
\mathbb{P}[|v-u|&gt;\boldsymbol{\epsilon}]\leq2exp(-2\boldsymbol{\epsilon}^2N)
\]</span> called Hoeffding’s Inequality, for marbles,coin,polling</p>
<p>the statement <span class="math inline">\(v=u\)</span> is <strong>probably approximately correct</strong>(PAC)</p>
<ul>
<li><p>valid for all N and <span class="math inline">\(\boldsymbol{\epsilon}\)</span></p></li>
<li><p>does not depend on <span class="math inline">\(u\)</span>,no need to know<span class="math inline">\(u\)</span></p></li>
<li><p>larger sample size <em>N</em> or looser gap <span class="math inline">\(\boldsymbol{\epsilon} \rightarrow\)</span>higher probability for <span class="math inline">\(v=u\)</span></p>
<p>if large N,can probably infer unknown <span class="math inline">\(u\)</span> by know <span class="math inline">\(v\)</span></p></li>
</ul>
<h1 id="connection-to-learning">Connection to Learning</h1>
<h2 id="added-components">Added Components</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/微信截图_20190404101452.png"></p>
<p>for any fixed <em>h</em>, can probably infer unkown <span class="math inline">\(E_out(h)=\underset{X\approx P}{\varepsilon}[h(x)\ne f(x)]\)</span>by known$ E_in(h)=^N_{n=1}[h(x)f(x)]$</p>
<h2 id="the-formal-guarantee">The Formal Guarantee</h2>
<p>if <span class="math inline">\(E_{in}(h)\approx E_{out}(h)\)</span> and$E_{in}(h)smallE_{out}(h)samllhf $with respect to P</p>
<h2 id="verification-of-one-h">Verification of One h</h2>
<p>if <span class="math inline">\(E_{in}(h)\)</span> small for the fixed h and A pick the h as g<span class="math inline">\(\rightarrow\)</span> g=f PAC</p>
<p>if A force to pick THE h as g<span class="math inline">\(\rightarrow E_{in}(h)\)</span> almost always not small<span class="math inline">\(\rightarrow g\ne f\)</span> PAC</p>
<p>real learning:</p>
<p>A shall make choices<span class="math inline">\(\in \H\)</span> (like PLA) rather than being forced to pick one h.</p>
<h2 id="the-verification-flow">The ‘Verification’ Flow</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554345523532.png"></p>
<h1 id="connection-to-real-learning">Connection to Real Learning</h1>
<h2 id="bad-sample-and-bad-data">BAD Sample and BAD Data</h2>
<p>BAD Sample:<span class="math inline">\(E_{out}=\frac{1}{2}\)</span>,but getting all heads(<span class="math inline">\(E_{in}=0\)</span>)</p>
<p>BAD Data for One h:<span class="math inline">\(E_{out}(h)\)</span> and <span class="math inline">\(E_{in}h\)</span> far away</p>
<h2 id="bad-data-for-many-h">BAD data for Many h</h2>
<p>BAD data for many h <span class="math inline">\(\Leftrightarrow\)</span> no freedom of choice by A <span class="math inline">\(\Leftrightarrow\)</span> there exists some h such that <span class="math inline">\(E_{out}(h)\)</span> and <span class="math inline">\(E_{in}(h)\)</span> far away</p>
<h2 id="bound-of-bad-data">Bound of BAD Data</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554349806026.png"></p>
<h2 id="the-statistical-learning-flow">The Statistical Learning Flow</h2>
<p>if <span class="math inline">\(|\mathbb{H}|\)</span>= M finite, N large enough,for whatever g picked by A,<span class="math inline">\(E_{out}(g)\approx E_{in}(g)\)</span></p>
<p>if A finds one g with <span class="math inline">\(E_{in}(g)\approx 0\)</span>,PAC guarantee for<span class="math inline">\(E_{out}(g)\Rightarrow\)</span>learning possible</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554350153964.png"></p>
<p>M=<span class="math inline">\(\infty\)</span>? - see you in the next lectures~</p>
<h1 id="吐槽">吐槽</h1>
<p>这个作业题是真的难啊，花了一个半小时才堪堪通过，尤其是最后几个写PLA和pocket算法的</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Data fusion series note 1</title>
    <url>/posts/bd7e58b0.html</url>
    <content><![CDATA[<p>There are five main data fusion approaches according to 'Spatio-temporal fusion for remote sensing data: an overview and new benchmark'. Here I will read the STARFM.</p>
<a id="more"></a>
<h1 id="weight-function-based-methods-starfm">Weight function-based methods: STARFM</h1>
<p>The spatial and temporal adaptive reflectance fusion model (STARFM) is the first weight function-based STF method developed in the literature. This method first assumes that all the pixels in the coarse images are pure. It uses a weighted strategy to add the reflectance changes between two coarse images to the prior fine image so as to predict the target image. STARFM has been shown to be able to capture phenological changes. However, its performance in highly heterogeneous landscapes and in the task of capturing land-cover changes is limited.</p>
<h2 id="data-requirement">Data Requirement</h2>
<p>(MODIS and Landsat)Their orbital parameters are equal, and as such the viewing (near-nadir) and solar geometries are close to those of the corresponding Landsat acquisition.</p>
<h2 id="performance">Performance</h2>
<p>The STARFM has been tested over forested areas, cropland regions, and heterogeneous mixtures of crop and forest. Results show that the STARFM can capture phenology changes precisely, although the accuracy depends on the characteristic patch size of the landscape.</p>
<h2 id="theoretical-basis">Theoretical Basis</h2>
<p>Assumptions</p>
<ol type="1">
<li>Neglecting geolocation errors and differences in atmospheric correction</li>
<li>MODIS surface reflectance <span class="math inline">\(M(x_i,y_j,t_k)\)</span> has been previously georeferenced and super sampled to the resolution and bounds of the Landsat surface reflectance image $L(x_i,y_j,t_k) $and thus shares the same image size, pixel size, and coordinate system.</li>
<li>if MODIS and Landsat surface reflectance are equal at a given time, then these values should be equal for the prediction date.</li>
<li>If the MODIS surface reflectance is constant over time, then the Landsat surface reflectance should not change as well.</li>
</ol>
<h3 id="basic-equations">Basic Equations</h3>
<p>Assumption 1</p>
<p>A heterogeneous coarse-resolution pixel at date <em>t</em> and surface reflectance (<span class="math inline">\(C_t\)</span>) can be aggregated from finer resolution homogeneous pixels of surface reflectance <span class="math inline">\(F^i_t\)</span> and percentage coverage <span class="math inline">\(A^i_t\)</span> according to <span class="math display">\[
C_t=\sum(F^i_t*A^i_t)\tag{1}
\]</span></p>
<p>where <span class="math inline">\(i\)</span> refers to the spatial index (location) of the fine- resolution pixel.</p>
<p>The key to finding an approximate solution is to find spectrally similar homogeneous neighboring pixels.</p>
<p>For a homogenous pixel at a coarser MODIS resolution, the surface reflectance measured by Landsat data can be ex- pressed as <span class="math display">\[
L(x_i,y_i,t_k)=M(x_i,y_i,t_i)+\varepsilon_k \tag{2}
\]</span> where <span class="math inline">\((x_i,y_j)\)</span> is a given pixel location for both Landsat and MODIS images, <span class="math inline">\(t_k\)</span> is the acquisition date for both MODIS and Landsat data, and <span class="math inline">\(ε_k\)</span> represents the difference between observed MODIS and Landsat surface reflectance (caused by differing bandwidth and solar geometry).</p>
<p>Assumption 2</p>
<p>Suppose we have n pairs input of $L(x_i,y_j,t_k) $and <span class="math inline">\(M(x_i,y_j,t_k)\)</span> and each pair is acquired on the same date, where <span class="math inline">\(k ∈ [1,n]\)</span>. The daily MODIS surface reflectance <span class="math inline">\(M(x_i,y_j,t_0)\)</span> at date <span class="math inline">\(t_0\)</span> is also a known value among inputs, then the predicted Landsat surface reflectance at date <span class="math inline">\(t_0\)</span> is <span class="math display">\[
L(x_i,y_j,t_0)= M(x_i,y_j,t_0)+ ε_0. \tag{3}
\]</span> Suppose the ground coverage type and system errors at pixel<span class="math inline">\((x_i,y_j)\)</span> does not change over prediction date <span class="math inline">\(t_0\)</span> and the date <span class="math inline">\(t_k\)</span>, we will have <span class="math inline">\(ε_0 = ε_k\)</span> and thus <span class="math display">\[
L(x_i,y_j,t_0)= M(x_i,y_j,t_0)+ L(x_i,y_j,t_k) −M(x_i,y_j,t_k).\tag{4}
\]</span> Such ideal situation cannot be satisfied from MODIS and Landsat observations. Their relationships are complicated by several factors:</p>
<ol type="1">
<li>MODIS observation is not a homogeneous pixel and may include mixed land-cover types when considered at Landsat spatial resolution</li>
<li>Land cover may change from one type to another type during the prediction period</li>
<li>Land-cover status (phenology) and solar geometry bidirectional reflectance distribution function (BRDF) changes will alter the reflectance from prediction date <span class="math inline">\(t_0\)</span> to date <span class="math inline">\(t_k\)</span>.</li>
</ol>
<p>By introducing additional information from neighboring pixels, we compute the surface reflectance for the central pixel at date t0 with a weighting function <span class="math display">\[
L (x_{w/2},y_{w/2},t_0) = \sum_{i=1}^{w} \sum_{j=1}^{w} \sum_{k=1}^{w}
W_{ijk}×(M(x_i,y_j,t_0)+ L(x_i,y_j,t_k) −M(x_i,y_j,t_k))\tag{5}
\]</span> where <span class="math inline">\(w\)</span> is the searching window size and <span class="math inline">\((x_{w/2},y_{w/2})\)</span> is the central pixel of this moving window.</p>
<p>To ensure that the right information from neighbor pixels is used, only spectrally similar (i.e., from the same spectral class) and cloud-free pixels from Landsat surface reflectance within the moving window are used to compute the reflectance.</p>
<p>The weight <span class="math inline">\(W_{ijk}\)</span> determines how much each neighboring pixel contributes to the estimated reflectance of the central pixel. It is very important and is determined by three measures as follows.</p>
<ol type="1">
<li><p>Spectral difference between MODIS and ETM+ data at a given location is <span class="math display">\[
S_{ijk} = |L(x_i,y_j,t_k) −M(x_i,y_j,t_k)| .\tag{6}
\]</span> A smaller value of <span class="math inline">\(S_{ijk}\)</span> implies that the fine spatial resolution pixel has closer spectral features to the averaged surrounding pixels; thus, the change at fine resolution should be comparable to that of the averaged surrounding pixels. Therefore, the pixel’s reflectance should be assigned a higher weight in (5).</p>
<p>A3</p></li>
<li><p>Temporal difference between the input and the predicted MODIS data is <span class="math display">\[
T_{ijk} = |M(x_i,y_j,t_k) −M(x_i,y_j,t_0)|\tag{7}
\]</span> This metric measures changes occurring between the prediction and the acquisition dates. A smaller <span class="math inline">\(T_{ijk}\)</span> means less vegetation change between time <span class="math inline">\(t_k\)</span> and <span class="math inline">\(t_0\)</span>; thus, the pixel should be assigned a higher weight.</p>
<p>A4</p>
<p>if changes are too subtle to be detected by the MODIS observation, this algorithm will not be able to predict any change when synthesizing the fine resolution imagery. Also, there may be situations where the STARFM algorithm cannot detect changes when two contradicting changes occur within a coarse-resolution pixel simultaneously and compensate for each other.</p></li>
<li><p>Location distance between central pixel <span class="math inline">\((x_{w/2},y_{w/2})\)</span> and candidate pixel <span class="math inline">\((x_i,y_j)\)</span> at date <span class="math inline">\(t_k\)</span> is <span class="math display">\[
d_{ijk} = \sqrt{(x_{w/2} − x_i )^2 + (y_{w/2} − y_j)^2}
\]</span> The spatial similarity is normally better for a closer pixel; thus, the closer candidate should be assigned a higher weight.</p></li>
</ol>
<h2 id="implementation-considerations">Implementation Considerations</h2>
<h3 id="how-to-weight-spatial-information">How to weight spatial information</h3>
<h4 id="spectrally-similar-neighbor-pixels">Spectrally Similar Neighbor Pixels</h4>
<p>The spectral similarity ensures that the correct spectral information is used from fine-resolution neighboring pixels: Unsupervised classification and using thresholds in surface reflectance directly. STARFM use the second approach.</p>
<p>"the purpose of the search process is to find pixels within the local moving window that are spectrally similar to the central pixel. Each central pixel becomes the center of the class, and the rules used to determine spectral similarity become local rules and thus vary from pixel to pixel. In contrast to the traditional classification, which applies the same classification rules over the whole region, our search process (second approach) will not be able to produce a unique classification map over the study area."</p>
<h4 id="combined-weighting-function">Combined Weighting Function</h4>
<p>Based one these assumptions:</p>
<ol type="1">
<li>coarse-resolution homogeneous pixels provide identical temporal changes as fine-resolution observations from the same spectral class</li>
<li>observations with less change from the prediction date provide better information for the prediction date</li>
<li>more proximal neighboring pixels normally provide better information for prediction.</li>
</ol>
<p>The final step is to combine these independent factors to create an ideal weight function that blends both temporal and spatial information</p>
<p>First, convert the actual distance to a relative distance through the function <span class="math display">\[
D_{ijk} =1.0+ d_{ijk}/A\tag{9}
\]</span> where <span class="math inline">\(A\)</span> is a constant that defines the relative importance of the spatial distance to the spectral and temporal distance.</p>
<p>The relative distance <span class="math inline">\(D_ijk\)</span> within searching area “<span class="math inline">\(w\)</span>” changes from 1to <span class="math inline">\([1 + (1/ \sqrt2) ∗ (w/A)]\)</span>. A smaller value of <span class="math inline">\(A\)</span> gives a larger dynamic range of <span class="math inline">\(D_{ijk}\)</span>.</p>
<p>The combined spectral, temporal, and spatial distance can be computed with <span class="math display">\[
C_{ijk} = S_{ijk} ∗ T_{ijk} ∗ D_{ijk}\tag{10}
\]</span> or in a logistic formula to make it less sensitive to the spectral differences <span class="math display">\[
C_{ijk} =ln(S_{ijk} ∗ B +1) ∗ ln(T_{ijk} ∗ B +1) ∗ D_{ijk}\tag{11}
\]</span> where <span class="math inline">\(B\)</span> is a scale factor (equal to 10 000 when using MODIS or LEDAPS reflectance products, which linearly scale reflectance from 0 to 10 000).</p>
<p>We use a normalized reverse distance as the weight function</p>
<p><span class="math display">\[
W_{ijk} =(1/C_{ijk}) /\sum_{i=1}^{w}\sum_{j=1}^{w}\sum_{k=1}^{n}(1/C_{ijk}).\tag{12}
\]</span></p>
<p>If the MODIS surface reflectance does not change, we have <span class="math inline">\(M(x_i,y_j,t_k)= M(x_i,y_j,t_0)\)</span>, then <span class="math inline">\(T_{ijk} =0\)</span> and <span class="math inline">\(C_{ijk} =0\)</span>, and weight <span class="math inline">\(W_{ijk}\)</span> is set to the maximum value. The predicted surface reflectance for central pixel of the moving window is then</p>
<p><span class="math display">\[
L (x_{w/2},y_{w/2},t_0) = M(x_i,y_j,t_0).
\]</span></p>
<p>This satisfies our other basic assumption: if MODIS and Landsat surface reflectance are equal at date <span class="math inline">\(t_k\)</span>, then they should be equal at date$ t_0$</p>
<h4 id="sample-filtering">Sample Filtering</h4>
<p>Additional filtering processes will then be applied to the candidates to remove poor- quality observations.</p>
<ol type="1">
<li><p>All poor-quality data are excluded from candidates according to the QA layer in the Landsat and MODIS surface reflectance products</p></li>
<li><p>Neighbor pixels are filtered out if they cannot provide better spectral and spatial information than the central pixel of the moving window</p>
<p>A good candidate should satisfy the following condition: <span class="math display">\[
S_{ijk} &lt; max (|L(x_{w/2},y_{w/2},t_k) −M(x_{w/2},y_{w/2},t_k)|)\tag{13}
\]</span> and <span class="math display">\[
T_{ijk} &lt; max(|M(x_{w/2},y_{w/2},t_k) −M(x_{w/2},y_{w/2},t_0)|) \tag{14}
\]</span></p></li>
</ol>
<p>Suppose we know that the uncertainties from Landsat and MODIS surface reflectance are <span class="math inline">\(\sigma_l\)</span> and <span class="math inline">\(\sigma_m\)</span>, respectively. All surface reflectance measurements are independent. The uncertainty for the spectral difference (6) between MODIS and ETM+ is <span class="math display">\[
\sigma_{lm} = \sqrt{\sigma_l^2+\sigma_m^2}
\]</span> The uncertainty for temporal difference (7) between two MODIS inputs is <span class="math display">\[
\sigma_{mm} = \sqrt{\sigma_m^2+\sigma_m^2}=\sqrt{2}*\sigma_m
\]</span> Considering the uncertainties in the candidate selection, (12)can be revised as</p>
<p><span class="math display">\[
S_{ijk}&lt; max(|{L(x_{w/2},y_{w/2},t_k)−M(x_{w/2},y_{w/2},t_k)}
+σ_{lm}\tag{15}
\]</span></p>
<p>and(13)can be revised as</p>
<p><span class="math display">\[
T_{ijk} &lt;max(|M(x_{w/2},y_{w/2},t_{k}−M(x_{w/2},y_{w/2},t_0) + \sigma_{mm}\tag{16}
\]</span></p>
<h2 id="following-methods">Following methods</h2>
<p>http://www.chen-lab.club/?page_id=11432</p>
<p>ESTARFM,IFSDAF</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Data Fusion</tag>
        <tag>Research Basis</tag>
        <tag>paper reading</tag>
      </tags>
  </entry>
  <entry>
    <title>How to follow the research progress in your field?</title>
    <url>/posts/eaba55e.html</url>
    <content><![CDATA[<p>This is the note of my own experiences.</p>
<p>As summarized in my former blog, the new result always from pre-print website, social media, conference. Here I will summary some source in oceanography, especially ocean color, and also give some methods for following new articles.</p>
<a id="more"></a>
<h1 id="social-media">Social media</h1>
<p>Actually it’s hard to follow academic in social media, because there are a lot of redundant information.</p>
<h2 id="official-account-for-journal-and-research-institute">Official account for journal and research institute</h2>
<p>This is a good way. A lot of famous journal has official account in social media. They even have local language version account. In this way we can get new big result quickly. Such kind of big paper is hard for me, but I think it is necessary for me.</p>
<p>Some research institute also has official account such as Plymouth. They will also share research progress in social media</p>
<h1 id="preprint">Preprint</h1>
<p>In oceanography or earth science, we have Earth ArXiv(https://eartharxiv.org/discover). But as the quality of paper varies a lot. I do not recommend following progress in this site. Maybe you can search some keywords monthly or just some time you are free.</p>
<h1 id="conference">Conference</h1>
<p>Here are some conference I think worthy attention. Although we always could not get full content from abstract, we can contact the author for further discussion.</p>
<ol type="1">
<li>AGU, EGU and JpGU annual meeting</li>
<li>International Ocean Color Science Meetinghttps://iocs.ioccg.org/</li>
<li>IEEE IGARSS</li>
<li>ISPRS</li>
<li>Ocean Optics Conference</li>
<li>Ocean Science Meeting</li>
<li>Pan Ocean Remote Sensing Conference</li>
<li>SPIE, Space, Satellites and Sustainability(http://www.spie.org/ss101call)</li>
</ol>
<p>You can also follow some in this websitehttps://ioccg.org/resources/workshops-and-conferences/</p>
<h1 id="journal-subscription">Journal Subscription</h1>
<p>Search “Journal name+subscribe”, you will find the way to subscribe new articles. If this journal publish new article, they will send a email to alert you.</p>
<p>Hear are the journal I think worthy subscription</p>
<ul>
<li>Remote sensing of Environment</li>
<li>Earth System Science Data</li>
<li>Limnology and Oceanography</li>
<li>Journal of Geophysical Research: Ocean</li>
<li>Geophysical Research Letters</li>
<li>Nature Climate Change</li>
<li>Nature Geoscience</li>
<li>PNAS</li>
<li>Science Advance</li>
<li>Plos one</li>
<li>Optical express</li>
<li>Applied Optics</li>
<li>Applied Optics</li>
<li>Global Change Biology</li>
<li>Fish and Fisheries</li>
<li>Fishery Oceanography</li>
<li>Deep Sea Research</li>
<li>Frontiers in Marine Science</li>
<li>Scientific Reports</li>
<li>Remote Sensing</li>
</ul>
<h1 id="google-scholar-and-researchgate">Google Scholar and ResearchGate</h1>
<p>You can search the scientists who have the similar interest with you in google scholar or ResearchGate, and you will get the alerts for their new articles.</p>
<p>You can also set key words alerts in google scholar.</p>
<p>This methods always could give you new research earlier compared with subscription.</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>JpGU-AGU Joint Meeting 2020 poster</title>
    <url>/posts/26d5d570.html</url>
    <content><![CDATA[<p>This year I attended the JpGU-AGU Joint Meeting 2020 and made a poster presentation.</p>
<p>https://confit.atlas.jp/guide/event/jpgu2020/subject/HTT15-P07/detail</p>
<a id="more"></a>
<h2 id="evaluation-and-comparison-of-karenia-mikimotoi-detection-in-the-seto-inland-sea-by-remote-sensing"><strong>Evaluation and comparison of <em>Karenia mikimotoi</em> detection in the Seto-Inland Sea by remote sensing</strong></h2>
<p>*<span class="exturl" data-url="aHR0cHM6Ly9jb25maXQuYXRsYXMuanAvZ3VpZGUvZXZlbnQvanBndTIwMjAvYXV0aG9yL0hUVDE1LVAwNy8wMzc5Njc=">Zhenjia Zhou<i class="fa fa-external-link-alt"></i></span>1, <span class="exturl" data-url="aHR0cHM6Ly9jb25maXQuYXRsYXMuanAvZ3VpZGUvZXZlbnQvanBndTIwMjAvYXV0aG9yL0hUVDE1LVAwNy8wMjUwMzY=">Joji Ishizaka<i class="fa fa-external-link-alt"></i></span>2 (1.GSES, Nagoya Univ., 2.ISEE, Nagoya Univ.)</p>
<p>Keywords:Seto-Inland Sea, Harmful Algae Blooms, Karenia mikimotoi, Remote Sensing</p>
<p>Harmful Algae Blooms (HABs) is a worldwide problem in coastal marine systems. Seto-Inland Sea is a semi-enclosed coastal area in Japan that suffered from HABs. Dinoflagellate <em>Karenia mikimotoi</em> is one of the most common species that form HABs in the Seto-Inland Sea. It could increase fish mortality, thereby causing economic losses for coastal aquaculture. A detection method based on the spectral difference in short wavelength was developed by limited field observation in the western part of the Seto-Inland Sea (Siswanto <em>et al.</em>, 2013). But the spectra in the short wavelength are always influenced by colored dissolved organic matters and non-algal particles as well as the error of atmospheric correction. Thus, it is necessary to evaluate the method with more filed observation data. Meanwhile, several methods for the detection of <em>Karenia brevis</em>, a HABs species belongs to the same genus and has similar optical properties with <em>Karenia mikimotoi</em>, were developed in the West Florida Shelf. These methods could be divided into chlorophyll-a based, apparent optical property based, inherent optical property based approach, etc. This research aims to compare results of different detection methods in the Seto-Inland Sea and evaluate them with the recent filed observation data.</p>
]]></content>
      <categories>
        <category>Papers And Thesis</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>International Conference</tag>
        <tag>Harmful Algae</tag>
        <tag>Poster</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter Lab</title>
    <url>/posts/c958af43.html</url>
    <content><![CDATA[<p>本菜鸡到现在也只能拿Jupyter写代码，但是原来的notebook因为我动不动就写个好几M的玩意越来越大越来越卡，所以我就换成Lab了。</p>
<p>这里讲一些用他的时候搞得一些配置啥的</p>
<a id="more"></a>
<h1 id="extension">Extension</h1>
<p>(开头黑人问号，我居然是在参照一个<span class="exturl" data-url="aHR0cHM6Ly9xaWl0YS5jb20vY2Fub25yb2NrMTYvaXRlbXMvZDE2NmM5MzA4N2E0YWFmZDJkYjQ=">日语的博客<i class="fa fa-external-link-alt"></i></span>来搞这个，居然找不到中文的)</p>
<p>安装Extension必须得安装NodeJS(黑人问号❓)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install -c conda-forge nodejs</span><br></pre></td></tr></table></figure>
<p>然后可以拿List看装了啥</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jupyter labextension list</span><br></pre></td></tr></table></figure>
<p>我主要装了<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21hcmt1c3NjaGFudGEvYXdlc29tZS1qdXB5dGVy">Awesome Jupyter<i class="fa fa-external-link-alt"></i></span>里面的几个，主要就是把它搞得跟原来的Notebook差不多就行，比如lsp,toc,drawio,latex,variableinspector。不在这里面的有<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Rlc2hhdy9qdXB5dGVybGFiLWV4ZWN1dGUtdGltZQ==">jupyterlab-execute-time<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2tpdGVjby9qdXB5dGVybGFiLWtpdGU=">jupyterlab-kite<i class="fa fa-external-link-alt"></i></span></p>
<p>最后来一句这个</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter lab build</span><br><span class="line">jupyter labextension <span class="built_in">enable</span> all</span><br></pre></td></tr></table></figure>
<p>或者在lab里的setting里手动开启extention</p>
<p>感觉不太方便的地方就是那个Variable inspector不能float</p>
<p>多说一句，纯路人，感觉kite没啥必要,lsp足够了</p>
<p>虽然但是，还是感觉notebook好用啊</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>MODIS OC data batch download</title>
    <url>/posts/8636bca2.html</url>
    <content><![CDATA[<p>This blog introduce a MODIS(also suitable for other available satellites) Ocean Color data batch download method without wget(since it doesn’t work on my laptop).</p>
<a id="more"></a>
<h2 id="requirement">Requirement</h2>
<p>1.Earthdata account</p>
<p>2.cygwim(https://www.cygwin.com/)</p>
<h2 id="step-by-step">Step by Step</h2>
<p>1.Login to Earthdata. Then enter <span class="exturl" data-url="aHR0cHM6Ly9zZWFyY2guZWFydGhkYXRhLm5hc2EuZ292L3NlYXJjaD9tPTAhLTAuMDcwMzEyNSEyITEhMCEwJTJDMiZhbXA7ZmRjPU9jZWFuJTIwQmlvbG9neSUyMERpc3RyaWJ1dGVkJTIwQWN0aXZlJTIwQXJjaGl2ZSUyMENlbnRlciUyMChPQi5EQUFDKSZhbXA7YWM9dHJ1ZQ==">https://search.earthdata.nasa.gov/search?m=0!-0.0703125!2!1!0!0%2C2&amp;fdc=Ocean%20Biology%20Distributed%20Active%20Archive%20Center%20(OB.DAAC)&amp;ac=true<i class="fa fa-external-link-alt"></i></span></p>
<p>2.Select desired satellite in the option ’Instruments’</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220141643.png"></p>
<p>3.Select desired region by spatial polygon, rectangular or coordinate.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220141833.png"></p>
<p>Then select desired product</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220142022.png"></p>
<p>4.Screen the data by granule filters</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220142153.png"></p>
<p>5.Click download all, then choose data access method and click download data in the end</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220142309.png"></p>
<p>6.Click download access script</p>
<p><img src="/posts/blog\source_posts\MODIS-L2-OC-batch-download\20200220142411.png"></p>
<p>download the script</p>
<figure>
<img src="/posts/blog\source_posts\MODIS-L2-OC-batch-download\1582176279212.png" alt="1582176279212"><figcaption aria-hidden="true">1582176279212</figcaption>
</figure>
<p>open cygwin in the same download folder</p>
<p>enter:</p>
<p><code>chmod 777 download.sh</code></p>
<p><code>./download.sh</code></p>
<p>Then enter your password. Waiting for the result.</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>Note in writing and presentation</title>
    <url>/posts/3da0aceb.html</url>
    <content><![CDATA[<a id="more"></a>
<h1 id="英语的标点符号">英语的标点符号</h1>
<p>(这部分来自于微博)</p>
<p>今天批改学生的学期作业，发现英文标点符号使用的错误仍未能杜绝。这些年来，在标点符号的使用上，对每一班的学生，特别是有写作内容的课程，都要求学生遵守英文的标点规范。但是，到了学期末，仍然有不少同学不能完全掌握。做英语学位论文时，标点符号的问题更突显。究其原因，其一，同学们对英文标点的知识还没有完全掌握，意识还有待加强；其二，电脑输入时，因为技术问题，也因为自己的“偷懒”，不能自觉转换英汉两种语言标点符号的使用。</p>
<p>标点符号的使用反映语言素养，虽是细节，意义重大——是书面表达是否presentable的重要鉴定标准之一。有时候，我会开玩笑地跟学生说，你的标点符号的使用，反映着你英语教育方面的breeding（也是老师没有尽到责任）。我也常跟学生说，以后投递简历、各类申请书时，你英文写作技术规范的表现，很可能是给雇主留下深刻印象的关键性因素。所谓细节决定成败，这是一个典型表现。</p>
<p>标点符号的使用属于英文写作mechanics范畴，相关书籍或章节的介绍很多，几乎所有英语写作教材中都能读到，很容易查找。我这里只提几处典型的错误，中国学生常常意识不到。</p>
<p>1、空格问题。英语的逗号、句号、分号、问号、叹号等标点（除了上引号和破折号）之后，都要空一个字符。中学时期，作文为手写，这一点不容易判断出来；上了大学，英文写作常需要完成电子稿时，却看到电子稿到处红线和绿线。标点使用的空格错误，电脑会自动标注为红线，可见其错误的严重性。这个问题在新生班里是普遍存在的。</p>
<p>2、行文中出现英语中没有的标点符号，最典型的是顿号、六个点的省略号（英语的省略号是三个点，在英文状态下输入三个点，自然生成）、汉语的破折号、书名号等。</p>
<p>3、英语和汉语的标点符号混用严重，例如逗号、引号、破折号等。首先确保汉语为全角状态；英语为半角状态。然后，选中英文部分，将字体变成英文字体；选中中文部分，将字体变为中文字体。这样，标点符号随之改变。也可以自己手动逐一修改——这个方法最可靠，因为全部选定进行转换的话，有可能波及到不需要转换的部分。</p>
<p>4、英文没有汉语的书名号（《》）。汉语中，所有的作品都可以用书名号，例如文章的题目用书名号，电影名字、乐章标题、书名、期刊杂志名等。英文的书名、期刊名用斜体（手写时，为了区分，用下划线）。但是文章题目不用书名号，用引号——这一点最容易错。</p>
<p>5、网络惹的祸——英语中使用汉语的书名号。英语中本来没有汉语的那种书名号（《》），但因很多网络格式中没有斜体，因此，有些汉语使用者就开始用自己的书名号框住英语的书名。这是错误用法，未来是否会因为使用人太多而被接受也未可知。但是目前，如果英语作文中出现这种用法就是硬伤了。</p>
<p>6、下载的材料未作规范处理，标点规范不统一，给人留下很坏的印象。标点符号暴露了你的“抄袭”行为。网上下载资料之后，没有经过统一处理，最明显的地方就是引号的不同规范。有些同学不明白，为什么老师一眼就看出来自己论文中“抄袭”的部分。很多时候，老师只要看看不一样的标点规范，（然后选取相关部分在网上进行搜索，甚至不需要搜索）便能判断出来了。这一点告诉我们，不同字体的标点符号长得不一样哈——在一项任务中统一很重要。除了了解这一点之外，也建议每位同学找到自己喜欢的、常用的字体。</p>
<p>7、破折号的输入方法是大家不熟悉的。首先要确定我们是在英文状态下输入，不要使用汉语的破折号。有些同学先输入一个汉语的破折号，然后再去掉一半儿，以此来充当英语的破折号。其实它们不同，你可以从符号空间上的高低位置判断出来（英文的低于中文的。在英文状态下，一个单词之后连续输入两个连字符，再接着输入其它或空格，英文的破折号就自然生成了。（英语的破折号使用其实更为复杂，因为有“n-dash”和“m-dash”之分，他们的使用场合也不全一样。）</p>
<p>8、冒号和破折号的使用。汉语标题之后如果有副标题，我们一般使用破折号；英语的副标题之前常用冒号，偶尔也会用破折号。两者有细微区别。</p>
<p>9、还有一个经常出现的标点问题，也可视为病句——run-on sentences。就是像汉语那样，用逗号连接很多小句。在这个方面，一个操作简便的基本规范是，英语中，一个句子一般只有一个主要动词；如果出现另一个主要动词，那要看是否以从句形式出现，是否有表示逻辑关系的连接词来连接，如果没有任何此类情况，那么一个完整句子包括一个主要动词。一句话结束了，就要使用句号。（这里不包括因为修辞需要而出现的特殊情况。）</p>
<p>10、最后，再提一个学位论文中常出现的标点问题。英文学位论文的参考文献的标点符号使用上，因为信息往往不以句子形式呈现，所以上面的规范不适合。同学们的主要问题除了上面提到的论文题目和书名、期刊名的标点错误之外，还表现在规范的不统一。这一点上，同学们需要清楚，不同的出版机构采用的规范不尽相同，每个学校的格式要求也不一样，大家要使用自己学校认可的那一种规范，并且要统一。不是你文献中看到的格式有错误，而是在特定环境中的一个统一的问题）。这一问题也常伴随着大小写规范的选择和统一问题</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>学术写作</tag>
        <tag>学术发表</tag>
      </tags>
  </entry>
  <entry>
    <title>Publishable plot using python&amp;R</title>
    <url>/posts/cd046c9b.html</url>
    <content><![CDATA[<p>这将会是一个长篇。</p>
<p>长到我也不知道要多久才能把他写完</p>
<p>天下人苦matplotlib已久</p>
<p>立个flag，这个月（2020年12月）结束它。</p>
<p>主要包括以下几个图的画法</p>
<ol type="1">
<li><p>站位图</p></li>
<li><p>海洋环境要素分布图</p></li>
<li><p>散点图</p></li>
<li><p>密度散点图</p></li>
<li><p>Bar</p></li>
<li><p>带CI的Lineplot</p>
<p>其中第一个会用R，后面的因为我需要在处理数据的时候直接调用，所以是python。</p>
<p>不过第二个我也在考虑把结果输出到nc文件后，用R来画。</p>
<p>还有这个我就懒得用中文了，因为主要是给自己用的代码备忘录。</p></li>
</ol>
<h1 id="散点图">散点图</h1>
<p>def wavelength_to_rgb(wavelength, gamma=0.8): ''' taken from http://www.noah.org/wiki/Wavelength_to_RGB_in_Python This converts a given wavelength of light to an approximate RGB color value. The wavelength must be given in nanometers in the range from 380 nm through 750 nm (789 THz through 400 THz).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wavelength_to_rgb</span>(<span class="params">wavelength, gamma=<span class="number">0.8</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; taken from http://www.noah.org/wiki/Wavelength_to_RGB_in_Python</span></span><br><span class="line"><span class="string">    This converts a given wavelength of light to an</span></span><br><span class="line"><span class="string">    approximate RGB color value. The wavelength must be given</span></span><br><span class="line"><span class="string">    in nanometers in the range from 380 nm through 750 nm</span></span><br><span class="line"><span class="string">    (789 THz through 400 THz).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Based on code by Dan Bruton</span></span><br><span class="line"><span class="string">    http://www.physics.sfasu.edu/astro/color/spectra.html</span></span><br><span class="line"><span class="string">    Additionally alpha value set to 0.5 outside range</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    wavelength = float(wavelength)</span><br><span class="line">    <span class="keyword">if</span> wavelength &gt;= <span class="number">380</span> <span class="keyword">and</span> wavelength &lt;= <span class="number">750</span>:</span><br><span class="line">        A = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        A = <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">if</span> wavelength &lt; <span class="number">380</span>:</span><br><span class="line">        wavelength = <span class="number">380.</span></span><br><span class="line">    <span class="keyword">if</span> wavelength &gt; <span class="number">750</span>:</span><br><span class="line">        wavelength = <span class="number">750.</span></span><br><span class="line">    <span class="keyword">if</span> wavelength &gt;= <span class="number">380</span> <span class="keyword">and</span> wavelength &lt;= <span class="number">440</span>:</span><br><span class="line">        attenuation = <span class="number">0.3</span> + <span class="number">0.7</span> * (wavelength - <span class="number">380</span>) / (<span class="number">440</span> - <span class="number">380</span>)</span><br><span class="line">        R = ((-(wavelength - <span class="number">440</span>) / (<span class="number">440</span> - <span class="number">380</span>)) * attenuation) ** gamma</span><br><span class="line">        G = <span class="number">0.0</span></span><br><span class="line">        B = (<span class="number">1.0</span> * attenuation) ** gamma</span><br><span class="line">    <span class="keyword">elif</span> wavelength &gt;= <span class="number">440</span> <span class="keyword">and</span> wavelength &lt;= <span class="number">490</span>:</span><br><span class="line">        R = <span class="number">0.0</span></span><br><span class="line">        G = ((wavelength - <span class="number">440</span>) / (<span class="number">490</span> - <span class="number">440</span>)) ** gamma</span><br><span class="line">        B = <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">elif</span> wavelength &gt;= <span class="number">490</span> <span class="keyword">and</span> wavelength &lt;= <span class="number">510</span>:</span><br><span class="line">        R = <span class="number">0.0</span></span><br><span class="line">        G = <span class="number">1.0</span></span><br><span class="line">        B = (-(wavelength - <span class="number">510</span>) / (<span class="number">510</span> - <span class="number">490</span>)) ** gamma</span><br><span class="line">    <span class="keyword">elif</span> wavelength &gt;= <span class="number">510</span> <span class="keyword">and</span> wavelength &lt;= <span class="number">580</span>:</span><br><span class="line">        R = ((wavelength - <span class="number">510</span>) / (<span class="number">580</span> - <span class="number">510</span>)) ** gamma</span><br><span class="line">        G = <span class="number">1.0</span></span><br><span class="line">        B = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">elif</span> wavelength &gt;= <span class="number">580</span> <span class="keyword">and</span> wavelength &lt;= <span class="number">645</span>:</span><br><span class="line">        R = <span class="number">1.0</span></span><br><span class="line">        G = (-(wavelength - <span class="number">645</span>) / (<span class="number">645</span> - <span class="number">580</span>)) ** gamma</span><br><span class="line">        B = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">elif</span> wavelength &gt;= <span class="number">645</span> <span class="keyword">and</span> wavelength &lt;= <span class="number">750</span>:</span><br><span class="line">        attenuation = <span class="number">0.3</span> + <span class="number">0.7</span> * (<span class="number">750</span> - wavelength) / (<span class="number">750</span> - <span class="number">645</span>)</span><br><span class="line">        R = (<span class="number">1.0</span> * attenuation) ** gamma</span><br><span class="line">        G = <span class="number">0.0</span></span><br><span class="line">        B = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        R = <span class="number">0.0</span></span><br><span class="line">        G = <span class="number">0.0</span></span><br><span class="line">        B = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">return</span> np.array([R, G, B, A]).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">single_color_scatter</span>(<span class="params">ax1, x, y, xlable: str, ylable: str, xlim: list = None, title: str = None, ylim: list = None , color: str = <span class="string">&#x27;k&#x27;</span>, </span>):</span></span><br><span class="line">  <span class="comment">##import packages</span></span><br><span class="line">  <span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">  <span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> mpl_patches</span><br><span class="line">  <span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">  <span class="comment"># from sklearn.metrics import mean_absolute_percentage_error</span></span><br><span class="line">  sns.set_style(<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">## do regression and get metrics</span></span><br><span class="line"></span><br><span class="line">  max_lim = np.max([np.max(x), np.max(y)])</span><br><span class="line">  min_lim = np.min([np.min(x), np.min(y)])</span><br><span class="line">  x_11 = np.linspace(min_lim, max_lim)</span><br><span class="line">  y_11 = x_11</span><br><span class="line">  N = len(x)</span><br><span class="line"></span><br><span class="line">  result = regress2(x.flatten(), y.flatten())</span><br><span class="line">  Slope = result[<span class="string">&#x27;slope&#x27;</span>]</span><br><span class="line">  Intercep = result[<span class="string">&#x27;intercept&#x27;</span>]</span><br><span class="line">  y_fit = Slope * x + Intercep</span><br><span class="line">  rmse = round(np.sqrt(mean_squared_error(x.flatten(), y.flatten())), <span class="number">5</span>)</span><br><span class="line">  r = round(result[<span class="string">&#x27;r&#x27;</span>], <span class="number">5</span>)</span><br><span class="line">  bias = (np.sum((y - x) / x)) / N</span><br><span class="line">  <span class="comment"># MAPE = round(mape(x.flatten(), y.flatten()), 5)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># start plot</span></span><br><span class="line">  line11, = ax1.plot(x_11, y_11, color=<span class="string">&#x27;k&#x27;</span>, linewidth=<span class="number">1.5</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&#x27;1:1 line&#x27;</span>, zorder=<span class="number">5</span>)</span><br><span class="line">  linefit, = ax1.plot(x, y_fit, color=<span class="string">&#x27;r&#x27;</span>, linewidth=<span class="number">2</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, label=<span class="string">&#x27;fitted line&#x27;</span>, zorder=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">  ax1.scatter(x, y, edgecolor=<span class="literal">None</span>, c=color, s=<span class="number">50</span>, marker=<span class="string">&#x27;s&#x27;</span>, facecolors=<span class="string">&quot;None&quot;</span>, zorder=<span class="number">3</span>)</span><br><span class="line">  fontdict1 = &#123;<span class="string">&quot;size&quot;</span>: <span class="number">30</span>,</span><br><span class="line">               <span class="string">&quot;color&quot;</span>: <span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;family&#x27;</span>: <span class="string">&#x27;Time New Roman&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">  ax1.set_xlabel(xlable, fontdict=fontdict1)</span><br><span class="line">  ax1.set_ylabel(ylable, fontdict=fontdict1)</span><br><span class="line">  ax1.grid(<span class="literal">False</span>)</span><br><span class="line">  l0 = ax1.legend(handles=[line11, linefit], loc=<span class="string">&#x27;lower right&#x27;</span>, prop=&#123;<span class="string">&quot;size&quot;</span>: <span class="number">25</span>&#125;)</span><br><span class="line">  <span class="comment"># set tick font</span></span><br><span class="line">  labels = ax1.get_xticklabels() + ax1.get_yticklabels()</span><br><span class="line">  [label.set_fontname(<span class="string">&#x27;Time New Roman&#x27;</span>) <span class="keyword">for</span> label <span class="keyword">in</span> labels]</span><br><span class="line">  <span class="keyword">for</span> spine <span class="keyword">in</span> [<span class="string">&#x27;top&#x27;</span>, <span class="string">&#x27;bottom&#x27;</span>, <span class="string">&#x27;left&#x27;</span>, <span class="string">&#x27;right&#x27;</span>]:</span><br><span class="line">      ax1.spines[spine].set_color(<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">  ax1.tick_params(left=<span class="literal">True</span>, bottom=<span class="literal">True</span>, direction=<span class="string">&#x27;in&#x27;</span>, labelsize=<span class="number">30</span>)</span><br><span class="line">  <span class="comment"># add title</span></span><br><span class="line">  titlefontdict = &#123;<span class="string">&quot;size&quot;</span>: <span class="number">40</span>,</span><br><span class="line">                   <span class="string">&quot;color&quot;</span>: <span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;family&#x27;</span>: <span class="string">&#x27;Time New Roman&#x27;</span>&#125;</span><br><span class="line">  ax1.set_title(title, titlefontdict, pad=<span class="number">20</span>)</span><br><span class="line">  <span class="comment"># ax.set_title()</span></span><br><span class="line">  h1fontdict = &#123;<span class="string">&quot;size&quot;</span>: <span class="number">25</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="string">&#x27;bold&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">  handles = [mpl_patches.Rectangle((<span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>, fc=<span class="string">&quot;white&quot;</span>, ec=<span class="string">&quot;white&quot;</span>,</span><br><span class="line">                                   lw=<span class="number">0</span>, alpha=<span class="number">0</span>)] * <span class="number">6</span></span><br><span class="line">  text = [<span class="string">r&#x27;$r:$&#x27;</span> + str(r),</span><br><span class="line">          <span class="string">r&#x27;$RMSE:$&#x27;</span> + str(rmse),</span><br><span class="line">          <span class="string">r&#x27;$Slope:$&#x27;</span> + str(round(Slope, <span class="number">3</span>)),</span><br><span class="line">          <span class="string">r&#x27;$Intercept:$&#x27;</span> + str(round(Intercep, <span class="number">3</span>)),</span><br><span class="line">          <span class="string">r&#x27;$Bias:$&#x27;</span> + str(round(<span class="number">100</span> * bias, <span class="number">3</span>)) + <span class="string">&#x27;%&#x27;</span>,</span><br><span class="line">          <span class="string">r&#x27;$N:$&#x27;</span> + str(N)]</span><br><span class="line">  <span class="comment"># text.append(r&#x27;$R^2=$&#x27;+str(round(r1,3)),fontdict=fontdict)</span></span><br><span class="line">  <span class="comment"># text.append(&quot;RMSE=&quot;+str(rmse),fontdict=fontdict)</span></span><br><span class="line">  <span class="comment"># text.append(r&#x27;$y=$&#x27;+str(round(A1,3))+&#x27;$x$&#x27;+&quot; + &quot;+str(round(B1,3)),fontdict=fontdict)</span></span><br><span class="line">  <span class="comment"># text.append(r&#x27;$N=$&#x27;+ str(N),fontdict=fontdict)</span></span><br><span class="line">  l1 = ax1.legend(handles, text, loc=<span class="string">&#x27;upper left&#x27;</span>, fancybox=<span class="literal">True</span>, framealpha=<span class="number">0</span>, prop=h1fontdict)</span><br><span class="line"></span><br><span class="line">  h2text_font = &#123;<span class="string">&#x27;size&#x27;</span>: <span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="string">&#x27;medium&#x27;</span>&#125;</span><br><span class="line">  label_font = &#123;<span class="string">&#x27;size&#x27;</span>: <span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="string">&#x27;medium&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">  orderhand = [mpl_patches.Rectangle((<span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>, fc=<span class="string">&quot;white&quot;</span>, ec=<span class="string">&quot;white&quot;</span>,</span><br><span class="line">                                     lw=<span class="number">0</span>, alpha=<span class="number">0</span>)]</span><br><span class="line">  <span class="comment">#     text2 = [order]</span></span><br><span class="line">  <span class="comment">#     l2 = ax1.legend(orderhand, text2, loc=&#x27;upper right&#x27;, fancybox=True, framealpha=0,prop=h2text_font)</span></span><br><span class="line">  <span class="comment"># ax.text(.7,.25,s=&#x27;Within EE = &#x27; + &#x27;&#123;:.0%&#125;&#x27;.format(bottom_top_counts/all_data),transform = ax.transAxes,</span></span><br><span class="line">  <span class="comment">#         ha=&#x27;left&#x27;, va=&#x27;center&#x27;,fontdict=text_font)</span></span><br><span class="line">  <span class="comment"># ax.text(.7,.18,s=&#x27;Above EE = &#x27; + &#x27;&#123;:.0%&#125;&#x27;.format(top_counts/all_data),transform = ax.transAxes,</span></span><br><span class="line">  <span class="comment">#         ha=&#x27;left&#x27;, va=&#x27;center&#x27;,fontdict=text_font)</span></span><br><span class="line">  <span class="comment"># ax.text(.7,.11,s=&#x27;Below EE = &#x27; + &#x27;&#123;:.0%&#125;&#x27;.format(bottom_counts/all_data),transform = ax.transAxes,</span></span><br><span class="line">  <span class="comment">#         ha=&#x27;left&#x27;, va=&#x27;center&#x27;,fontdict=text_font)</span></span><br><span class="line">  ax1.add_artist(l1)</span><br><span class="line">  <span class="comment">#     ax1.add_artist(l2)</span></span><br><span class="line">  ax1.add_artist(l0)</span><br><span class="line">  <span class="keyword">if</span> xlim <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      ax1.set_xlim(xlim)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      ax1.set_xlim(min_lim, max_lim)</span><br><span class="line">  <span class="keyword">if</span> ylim <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      ax1.set_ylim(ylim)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      ax1.set_ylim(min_lim, max_lim)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title>IOP inversion</title>
    <url>/posts/f5ee8139.html</url>
    <content><![CDATA[<p>This note is based on Lee 1998,1999,2002 and P. Werdell 2013</p>
<a id="more"></a>
<h1 id="qaa">QAA</h1>
<h2 id="the-reason-for-failure-of-qaa">The reason for failure of QAA</h2>
<p>After one year I found that I haven't finish the note. I will try to finish this.</p>
<p>But before that I think I found the reason for the failure of QAA</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021118142948938.png" alt="image-00021118142948938"><figcaption aria-hidden="true">image-00021118142948938</figcaption>
</figure>
<p>Address: http://www.ioccg.org/groups/Software_OCA/QAA_v6_2014209.pdf</p>
<p>This is the whole process of QAA v6. Compared with the former one, the main update is in step2.</p>
<p>This is because in the first version, in the oligotrophic water, the <span class="math inline">\(a_{ph}\)</span> is very low. Meanwhile the <span class="math inline">\(a_{CDOM}\)</span> has a very influence in the <span class="math inline">\(a_{total}\)</span> at 55xnm. So the <span class="math inline">\(a_{total}\)</span> is mainly determined by <span class="math inline">\(a_w\)</span>. As a result, lee used an emprical relationship from <span class="math inline">\(r_{rs}\)</span> to estimated <span class="math inline">\(a_{total}(55x)\)</span>. But in the coastal area, the <span class="math inline">\(a_{total}\)</span> is dominated other constituents besides water, it make a lot of difference. It is also the reason that the update mainly happened in step2.</p>
<h2 id="nir-base-qaa">NIR base QAA</h2>
<p>Some recent research use NIR wavelength for the step 2 as the non-water absorption at NIR is low.</p>
<p>Here is the 'A blended inherent optical property algorithm for global satellite ocean color observations'.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021210194200562.png" alt="image-00021210194200562"><figcaption aria-hidden="true">image-00021210194200562</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021210194014638.png" alt="image-00021210194014638"><figcaption aria-hidden="true">image-00021210194014638</figcaption>
</figure>
<p>Another two is in Taihu.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021210194504447.png" alt="image-00021210194504447"><figcaption aria-hidden="true">image-00021210194504447</figcaption>
</figure>
<figure>
<img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00021210194529712.png" alt="image-00021210194529712"><figcaption aria-hidden="true">image-00021210194529712</figcaption>
</figure>
<p>QAA-750 is somewhat almost same with NIR-QAA, but QAA750-ap found that in Taihu, the ap750 sometime is still can't negletable.</p>
<p>We don't have ap763, I hope we can have that dataset later.</p>
<h1 id="giop">GIOP</h1>
<p>This is another commly used Semi-analytical algorithm for IOP inversion.</p>
<p>This is the default algorithm of NASA IOP product</p>
<h2 id="introduction">Introduction</h2>
<ul>
<li>SAA always differentiations only in the assumputions employed to define the eigenvectors and in the mathematical methods applied to calculate the eigenvalues</li>
<li>GIOP allows construction of different IOP models at runtime by selection from a wide assort-ment of published absorption and backscattering eigenvectors.</li>
</ul>
<h2 id="method">Method</h2>
<h3 id="model-development">Model Development</h3>
<p>Lee et al 2002, Rrs to rrs <span class="math display">\[
r_{rs}(\lambda,0^-)=\frac{R_{rs}(\lambda)}{0.52+1.7R_{rs}(\lambda)}
\]</span> rrs to IOP <span class="math display">\[
r_{rs}(\lambda,0^-)=G_1(\lambda)u(\lambda)+G_2(\lambda)u(\lambda)^2
\]</span></p>
<p><span class="math display">\[
u(\lambda)=\frac{b_b{(\lambda)}}{a(\lambda)+b_b(\lambda)}
\]</span></p>
<p>Common methods for estimating G?λ? include Gordon et al. [21], where G1 and G2 are spectrally fixed to 0.0949 and 0.0794 (see [7,23] for alternative coefficients), and the tabulated results ofMorel et al. [22], where G1 is estimated using solar and sensor geometries and an estimate of algal bio- mass and G2 is set to 0. GIOP supports all of these options.</p>
<p>IOP decomposition</p>
<p>each component can be expressed as the product of its concentration-specific absorption spectrum (eigenvector; a?) and its concentration or amplitude (eigenvalue; A): <span class="math display">\[
a(\lambda)=a_w(\lambda)+\sum_{i=1}^{N}A_{ph}a_{ph}^{*}(\lambda)+\sum_{i=1}^{N}A_{d}a_{d}^{*}(\lambda)+\sum_{i=1}^{N}A_{g}a_{g}^{*}(\lambda)
\]</span> Both <span class="math inline">\(a_{d}^*(\lambda)\)</span> and <span class="math inline">\(a_g^*(λ)\)</span> are commonly expressed as <span class="math display">\[
a_{d,g}^*(\lambda)=exp(-S_{d,g}\lambda)
\]</span> where Sd and Sg typically vary between 0.01 and 0.02 nm−1 in natural waters [24].</p>
<p>As the spectral shapes of NAP and CDOM absorption differ only in their exponential slopes, the two components are typically combined for satellite applications and Eq. (4) becomes</p>
<p><span class="math display">\[
a(\lambda)=a_w(\lambda)+\sum_{i=1}^{N}A_{ph}a_{ph}^{*}(\lambda)+\sum_{i=1}^{N}A_{dg}a_{dg}^{*}(\lambda)
\]</span> For total backscattering <span class="math display">\[
b_b(\lambda)=b_{bw}({\lambda})+\sum_{i=1}^NB_{bp}b_{bp}(\lambda)
\]</span> Bbp provides the eigenvalue and a power function often represents the eigenvector: <span class="math display">\[
b_{bp}^*(\lambda)=\lambda^{S_{bp}}
\]</span> where Sbp typically varies between −2 and 0 from small to large particles.</p>
<p>While commonly employed in the remote-sensing paradigm, we acknowledge the validity of the power function for b? bpλ remains debatable [25–27].</p>
<p>Using Rrsλ and eigenvectors as input, eigenvalues for absorption (A) and backscattering (B) can be estimated via linear or nonlinear least squares inversion of Eqs. (1)–(3).</p>
<p>Note that this model describes each component of absorption and back- scattering as a linear sum of subcomponents, presumably with unique spectral dependencies [sym- bolized by the summation over N in Eqs. (4), (6), and (7)]. In this way, the absorption characteristics for different phytoplankton populations and the scatter- ing characteristics of multiple size distributions of suspended particles can be represented, or Eq. (6) can be re-expanded to Eq. (4).</p>
<h3 id="model-configuration">Model configuration</h3>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021124160320671.png" alt="image-00021124160320671"><figcaption aria-hidden="true">image-00021124160320671</figcaption>
</figure>
<p>Here explained the default configuration of GIOP.</p>
<ol type="1">
<li></li>
</ol>
<h2 id="code">Code</h2>
<p>I think code is more visble for me</p>
<p>I skip the former part</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">GIOP ocean color reflectance inversion model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">P.J. Werdell and 18 co-authors, &quot;Generalized ocean color</span></span><br><span class="line"><span class="string">inversion model for retrieving marine inherent optical</span></span><br><span class="line"><span class="string">properties,&quot; Appl. Opt. 52, 2019-2037 (2013).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">GIOP is an ocean reflectance inversion model that</span></span><br><span class="line"><span class="string">can be configured at run-time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Requires equally-sized vectors of wavelength and Rrs</span></span><br><span class="line"><span class="string">plus an estimate of chlorophyll; all other parameterizations</span></span><br><span class="line"><span class="string">are controlled by the structure &#x27;gopt&#x27;, described below</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Processing comments:</span></span><br><span class="line"><span class="string">- defaults to GIOP-DC configuration</span></span><br><span class="line"><span class="string">- currently requires 412, 443, and 547/555 nm to be present</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Outputs are a vector of the magnitudes of the eigenvalues</span></span><br><span class="line"><span class="string">for adg, bbp, and aph (x), plus modeled spectra of apg,</span></span><br><span class="line"><span class="string">aph, adg, bbp, and Rrs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Rewritten in python via:</span></span><br><span class="line"><span class="string">- C implementation (B. Franz, 2008) (https://oceancolor.gsfc.nasa.gov/docs/ocssw/giop_8c_source.html)</span></span><br><span class="line"><span class="string">- Matlab implementation (J. Werdell, 2013)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Brandon Smith, NASA Goddard Space Flight Center, April 2018</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> MDN.Benchmarks.chl.OC.model <span class="keyword">import</span> model3 <span class="keyword">as</span> OC3</span><br><span class="line"><span class="keyword">from</span> MDN.Benchmarks.utils <span class="keyword">import</span> get_required, optimize, loadtxt, to_rrs</span><br><span class="line"><span class="keyword">from</span> MDN.Benchmarks.meta <span class="keyword">import</span> (</span><br><span class="line">    h0, h1, h2,</span><br><span class="line">    g0_Gordon <span class="keyword">as</span> g0,</span><br><span class="line">    g1_Gordon <span class="keyword">as</span> g1,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> CubicSpline <span class="keyword">as</span> Interpolate</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define any optimizable parameters</span></span><br><span class="line"><span class="meta">@optimize([])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span>(<span class="params">Rrs, wavelengths, sensor, *args, independent=True, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  With independent=False, there is a dependency between sample</span></span><br><span class="line"><span class="string">  estimations - meaning the estimated parameters can vary wildly</span></span><br><span class="line"><span class="string">    depending on which samples are passed in.</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bricaud</span>(<span class="params">chl, wavelengths</span>):</span></span><br><span class="line">      data = loadtxt(<span class="string">&#x27;../IOP/bricaud_1998_aph.txt&#x27;</span>)</span><br><span class="line">      aphs = (data[:, <span class="number">3</span>] * chl ** (data[:, <span class="number">4</span>] - <span class="number">1</span>)).T</span><br><span class="line">      aphs *= <span class="number">0.055</span> / aphs[data[:, <span class="number">0</span>] == <span class="number">442</span>]</span><br><span class="line">      <span class="keyword">return</span> Interpolate(data[:, <span class="number">0</span>], aphs)(wavelengths).T</span><br><span class="line"></span><br><span class="line">  wavelengths = np.array(wavelengths)</span><br><span class="line">  required = [<span class="number">443</span>, <span class="number">555</span>]</span><br><span class="line">  tol = kwargs.get(<span class="string">&#x27;tol&#x27;</span>, <span class="number">9</span>)  <span class="comment"># allowable difference from the required wavelengths</span></span><br><span class="line">  Rrs = get_required(Rrs, wavelengths, required, tol)</span><br><span class="line"></span><br><span class="line">  aw = Interpolate(*loadtxt(<span class="string">&#x27;../IOP/optics_coef.txt&#x27;</span>, <span class="string">&#x27; &#x27;</span>)[:, :<span class="number">2</span>].T)(wavelengths)</span><br><span class="line">  bbw = <span class="number">0.0038</span> * (<span class="number">400</span> / wavelengths) ** <span class="number">4.32</span></span><br><span class="line">  chl = OC3(Rrs(<span class="literal">None</span>), wavelengths, sensor).flatten()[:, <span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">  rrs = get_required(to_rrs(Rrs(<span class="literal">None</span>)), wavelengths, required, tol)</span><br><span class="line">  eta = <span class="number">2</span> * (<span class="number">1</span> - <span class="number">1.2</span> * np.exp(<span class="number">-0.9</span> * rrs(<span class="number">443</span>) / rrs(<span class="number">555</span>)))</span><br><span class="line">  sdg = <span class="number">0.018</span></span><br><span class="line"></span><br><span class="line">  aph = bricaud(chl, wavelengths)</span><br><span class="line">  bbp = (<span class="number">443</span> / wavelengths) ** eta</span><br><span class="line">  adg = np.exp(-sdg * (wavelengths - <span class="number">443</span>))</span><br><span class="line">  rrs = rrs(<span class="literal">None</span>)</span><br><span class="line"><span class="comment">## 前面的部分都是给这个优化设置初始值</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">assert</span> (len(rrs) == len(chl) == len(bbp) == len(aph)), \</span><br><span class="line">      [rrs.shape, chl.shape, bbp.shape, aph.shape]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> independent:</span><br><span class="line">      aph = aph[:, <span class="literal">None</span>]</span><br><span class="line">      bbp = bbp[:, <span class="literal">None</span>]</span><br><span class="line">      rrs = rrs[:, <span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">  results = []</span><br><span class="line">  <span class="keyword">for</span> _aph, _bbp, _rrs, _chl <span class="keyword">in</span> zip(aph, bbp, rrs, chl):</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Function minimization</span></span><br><span class="line">      <span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">          <span class="function"><span class="keyword">def</span> <span class="title">cost_func</span>(<span class="params">guess</span>):</span></span><br><span class="line">              guess = np.array(guess).reshape((<span class="number">3</span>, <span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">              atot = aw + _aph * guess[<span class="number">2</span>] + adg * guess[<span class="number">0</span>]</span><br><span class="line">              bbtot = bbw + _bbp * guess[<span class="number">1</span>]</span><br><span class="line">              u = bbtot / (atot + bbtot)</span><br><span class="line">              rmod = g0 * u + g1 * u ** <span class="number">2</span></span><br><span class="line">              cost = np.sum((_rrs - rmod) ** <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># Sum over bands</span></span><br><span class="line"></span><br><span class="line">              <span class="keyword">return</span> cost.mean()  <span class="comment"># Average over samples</span></span><br><span class="line"><span class="comment"># 然后这里是通过一个优化的方式来得到最终确定的参数的，这个是cost function</span></span><br><span class="line">          init = [[<span class="number">0.01</span>] * len(_chl), [<span class="number">0.001</span>] * len(_chl), _chl]</span><br><span class="line">          res = minimize(cost_func, init, tol=<span class="number">1e-6</span>, options=&#123;<span class="string">&#x27;maxiter&#x27;</span>: <span class="number">1e3</span>&#125;, method=<span class="string">&#x27;BFGS&#x27;</span>)</span><br><span class="line">          <span class="comment"># res  = minimize(cost_func, init, tol=1e-6, options=&#123;&#x27;maxiter&#x27;:1e3&#125;, method=&#x27;SLSQP&#x27;, bounds=[(0, 1e3)]*len(init))</span></span><br><span class="line">          <span class="comment"># res  = minimize(cost_func, init, tol=1e-10, options=&#123;&#x27;maxiter&#x27;:1e5&#125;, method=&#x27;SLSQP&#x27;)</span></span><br><span class="line">          x = np.array(res.x).reshape((<span class="number">3</span>, <span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment">#求解的方式是Linear Matrix inversion</span></span><br><span class="line">      <span class="comment"># Linear matrix inversion</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          q = (-g0 + (g0 ** <span class="number">2</span> + <span class="number">4</span> * g1 * _rrs) ** <span class="number">0.5</span>) / (<span class="number">2</span> * g1)</span><br><span class="line">          b = (bbw * (<span class="number">1</span> - q) - aw * q).T</span><br><span class="line">          Z = np.vstack([np.atleast_2d(adg) * q, np.atleast_2d(_bbp) * (q - <span class="number">1</span>), np.atleast_2d(_aph) * q]).T</span><br><span class="line">          Q, R = np.linalg.qr(Z)</span><br><span class="line">          x = np.linalg.lstsq(R, np.linalg.lstsq(R.T, np.dot(Z.T, b))[<span class="number">0</span>])[<span class="number">0</span>]</span><br><span class="line">          r = b - np.dot(Z, x)</span><br><span class="line">          err = np.linalg.lstsq(R, np.linalg.lstsq(R.T, np.dot(Z.T, r))[<span class="number">0</span>])[<span class="number">0</span>]</span><br><span class="line">          x = (x + err).flatten().reshape((<span class="number">3</span>, <span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">      madg = x[<span class="number">0</span>] * adg</span><br><span class="line">      mbbp = x[<span class="number">1</span>] * _bbp</span><br><span class="line">      maph = x[<span class="number">2</span>] * _aph</span><br><span class="line">      mchl = x[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">      mapg = madg + maph</span><br><span class="line">      moda = aw + mapg</span><br><span class="line">      modb = bbw + mbbp</span><br><span class="line">      modx = modb / (modb + moda)</span><br><span class="line">      mrrs = g0 * modx + g1 * modx ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">      results.append([mchl, mbbp, madg, maph, mapg, moda, modb])</span><br><span class="line">  <span class="keyword">return</span> dict(zip([<span class="string">&#x27;chl&#x27;</span>, <span class="string">&#x27;bbp&#x27;</span>, <span class="string">&#x27;adg&#x27;</span>, <span class="string">&#x27;aph&#x27;</span>, <span class="string">&#x27;apg&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], map(np.vstack, zip(*results))))</span><br></pre></td></tr></table></figure>
<h1 id="evaluating-semi-analytical-algorithms-for-estimating-inherent-optical-properties-in-the-south-china-sea">Evaluating semi-analytical algorithms for estimating inherent optical properties in the South China Sea</h1>
<p>这是一篇比较新也比较系统的评价文章，同时他们还做了match up和QA score</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/getImage.cfm" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>这是No-water absorption的结果</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/Screen%20Shot%200002-12-17%20at%2011.49.14.png" alt="Screen Shot 0002-12-17 at 11.49.14"><figcaption aria-hidden="true">Screen Shot 0002-12-17 at 11.49.14</figcaption>
</figure>
<p>可看出来这俩几乎差不多</p>
<p>这是aph的结果</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/getImage-00021217115028689.cfm" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021217115108762.png" alt="image-00021217115108762"><figcaption aria-hidden="true">image-00021217115108762</figcaption>
</figure>
<p>GIOP表现的会比 QAA在Mesotrophic好一些</p>
<p>bbp</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021217115248284.png" alt="image-00021217115248284"><figcaption aria-hidden="true">image-00021217115248284</figcaption>
</figure>
<p>反而是QAA</p>
<p>总而言之 他们发现没有特别大的区别</p>
<p>反而GIOP的Chla-aph关系式最好进行重新参数化</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
        <tag>paper reading</tag>
      </tags>
  </entry>
  <entry>
    <title>Scipy optimize</title>
    <url>/posts/7decea87.html</url>
    <content><![CDATA[<p>主要是几个常用的</p>
<p>minimize</p>
<p>Least_square</p>
<p>nnls</p>
<p>Lsq_linear</p>
<p>Curve_fit</p>
<p>另外附带一个numpy.linalg.lstsq</p>
<p>另外我发现了一个非常及乖的东西，一般都得x作为func的第一个参数才能拟合好</p>
<a id="more"></a>
<h1 id="minimize">minimize</h1>
<p>这个主要是用来代替matlab中的fminunc</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scipy.optimize.minimize(fun, x0, args=(), method=<span class="literal">None</span>, jac=<span class="literal">None</span>, hess=<span class="literal">None</span>, hessp=<span class="literal">None</span>, bounds=<span class="literal">None</span>, constraints=(), tol=<span class="literal">None</span>, callback=<span class="literal">None</span>, options=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>fun就是要去最小化的cost func，对cost func的要求是</p>
<blockquote>
<p>fun:callable</p>
<p>The objective function to be minimized.</p>
<p>fun(x, *args) -&gt; float</p>
<p>where x is an 1-D array with shape (n,) and args is a tuple of the fixed parameters needed to completely specify the function.</p>
</blockquote>
<p>x0是初始化的参数，也就是常说的initial guess. Array of real elements of size (n,), where ‘n’ is the number of independent variables.</p>
<p>method：该参数代表采用的方式，默认是<code>BFGS</code>, <code>L-BFGS-B</code>, <code>SLSQP</code>中的一种，可选<code>TNC</code>,</p>
<p>jac是用来计算梯度的方法，这个大多数时候可以忽略，也就是雅各比矩阵</p>
<p>options：用来控制最大的迭代次数，以字典的形式来进行设置，例如：options={‘maxiter’:400}</p>
<blockquote>
<p><strong>bounds</strong>sequence or <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.Bounds.html#scipy.optimize.Bounds"><code>Bounds</code></a>, optional</p>
<p>Bounds on variables for L-BFGS-B, TNC, SLSQP, Powell, and trust-constr methods. There are two ways to specify the bounds:</p>
<blockquote>
<ol type="1">
<li>Instance of <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.Bounds.html#scipy.optimize.Bounds"><code>Bounds</code></a> class.</li>
<li>Sequence of <code>(min, max)</code> pairs for each element in <em>x</em>. None is used to specify no bound.</li>
</ol>
</blockquote>
<p><strong>constraints</strong>{Constraint, dict} or List of {Constraint, dict}, optional</p>
<p>Constraints definition (only for COBYLA, SLSQP and trust-constr).</p>
<p>Constraints for ‘trust-constr’ are defined as a single object or a list of objects specifying constraints to the optimization problem. Available constraints are:</p>
<blockquote>
<ul>
<li><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.LinearConstraint.html#scipy.optimize.LinearConstraint"><code>LinearConstraint</code></a></li>
<li><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.NonlinearConstraint.html#scipy.optimize.NonlinearConstraint"><code>NonlinearConstraint</code></a></li>
</ul>
</blockquote>
</blockquote>
<p>bounds主要是用来控制上下界，constraions则是通过变量间的关系来缩小范围</p>
<blockquote>
<p><strong>tol</strong>: float, optional</p>
<p>Tolerance for termination. For detailed control, use solver-specific options.</p>
</blockquote>
<p>Tol 是最小迭代值，就是迭代停止的条件</p>
<p>Here is the example of <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUm9zZW5icm9ja19mdW5jdGlvbg==">Rosenbrock function<i class="fa fa-external-link-alt"></i></span> <span class="math display">\[
f(x)=\sum_{i=1}^{N-1}100(x_{x+1}-x_i^2)+(1-x_i)^2
\]</span></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/2560px-Rosenbrock_function.svg.png" alt="2560px-Rosenbrock_function.svg"><figcaption aria-hidden="true">2560px-Rosenbrock_function.svg</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rosen</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The Rosenbrock function&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> sum(<span class="number">100.0</span>*(x[<span class="number">1</span>:]-x[:<span class="number">-1</span>]**<span class="number">2.0</span>)**<span class="number">2.0</span> + (<span class="number">1</span>-x[:<span class="number">-1</span>])**<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">x0 = np.array([<span class="number">1.3</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">1.9</span>, <span class="number">1.2</span>])</span><br><span class="line">res = minimize(rosen, x0, method=<span class="string">&#x27;nelder-mead&#x27;</span>,</span><br><span class="line">               options=&#123;<span class="string">&#x27;xatol&#x27;</span>: <span class="number">1e-8</span>, <span class="string">&#x27;disp&#x27;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">Optimization terminated successfully.</span><br><span class="line">         Current function value: <span class="number">0.000000</span></span><br><span class="line">         Iterations: <span class="number">339</span></span><br><span class="line">         Function evaluations: <span class="number">571</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">print(res.x)</span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br></pre></td></tr></table></figure>
<p>More often, we need to use the boudnarrays or constrains. Here I show the boundary</p>
<h1 id="least_square">Least_square</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scipy.optimize.least_squares(fun, x0, jac=<span class="string">&#x27;2-point&#x27;</span>, bounds=- inf, inf, method=<span class="string">&#x27;trf&#x27;</span>, ftol=<span class="number">1e-08</span>, xtol=<span class="number">1e-08</span>, gtol=<span class="number">1e-08</span>, x_scale=<span class="number">1.0</span>, loss=<span class="string">&#x27;linear&#x27;</span>, f_scale=<span class="number">1.0</span>, diff_step=<span class="literal">None</span>, tr_solver=<span class="literal">None</span>, tr_options=&#123;&#125;, jac_sparsity=<span class="literal">None</span>, max_nfev=<span class="literal">None</span>, verbose=<span class="number">0</span>, args=(), kwargs=&#123;&#125;)</span><br></pre></td></tr></table></figure>
<p>这个与上一个几乎一样</p>
<h1 id="nnls">nnls</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scipy.optimize.nnls(A, b, maxiter=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>Solve <code>argmin_x || Ax - b ||_2</code> for <code>x&gt;=0</code>.</p>
<p>Parameters</p>
<ul>
<li><p><strong>A </strong>ndarray</p>
<p>Matrix <code>A</code> as shown above.</p></li>
<li><p><strong>b </strong> ndarray</p>
<p>Right-hand side vector.</p></li>
<li><p><strong>maxiter: int, optional</strong></p>
<p>Maximum number of iterations, optional. Default is <code>3 * A.shape[1]</code>.</p></li>
</ul>
<p>Returns</p>
<ul>
<li><p><strong>x </strong> ndarray</p>
<p>Solution vector.</p></li>
<li><p>**rnorm: float</p>
<p>The residual, <code>|| Ax-b ||_2</code>.</p></li>
</ul>
<h1 id="lsq_linear">lsq_linear</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scipy.optimize.lsq_linear(A, b, bounds=- inf, inf, method=<span class="string">&#x27;trf&#x27;</span>, tol=<span class="number">1e-10</span>, lsq_solver=<span class="literal">None</span>, lsmr_tol=<span class="literal">None</span>, max_iter=<span class="literal">None</span>, verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>Solve a linear least-squares problem with bounds on the variables.</p>
<p>Given a m-by-n design matrix A and a target vector b with m elements, <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.lsq_linear.html#scipy.optimize.lsq_linear"><code>lsq_linear</code></a> solves the following optimization problem:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">minimize <span class="number">0.5</span> * ||A x - b||**<span class="number">2</span></span><br><span class="line">subject to lb &lt;= x &lt;= ub</span><br></pre></td></tr></table></figure>
<h1 id="curve_fit">curve_fit</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scipy.optimize.curve_fit(f, xdata, ydata, p0=<span class="literal">None</span>, sigma=<span class="literal">None</span>, absolute_sigma=<span class="literal">False</span>, check_finite=<span class="literal">True</span>, bounds=- inf, inf, method=<span class="literal">None</span>, jac=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<p>这个其实是最常用的一个函数</p>
<p>需要注意 这里的f并不是cost func,而是model func，例如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f_1</span>(<span class="params">x, A, B</span>):</span></span><br><span class="line">    <span class="keyword">return</span> A * x + B</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>xdata array_like or object </strong>The independent variable where the data is measured. Should usually be an M-length sequence or an (k,M)-shaped array for functions with k predictors, but can actually be any object.[<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDQzNTMxMjYjcmVmXzE=">1]<i class="fa fa-external-link-alt"></i></span> 简单说就是要拟合的自变量数组</li>
<li><strong>ydata array_like </strong>The dependent data, a length M array - nominally<code>f(xdata,...)</code>.[<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDQzNTMxMjYjcmVmXzE=">1]<i class="fa fa-external-link-alt"></i></span> 简单说就是要拟合的因变量的值</li>
<li><strong>p0 array_like , optional</strong>Initial guess for the parameters (length N). If None, then the initial values will all be 1 (if the number of parameters for the function can be determined using introspection, otherwise a ValueError is raised).[<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDQzNTMxMjYjcmVmXzE=">1]<i class="fa fa-external-link-alt"></i></span> 就是给你的函数的参数确定一个初始值来减少计算机的计算量</li>
<li>Method to use for optimization. See <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html#scipy.optimize.least_squares"><code>least_squares</code></a> for more details. Default is ‘lm’ for unconstrained problems and ‘trf’ if <em>bounds</em> are provided. The method ‘lm’ won’t work when the number of observations is less than the number of variables, use ‘trf’ or ‘dogbox’ in this case.</li>
</ul>
<p>这里放一下官方例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">x, a, b, c</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a * np.exp(-b * x) + c</span><br></pre></td></tr></table></figure>
<p>Define the data to be fit with some noise:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xdata = np.linspace(<span class="number">0</span>, <span class="number">4</span>, <span class="number">50</span>)</span><br><span class="line">y = func(xdata, <span class="number">2.5</span>, <span class="number">1.3</span>, <span class="number">0.5</span>)</span><br><span class="line">np.random.seed(<span class="number">1729</span>)</span><br><span class="line">y_noise = <span class="number">0.2</span> * np.random.normal(size=xdata.size)</span><br><span class="line">ydata = y + y_noise</span><br><span class="line">plt.plot(xdata, ydata, <span class="string">&#x27;b-&#x27;</span>, label=<span class="string">&#x27;data&#x27;</span></span><br></pre></td></tr></table></figure>
<p>it for the parameters a, b, c of the function <em>func</em>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">popt, pcov = curve_fit(func, xdata, ydata)</span><br><span class="line">popt</span><br><span class="line"></span><br><span class="line">plt.plot(xdata, func(xdata, *popt), <span class="string">&#x27;r-&#x27;</span>,</span><br><span class="line">         label=<span class="string">&#x27;fit: a=%5.3f, b=%5.3f, c=%5.3f&#x27;</span> % tuple(popt))</span><br></pre></td></tr></table></figure>
<p>Constrain the optimization to the region of <code>0 &lt;= a &lt;= 3</code>, <code>0 &lt;= b &lt;= 1</code> and <code>0 &lt;= c &lt;= 0.5</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">popt, pcov = curve_fit(func, xdata, ydata, bounds=(<span class="number">0</span>, [<span class="number">3.</span>, <span class="number">1.</span>, <span class="number">0.5</span>]))</span><br><span class="line">popt</span><br><span class="line"></span><br><span class="line">plt.plot(xdata, func(xdata, *popt), <span class="string">&#x27;g--&#x27;</span>,</span><br><span class="line">         label=<span class="string">&#x27;fit: a=%5.3f, b=%5.3f, c=%5.3f&#x27;</span> % tuple(popt))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/scipy-optimize-curve_fit-1.png" alt="scipy-optimize-curve_fit-1"><figcaption aria-hidden="true">scipy-optimize-curve_fit-1</figcaption>
</figure>
<p>但是这里有个问题，如果我想固定a的值，或者我想得到一串的函数每个函数都有固定的a的值，该怎么办呢？</p>
<p>这种时候其实就需要把a不视为变量，再次建立一个函数 把a传进去，例如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">custom_gaussian = <span class="keyword">lambda</span> x, mu: gaussian(x, mu, <span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<p>利用lambda建立了小的匿名函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.optimize </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian</span>(<span class="params">x, mu, sigma</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / sigma / np.sqrt(<span class="number">2</span> * np.pi) * np.exp(-(x - mu)**<span class="number">2</span> / <span class="number">2</span> / sigma**<span class="number">2</span>)</span><br><span class="line"><span class="comment"># This is the original, full parameter gaussion function</span></span><br><span class="line"><span class="comment"># Create sample data</span></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">2</span>, <span class="number">200</span>)</span><br><span class="line">y = gaussian(x, <span class="number">1</span>, <span class="number">0.1</span>) + np.random.rand(*x.shape) - <span class="number">0.5</span></span><br><span class="line">plt.plot(x, y, label=<span class="string">&quot;sample data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit with original fit function</span></span><br><span class="line">popt, _ = scipy.optimize.curve_fit(gaussian, x, y)</span><br><span class="line">plt.plot(x, gaussian(x, *popt), label=<span class="string">&quot;gaussian&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit with custom fit function with fixed `sigma`</span></span><br><span class="line">custom_gaussian = <span class="keyword">lambda</span> x, mu: gaussian(x, mu, <span class="number">0.05</span>)</span><br><span class="line"><span class="comment"># this is the customed gaussion function that we want to fuit</span></span><br><span class="line">popt, _ = scipy.optimize.curve_fit(custom_gaussian, x, y)</span><br><span class="line">plt.plot(x, custom_gaussian(x, *popt), label=<span class="string">&quot;custom_gaussian&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/fiwXS.png" alt="fiwXS"><figcaption aria-hidden="true">fiwXS</figcaption>
</figure>
<h1 id="numpy.linalg.lstsq">numpy.linalg.lstsq</h1>
<p>这个是numpy自带的the least-squares solution to a linear matrix equation.</p>
<p>这里需要回忆一下线性方程组的问题 $$ <span class="math display">\[\begin{equation}
\left\{ 

a_{1,1}x_1+a_{1,2}x_2+\cdots+a_{1,n}=b_1,\\
a_{2,1}x_1+a_{2,2}x_2+\cdots+a_{1,n}=b_2, \\
\vdots \\
a_{m,1}x_1+a_{m,2}x_2+...+a_{m,n}=b_m,
\right.
\end{equation}\]</span> $$ 这个大括号的排版是不是有点问题</p>
<p>其中的<span class="math inline">\({\displaystyle a_{1,1},\,a_{1,2}}\)</span>以及<span class="math inline">\({\displaystyle b_{1},\,b_{2}}\)</span>等等是已知的常数，而<span class="math inline">\({\displaystyle x_{1},\,x_{2}}\)</span>等等则是要求的未知数。</p>
<p>如果用线性代数的概念来表达，线性方程组则可以写成 <span class="math display">\[
Ax=b
\]</span></p>
<p><span class="math display">\[
A=
\begin{bmatrix}
a_{1,1}&amp;\ a_{1,2}&amp;\ \cdots&amp;\ a_{1,n}\\
a_{2,1}&amp;\ a_{2,2}&amp;\ \cdots&amp;\ a_{2,n}\\
\vdots&amp;\ \vdots&amp;\ \ddots&amp;\ \vdots \\
a_{m,1}&amp;\ a_{m,2}&amp;\ \cdots&amp;\ a_{m,n}
\end{bmatrix}
, 
\
x=
\begin{bmatrix}
x_{1}\\
x_{2}\\
\vdots\\
x_n
\end{bmatrix}
,
b=
\begin{bmatrix}
b_{1}\\
b_{2}\\
\vdots\\
b_m
\end{bmatrix}
\]</span></p>
<p>这里的<em>A</em>是<em>m</em>×<em>n</em> <span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv55+p6Zmj">矩阵<i class="fa fa-external-link-alt"></i></span>，<strong>x</strong>是含有<em>n</em>个元素<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5ZCR6YeP">列向量<i class="fa fa-external-link-alt"></i></span>，<strong>b</strong>是含有<em>m</em> 个元素列向量。</p>
<p>如果有一组数<strong>x</strong>1、<strong>x</strong>2、……<strong>x</strong>n使得方程组的等号都成立，那么这组数就叫做方程组的解。一个线性方程组的所有的解的<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv6ZuG5ZCI">集合<i class="fa fa-external-link-alt"></i></span>会被简称为<strong>解集</strong>。根据解的存在情况，线性方程组可以分为三类：</p>
<ul>
<li><p>有唯一解的恰定方程组，</p></li>
<li><p>解不存在的超定方程组，</p></li>
<li><p>有无穷多解的欠定方程组（也被通俗地称为不定方程组）。</p>
<p>线性代数基本就是讲了怎判断有没有解和怎么求解这两件事</p>
<p>想复习线性方程组可以看<span class="exturl" data-url="aHR0cHM6Ly9tYXRoLmZ1ZGFuLmVkdS5jbi9nZHN4L0pJQU9BTi8lRTclQkElQkYlRTYlODAlQTclRTYlOTYlQjklRTclQTglOEIlRTclQkIlODQucGRm">/Users/zhenjia/hexoblog/source/_posts/Scipy-optimize/线性方程组.pdf<i class="fa fa-external-link-alt"></i></span></p></li>
</ul>
<p>不严格地说，当m&gt;n的时候一般没有解，成为超定方程组，但是这种时候可以把问题转化为优化问题，即求一组x使得<span class="math inline">\(|Ax-b|^2\)</span>最小，这就是个最小二乘问题</p>
<p>Parameters</p>
<ul>
<li><p><strong>a</strong>(M, N) array_like</p>
<p>“Coefficient” matrix.</p></li>
<li><p><strong>b</strong>{(M,), (M, K)} array_like</p>
<p>Ordinate or “dependent variable” values. If <em>b</em> is two-dimensional, the least-squares solution is calculated for each of the <em>K</em> columns of <em>b</em>.</p></li>
<li><p><strong>rcond</strong>float, optional</p>
<p>Cut-off ratio for small singular values of <em>a</em>. For the purposes of rank determination, singular values are treated as zero if they are smaller than <em>rcond</em> times the largest singular value of <em>a</em>.<em>Changed in version 1.14.0:</em> If not set, a FutureWarning is given. The previous default of <code>-1</code> will use the machine precision as <em>rcond</em> parameter, the new default will use the machine precision times <em>max(M, N)</em>. To silence the warning and use the new default, use <code>rcond=None</code>, to keep using the old behavior, use <code>rcond=-1</code>.</p></li>
</ul>
<p>Returns</p>
<ul>
<li><p><strong>x</strong>{(N,), (N, K)} ndarray</p>
<p>Least-squares solution. If <em>b</em> is two-dimensional, the solutions are in the <em>K</em> columns of <em>x</em>.</p></li>
<li><p><strong>residuals</strong>{(1,), (K,), (0,)} ndarray</p>
<p>Sums of residuals; squared Euclidean 2-norm for each column in <code>b - a*x</code>. If the rank of <em>a</em> is &lt; N or M &lt;= N, this is an empty array. If <em>b</em> is 1-dimensional, this is a (1,) shape array. Otherwise the shape is (K,).</p></li>
<li><p><strong>rank</strong>int</p>
<p>Rank of matrix <em>a</em>.</p></li>
<li><p><strong>s</strong>(min(M, N),) ndarray</p>
<p>Singular values of <em>a</em>.</p>
<p>Examples fot <span class="math inline">\(y=mx+c\)</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">y = np.array([<span class="number">-1</span>, <span class="number">0.2</span>, <span class="number">0.9</span>, <span class="number">2.1</span>])</span><br></pre></td></tr></table></figure></li>
</ul>
<p>By examining the coefficients, we see that the line should have a gradient of roughly 1 and cut the y-axis at, more or less, -1.</p>
<p>We can rewrite the line equation as <code>y = Ap</code>, where <code>A = [[x 1]]</code> and <code>p = [[m], [c]]</code>. Now use <a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html#numpy.linalg.lstsq"><code>lstsq</code></a> to solve for <em>p</em>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = np.vstack([x, np.ones(len(x))]).T</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">2.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">m, c = np.linalg.lstsq(A, y, rcond=<span class="literal">None</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m, c</span><br><span class="line">(<span class="number">1.0</span> <span class="number">-0.95</span>) <span class="comment"># may vary</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_ = plt.plot(x, y, <span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;Original data&#x27;</span>, markersize=<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_ = plt.plot(x, m*x + c, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;Fitted line&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_ = plt.legend()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/numpy-linalg-lstsq-1.png" alt="numpy-linalg-lstsq-1"><figcaption aria-hidden="true">numpy-linalg-lstsq-1</figcaption>
</figure>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>Tennary plot</title>
    <url>/posts/2b01b12c.html</url>
    <content><![CDATA[<p>Description for ternary plot</p>
<a id="more"></a>
<h1 id="python-package">Python package</h1>
<p>This is the package I used https://github.com/marcharper/python-ternary</p>
<p>The following is the most usefull sample for me.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ternary</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">cm = plt.cm.get_cmap(<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dat=pd.DataFrame(columns=list(<span class="string">&#x27;XYZV&#x27;</span>))</span><br><span class="line"></span><br><span class="line">dat[<span class="string">&#x27;X&#x27;</span>]=random.sample(range(<span class="number">45</span>),<span class="number">10</span>)</span><br><span class="line">dat[<span class="string">&#x27;Y&#x27;</span>]=random.sample(range(<span class="number">45</span>),<span class="number">10</span>)</span><br><span class="line">dat[<span class="string">&#x27;Z&#x27;</span>]=<span class="number">100</span>-(dat[<span class="string">&#x27;X&#x27;</span>]+dat[<span class="string">&#x27;Y&#x27;</span>])</span><br><span class="line">dat[<span class="string">&#x27;V&#x27;</span>]=<span class="number">10</span>**np.random.randint(<span class="number">0</span>,high=<span class="number">10</span>,size=<span class="number">10</span>)/<span class="number">1e5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># sc = plt.scatter(dat.X, dat.Y, c=dat.V, vmin=0, vmax=7, s=35, cmap=cm)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scale=<span class="number">100</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig, tax = ternary.figure(scale=scale)</span><br><span class="line">fig.set_size_inches(<span class="number">10</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">points=dat[[<span class="string">&#x27;X&#x27;</span>,<span class="string">&#x27;Y&#x27;</span>,<span class="string">&#x27;Z&#x27;</span>]].values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">minv=np.log10(dat.V.min())</span><br><span class="line">maxv=np.log10(dat.V.max())</span><br><span class="line"></span><br><span class="line">tax.scatter(points,s=<span class="number">60</span>,vmin=minv,vmax=maxv,colormap=plt.cm.viridis,colorbar=<span class="literal">True</span>,c=np.log10(dat[<span class="string">&#x27;V&#x27;</span>].values),cmap=plt.cm.viridis)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Decoration.</span></span><br><span class="line">tax.boundary(linewidth=<span class="number">1</span>)</span><br><span class="line">tax.gridlines(multiple=<span class="number">10</span>, color=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">tax.ticks(axis=<span class="string">&#x27;lbr&#x27;</span>, linewidth=<span class="number">1</span>, multiple=<span class="number">20</span>)</span><br><span class="line">tax.get_axes().axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">figure.set_size_inches(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">tax.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/D75BADEA-86A3-4AA9-81C8-159829A7F2F7.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h1 id="how-to-read-tennary-plot">How to read tennary plot</h1>
<p>这个才是重头戏</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/ternary_3.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>一个简单的理解是，三元图是重心图，离哪个顶点近，哪个占比大。</p>
<p>由点向底边做两条平行线建立小正三角形，将底边分成三段，中间为顶部组所占比例，左段为右侧组比例，右段为左侧组比例。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/512.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h1 id="我录个视频吧">我录个视频吧</h1>
<p>发现自己在中文网站上找不到相关的信息</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>The optics of backscattering</title>
    <url>/posts/99c2b0bb.html</url>
    <content><![CDATA[<p>I need to understand the optics of backscattering to understand the strange 'bbp' calculted from Rrs and and.</p>
<p>Material mainly from IOCCG summer lecture 2018 and ocean optics web book.</p>
<a id="more"></a>
<h1 id="volume-scattering-function">Volume scattering function</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/VSF-geometry-600.jpg" alt="VSF-geometry-600"><figcaption aria-hidden="true">VSF-geometry-600</figcaption>
</figure>
<p>the <em>fraction</em> of incident power scattered out of the beam through an angle <span class="math inline">\(\psi\)</span> into a solid angle <span class="math inline">\(\Delta\Omega\)</span> (total radiance inside the cone)centered on <span class="math inline">\(\psi\)</span>, is <span class="math inline">\(\Delta^2\Phi_s(\psi,\lambda)/\Phi_i\)</span>.</p>
<p>If we change <span class="math inline">\(\Omega\)</span> to <span class="math inline">\(\Omega+\Delta\Omega\)</span>, the increase part is inside the red ring,</p>
<p>The volume scattering function β(ψ,λ) is deﬁned as the limit of this fraction as Δr→0 and ΔΩ→0:</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505202530364.png" alt="image-00030505202530364"><figcaption aria-hidden="true">image-00030505202530364</figcaption>
</figure>
<p>The physical meaning of VSF is</p>
<p>scattered intensity per unit incident irradiance per unit volume of water</p>
<p>Or</p>
<p>the diﬀerential scattering cross section per unit volume.</p>
<p>So the scattering is the integration of VSF over all direction <span class="math display">\[
b(\lambda)=\int\beta(\psi,\lambda)d\Omega
\]</span> <span class="math inline">\(\Omega\)</span> is the <span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU3JUFCJThCJUU5JUFCJTk0JUU4JUE3JTky">solid angle<i class="fa fa-external-link-alt"></i></span></p>
<blockquote>
<p>https://www.youtube.com/watch?v=VmnkkWLwVsc</p>
<p>https://www.youtube.com/watch?v=gLfYTP4F23g</p>
<p>https://www.youtube.com/watch?v=RMJucQJ1NGo</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/220px-SolidAngleWiki.png" alt="img"> <span class="math display">\[
d\Omega=\frac{dA}{r^2}\\=\frac{d(rsin\theta d\psi)(rd\theta)}{r^2}\\=\frac{dr^2sin\theta d\theta d\psi}{r^2}\\=sin\theta d\theta d\psi
\]</span> By assuming azimuthal symmetry, this means it is a cone, the eq2 can be simplifed as : <span class="math display">\[
d\Omega=\frac{dA}{r^2}\\
=\frac{d(2\pi r^2(1-cos\theta))}{r^2}\\
=2\pi sin \theta d\theta
\]</span></p>
<p><span class="math display">\[
\therefore\\
b(\lambda)=\int\beta(\psi,\lambda)d\Omega\\
=2\pi\int_0^{\pi} sin(\theta)\beta(\theta,\lambda)d\theta\\
\]</span> <img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505220017394.png" alt="image-00030505220017394"></p>
<p>The scattering is addictive</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505220107010.png" alt="image-00030505220107010"><figcaption aria-hidden="true">image-00030505220107010</figcaption>
</figure>
<p>There are some other scattering properties</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505220204576.png" alt="image-00030505220204576"><figcaption aria-hidden="true">image-00030505220204576</figcaption>
</figure>
<p>50% typically &lt;3 to 4 deg</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505221010160.png" alt="image-00030505221010160"><figcaption aria-hidden="true">image-00030505221010160</figcaption>
</figure>
<h1 id="scattering-components">Scattering components</h1>
<h2 id="pure-water">Pure water</h2>
<p>The best value of pure water scattering is</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505224321192.png" alt="image-00030505224321192"><figcaption aria-hidden="true">image-00030505224321192</figcaption>
</figure>
<p>detailed can check Lee lecture bases</p>
<h2 id="phytoplankton">Phytoplankton</h2>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030506095901340.png" alt="image-00030506095901340"><figcaption aria-hidden="true">image-00030506095901340</figcaption>
</figure>
<h2 id="particles">Particles</h2>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030506100604399.png" alt="image-00030506100604399"><figcaption aria-hidden="true">image-00030506100604399</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030506101019868.png" alt="image-00030506101019868"><figcaption aria-hidden="true">image-00030506101019868</figcaption>
</figure>
<p>DDA is most popular one but only could compute very small size</p>
<p>Improve IGOM for larger size</p>
<p>Rayleigh cover very very small</p>
<p>Mie all size but homogeneous spheres</p>
<p>T-matrix is also popular</p>
<h1 id="measurement">Measurement</h1>
<p>I'm not very totally understand this process</p>
<p>But one thing I can now is that</p>
<p>The backscattering is the integration, but the measurement is a weighted sum</p>
<h1 id="interpretation-and-application">Interpretation and Application</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030506111348360.png" alt="image-00030506111348360"><figcaption aria-hidden="true">image-00030506111348360</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030506111806825.png" alt="image-00030506111806825"><figcaption aria-hidden="true">image-00030506111806825</figcaption>
</figure>
<h1 id="mie-theory">Mie theory</h1>
<h1 id="beam-attenuation">Beam Attenuation</h1>
<p>Unlike backscattering or total scattering, particle beam attenuation is almost a perfect powe law shape <span class="math display">\[
c_p=a_p+b_p\\
=a_{ph}+a_{nap}+b_p
\]</span></p>
<p>Not here this is <span class="math inline">\(b_p\)</span>, total scattering , not backscattering. Backscattering only contributed to almost one to two percent of total scattering.</p>
<p>In order to related to the backscattering that can be received by satellite, we need one bridge <span class="math inline">\(\hat{b}_{bp}\)</span>, defined as <span class="math display">\[
\hat{b}_{bp}=\frac{b_{bp}}{b_{p}}
\]</span> The <span class="math inline">\(\hat{b}_{bp}\)</span> almost same in different wavelength.</p>
<p>So the term u can be replaced as <span class="math display">\[
u=\frac{b_b}{a+b_b}\\
=\frac{b_w+b_{bp}}{a_w+a_p+a_{CDOM}+b_w+b_{bp}}\\
=\frac{b_w+b_{p}*\hat{b}_{bp}}{a_w+a_p+a_{CDOM}+b_w+b_{p}*\hat{b}_{bp}}\\
=\frac{b_w+(c_p-a_p)*\hat{b}_{bp}}{a_w+a_p+a_{CDOM}+b_w+(c_p-a_p)*\hat{b}_{bp}}\\
\]</span></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Ocean Optics</tag>
        <tag>particle backscattering</tag>
        <tag>Inversion</tag>
      </tags>
  </entry>
  <entry>
    <title>Tutorial for handling MODIS ocean color data</title>
    <url>/posts/ef746e52.html</url>
    <content><![CDATA[<p>This tutorial covers mainly two parts:</p>
<ol type="1">
<li>Using python to analyse MODIS ocean color data</li>
<li>Installation and application of SeaDA OCSSW</li>
</ol>
<a id="more"></a>
<h1 id="using-python-to-analyse-modis-ocean-color-data">Using python to analyse modis ocean color data</h1>
<h2 id="package-and-working-environment">Package and working environment</h2>
<p>This this the first difficult thing for a rookie.</p>
<h3 id="anaconda-pycharm">Anaconda &amp; Pycharm</h3>
<p>Anaconda contains most of the package</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>absorption measurement process</title>
    <url>/posts/49ca7bc7.html</url>
    <content><![CDATA[<p>This is a summary of how to process absorption measurement data.</p>
<p>The measurement is basically based on the QFT-T mode. More details could be found at <span class="exturl" data-url="aHR0cHM6Ly9pb2NjZy5vcmcvd2hhdC13ZS1kby9pb2NjZy1wdWJsaWNhdGlvbnMvb2NlYW4tb3B0aWNzLXByb3RvY29scy1zYXRlbGxpdGUtb2NlYW4tY29sb3VyLXNlbnNvci12YWxpZGF0aW9uLw==">IOCCG protocols volume 1<i class="fa fa-external-link-alt"></i></span></p>
<a id="more"></a>
<h1 id="cdom">CDOM</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224105720968.png" alt="image-00030224105720968"><figcaption aria-hidden="true">image-00030224105720968</figcaption>
</figure>
<p>This is the excel sheet we used for CDOM measurement</p>
<p>Each time we measure two blank and two samples.</p>
<p>The <span class="math inline">\(a_{CDOM}\)</span> is calcualted follow: <span class="math display">\[
a_{CDOM}=\frac{2.303}{l}[[OD_s(\lambda)-OD_{bs}(\lambda)]-OD_{null}]
\]</span> <span class="math inline">\(l\)</span> is the path length of the quartz cell. In MPS-2400, the <span class="math inline">\(l=10cm(0.1m)\)</span>. 2.303 is the factor to convert <span class="math inline">\(log_{10}\)</span> to <span class="math inline">\(log_{e}\)</span></p>
<p><span class="math inline">\(OD_s(\lambda)\)</span> is the optical density of the filtered water sample, <span class="math inline">\(OD_{bs}(\lambda)\)</span> is the optical density of purified water, and <span class="math inline">\(OD_{null}(\lambda)\)</span> is the apparent residual optical density at a long visible or near infrared wavelength where absorption by dissolved materials is assumed to be zero. In the previous measurement, we use the 700 nm as null wavelength.</p>
<p>So this excel file is quite clear.</p>
<h1 id="ap-ad-aph">ap ad aph</h1>
<p>The optical density of total particles retained on the filter (<span class="math inline">\(OD_p(λ)\)</span>) were kept below 0.3 by adjusting the filtration volume. Subsequently, <span class="math inline">\(OD_p(λ)\)</span> was measured between 350 and 750 nm at 1 nm intervals, using a dual beam multi-purpose spectrophotometer (MPS-2400, Shimadzu Inc.). A blank filter soaked with 0.2 µm-filtered seawater (FSW) was used as the reference. To correct the path length amplification effect caused by multiple scattering in the glass fibre filter, the following equation was utilized according to Cleveland and Weidemann (1993): <span class="math display">\[
OD_s(\lambda)=0.378OD_p(\lambda)+0.523D_p(\lambda)^2
\]</span> where <span class="math inline">\(OD_s(λ)\)</span> is the optical density of particulate matter in suspension. The absorption coefficient of the total particles (<span class="math inline">\(ap(λ)\)</span>) was calculated using the following equation: <span class="math display">\[
a_p(\lambda)=2.303OD_s(\lambda)S/V
\]</span> where 2.303 is the factor used to convert <span class="math inline">\(log_{10}\)</span> to <span class="math inline">\(log_e\)</span> , S is the filter clearance area (<span class="math inline">\(m^2\)</span> ), and V is the filtered volume (<span class="math inline">\(m^3\)</span> ). The ratio of S to V approximates the geometrical light pass length.</p>
<p>After measurements of the optical density of the total particles, the filters were soaked in methanol for at least 24 h to extract phytoplankton pigments, and then rinsed with FSW. The absorbance of a decolourized filter was re-measured using the same method to obtain the optical density of the non-phytoplankton particles (Kishino et al., 1985). Similarly, the absorption coefficient of non-alga particles (<span class="math inline">\(a_{nah}(λ)\)</span>) was determined using Eq. (2) and (3). <span class="math inline">\(a_{ph}(λ)\)</span> was then obtained from the following equation: <span class="math display">\[
a_{ph}(\lambda)=a_{p}(\lambda)-a_{nap}(\lambda)
\]</span></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030225145047326.png" alt="image-00030225145047326"><figcaption aria-hidden="true">image-00030225145047326</figcaption>
</figure>
<p>This the the excel sheet for ap. Blank 1&amp;Blank2 are measrued before ap, Blank 3&amp;Blank4 are measrued after ap</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Experiment Protocols</tag>
        <tag>Absorption Measurement</tag>
      </tags>
  </entry>
  <entry>
    <title>assert</title>
    <url>/posts/b1ef4fab.html</url>
    <content><![CDATA[<p>最近在读别人代码的时候发现了好多自己当时学python的时候没有学过的东西</p>
<a id="more"></a>
<h1 id="语法">语法</h1>
<p>Python assert用于判断一个表达式，在表达式条件为false的时候触发异常。</p>
<p>语法格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression</span><br></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> expression:</span><br><span class="line">    <span class="keyword">raise</span> AssertionError</span><br></pre></td></tr></table></figure>
<p>后面也可以跟参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression [, arguments]</span><br></pre></td></tr></table></figure>
<p>等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression [, arguments]</span><br></pre></td></tr></table></figure>
<h1 id="使用实例">使用实例</h1>
<blockquote>
<p>检查 先验条件 使用assert，检查 后验条件 使用 异常处理</p>
</blockquote>
<p>举个例子来说明一下，在开发中我们经常会遇到读取本地文件的场景。我们定义一个read_file方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> isinstance(file_path, str)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>read_file函数要求在开始执行的时候满足一定条件：file_path必须是str类型，这个条件就是*<strong>先验条件*</strong>，如果不满足，就不能调用这个函数，如果真的出现了不满足条件的情况，证明代码中出现了bug，这时候我们就可以使用assert语句来对file_path的类型进行推断，提醒程序员修改代码，也可以使用if...raise...语句来实现assert，但是要繁琐很多。在很多优秀的Python项目中都会看到使用assert进行先验判断的情况，平时可以多多留意。</p>
<p>read_file函数在被调用执行后，依然需要满足一定条件，比如file_path所指定的文件需要是存在的，并且当前用户有权限读取该文件，这些条件称为后验条件，对于后验条件的检查，我们需要使用异常来处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span>(<span class="params">file_path</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> isinstance(file_path, str)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> check_exist(file_path):</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> has_privilege(file_path):</span><br><span class="line">        <span class="keyword">raise</span> PermissionError()</span><br></pre></td></tr></table></figure>
<p>文件不存在和没有权限，这两种情况并不属于代码bug，是代码逻辑的一部分，上层代码捕获异常后可能会执行其他逻辑，因此我们不能接受这部分代码在生产环境中被忽略，这属于*<strong>后验条件*</strong>。并且，相比于assert语句只能抛出AssertionError，使用异常可以抛出更详细的错误，方便上层代码针对不同错误执行不同的逻辑。</p>
<p>再比如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">assert</span> (<span class="string">&#x27;linux&#x27;</span> **<span class="keyword">in</span>** sys.platform), <span class="string">&quot;该代码只能在 Linux 下执行&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="其他异常处理">其他异常处理</h1>
<p>顺手补一下其他异常处理</p>
<h2 id="try...except">try...except</h2>
<p>这个语句主要是用来可能发生错误的语句里面，比如在跑一个循环的时候有的除以零，有的没有除以零，可以使用try except把除以零的赋值nan避免这个循环停止，让程序继续跑下去。</p>
<h2 id="try...finally">try...finally</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># try..finally模式</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  &lt;statement&gt;        <span class="comment">#运行别的代码</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">  &lt;statement&gt;        <span class="comment">#不管有无异常都会执行 </span></span><br></pre></td></tr></table></figure>
<p>try..finally模式是:</p>
<ol type="1">
<li>没有异常就先运行try所有语句,再运行finally所有语句.</li>
<li>要是有异常,try执行到异常就跳到finally,然后直接跳出将异常递交给上层的try.控制流并不通过所有try语句.</li>
<li>finally能跟在except/else后,优先先执行except/else再执行finally.</li>
</ol>
<p>由此可知, try…finally 模式更适合于嵌套在try..except内作为保证某些代码一定执行.因为try..except…else要是执行了except就不会执行else,无法保证某个代码必须执行.所以常见的整合模式为:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 两种模式的嵌套和结合</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  &lt;statement1&gt;        <span class="comment">#运行测试代码1</span></span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">     &lt;statement2&gt;        <span class="comment">#运行测试代码2</span></span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">     &lt;statement3&gt;        <span class="comment">#不管测试代码2有无异常都会执行</span></span><br><span class="line"><span class="keyword">except</span> &lt;name&gt;：</span><br><span class="line">    &lt;statement&gt;        <span class="comment">#测试代码1或2发生错误而被捕获,就会执行异常</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"> &lt;statement&gt;        <span class="comment">#测试代码1和2都没有发生错误就会执行</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">  &lt;statement4&gt;        <span class="comment">#无论两个try有无异常,都会运行一次.</span></span><br></pre></td></tr></table></figure>
<p>PS: 要是finally在except/else前面肯定会报错.因为try后直接给finally,然后会交给上层try.但没有上层try…</p>
<p>实例:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   fh = open(<span class="string">&quot;testfile&quot;</span>, <span class="string">&quot;w&quot;</span>)</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">      fh.write(<span class="string">&quot;This is my test file for exception handling!!&quot;</span>)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">      <span class="keyword">print</span> <span class="string">&quot;Going to close the file&quot;</span></span><br><span class="line">      fh.close()</span><br><span class="line"><span class="keyword">except</span> IOError:</span><br><span class="line">   <span class="keyword">print</span> <span class="string">&quot;Error: can&#x27;t find file or read data&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="raise">raise</h2>
<h3 id="与try一起使用">与try一起使用</h3>
<p>raise语句可以很好地用于抛出某个异常从而被try捕获. 更常用于结合if等进行条件检查.例如某变量假定[0,10],&lt;0时抛出一个错,&gt;10抛出另一个错误.</p>
<p>raise一般是<code>raise exception,args</code>,args一般采用一个值,来初始化异常类的args属性,也可以直接使用元组来初始化args.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">raise</span> &lt;name&gt;    <span class="comment">#手工地引发异常</span></span><br><span class="line"><span class="keyword">raise</span> &lt;name&gt;,&lt;data&gt;    <span class="comment">#传递一个附加的数据(一个值或者一个元组),要是不指定参数,则为None.</span></span><br><span class="line"><span class="keyword">raise</span> Exception(data)    <span class="comment">#和上面等效.</span></span><br><span class="line"><span class="keyword">raise</span> [Exception [, args [, traceback]]]  <span class="comment"># 第三个参数是用于跟踪异常对象,基本不用.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"> <span class="keyword">if</span> (i&gt;<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(i)</span><br><span class="line">   <span class="keyword">elif</span> (i&lt;<span class="number">0</span>):</span><br><span class="line">       <span class="keyword">raise</span> ValueError,i</span><br><span class="line"><span class="comment">#下面的e实际是返回错误的对象实例.</span></span><br><span class="line"><span class="keyword">except</span> TypeError,e:</span><br><span class="line">    <span class="keyword">print</span> str(e)+<span class="string">&quot; for i is larger than 10!&quot;</span></span><br><span class="line"><span class="keyword">except</span> ValueError,e:</span><br><span class="line">    <span class="keyword">print</span> str(e)+<span class="string">&quot; for i is less than 0!&quot;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  <span class="keyword">print</span> <span class="string">&quot;i is between 0 and 10~&quot;</span></span><br></pre></td></tr></table></figure>
<h1 id="参考资料">参考资料</h1>
<p>https://stackoverflow.com/questions/40182944/difference-between-raise-try-and-assert</p>
<p>https://www.cnblogs.com/lsdb/p/11063568.html</p>
<p>https://blog.csdn.net/qq_29287973/article/details/78053764</p>
<p>https://www.runoob.com/python3/python3-assert.html</p>
<p>https://zhuanlan.zhihu.com/p/91853234</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>book reading note 4</title>
    <url>/posts/5ab69b8e.html</url>
    <content><![CDATA[<p>Chapter 10.1.-10.2 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<h1 id="introduction">Introduction</h1>
<p>From this week we will start a new chapter, the oceans and global climate change: physical and biological aspects. Today I will talk about the introduction and physical part</p>
<p>The physical aspects contains the greenhouse effect and climate change</p>
<p>The oceans have a deep circulation, the thermohaline circulation. Water is heated in equatorial regions, and then moves poleward in major currents, giving off heat to the atmosphere. In subarctic regions cooling and ice formation cause water to become more dense. The water then sinks to form the “deep water.” This sinking is the beginning of a long journey close to the ocean floor. Some of the deep water travels south in the Atlantic basin, moves across to the Pacific basin, and there moves slowly northward in a journey that may take a thousand years.</p>
<p>The exchange mechanism contains two part, the physical part is related to the thermohaline circulation. At the regions of deep-water formation large quantities of carbon dioxide dissolved in the water sink to great depth and are removed from contact with the atmosphere. Conversely, at regions of upwelling, especially the large upwellings at the tropical divergence, heating of the cold upwelled water causes it to give off billions of tons of carbon dioxide. The exchange amount of CO2 is approximately balanced in the physical mechanism. But some biological process could also remove cp2 from atmosphere to the deep ocean. Over 99% of the carbon dioxide added to the earth’s atmosphere throughout its history has been taken up by phytoplankton and sedimented to the sea floor to form the calcareous rocks and the fossil fuels. This biological mechanism is known as the biological pump.</p>
<p>In the past 150 years, the co2 concentration in the atmosphere is absolutely rising, so here an important problem is that How much excess CO2 can be absorbed by ocean?</p>
<p>In order to answer this question, this chapter will talk about the the mechanism of global warming and the present-day global carbon cycle first. Then explore the relative importance of oceanic sources and sinks compared with industrial activities and terrestrial biota. Finally, consider what changes might be expected to occur in physical and biological mechanisms for circulating carbon in the ocean if the expected rise in global atmospheric temperature occurs</p>
<h1 id="physical-aspects">Physical aspects</h1>
<h2 id="the-greenhouse-effect">The greenhouse effect</h2>
<h3 id="the-process">The process</h3>
<p>So here we come to our first part, about the physical aspects. First lets talk about the process of greenhouse effect.</p>
<p>The average surface temperature of earth surface is about 15 Celsius degree. If there were no water vapor, carbon dioxide, or methane in the atmosphere, the surface temperature would be below freezing by ~18 °C and all the rivers, lakes, and oceans would be frozen solid. The reason for the higher, more habitable temperature is the fact that these greenhouse gases delay heat from leaving the earth by trapping it in the lower atmosphere.</p>
<p>all the heat received on the earth comes originally from the sun’s surface via electromagnetic radiation with wavelengths between 0.2 and 2.4 Micrometre, often called the short-wave radiation. approximately 31% of this incoming radiation is reflected back into space, ~20% is absorbed by the ozone, water vapor, clouds, and dust in the atmosphere, and ~49% is absorbed by the land and water at the earth’s surface.</p>
<p>All these absorbers in turn radiate heat in the form of electromagnetic radiation. The back radiation is at wavelengths between 5 and 100 Micrometre: long-wave radiation according to Planck’s radiation law. As I talked before, the radiation from the sun, the short-wave radiation, only 20% of them is absorbed by atmosphere. But here 90% long-wave radiation is absorbed by greenhouse gases inside atmosphere. The amount of heat trapped and the resulting temperature of the atmosphere clearly vary directly with the concentrations of these gases. If the gases are very concentrated, as on the planet Venus, the temperature is very high (+400 Celsius degree) and if they are low, as on Mars, the temperature is very low (−50 Celsius degree)</p>
<p>The greenhouse gases in the atmosphere. ranged from naturally occurred to human-produced, are carbon dioxide, water vapor, methane,ozone, nitrous oxide, chlorofluorocarbon.</p>
<p>The warming effect of each of these gases is different because their concentrations are different and because they absorb radiation with different efficiencies at different wavelengths. Under clear-sky conditions, Kiehl and Trenberth (1997) estimate that 60% of the warming effect is due to water vapor, 26% to carbon dioxide, 8% to ozone, and 6% to methane and nitrous oxide. The other gases, such as chlorofluorocarbons, contribute ~1% or less to the total warming effect. For life in the oceans, the most important element in these gases is the carbon (C) in the carbon dioxide (CO2).</p>
<h3 id="the-carbon-cycle">The carbon cycle</h3>
<p>Estimations of the magnitudes of the carbon reservoirs and fluxes in the global carbon cycle are constantly being updated. Here is an estimation conducted by Sarmiento and Gruber in 2002. The value here shows carbon flux. value without underline is pre-industrial value and with underline is anthropogenic value. In the atmosphere, for example, there were ~590 Petagram of carbon in the pre-industrial era but today the value is ~161 Petagram higher for an increase of ~30%.</p>
<p>For the carbon between ocean and atmosphere, we can see that 90.6 Pg carbon come from ocean to the atmosphere while 91.9 Pg come back, which result in net increase in the ocean 1.3 Pg C y^-1</p>
<p>When the co2 dissolve in the ocean, only 1% dissolved carbon retains CO2 structure that participate in the exchange with the atmosphere.</p>
<p>The Dissolved Inorganic Cabon(DIC) is also called total CO2.Here are two examples of vertical distributions of total CO2. In the surface layer the total co2 is low and increase until 1000m, then stay roughly constant until the bottom. On obvious result is that higher concentration in the deeper water. Also evident in this figure is the greater concentration below 1000 m in the North Pacific than in the North Atlantic. Such difference is thought to reflect the greater length of time since the deep Pacific has been in contact with the atmosphere and thus the greater length of time it has had to accumulate carbon from sinking plant and animal detritus.</p>
<h2 id="climate-change">Climate change</h2>
<h3 id="carbon-dioxide">Carbon dioxide</h3>
<p>The increasing greenhouse gases will absolutely increase the greenhouse effect. Here shows the atmosphere carbon dioxide concentration since 900. Before 1985, the concentration was obtained by analyzing air trapped in glaciers. And after 1985, the concentration was measured directly at Mauna Loa, Hawaii.</p>
<p>We can see that from 900 to 2850, the concentration is about 280 Parts Per Million (ppm).In 2001, the concentration is about 37Parts Per Million, about 30% increase in 150 years. And this might be the highest concentration in the past 420 000 years.</p>
<p>In the rising co2, about two thirds of them is anthropogenic co2 from burning of coal, oil and gas. Remaining thirds are from the release of co2 from deforestation.</p>
<p>The co2 is responsible for about 60% percent of greenhouse effect since 1850, while methane and nitrous , trace gases takes the rest 40%.</p>
<p>Such rising concentration give use two questions:</p>
<p>What effects are these increases having on the world’s temperature, precipitation, sea level, ice cover, and biological processes?</p>
<p>What about the future if the greenhouse effect continues to increase?</p>
<p>These two question will be discussed later in this chapter.</p>
<p>Here is another figure shows The annual flux of carbon dioxide into the atmosphere from fossil fuel emissions and the annual increase in carbon dioxide observed in the atmosphere, 1958–2000.</p>
<p>One interesting thing is that about half the amount of CO2 estimated to have been put into the atmosphere by human activities.</p>
<p>Before 1950, about 2.5 pg y-1 emission but only 1.5 increase. Recently about 7 emission but only 4 pg in the atmosphere. The missing part of emission is now known to be dissolving in the oceans or being incorporated into the terrestrial biomass</p>
<p>For the missing part in the ocean, now it is possible to identify the source of co2 in the ocean , because the 13C/12C ratio is lower in fossil-fuel CO2. And they found that the anthropogenic co2 most are limited in Upper few hundred meters of the ocean. In the deep ocean, the anthropogenic co2 was only found in the deep North Atlantic, where the co2 was renewed by contacting with atmosphere</p>
<p>Another interesting thing here, the peak of annual accumulation coincide with El Niño events. Here the red bar shows the time of ei nino events. The only one exception is 1992-3,minimum accumulation rate. which is the minimum accumulation rate. The exception might because Eruption of Mount Pinatubo in the early 1990s cooled the atmosphere.</p>
<p>But the peak coincidence remain controversial. One possible reason is that the warmer water in the equatorial Pacific during El Niño events would lead to an increased flux of CO2 into the atmosphere. Observations however indicate the flux is probably decreased during El Niños in the equatorial region because of the decrease in upwelling along the equator of water with higher CO2 content.</p>
<p>Another reason might be the response of terrestrial biosphere. But this is still poorly understood.</p>
<h3 id="temperature">Temperature</h3>
<p>Temperature is the key variable to monitor effect of greenhouse gases.</p>
<p>Here this figure shows the Surface temperature of the earth, including land and marine data.</p>
<p>we can see that the temperature fluctuated about a constant level between 1860 and 1910, and then rise 0.3℃ by 1940s, but it is still stable until 1970s. After 1970 the temperature increase quickly. 1998 is the warmest year. The Total increase in past 150 years is about 0.6 ± 0.2 °C.</p>
<p>But the warming is not the same everywhere and in a few locations surface temperature actually decreased while other regions experienced strong increases.</p>
<p>Also in this figure, the grey band shows temperature range by model simulation</p>
<p>We can see that the model result have good agreement with past observed temperature. And base on the prediction of these model, the temperature will Increase from 1.5℃ to 5.5℃ over the next 100 years, in average is about 3.</p>
<p>Here this figure shows a longer time series of surface temperature in the northern hemisphere. The time series was constructed from instrumental record(Jones et al., 2001) and proxy data from variation in tree rings, corals, and ice cores.</p>
<p>We can see that 1000-1900: the temperature decrease about 0.02℃→earth’s orbit and rotation.</p>
<p>But Over the past century, there have been significant temperature anomalies due to the growth of co2</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>book-reading-note2</title>
    <url>/posts/44f3f721.html</url>
    <content><![CDATA[<p>Chapter 7.1-7.2.4 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<h1 id="tides-tidal-mixing-and-internal-waves">Tides, tidal mixing, and internal waves</h1>
<h2 id="introduction">Introduction</h2>
<p>This chapter focus on the tides, tidal mixing and internal waves and today I will talk from the introduction to the physics of tidal currents.</p>
<p>Tides are created by the gravitational pull of the moon and the sun. The changing water level leads to interesting patterns of intertidal organisms( place a figure of intertidal zone ) but it is not the emphases of this chapter.</p>
<p>Besides the intertidal zone, the tides also generate currents in the water that interact with the bottom to produce turbulence. And if the currents are sufficiently strong, the turbulence could prevent any stratification , thus the wholes area may be permanently tidally mixed. There are some researches shows that a great number of stocks only live in such strong tidal mixing area. In this chapter we will explore the possible significance of this observation.</p>
<p>And if the tidal mixing is not so strong, the water column becomes stratified, the interaction of the tidal currents with the bottom topography could lead to the formation of internal waves. Internal waves could cause vertical mixing and redistribution of nutrients, which is important effects on phytoplankton production. Some times as the internal wave decays, they produce solitary waves and bores,which could have a strong influence of on the distribution of zooplankton and larval fishes.</p>
<p>Around the shallow bank, the interaction between tidal currents and bottom topography could generate unidirectional currents that form gyres. The combination of tidally mixed water over the top of a bank and a gyre around its periphery is thought to provide conditions particularly suitable for the eggs and larvae of fish. In this chapter we shall explore some of these interesting consequences of tidally induced water movement.</p>
<p>(Needs some more figures and references to tell the story)</p>
<h2 id="the-physics-of-tides">The physics of tides</h2>
<h3 id="tide-generating-forces-and-the-equilibrium-tide.">Tide-generating forces and the equilibrium tide.</h3>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200207160250.png"></p>
<p>First part is the physics of tides. Lets start from the most simple occasion. Here the earth and the moon are seen from above the north pole of the earth</p>
<ol type="1">
<li>The water on the earth only receive the gravitational pull of the moon, remove the sun and the centripetal force from earth.</li>
<li>The earth and moon are assumed to be stationary except for the earth’s rotation.</li>
<li>The earth doesn’t have continents and is covered with a uniform layer of water.</li>
<li>Without the Coriolis force and friction force.</li>
</ol>
<p>Our observer is located in O. It is clear that the , the highest tide will always under the moon and the lowest tide will be on the opposite side to the moon as a result of gravitational pull of moon and centripetal force from earth. With the earth rotate, our observer will see one high tide and one low tide a day.</p>
<p>This elementary model could produce a tide but it is not a very good model because most places on the earth usually have two high and two low tides during the day.</p>
<p>One thing that need to consider is the rotation of the earth moon pair, about 29.5 day once. Because the earth’s mass is roughly 80 times that of the moon the common center of rotation is inside the earth about 1600 km below the surface along a line from the moon to the earth. The the common center of rotation is inside the earth about 1600 km below the surface along a line from the moon to the earth. And in order to make the earth and moon rotate around the center of mass, both of them will receive a centripetal force from the center of mass. This force is supplied by the gravity between earth and moon. But for us, the earth is stationary, that mean we choose our earth as reference system. So in order to make our earth stationary, we need add a fictitious force or inertial force. As a result, the water in our earth now receive two force, one is the gravity from moon, another is inertial force which backwards the center of mass.</p>
<p>Therefore, the shape of water on our earth likes a rugby.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200207212741.png"></p>
<p>And this bulge is called tide bulge.</p>
<p>This model could help us describe two things. One is that we can observe two high tides and two low tides every day. Another is that why the tides do not occur at the same time every day. The earth and moon rotate around one another in a lunar month that is roughly 29.5 days. As our observer at O rotates through exactly one day back to O the moon has moved about 12° further around in its orbit to the position marked “tomorrow”.The high tide that is under the moon will still be under the moon tomorrow, but it will be observed later in the observer’s day.. Since the earth spins on its axis at about 4 minutes per degree the tides will appear about 50 minutes later each day.</p>
<p>The next refinement is. If we observe both from the side, not the pole, moon is not directly over the equator. The moon can be found at various angles to the north and south of the equator up to a maximum of 35° depending on the season and the time of the lunar month. So the tide bulge is no longer on the equator. No our observer in O could observe two high tide and two low tides every day. But the high tides are unequal height, as are the low tides. This difference is called the diurnal (daily) inequality.</p>
<p>This model only consider the effect of moon,without continents Coriolis force and friction force. Such tide is called equilibrium tide and this theory is called The Equilibrium Theory of Tides or “static” theory of tides.</p>
<p>It cannot predict It cannot predict the tide at any particular location but it does explain some of the main features of the tide such as</p>
<ol type="1">
<li>diurnal variation</li>
<li>diurnal inequality in the height</li>
<li>daily delay</li>
</ol>
<p>The next improvement of equilibrium theory of tide is considering the effects of the earth-sun system on top of the effects of the earth–moon system.</p>
<p>The mass of the sun is 27 × 106 times the mass of the moon but its distance from the earth is 400 times that of the moon. Because of this great distance, the gravitational attraction on a particle of water on the earth due to the sun is about one-half that due to the moon. So we can construct diagrams like those shown in Figs. 7.03 and 7.04 for the tide due to the sun, but the height of the tide will be only half that due to the moon. The important effect of the tide due to the sun arises because its tidal bulge moves relative to the moon’s tidal bulge through- out the lunar month.</p>
<p>When the two tidal bulges coincide they add together to create the extra high tides called the spring tides. When the tidal bulges are opposed their effects tend to cancel one another, creating the neap tides. Thus, the equilibrium tide model can also qualitatively explain the fortnightly inequality in addition to the other effects.</p>
<h3 id="tides-in-the-real-ocean">Tides in the real ocean</h3>
<p>The next development of tide theory is dynamic theory of tide. It considered the continents, topography, Coriolis force and friction force, etc.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208170201.png"></p>
<p>This is the <strong>Laplace's tidal equations</strong>. But it is hard to solve. For prediction, one solution is that we can decompose the tide. We can think the real tide in our ocean is composed by a lot of tide constituents . Each tide constituents induced by each an imaginary planets. There are three main categories of constituents (Pond and Pickard 1983):</p>
<ol type="1">
<li>semi-diurnal, period about 12 hours</li>
<li>diurnal, period about 24 hours</li>
<li>long period, greater than 24 hours.</li>
</ol>
<p>The four most important constituents are:</p>
<ol type="1">
<li>The lunar semi-diurnal ,M2, Period=12.42h</li>
<li>The solar semi-diurnal, S2, Period=12.00h</li>
<li>The lunisolar diurnal, K1, Period=23.93h</li>
<li>The principal lunar diurnal, O1, period=25.82h</li>
</ol>
<p>The M2 constituent is roughly twice the amplitude of the other three.</p>
<p>In different location around the word, the relative importance of constituents is quite different. So we have different patterns of tides. The four main classifications of the form of the tides are illustrated in the next figure.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208172014.png"></p>
<p>The first one has two high tides and two low tides every day and Both the highs are about the same height and both the lows are about the same height. Such a tide is called a semi-diurnal in form because there are two per day and both are about the same height.In this case the semi-diurnal constituents dominate the diurnal ones. This fact is often quantified with the ratio F = (K1+O1)/(M2 + S2 ), where each letter stands for the amplitude of the constituent. If F is small (0.11), as in the upper record, the sum of the amplitudes of the diurnal constituents (K1+O1 ) is small relative to the sum of the semi-diurnal ones (M2+S2 ).</p>
<p>The four records in Fig. 7.05 show a marked decrease from top to bottom in the amplitude of the semi-diurnal tidal oscillation relative to the diurnal oscillation, which is confirmed by the increase in F from 0.11 to ~19. At San Francisco there are always two tides per day but they are usually of unequal amplitude. At Manila there are two tides per day during the neap tides but only one rise and fall per day during spring tides. At Do-Son there is only one rise and fall of the tide per day throughout the month, which is a purely diurnal form of tidal oscillation. This occurrence is the rarest form of tide. The changing form of the tide between locations is due partly to the shape of the ocean basin in which the tidal wave is contained and partly to the latitude (Hendershott 1981).</p>
<h3 id="moving-the-tidal-bulge-over-the-earth-kelvin-waves">Moving the tidal bulge over the earth: Kelvin waves</h3>
<p>The former one is more focus on the coast, if we focus on a more large scale, the water depth is almost the same and the friction from the topography could be ignored. More idealized, if we assume the coast line is straight, we could get One solution of former dynamic tide equation set is that the velocity of tide is</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208202646.png"></p>
<p>here g is Gravitational acceleration and k is the depth of the water. and the Kelvin wave is a reasonable approximation for tidal waves in the vicinity of a straight coastline.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208204932.png"></p>
<p>And here the Coriolis force is an important feature of the motion.</p>
<p>. The effect of the Coriolis force is to push the water to the right in the northern hemisphere</p>
<p>The Coriolis effect causes the amplitude of the wave to increase toward the shore and leads to the expression that the wave is “trapped” against the shore. Such a trapped Kelvin wave causes the water particles to move back and forth parallel to the coast as the wave goes by</p>
<p>The horizontal scale of the wave, or the approximate distance from the coast to where the sea level is undisturbed by the wave, is estimated by the Rossby radius.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208205203.png"></p>
<p>For the Kelvin wave in Fig. 7.06 we put g = 10 m s−2 , h = 4000 m, and f= 10−4 s−1 to get Re = 2000 km. This value is commonly called the external Rossby radius, or deformation scale</p>
<h3 id="tidal-currents">Tidal currents</h3>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>book-reading-note3</title>
    <url>/posts/33f4c7b7.html</url>
    <content><![CDATA[<p>Chapter 8.3.2.-8.4.4 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<p>Good afternoon everyone, today I will talk two part. The first part is the from section three, the distribution of biological production in ocean basin. The second part is section four, biology of eddies and rings.</p>
<p>And in the first part, I'd like to add an additional story about Japanese eel.</p>
<h1 id="distribution-of-biological-production-in-ocean-basin">8.3 Distribution of biological production in ocean basin</h1>
<h2 id="eels-and-the-north-atlantic-gyre">8.3.2 Eels and the North Atlantic gyre</h2>
<p>Eel is a very important fishery species globally. Here I show And one of the very confusion problem about it ,In a long time, Fishermen never caught anything they could identify as a young eel. So where is the young eel? It is very important to find Find spawning area,Get egg for aquaculture and Establish fishing policy.</p>
<p>In 1922，Schmidt propose a Starling theory about eel, contain three part</p>
<p>•Two species in the North Atlantic: European eel and America eel</p>
<p>•Morphological change when grow up</p>
<p>•Both spawning in Sargasso Sea</p>
<p>The fisrt part is confirmed by various research such as the difference in Muscle blocks</p>
<p>,Vertebrae,Parasite,mtDNA. The second one also.</p>
<p>The most difficult part to prove last part. If they both saw in the Sargasso Sea, how can they travel such long distance as a larvae? One answer that easily to think is by basin current. But American eel only live in the side of American, European eel only live in the side of European. So the next question is why they come to different region with same current?</p>
<p>So let us open the mystery of American eel first. It is based one research about larvae distribuiton.</p>
<p>The American eel always spawns from mid Februrary to April. After spawning, they will enter the Gulf Stream in a growth rate about 0.24 millimetre per day from February to October. Some part might enter Antilles Current or Caribbean Current. But they will finnally enter gulf stream by Apr.</p>
<p>Then we can notice the distribution of most abundant larvae in the coastal. The time is not spawning season. So after spawning, the larvae will move north first, then come back south. Base one this observation, the author conclude that the larvae will Larvae actively migrate westword out of Gulf Stream. And in the north boundary, the larvae will be Carried southward passively by Larador Current and Slope water.</p>
<p>Anothe research base on the age also support the trend of southward movement of larvae. So as a result , the American eel will be Tapped in America by self movement and current, instead of going to European.</p>
<p>So obviously, the European eel larvae will not move out Gulf Stream, then it will enter North Atlantic Current and takes one or two years to reach European. In the end, they will back to Sagarsso Sea by Canary Current and North Equatorial Current.</p>
<p>In 1980s, a drastic decline in the catch of both America and European eel occurred. The solid line is the catch in Nervertheland,represent European eel. And the dotted line is the catch in Canada, represented the Catch of European eel. The Polution and habitat destruction may affect , but could not produce such big decline. A more probable reason is the ocean-scale change. One is the Slowing of Gulf Stream. As a result, the larvae will miss the best time to metaphose, and will be hunted by other species. Another one is there are more More warm core rings created by Gulf Stream, which could bring larvae out of Gulf Stream.</p>
<h2 id="salmon-and-the-alaskan-gyre">8.3.3 Salmon and the Alaskan gyre</h2>
<p>Another speices talked here is salmon fish. Unlike eel, it will spawn in fresh water and feed and grows in the sea. It's full migration pattern is known untill 1960. Here we will talke about two species, pink salmon and sockeye salmon. These are the two most productive types of salmon.</p>
<p>For the pink salmon, it usually</p>
<ul>
<li>Spawn in rive from mid-Jul. to mid-Oct</li>
<li>•Migrate out to the ocean between Jul. and Sep. in one year old</li>
<li>•Travel between 5500km and 7500km with Alaskan Gyre in one year</li>
<li>•Move north and west in summer, travel and feed along the coast</li>
<li>•Move 10° south into west-wind drift in winter</li>
<li>•Come back to parent river to spawn at two years old</li>
</ul>
<p>So it will Travel with Alaskan Gyre for one year with one circuits.</p>
<p>For the sockeye salmon, it usually</p>
<p>•Stay one or two winters in fresh water</p>
<p>•Stay two years in the sea, travle two circuits Alaskan Gyre from British Columbia</p>
<p>•Stay three years in the sea, one circle in Bering Gyre and two circuits in Alaskan Gyre from river on the shore of Bering Sea</p>
<p>So it will Travel with Alaskan Gyre for two year(additional year with Bering Gyre) with two (three) circuits.</p>
<h2 id="transport-of-invertebrate-larvae-across-ocean-basin">8.3.4 Transport of invertebrate larvae across ocean basin</h2>
<p>Besides fish, the larvae of invertebrate also could be transported. The fisrt evident is founded by Scheltema. He found the larvae of gastropod throughout Gulf Stream and North Atalantic Current. And he kept larvae alive in lab longer than necessary for transtport.</p>
<p>Both proof that Invertebrate larvae could be transported across ocean basins .</p>
<h1 id="biology-of-eddies-and-rings-associated-with-major-currents">8.4 Biology of eddies and rings associated with major currents</h1>
<p>The next session is about the biology of eddies and rings associated with major current.Include four part.</p>
<p>•Gulf Stream frontal eddies</p>
<p>•Formation of Gulf Stream rings</p>
<p>•Ecology of cold-core rings</p>
<p>•Ecology of warm-core rings</p>
<h2 id="gulf-stream-frontal-eddies">8.4.1 Gulf Stream frontal eddies</h2>
<p>The first one is about Gulf stream frontal eddies.</p>
<p>•Usually occur when the distance between Gulf Stream and coast is great.</p>
<p>•Finger like extention from Gulf Stream</p>
<p>•A new one formed every two weeks on average in the south of Cap Hatteras</p>
<p>•Introduce about 55,000 tons of nitrogen annually to the outer shelf(Lee, 1981)</p>
<p>•Breeding center for some species such as blue fish</p>
<h2 id="formation-of-gulf-stream-rings">8.4.2 Formation of Gulf Stream rings</h2>
<p>About the ring.</p>
<p>The ring will occur if the meander of Gulf Stream become too large.</p>
<p>•Every one or two month create a ring in the North of Cap Hatters</p>
<p>•Cold core ring in the south and warm core in the north</p>
<p>•Move southwesterly about 3-5km per day</p>
<h2 id="ecology-of-cold-core-rings">8.4.3 Ecology of cold-core rings</h2>
<p>Regarding the ecology of cold-core rings. Here is the verticle profile of a cold-core ring. The line is the isotherms.</p>
<p>Compared with Sargasso Sea, it contains Larger concentration of plankton, nekton and nutrient from continent shelf.</p>
<p>The Counter-clockwise rotation lead to upwelling in the center and •Bring nutrient-enriched water into the euphotic zone.</p>
<p>As a result, it is more productive than surrounding water.</p>
<p>Another feature of a cold-core ring is that Biological characteristcs change rapidlly than physical characteristics.</p>
<p>The chlorophyll-a in a cold coring is much higher in April, but will Declined eight times in August.</p>
<p>The phytoplankton species will become smaller and diversity will becom greater with time, more like the surrounding waters.</p>
<p>As for the zooplankton, the original zooplankton could not be found in a 17-month-old ring.</p>
<p>And the larvae and mesopelagic fish will also become more like surrouding water in Sargasso Sea with time.</p>
<p>I found some satellite image from NOAA. The left is the SST and chlorophyll-a in MARCH 2019, the right is in April. In the SST, we could find the cold -core ring in the red square in both image. But in the Chla. we can see some difference between cold core ring and Sargasso Sea in March. In April, we could barely see that.</p>
<p>This also indicate that Biological characteristcs change rapidlly than physical characteristics.</p>
<h2 id="ecology-of-warm-core-rings">8.4.4 Ecology of warm-core rings</h2>
<p>Warm-core ring is in clockwise circulation and will cause downwelling at the center. It lacks nutrient in the center.</p>
<p>Usually, we will think it is Biological unproductive.</p>
<p>But the fact is that it productivity is not very different from surronding water.</p>
<p>It has two enhance mechanisms</p>
<p>•Upwelling the nutrient-rich water in the thermostad (deep mix layer) to the periphery</p>
<p>•Convective mixing caused by surface water as move north</p>
<p>As for the species in the warm core rings.</p>
<p>The biomass of mesozooplankton is low and will increase by time.</p>
<p>The nonmigratory mesopelagic fish and siponiphores do not have significant change in the warm-core rings.</p>
<p>And the warm-core rings in the eastern boundaries of Gulf Stream is preferred by sperm whales.</p>
<p>The warm-core ring contacts with the continetal shelf usually. Because it is in clockwise, it will drag cold water from shelf by rotation movement to northern side and enhance poductivity.</p>
<p>These two figure is about the chla in the Georges bank, the red square is the area of georges bank. And here is a cold core ring. We can see that the chl-a is clearly enhanced by the offshore movement of shelf water, which accompanied by vigorous upwelling and vertical mixing.</p>
<p>And it will also drag cold water from shelf by rotation movement to offshore</p>
<p>This will bring larvae of sand lance, and larvae and juvenile of white hake offshore, which could •Result in the loss of population</p>
<p>As estimated, Increased warm-core activity was associated with reduced recruitment in 15 commercial species.</p>
<p>Besides, it will also bing •Warm water onto the shelf on the western and sourthern side of rings. This will make Tropical and subtropical fish larvae is founded in the high latitude .</p>
<p>In summary</p>
<ul>
<li>•Eel and salmon is transported by gyre to finish life histroy</li>
<li>•Basin-scale change may affect theire population</li>
<li>•Interterbrates also could be transport across ocean basin</li>
<li>•Frontal eddies could enhance productivity and is breeding center for some species</li>
<li>The cold core ring and warm core ring have different ecology effect as in this table</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>cartopy</title>
    <url>/posts/c6b8edee.html</url>
    <content><![CDATA[<p>Basemap在2020年底停止维护，取而代之的是cartopy，在这里写一下一些学习笔记。</p>
<p>先说结论，截止到2020年8月1日,0.18版本仍然不能完全取代basemap，尤其是近岸数据分辨率的问题，但是已经展现出优势了，自己要在之后多多尝试使用。</p>
<a id="more"></a>
<h1 id="代码范例">代码范例</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> netCDF4 <span class="keyword">as</span> nc</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> cartopy.crs <span class="keyword">as</span> ccrs</span><br><span class="line"><span class="keyword">import</span> cartopy.feature <span class="keyword">as</span> cfeature</span><br><span class="line"><span class="keyword">from</span> cartopy.mpl.gridliner <span class="keyword">import</span> LONGITUDE_FORMATTER, LATITUDE_FORMATTER</span><br><span class="line">file=<span class="string">r&#x27;I:\Nagoya University\Project\Seto\MODIS\20100608T04.nc&#x27;</span></span><br><span class="line">nc=nc.Dataset(file,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">lon=nc.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;longitude&#x27;</span>][:]</span><br><span class="line">lat=nc.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;latitude&#x27;</span>][:]</span><br><span class="line">variables=nc.groups[<span class="string">&#x27;geophysical_data&#x27;</span>].variables</span><br><span class="line">chl=variables[<span class="string">&#x27;chlor_a&#x27;</span>]</span><br><span class="line">minlat = <span class="number">32.5</span></span><br><span class="line">minlon = <span class="number">130.5</span></span><br><span class="line">maxlat = <span class="number">35</span></span><br><span class="line">maxlon = <span class="number">136</span></span><br><span class="line">f = plt.figure(figsize=(<span class="number">20</span>, <span class="number">20</span>), dpi=<span class="number">300</span>)</span><br><span class="line">m = plt.axes(projection=ccrs.PlateCarree(central_longitude=<span class="number">0.0</span>))</span><br><span class="line">f = plt.pcolormesh(lon, lat,chl, shading=<span class="string">&#x27;flat&#x27;</span>, vmin=np.log10(<span class="number">0.01</span>), vmax=np.log10(<span class="number">50</span>), cmap=plt.cm.viridis)</span><br><span class="line">m.coastlines(resolution=<span class="string">&#x27;10m&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">extent=[<span class="number">130.5</span>,<span class="number">136</span>,<span class="number">32</span>,<span class="number">35</span>]</span><br><span class="line">m.set_extent(extent)</span><br><span class="line">m.add_feature(cfeature.RIVERS)</span><br><span class="line">m.add_feature(cfeature.COASTLINE.with_scale(<span class="string">&#x27;10m&#x27;</span>))</span><br><span class="line">m.add_feature(cfeature.LAND.with_scale(<span class="string">&#x27;10m&#x27;</span>), facecolor=<span class="string">&#x27;0.75&#x27;</span>)</span><br><span class="line"></span><br><span class="line">g1 = m.gridlines(draw_labels = <span class="literal">True</span>)</span><br><span class="line">g1.xlabels_top = <span class="literal">False</span></span><br><span class="line">g1.xlabel_style = &#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;gray&#x27;</span>&#125;</span><br><span class="line">g1.ylabel_style = &#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;gray&#x27;</span>&#125;</span><br><span class="line">g1.xformatter = LONGITUDE_FORMATTER</span><br><span class="line">g1.yformatter = LATITUDE_FORMATTER</span><br><span class="line">cbar = plt.colorbar(f, orientation=<span class="string">&quot;horizontal&quot;</span>, fraction=<span class="number">0.05</span>, pad=<span class="number">0.07</span>, ticks=[np.log10(<span class="number">0.01</span>), np.log10(<span class="number">0.1</span>),np.log10(<span class="number">0.5</span>), np.log10(<span class="number">1</span>),np.log10(<span class="number">3</span>),np.log10(<span class="number">10</span>),np.log10(<span class="number">50</span>)]) </span><br><span class="line">cbar.ax.set_xticklabels([<span class="string">&#x27;0.01&#x27;</span>,<span class="string">&#x27;0.1&#x27;</span>,<span class="string">&#x27;0.5&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;10&#x27;</span>,<span class="string">&#x27;50&#x27;</span>], fontsize=<span class="number">20</span>) </span><br><span class="line">cbar.set_label(<span class="string">&#x27;Chlorophyll, mg m$^&#123;-3&#125;$&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MODIS [Chl a] mg m$^&#123;-3&#125;$&#x27;</span>, fontsize=<span class="number">20</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>相比basemap这个方便很多，但是分辨率还是有一点问题。</p>
<h1 id="一些参考资料">一些参考资料</h1>
<p>https://zhajiman.github.io/post/cartopy_introduction/</p>
<p>https://scitools.org.uk/cartopy/docs/latest/index.html</p>
<p>https://www.net-analysis.com/blog/cartopylayout.html</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows环境下hexo博客搭建</title>
    <url>/posts/b1f5683b.html</url>
    <content><![CDATA[<p>自己算来算去都搭建了三次博客了，前两次是在ubuntu上，第二次在ubuntu搭建的时候花费了好多时间解决node.js和npm的问题，索性这次就在windows上了，虽然windows的命令行用着很蛋疼，但是架不住方便啊。赶紧把博客搭出来写文章才是最主要的。</p>
<a id="more"></a>
<p>每次搭建都得花好多时间搜集资料贴，这次索性把资料贴整理出来，免得自己下次再去到处找。</p>
<h2 id="博客生成">博客生成</h2>
<h3 id="入门">入门</h3>
<p>Github Pages可以被认为是用户编写的、托管在github上的静态网页。使用Github Pages可以为你提供一个免费的服务器，免去了自己搭建服务器和写数据库的麻烦。此外还可以绑定自己的域名。因此，我们需要去<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLw==">github官网<i class="fa fa-external-link-alt"></i></span>注册一个账号。</p>
<p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p>
<h3 id="安装环境">安装环境</h3>
<p>1.安装<span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS8=">git<i class="fa fa-external-link-alt"></i></span></p>
<p>2.安装<span class="exturl" data-url="aHR0cHM6Ly9ub2RlanMub3JnL2VuLw==">node.js<i class="fa fa-external-link-alt"></i></span></p>
<p>以上两步对于windows用户来说非常友好了，按照默认来装就可以了。</p>
<p>3.安装hexo</p>
<p>右键呼出git bash。输入： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo</span><br><span class="line">npm install hexo-deployer-git --save </span><br></pre></td></tr></table></figure> 然后输入<code>hexo -v</code> 出现一系列版本号就是安装成功了，像我这样 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo -v</span><br><span class="line">hexo: 3.8.0</span><br><span class="line">hexo-cli: 1.1.0</span><br><span class="line">os: Windows_NT 10.0.17763 win32 x64</span><br><span class="line">http_parser: 2.8.0</span><br><span class="line">node: 10.15.3</span><br><span class="line">v8: 6.8.275.32-node.51</span><br><span class="line">uv: 1.23.2</span><br><span class="line">zlib: 1.2.11</span><br><span class="line">ares: 1.15.0</span><br><span class="line">modules: 64</span><br><span class="line">nghttp2: 1.34.0</span><br><span class="line">napi: 3</span><br><span class="line">openssl: 1.1.0j</span><br><span class="line">icu: 62.1</span><br><span class="line">unicode: 11.0</span><br><span class="line">cldr: 33.1</span><br><span class="line">tz: 2018e`</span><br></pre></td></tr></table></figure> 如果不成功的话可以同时按下win和R，输入cmd,分别使用如下三个命令，如果有一个没有返回版本信息则说明这个软件装失败。 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git --version</span><br><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure> ### 生成博客 从现在开始，你在windows和ubuntu下的操作几乎一样了。在网上搜帖子的时候如果是ubuntu系统下的解决方案也可以尝试在windows下解决。</p>
<p>新建文件夹，例如我的文件夹为： I。博客相关文件将储存在此文件夹下。右键呼出gitbash。输入以下命令： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure> 如果最后出现 &gt;Start blogging with Hexo!</p>
<p>则说明生成成功。</p>
<p>执行以下命令 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure> 显示以下信息说明操作成功 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure> 执行完可以登录http://localhost:4000/ 查看效果。 ## 博客部署 到目前为止，我们只能通过本地连接查看博客，接下来我们需要把他部署在github pages上。来，让我们登录我们上一步申请的账号。 ### 创建项目代码库 点击 New 创建一个代码库。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/resp.png"></p>
<p>在这里需要注意仓库名必须是 用户名.github.io的形式（我这里因为已经申请了所以显示无法创建）。最后记得勾选初始化readme文件。</p>
<h3 id="配置ssh密钥">配置ssh密钥</h3>
<p>配置好SSH密钥之后，才可以通过git实现本地代码库与github代码库同步。右键唤出gitbash进入你新建的文件夹（例如我的是I:)，输入以下命令： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -C <span class="string">&quot;your email@example.com&quot;</span> </span><br><span class="line"> //引号里面填写你的邮箱地址，比如我的是zhouthepassion@outlook.com</span><br></pre></td></tr></table></figure> 之后会出现： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Generating public/private rsa key pair.  </span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/c/Users/you/.ssh/id_rsa):  </span><br><span class="line">//到这里可以直接回车将密钥按默认文件进行存储</span><br></pre></td></tr></table></figure> 然后会出现 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase):  </span><br><span class="line">//这里是要你输入密码，其实不需要输什么密码，直接回车就行 </span><br><span class="line">Enter same passphrase again: </span><br></pre></td></tr></table></figure> 接下来屏幕会显示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Your identification has been saved <span class="keyword">in</span> /c/Users/you/.ssh/id_rsa.  </span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /c/Users/you/.ssh/id_rsa.pub.  </span><br><span class="line">The key fingerprint is:  </span><br><span class="line">这里是各种字母数字组成的字符串，结尾是你的邮箱  </span><br><span class="line">The key<span class="string">&#x27;s randomart image is:  </span></span><br><span class="line"><span class="string">这里也是各种字母数字符号组成的字符串 </span></span><br></pre></td></tr></table></figure>
<p>运行以下命令,将公钥的内容复制粘贴到系统粘贴板上。 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ clip &lt; ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure> ### 在github账户中添加你的公钥 点击你的github头像，进入settings，点击SSH and GPG Keys，选择New SSH key，然后把你刚才复制的公填在key那里就可以了，title可以随便填，最后点击下面的add ssh key。 ### 测试 输入以下命令 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh -T git@github.com</span><br></pre></td></tr></table></figure> 之后会显示 &gt;Are you sure you want to continue connecting(yes/no)? &gt;</p>
<p>输入yes后显示 &gt;Hi,XXXXX!You've successfully authenticated, but GitHub does not provide shell access. &gt;</p>
<p>表示设置正确。 ### 配置Git个人信息 这一步相当于赋予你的电脑连接到github的权限。输入以下命令 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git config --global user.name <span class="string">&quot;此处填你的用户名&quot;</span>  </span><br><span class="line">$ git config --global user.email  <span class="string">&quot;此处填你的邮箱&quot;</span></span><br></pre></td></tr></table></figure> 到此为止SSH Key配置成功 ## 将本地hexo文件更新到GitHub仓库中 打开创建的文件夹，打开_config.yml文件（这里推荐使用Notepad++）</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/deploy.png"></p>
<p>拉到最后，修改deploy的属性 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  </span><br><span class="line">  repo: git@github.com:username/username.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure> 其中username改为你的用户名。注意冒号之后必须空一个英文空格。 在创建的文件夹中分别执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo g  </span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>
<p>或者直接 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure> 执行完之后会让你输入你的Github账号和密码。如果显示以下错误，说明你的deployer没有安装成功。 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ERROR Deployer not found: git</span><br></pre></td></tr></table></figure> 那就执行以下命令再安装一次: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure> 再执行<code>hexo g -d</code>，你的博客就会部署到github上了。你的网址就是https://username.github.io ## 在博客上发表文章</p>
<ol type="1">
<li><p>新建文章</p>
<p>新建一个空文章，输入以下命令，会在项目 _posts 中生成 文章标题.md 文件，文章标题根据需要命名</p></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo n <span class="string">&quot;文章标题&quot;</span></span><br><span class="line">More info: [Writing](https://hexo.io/docs/writing.html)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li><p>编辑文章</p>
<p>Markdown 是 2004 年由 John Gruberis 设计和开发的纯文本格式的语法，非常的简单实用，常用的标记符号屈指可数，几分钟即可学会， .md 文件可以使用支持 Markdown 语法的编辑器编辑，我这里使用的是typora来编辑，对于初学者十分友好。这里贴出一个Markdown格式的<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC8xZTQwMjkyMmVlMzI=">语法指南<i class="fa fa-external-link-alt"></i></span></p></li>
<li><p>发布文章</p>
<p>文章写好后，可以使用如下命令发布</p></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo g  </span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>
<p>或者直接 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure></p>
<p>然后就可以在刚才的网址里面看到你写的文章了</p>
<h2 id="参考资料">参考资料</h2>
<p>搭建：https://blog.csdn.net/qq_36759224/article/details/82121420</p>
<!--


乱码解决：https://blog.csdn.net/Aoman_Hao/article/details/79275570

;实用：https://blog.csdn.net/qq_36759224/article/details/85010191

;美化：https://blog.csdn.net/qq_36759224/article/details/85420403

;常见错误：http://www.aichengxu.com/other/2538446.htm

;next配置：http://theme-next.iissnan.com/theme-settings.htm

;关于页面：https://www.jianshu.com/p/7667d8e8f91c

;英文标签改中文改前面就行

;https://blog.csdn.net/qq_32337109/article/details/78755729只展示一部分;
;https://blog.csdn.net/lewky_liu/article/details/81277337



;gitalkhttps://asdfv1929.github.io/2018/01/20/gitalk/

;issue:https://liujunzhou.top/2018/8/10/gitalk-error/#%E6%9C%AA%E6%89%BE%E5%88%B0%E7%9B%B8%E5%85%B3%E7%9A%84Issues%E8%BF%9B%E8%A1%8C%E8%AF%84%E8%AE%BA%EF%BC%8C%E8%AF%B7%E8%81%94%E7%B3%BBXXX%E8%BF%9B%E8%A1%8C%E5%88%9B%E5%BB%BA

;分析https://marketingplatform.google.com/about/analytics/

;https://www.cnblogs.com/tengj/p/5357879.html

;```text
tags: [标签1,标签2,标签3]

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">;http:&#x2F;&#x2F;cnneillee.github.io&#x2F;2017&#x2F;05&#x2F;10&#x2F;hexo&#x2F;Hexo%E8%BF%9B%E9%98%B6%E2%80%94%E2%80%94%E6%B7%BB%E5%8A%A0%E7%AB%99%E7%82%B9%E5%9C%B0%E5%9B%BE&#x2F;</span><br><span class="line"></span><br><span class="line">;sitemap</span><br><span class="line"></span><br><span class="line">;提交http:&#x2F;&#x2F;fionat.github.io&#x2F;blog&#x2F;2013&#x2F;10&#x2F;23&#x2F;sitemap&#x2F;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;https:&#x2F;&#x2F;alanlee.fun&#x2F;2017&#x2F;12&#x2F;30&#x2F;google-sitemap&#x2F;</span><br><span class="line"></span><br><span class="line">;https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;efbeddc5eb19</span><br><span class="line">;备份</span><br><span class="line">https:&#x2F;&#x2F;www.simon96.online&#x2F;2018&#x2F;10&#x2F;12&#x2F;hexo-tutorial&#x2F;</span><br></pre></td></tr></table></figure>
<p>RSS：https://segmentfault.com/a/1190000012647294</p>
<p>https://mritd.me/2016/03/08/Hexo%E6%B7%BB%E5%8A%A0Rss%E8%AE%A2%E9%98%85/</p>
<p>leancloud:https://lfwen.site/2016/05/31/add-count-for-hexo-next/</p>
<p>https://lruihao.cn/hexo/hexo-%E6%B7%BB%E5%8A%A0%E5%9B%BE%E7%89%87%EF%BC%8C%E9%9F%B3%E4%B9%90%EF%BC%8C%E9%93%BE%E6%8E%A5%EF%BC%8C%E8%A7%86%E9%A2%91.html 网易云 图片 视频</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC8yNzU2NzI0YTVkZWU=">https://www.jianshu.com/p/2756724a5dee<i class="fa fa-external-link-alt"></i></span>图片问题终于解决了</p>
<p>百度推广https://www.jianshu.com/p/8c0707ce5da4</p>
<p>RSS<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEzMDM0NDMvYXJ0aWNsZS9kZXRhaWxzLzUyMzMzNjk1">https://blog.csdn.net/u011303443/article/details/52333695<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnRhbmd4aWFvemh1LmNvbS8xNTI1MDkyMjMyOTczMy5odG1s">https://blog.tangxiaozhu.com/15250922329733.html<i class="fa fa-external-link-alt"></i></span>深度定制</p>
<p><span class="exturl" data-url="aHR0cDovL2xpdXFp5pel5Y6G5LqRbmd3ZW4ubWUvYmxvZy8yMDE4LzEwLzI2L3NoYXJlLWEtY3V0ZS1oZXhvLWJsb2ctcGx1Z2luLXRoZS1jbG91ZC1jYWxlbmRhci8=">http://liuqi日历云ngwen.me/blog/2018/10/26/share-a-cute-hexo-blog-plugin-the-cloud-calendar/<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly90YW5rZXJ5YW5nLmdpdGh1Yi5pby9wb3N0cy9IZXhvJTIwKyUyME5leFQlMjArJTIwR2l0aHViJTIwUGFnZXMlMjArJTIwQ29kaW5nJTIwUGFnZXMlMjArJTIwR2l0ZWUlMjBQYWdlcyUyMCslMjBUcmF2aXMlMjDlhajmlLvnlaUv">https://tankeryang.github.io/posts/Hexo%20+%20NexT%20+%20Github%20Pages%20+%20Coding%20Pages%20+%20Gitee%20Pages%20+%20Travis%20%E5%85%A8%E6%94%BB%E7%95%A5/<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9zZXNwcmllLmJpZC9hcnRpY2xlcy8yMS5odG1s">https://sesprie.bid/articles/21.html<i class="fa fa-external-link-alt"></i></span>进度条</p>
<p>自己要好好想想怎么实现follow效果</p>
<p>升级<span class="exturl" data-url="aHR0cHM6Ly8xMS50dC9wb3N0cy8yMDE4L2hvdy10by11cGRhdGUtaGV4by10aGVtZS1uZXh0Lw==">https://11.tt/posts/2018/how-to-update-hexo-theme-next/<i class="fa fa-external-link-alt"></i></span></p>
<p>后面这些还有</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC81Y2FkZGQxZmYyNjVkYTAzNWUyMTBkY2UjaGVhZGluZy00OQ==">https://juejin.im/post/5caddd1ff265da035e210dce#heading-49<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9lMjExZTkxMTk1MjI=">https://www.jianshu.com/p/e211e9119522<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly93aGprbS5naXRodWIuaW8vMjAxOC8wNy8xNy9IZXhv54mI5pys5Y2H57qn5ZKMTmV4dOS4u+mimOWNh+e6p+S5i+WdkS8=">https://whjkm.github.io/2018/07/17/Hexo%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%E5%92%8CNext%E4%B8%BB%E9%A2%98%E5%8D%87%E7%BA%A7%E4%B9%8B%E5%9D%91/<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RoZW1lLW5leHQvaGV4by10aGVtZS1uZXh0L2Jsb2IvbWFzdGVyL2RvY3MvemgtQ04vVVBEQVRFLUZST00tNS4xLlgubWQ=">https://github.com/theme-next/hexo-theme-next/blob/master/docs/zh-CN/UPDATE-FROM-5.1.X.md<i class="fa fa-external-link-alt"></i></span></p>
<p>hexo-wordcounthttps://github.com/theme-next/hexo-symbols-count-time</p>
<p>代码复制</p>
<p>--&gt;</p>
-->]]></content>
      <categories>
        <category>资料贴整理</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title>hyperspectral and phytoplankton</title>
    <url>/posts/ed08fed2.html</url>
    <content><![CDATA[<p>This is an Annotated Bibliography for the doctor proposal.</p>
<p>Hyperspectral Remote Sensing of Phytoplankton Species Composition Based on Transfer Learning</p>
<p>Hyperspectral Differentiation of Phytoplankton Taxonomic Groups: A Comparison between Using Remote Sensing Reflectance and Absorption Spectra</p>
<p>Distinguishing cyanobacteria from algae in optically complex inland waters using a hyperspectral radiative transfer inversion algorithm</p>
<p>Hyperspectral optical discrimination of phytoplankton community structure in Funka Bay and its implications for ocean color remote sensing of diatoms</p>
<p>Remote estimation of phytoplankton size fractions using the spectral shape of light absorption</p>
<p>On the discrimination of multiple phytoplankton groups from light absorption spectra of assemblages with mixed taxonomic composition and variable light conditions</p>
<p>Linking phytoplankton absorption to community composition in Chinese marginal seas</p>
<p>Another way is to see the analyze the NPP/PSC</p>
<p>Ultimate goal is to propose a hypothesis-test 的论文，并且跟我现在的修士论文有联系</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Inherent Optical Properties</tag>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
        <tag>Phytoplankton</tag>
      </tags>
  </entry>
  <entry>
    <title>kriging</title>
    <url>/posts/f4af350.html</url>
    <content><![CDATA[<p>Ordinary Kriging</p>
<p>Poisson Kriging-Area to Area</p>
<p>Poisson Kriging-Area to Point</p>
<p>These are the three types inside https://github.com/szymon-datalions/pyinterpolate</p>
<p>I also wan to show how to apply them to satellite image as an practice for APTRK</p>
<a id="more"></a>
<h1 id="general-introduction">General Introduction</h1>
<p>Reference: https://www.youtube.com/watch?v=J-IB4_QL7Oc</p>
<h2 id="problem-setup">Problem Setup</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022110419095.png"></p>
<p>Here we have a island and we take some measurement for some red points. Each point include two attributes. <span class="math inline">\(x_i\)</span> is the location and <span class="math inline">\(y_i\)</span> is the thing we are interested in, like elevation.</p>
<p>Now we want to get the elevation in some other point that we did not explicitly collect data. For example in this black dot.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022110833500.png"></p>
<p>So we just could use the data we have to predict the elevation of black dot. There are five closest red dots to this unknown dot. We are gonna to use these five dots to predict the unknown dots. <span class="math display">\[
y_{new}=w^Ty+\epsilon_{new}\\
=w_1y_1+w_2y_2+...+w_5y_5+\epsilon_{new}
\]</span> This is a linear combination weight of neighbor dots. This is the kirging model. So the important thing is to know the <span class="math inline">\(w\)</span> .</p>
<h2 id="variogram">Variogram</h2>
<p>A general idea is that the closer one should have higher weigh. But how do I formalize this idea in math? Here the things determines the weight is called the variogram. <span class="math display">\[
\gamma(x_i,x_j)=\frac{1}{2}(y_i-y_j)^2
\]</span> This is the equation of variogram. <span class="math inline">\((x_i,x_j)\)</span> indicate the distance between two points. The distance is the input of <span class="math inline">\(\gamma\)</span> function. And the output of <span class="math inline">\(\gamma\)</span> function is half the difference of elevation. It should be increasing function since the smaller distance, the smaller difference.</p>
<p>So lets plot the graph between H, the distance <span class="math inline">\((x_i,x_j)\)</span> and the output of <span class="math inline">\(\gamma\)</span> function.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022142200533.png"></p>
<p>This graph should reach the plateau as H increase. Because if the distance is two large, the difference should be almost the same, which indicate that the elevation belong to different group.</p>
<p>There are some terminology here. First is the nugget. The nugget is the intercept that our graph begin. It should be not equal to zero. Because the variogram is a fit line and maybe we have a lot of closed dot with different elevation. But it shoul be small.</p>
<p>Second one is the sill. Sill is the silling of a variogram. And the he range is the H value of sill.</p>
<h2 id="solving-model">Solving model</h2>
<p>So we can get the weight from the variogram by solving a matrix equation.</p>
<p><span class="math inline">\(Aw=b\)</span></p>
<p>Here A is the <span class="math inline">\(\gamma(x_i,x_j)\)</span> and b is the <span class="math inline">\(\gamma(x_{new},x_i)\)</span>, <span class="math inline">\(w\)</span> is the vector from <span class="math inline">\(w_1\)</span> to<span class="math inline">\(w_5\)</span></p>
<p>So I can just take a inverse to get the <span class="math inline">\(w\)</span>.</p>
<h2 id="several-assumpution">Several Assumpution</h2>
<ol type="1">
<li>Stationarity: In every small part of island, the change speed of elevation should be almost the same.</li>
<li>Constant variogram. In every small part of the island, the variogram shoul be almost the same.</li>
</ol>
<h2 id="pros-and-cons">Pros and Cons</h2>
<p>Pros: we can estimate the error</p>
<p>Cons: For every new point, we need to solve different equation matrix.</p>
<h1 id="ordinary-kriging">Ordinary Kriging</h1>
<p>Refference: Olea R A. Geostatistics for engineers and earth scientists[M]. Springer Science &amp; Business Media, 2012.</p>
<p>The kriging model we describe before is the ordinary kriging. Kriging covers a range of least-squares methods of spatial prediction.</p>
<ul>
<li>􏰀 Ordinary kriging of a single variable, as described in Section 8.2, is the most robust method and the one most used.</li>
<li>􏰀 Simple kriging (Section 8.9) is rather little used as it stands because we usually do not know the mean. It finds application in other forms such as indicator and disjunctive kriging in which the data are transformed to have known means.</li>
<li>􏰀 Lognormal kriging (Section 8.10) is ordinary kriging of the logarithms of the measured values. It is used for strongly positively skewed data that approximate a lognormal distribution.</li>
<li>􏰀 Kriging with drift (Chapter 9), also known as universal kriging, recognizes both non-stationary deterministic and random components in a variable, estimates the trend in the former and the variogram of the latter, and recombines the two for prediction. This introduces residual maximum likelihood into the kriging procedure (see Section 9.2).</li>
<li>􏰀 Factorial kriging or kriging analysis (Chapter 9) is of particular value where the variation is nested, i.e. more than one scale of variation is present. Factorial kriging estimates the individual components of variation sepa- rately, but in a single analysis.</li>
<li>􏰀 Ordinary cokriging (Chapter 10) is the extension of ordinary kriging of a single variable to two or more variables. There must be some coregionaliza- tion among the variables for it to be profitable. It is particularly useful if some property that can be measured cheaply at many sites is spatially correlated with one or more others that are expensive to measure and are measured at many fewer sites. It enables us to estimate the more sparsely sampled property with more precision by cokriging using the spatial information from the more intensely measured one.</li>
<li>􏰀 Indicator kriging (see Chapter 11) is a non-linear, non-parametric form of kriging in which continuous variables are converted to binary ones (indicators). It is becoming popular because it can handle distribu- tions of almost any kind, and empirical cumulative distributions of estimates can be computed and thereby provide confidence limits on them. It can also accommodate ‘soft’ qualitative information to improve prediction.</li>
<li>􏰀 Disjunctive kriging (see Chapter 11) is also a non-linear method of kriging, but it is strictly parametric. It is valuable for decision-making because the probabilities of exceeding or not exceeding a predefined threshold are determined in addition to the kriged estimates.</li>
<li>􏰀 Probability kriging (not described further in this book) was proposed by Sullivan (1984) because indicator kriging does not take into account the proximity of a value to the threshold, but only its position. It uses the rank order for each value, zðxÞ, normalized to 1 as the secondary variable to estimate the indicator by cokriging. Chile`s and Delfiner (1999) and Goo- vaerts (1997) describe the method briefly.</li>
<li>􏰀 Bayesian kriging (not described further in this book) was introduced by Omre (1987) for situations in which there is some prior knowledge about the drift. It is intermediate between simple kriging, used when there is no drift, and universal kriging where there is known to be drift. The kriging equations are those of simple kriging, but with non-stationary covariances (Chile`s and Delfiner, 1999).</li>
</ul>
<p>Here I just gonna to talk about the three kinds of kriging model. For further you can just find that textbook.</p>
<p>But before we talk more deeply about that two type. Lets write the former introduction more detailed.</p>
<h2 id="theory-of-ordinary-kriging">THEORY OF ORDINARY KRIGING</h2>
<p>The aim of kriging is to estimate the value of a random variable,<span class="math inline">\(Z\)</span>, at one or more unsampled points or over larger blocks, from more or less sparse sample data on a given support, say <span class="math inline">\(z(\boldsymbol{x}_1),z(\boldsymbol{x}_2),...,z(\boldsymbol{x}_N)\)</span>, at points <span class="math inline">\(\boldsymbol{x}_1,\boldsymbol{x}_2,...,\boldsymbol{x}_N\)</span>. The data may be distributed in one, two or three dimensions, though applications in the environmental sciences are usually two-dimensional.</p>
<p>Ordinary kriging is by far the most common type of kriging in practice,and for this reason we focus on its theory here. It is based on the assumption that we do not know the mean. If we consider punctual estimation first, then we estimate <span class="math inline">\(Z\)</span> at a point <span class="math inline">\(\boldsymbol{x}_0\)</span>by <span class="math inline">\(\hat{Z}(\boldsymbol{x}_0)\)</span>, with the same support as the data, by <span class="math display">\[
\hat{Z}(\boldsymbol{x}_0)=\sum_{i=1}^{N}\lambda_i(\boldsymbol{x}_i),
\]</span> where <span class="math inline">\(\lambda_i\)</span> are the weights. To ensure that the estimate is unbiased the weights are made to sum to 1, <span class="math display">\[
\sum_{i=1}^{N}\lambda_i=1
\]</span></p>
<blockquote>
<p>Review about the unbiased, consistent, efficient estimator https://en.wikipedia.org/wiki/Consistent_estimator#Unbiased_but_not_consistent</p>
</blockquote>
<p>and the expected error is <span class="math inline">\(E[\hat{Z}(\boldsymbol{x}_0)-Z(\boldsymbol{x}_0)]=0\)</span>.</p>
<p>The estimation variance is <span class="math display">\[
var[\hat{Z}(\boldsymbol{x}_0)]=E[\{\hat{Z}(\boldsymbol{x}_0)-Z(\boldsymbol{x}_0)\}^2]\\
=2\sum_{i=1}^{N}\lambda_i\gamma(\boldsymbol{x}_i,\boldsymbol{x}_0)-\sum_{i=1}^{N}\sum_{i=1}^{N}\lambda_i\lambda_j\gamma(\boldsymbol{x}_i,\boldsymbol{x}_j)
\]</span> where <span class="math inline">\(\gamma(\boldsymbol{x}_i,\boldsymbol{x}_j)\)</span> is the semivariance of <span class="math inline">\(Z\)</span> between the data points<span class="math inline">\(\boldsymbol{x}_i\)</span> and <span class="math inline">\(\boldsymbol{x}_j\)</span>, and <span class="math inline">\(\gamma(\boldsymbol{x}_i,\boldsymbol{x}_0)\)</span> is the semivariance between the ith data point and the target point <span class="math inline">\(x_0\)</span>.</p>
<blockquote>
<p>Semi variance:http://www.kgs.ku.edu/Tis/surf3/s3krig2.html</p>
</blockquote>
<p>In the more general case we may wish to estimate <span class="math inline">\(Z\)</span> in a block <span class="math inline">\(B\)</span>, which may be a line, an area or a volume depending on whether it is in one, two or three spatial dimensions. The kriged estimate in <span class="math inline">\(B\)</span> is still a simple weighted average of the data, <span class="math display">\[
\hat{Z}(\boldsymbol{B})=\sum_{i=1}^{N}\lambda_iz(\boldsymbol{x}_i),
\]</span> but with <span class="math inline">\(x_0\)</span> of equation (3) replaced by <span class="math inline">\(B\)</span>. Its variance is <span class="math display">\[
var[\hat{Z}(\boldsymbol{B})]=E[\{\hat{Z}(\boldsymbol{B})-Z(\boldsymbol{B})\}^2]\\
=2\sum_{i=1}^{N}\lambda_i\gamma(\boldsymbol{x}_i,\boldsymbol{B})-\sum_{i=1}^{N}\sum_{i=1}^{N}\lambda_i\lambda_j\gamma(\boldsymbol{x}_i,\boldsymbol{x}_j)-\bar{\gamma}(B,B).
\]</span> The quantity <span class="math inline">\(\bar\gamma(\boldsymbol{x}_i,B)\)</span> is the average semivariance between the <span class="math inline">\(i\)</span>th sampling point and the block <span class="math inline">\(B\)</span> and is the integral <span class="math display">\[
$\bar\gamma(\boldsymbol{x}_i,B)$ =\frac{1}{B}\int_B\gamma(\boldsymbol{x}_i,\boldsymbol{x})d\boldsymbol{x},
\]</span> where <span class="math inline">\(\gamma(\boldsymbol{x}_i,\boldsymbol{x})\)</span> denotes the semivariance between the sampling point xi and a point x describing the block.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022160855202.png"></p>
<p>The third term on the right-hand side of equation (7) is the double integral <span class="math display">\[
\bar{\gamma}(B,B)=\frac{1}{|B^2|}\int_B\int_B\gamma(\boldsymbol{x},\boldsymbol{x^{\prime}})d\boldsymbol{x}d\boldsymbol{x^{\prime}}
\]</span> where <span class="math inline">\(\gamma(\boldsymbol{x},\boldsymbol{x^{\prime}})\)</span> is the semivariance between two points <span class="math inline">\(x\)</span> and <span class="math inline">\(x^{\prime}\)</span> that sweep independently over B. It is the within-block variance. In punctual kriging <span class="math inline">\(\bar{\gamma}(B,B)\)</span>becomes <span class="math inline">\(\bar{\gamma}(x_0,x_0)=0\)</span>, which is why equation (5) has two terms rather than three.</p>
<p>For each kriged estimate there is an associated kriging variance, which we can denote by <span class="math inline">\(\sigma^2(\boldsymbol{x}_0)\)</span> and <span class="math inline">\(\sigma^2(B)\)</span> for the point and block, respectively, and which are defined in equation(5) and equation(7).</p>
<p>The next step in kriging is to find the weights that minimize these variances, subject to the constraint that they sum to 1. We achieve this using the method of Lagrange multipliers.</p>
<p>Here I do not want to show how Lagrange multipliers works. Anyway this post is just a general introduction.</p>
<h2 id="weights">WEIGHTS</h2>
<p>When the kriging equations are solved to obtain the weights, <span class="math inline">\(\lambda_i\)</span>, in general the only large weights are those of the points near to the point or block to be kriged. The nearest four or five might contribute 80% of the total weight, and the next nearest ten almost all of the remainder. The weights also depend on the configuration of the sampling. We can summarize the factors affecting the weights as follows.</p>
<ol type="1">
<li>Near points carry more weight than more distant ones. Their relative proportions depend on the positions of the sampling points and on the variogram: the larger is the nugget variance, the smaller are the weights of the points that are nearest to target point or block.</li>
<li>The relative weights of points also depend on the block size: as the block size increases, the weights of the nearest points decrease and those of the more distant points increase , until the weights become nearly equal.</li>
<li>Clustered points carry less weight individually than isolated ones at the same distance</li>
<li>Data points can be screened by ones lying between them and the target</li>
</ol>
<p>These effects are all intuitively desirable, and the first shows that kriging is local. They will become evident in the examples below. They also have practical implications. The most important for present purposes is that because only the nearest few data points to the target carry significant weight, matrix A in the kriging system need never be large and its inversion will be swift.</p>
<h1 id="covariance-and-variogram">Covariance and Variogram</h1>
<p>Before we step into the next one, we need to clarify some basic definition.</p>
<p>This part also comes from the previous textbook.</p>
<h2 id="a-stochastic-approach-to-spatial-variation-the-theory-of-regionalized-variables">A STOCHASTIC APPROACH TO SPATIAL VARIATION: THE THEORY OF REGIONALIZED VARIABLES</h2>
<h3 id="random-variables">Random variables</h3>
<h1 id="poisson-kriging-area-to-area">Poisson Kriging-Area to Area</h1>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Kriging model</tag>
        <tag>Spatial staticstics</tag>
      </tags>
  </entry>
  <entry>
    <title>Some Usefull python function</title>
    <url>/posts/d39dff82.html</url>
    <content><![CDATA[<h1 id="python-lambda">Python Lambda</h1>
<p>在读别人代码的时候看到的，发现自己对这个东西不是很熟悉，复习一下记个笔记。</p>
<p><strong>lambda 函数是一种小的匿名函数。</strong></p>
<p><strong>lambda 函数可接受任意数量的参数，但只能有一个表达式。</strong></p>
<a id="more"></a>
<h2 id="语法">语法</h2>
<p><code>lambda arguments : expression</code></p>
<p>执行表达式并返回结果</p>
<h2 id="实例">实例</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="keyword">lambda</span> a : a + <span class="number">10</span></span><br><span class="line">print(x(<span class="number">5</span>))</span><br></pre></td></tr></table></figure>
<p>这一句话就定义了一个lambda函数，a是这个函数的参数，a+10是这个函数的表达式，x是这个函数的名字。</p>
<p>Lambda可以接受任意数量的参数，比如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="keyword">lambda</span> a, b, c : a + b + c</span><br><span class="line">print(x(<span class="number">5</span>, <span class="number">6</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>这个函数就是三个参数</p>
<h2 id="函数内匿名函数">函数内匿名函数</h2>
<p>假设我定义了这么一个函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc</span>(<span class="params">n</span>):</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">lambda</span> a : a * n</span><br></pre></td></tr></table></figure>
<p>这个函数的作用是把a变成n倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc</span>(<span class="params">n</span>):</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">lambda</span> a : a * n</span><br><span class="line"></span><br><span class="line">mydoubler = myfunc(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>这样就可以很快速地构建出来这样的一个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mydoubler</span>(<span class="params">a</span>):</span></span><br><span class="line">  <span class="keyword">return</span> n*<span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>不需要想用别的的时候再去定义，比如我还想再来一个三倍的函数，就直接：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mytripler = myfunc(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h1 id="zip">zip</h1>
<p><strong>zip()</strong> 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象，这样做的好处是节约了不少的内存。</p>
<p>我们可以使用 list() 转换来输出列表。</p>
<p>如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 ***** 号操作符，可以将元组解压为列表。</p>
<h2 id="语法-1">语法</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">zip([iterable, ...])</span><br></pre></td></tr></table></figure>
<h2 id="实例-1">实例</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>] </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>] </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>] </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>zipped = zip(a,b)     <span class="comment"># 返回一个对象 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>zipped </span><br><span class="line">&lt;zip object at <span class="number">0x103abc288</span>&gt; </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(zipped)  <span class="comment"># list() 转换为列表 </span></span><br><span class="line">[(<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)] </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(zip(a,c))<span class="comment"># 元素个数与最短的列表一致 </span></span><br><span class="line">[(<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)]  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a1, a2 = zip(*zip(a,b))<span class="comment"># 与 zip 相反，zip(*) 可理解为解压，返回二维矩阵式 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(a1) </span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(a2) </span><br><span class="line">[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br></pre></td></tr></table></figure>
<h1 id="map">map</h1>
<p><strong>map()</strong> 会根据提供的函数对指定序列做映射。</p>
<p>第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表</p>
<h2 id="语法-2">语法</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">map(function, iterable, ...)</span><br></pre></td></tr></table></figure>
<h2 id="实例-2">实例</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="function"><span class="keyword">def</span> <span class="title">square</span>(<span class="params">x</span>) :</span>            <span class="comment"># 计算平方数     </span></span><br><span class="line"><span class="keyword">return</span> x ** <span class="number">2</span>  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>map(square, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])   <span class="comment"># 计算列表各个元素的平方 </span></span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>] </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>map(<span class="keyword">lambda</span> x: x ** <span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])  <span class="comment"># 使用 lambda 匿名函数 </span></span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>]  <span class="comment"># 提供了两个列表，对相同位置的列表数据进行相加 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>map(<span class="keyword">lambda</span> x, y: x + y, [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>]) </span><br><span class="line">[<span class="number">3</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">19</span>]</span><br></pre></td></tr></table></figure>
<h1 id="dict">dict</h1>
<p>字典是另一种可变容器模型，且可存储任意类型对象。</p>
<p>字典的每个键值 <strong>key=&gt;value</strong> 对用冒号 <strong>:</strong> 分割，每个键值对之间用逗号 <strong>,</strong> 分割，整个字典包括在花括号 <strong>{}</strong> 中 ,格式如下所示：</p>
<p><code>'d = &#123;key1 : value1, key2 : value2 &#125;'</code></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器部署自动机器学习</title>
    <url>/posts/c23e0e6e.html</url>
    <content><![CDATA[<p>借着毕业实习的机会将代码放到了实验室的服务器上，在这里记录一下全过程。</p>
<a id="more"></a>
<h1 id="实验室服务器的登陆及基本操作">实验室服务器的登陆及基本操作</h1>
<p>除了直接在服务器主机上登陆之外，还可以通过一些连接软件进行远程登陆。我这里使用的是PuTTY软件。</p>
<p>PuTTY是一款开源(Open Source Software)的连接软件，主要由Simon Tatham维护，使用MIT许可证授权。包含的组件有：PuTTY, PuTTYgen,PSFTP, PuTTYtel, Plink, PSCP, Pageant,默认登录协议是SSH，默认的端口为22。Putty是用来远程连接服务器的，支持SSH、Telnet、Serial等协议的连接。其中最常用的是SSH。用它来远程管理Linux十分好用，其主要优点如下：</p>
<ul>
<li>完全免费开源;</li>
<li>全面支持windows系统;</li>
<li>全面支持SSH1和SSH2；</li>
<li>绿色软件，无需安装，下载后在桌面建个快捷方式即可使用；</li>
<li>体积很小，不到1M；</li>
<li>操作简单，所有的操作都在一个控制面板中实现。</li>
</ul>
<p>PuTTY的下载页面为<span class="exturl" data-url="aHR0cHM6Ly9wdXR0eS5vcmcv">https://putty.org/<i class="fa fa-external-link-alt"></i></span>，选择合适的版本下载安装即可。</p>
<p>下载好之后在Saved Sessions处输入服务器IP地址，点击Save，然后点Open即可打开会话，输入用户名和密码即可登陆。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190605143842.png"></p>
<p>接着使用一些基本命令来确定服务器的系统版本和python版本。</p>
<p>输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /etc/redhat-release</span><br></pre></td></tr></table></figure>
<p>返回的系统版本为Centos 7.3.1611 Redhat。</p>
<p>输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python</span><br></pre></td></tr></table></figure>
<p>返回的系统版本为python2.7。</p>
<p>利用mkdir命令新建一个目录，后续操作皆在此目录下进行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir amf</span><br></pre></td></tr></table></figure>
<p>CPUE自动预测系统的环境配置</p>
<p>实验室所用linux服务器版本为Centos 7.3.1611 Redhat，默认python版本为2.7，因此首先需要将python3安装到服务器上。</p>
<h1 id="python3的安装">python3的安装</h1>
<h2 id="rpm包安装">RPM包安装</h2>
<p>本次安装使用的是来源于IUS社区的RPM包进行安装。IUS是“Inline with Upstream Stable”的缩写，他主要是一个提供新版本RPM包的社区，具体情况可以查看<span class="exturl" data-url="aHR0cHM6Ly9pdXMuaW8vR2V0dGluZ1N0YXJ0ZWQvI2luc3RhbGwtdmlhLWF1dG9tYXRpb24=">官方文档<i class="fa fa-external-link-alt"></i></span>。</p>
<p>所使用的具体操作如下(部分操作需要sudo权限，在这里不一一列出)：</p>
<ol type="1">
<li>添加IUS地址：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install https://centos7.iuscommunity.org/ius-release.rpm</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>创建缓存元数据：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum makecache</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>安装python3.6：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install python36u</span><br><span class="line"></span><br><span class="line">yum -y install python36u-pip</span><br><span class="line"></span><br><span class="line">yum -y install python36u-devel</span><br></pre></td></tr></table></figure>
<p>（4）测试环境：输入python3.6出现如下文字即代表安装成功。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Python <span class="number">3.6</span><span class="number">.8</span> (default, May  <span class="number">2</span> <span class="number">2019</span>, <span class="number">20</span>:<span class="number">40</span>:<span class="number">44</span>)</span><br><span class="line"></span><br><span class="line">[GCC <span class="number">4.8</span><span class="number">.5</span> <span class="number">20150623</span> (Red Hat <span class="number">4.8</span><span class="number">.5</span><span class="number">-36</span>)] on linux</span><br><span class="line"></span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br></pre></td></tr></table></figure>
<h2 id="虚拟环境的配置">虚拟环境的配置</h2>
<p>因为系统中存在多个python版本，为了避免环境污染，我使用virtualenv创建了独立的虚拟环境，具体过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python3.6 -m venv py3</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> py3/bin/activate</span><br></pre></td></tr></table></figure>
<p>执行完之后再命令行前会出现(py3)的字样，即代表进入虚拟环境中，输入python -V返回python3.6.8即代表安装成功。</p>
<h2 id="机器学习环境配置">机器学习环境配置</h2>
<p>自动预测系统是基于auto-sklearn开发的，需要scipy、sci-kit、pands、numpy等代码库的支持。在上一不中我们安装了pip这一python包管理工具，它可以提供对python包的查找、下载、安装、卸载等功能，因此这里直接采用pip命令进行安装即可</p>
<p>需要注意的是，在配置之前要先进入上一步配置的虚拟环境。</p>
<p>依次执行如下命令即可进行安装。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install pandas</span><br><span class="line"></span><br><span class="line">pip install scipy</span><br><span class="line"></span><br><span class="line">pip install scikit-learn</span><br><span class="line"></span><br><span class="line">pip install auto-sklearn</span><br><span class="line"></span><br><span class="line">pip install matplotlib</span><br><span class="line"></span><br><span class="line">pip install xlrd</span><br><span class="line"></span><br><span class="line">pip install openpyxl</span><br></pre></td></tr></table></figure>
<p>在安装auto-sklearn的过程中遇到如下错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Error: Syntax error <span class="keyword">in</span> input(3).     error: <span class="built_in">command</span> <span class="string">&#x27;swig&#x27;</span> failed with <span class="built_in">exit</span> status 1</span><br></pre></td></tr></table></figure>
<p>根据提示可知是由于swig而出现的错误，SWIG本质上是个代码生成器，为C/C++程序生成到其他语言的包装代码(wrapper code)，这些包装代码里会利用各语言提供的C API，将C/C++程序中的内容暴露给相应语言。为了生成这些包装代码，SWIG需要一个接口描述文件，描述将什么样的接口暴露给其他语言。</p>
<p>查看swig所用的版本为2.0.10，为python2.7所对应的版本，因此需要在系统中将swig升级到3版本。</p>
<p>首先将swig2卸载，执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y remove swig</span><br></pre></td></tr></table></figure>
<p>然后安装swig 3，执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install swig3</span><br></pre></td></tr></table></figure>
<p>安装以后执行命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">swig -version</span><br></pre></td></tr></table></figure>
<p>可以看到swig的版本变成了3.0.12。</p>
<p>重新执行pip install auto-sklearn即可完成安装。</p>
<p>安装完成后在虚拟环境中输入python，进入python语言，执行如下命令，如果没有报错，即说明环境配置完成。按Ctrl+D即可退出虚拟环境和puTTY。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> autosklearn.regression</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h1 id="服务器与windows之间的文件传输">服务器与windows之间的文件传输</h1>
<p>在运行程序之前，需要将要用到的数据传输到服务器上，这里采用的是puTTY提供的PSFTP工具。在之前安装puTTY时已经一并安装了。</p>
<p>打开PSFTP，输入open 服务器地址，完成登陆，然后采用put命令将本地文件传输到服务器上，get命令将服务器上的文件取回。</p>
<h1 id="程序调试">程序调试</h1>
<p>利用PSFTP将源代码传输到服务器上，进入虚拟环境，在命令行中输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python code.py</span><br></pre></td></tr></table></figure>
<p>即可看到程序开始运行。</p>
<p>如果程序报错，需要利用系统自带的vim编辑器进行编辑与调试。vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 这三种模式的作用分别是：</p>
<p>（1）命令模式：</p>
<p>用户刚刚启动 vim，便进入了命令模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。</p>
<p>以下是常用的几个命令：</p>
<ul>
<li>l i 切换到输入模式，以输入字符。</li>
<li>l x 删除当前光标所在处的字符。</li>
<li>l : 切换到底线命令模式，以在最底一行输入命令。</li>
</ul>
<p>若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。</p>
<p>命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。</p>
<p>（2）输入模式：</p>
<p>在命令模式下按下i就进入了输入模式。在输入模式中，可以使用以下按键：</p>
<ul>
<li>l 字符按键以及Shift组合，输入字符</li>
<li>l ENTER，回车键，换行</li>
<li>l BACK SPACE，退格键，删除光标前一个字符</li>
<li>l DEL，删除键，删除光标后一个字符</li>
<li>l 方向键，在文本中移动光标</li>
<li>l HOME/END，移动光标到行首/行尾</li>
<li>l Page Up/Page Down，上/下翻页</li>
<li>l Insert，切换光标为输入/替换模式，光标将变成竖线/下划线</li>
<li>l ESC，退出输入模式，切换到命令模式</li>
</ul>
<p>（3）底线命令模式：</p>
<p>在命令模式下按下:（英文冒号）就进入了底线命令模式。底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。在底线命令模式中，基本的命令有（已经省略了冒号）：</p>
<ul>
<li>l q 退出程序</li>
<li>l w 保存文件</li>
<li>l 按ESC键可随时退出底线命令模式。</li>
</ul>
<p>如果你想用vim来编辑或者建立一个名为test.txt的文件时，只需要在虚拟环境中输入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim test.txt</span><br></pre></td></tr></table></figure>
<p>即可。此时进入的是一般模式，在一般模式下按i即可进入输入模式，此时左下角状态栏会出现–INSERT- 的字样，即代表可以输入任意字符。这时除了ESC之外，其余按键都可以作为一般的输入按钮。编辑完成之后按ESC即可挥动一般模式。在一般模式下按：，输入wq即可保存离开。</p>
<p>除此之外还有很多进阶命令，在这里就不再细数了。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Linux</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>Material for ocean color</title>
    <url>/posts/3aa0ed1a.html</url>
    <content><![CDATA[<p>I have been in master course for half years. It’s time to organize the materials I have used.</p>
<p>This article will update as soon as I get new resource.</p>
<a id="more"></a>
<h1 id="basic-knowledge">Basic Knowledge</h1>
<h2 id="textbook">Textbook</h2>
<p>Kirk, J. (1994). <em>Light and Photosynthesis in Aquatic Ecosystems</em>. Cambridge: Cambridge University Press. doi:10.1017/CBO9780511623370 https://www.cambridge.org/core/books/light-and-photosynthesis-in-aquatic-ecosystems/C19B28AE07B1CDEBDA5593194DE4E304</p>
<p>Martin, S. (2014). <em>An Introduction to Ocean Remote Sensing</em>. Cambridge: Cambridge University Press. doi:10.1017/CBO9781139094368 https://www.cambridge.org/core/books/an-introduction-to-ocean-remote-sensing/B05BDCA4B71B9F41E1F1E97FBDCDC9BB</p>
<p>Ocean Optics Web book http://www.oceanopticsbook.info/</p>
<p>IOCCG report https://ioccg.org/what-we-do/ioccg-publications/ioccg-reports/</p>
<p>NASA's Ocean Biology Processing Group (OBPG) Technical Documents:https://oceancolor.gsfc.nasa.gov/docs/technical/</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9pb2NjZy5vcmcvd3AtY29udGVudC91cGxvYWRzLzIwMjAvMDkvZ29yZG9uLWJvb2tfbm92XzIwMTlfd2l0aF9kb2kucGRm">Physical Principles of Ocean Color Remote Sensing<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="video-and-training-course">Video and Training course</h2>
<p>IOCCG training course https://ioccg.org/what-we-do/training-and-education/</p>
<p>Cornell Summer Satellite Remote Sensing Training Program http://oceanography.eas.cornell.edu/satellite/</p>
<p>Lecture Material from IOCCG Training Courses https://ioccg.org/what-we-do/training-and-education/lectures/</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vY2hhbm5lbC9VQ0pZNWlTcmRGaGUybFpmTHFvLVhDYVEvdmlkZW9z">2019 Ocean Optics class on “Calibration &amp; Validation for Ocean Color Remote Sensing<i class="fa fa-external-link-alt"></i></span>” (University of Maine’s Darling Marine Center). See <span class="exturl" data-url="aHR0cDovL21pc2NsYWIudW1lb2NlLm1haW5lLmVkdS9PY2Vhbk9wdGljc0NsYXNzMjAxOS9zY2hlZHVsZS8=">schedule<i class="fa fa-external-link-alt"></i></span> for links to PowerPoint slides.</p>
<h1 id="programming-resource">Programming Resource</h1>
<h2 id="python-package">Python package</h2>
<p>I strongly recommend you install them by Anaconda</p>
<p>numpy,pandas,scipy,scikit-learn,matplotlib,Basemap,GDAL,geopandas,geos,h5py, hdf4,hdf5,netcdf4,pyresample,rasterio,shapely,earthpy,</p>
<p>one community: <span class="exturl" data-url="aHR0cHM6Ly9weWFvcy5naXRodWIuaW8=">PyAOS<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="github-account">Github account</h2>
<p>Dimitris Poursanidis: https://github.com/dpoursanidis</p>
<p>Bingzhang Chen: https://github.com/BingzhangChen</p>
<p>Erdem Karakoylu： https://github.com/madHatter106</p>
<p>Quinten Vanhellemont：https://github.com/acolite (ACOLITE: Atmospheric correction for aquatic applications of Landsat and Sentinel-2)</p>
<p>Brand Smith: https://github.com/BrandonSmithJ</p>
<p>Wei Jianwei: https://github.com/jianweiocean ,https://github.com/Ocean-Color-Remote-Sensing-Algorithm</p>
<p>UMaine MISC Lab: https://github.com/OceanOptics</p>
<p>Shun Bi: https://github.com/bishun945</p>
<p>Kunming Wang: https://github.com/qunmingwang</p>
<h2 id="material-for-programming">Material for programming</h2>
<p>PyHOGs: Python Hour for Oceanographers and Geoscientists http://pyhogs.github.io/</p>
<p>RGB 3S blog:https://www.ixxin.cn/</p>
<p>OceanPython.org: https://oceanpython.org/table-of-contents/</p>
<p>python4geosciences:materials for the Texas A&amp;M Python for Geoscientists class, OCNG 489/689.</p>
<p>https://github.com/hetland/python4geosciences_OLD</p>
<p>Python for Geosciences: https://github.com/koldunovn/python_for_geosciences</p>
<p>R and Python for Oceanographers 1st Edition:https://www.elsevier.com/books/r-and-python-for-oceanographers/alyuruk/978-0-12-813491-7</p>
<p>Earth Lab:https://www.earthdatascience.org/</p>
<p>Processing Remote Sensing Data with Python:https://skemman.is/bitstream/1946/16233/1/final_processingwithpython_dillon.pdf</p>
<p>Geo-python: https://geo-python.github.io/site/</p>
<p>Ocean Optics UMaine MISC Lab:https://github.com/OceanOptics</p>
<p>Optical Oceanography Lab :http://oceanoptics.umb.edu/resources/</p>
<p>The missing semester: https://missing.csail.mit.edu/</p>
<h2 id="software">Software</h2>
<p>Seadas:https://seadas.gsfc.nasa.gov/</p>
<p>Windows Image Manager:http://www.wimsoft.com/index.html</p>
<p>GOCI Data Processing System(GDPS):http://kosc.kiost.ac.kr/eng/p30/kosc_p31.html</p>
<p>Ocean Data View:https://odv.awi.de/</p>
<p>GISS:https://www.giss.nasa.gov/tools/</p>
<p>SNAP: https://step.esa.int/main/download/snap-download/</p>
<h1 id="data-resource">Data Resource</h1>
<h2 id="ocean-color-data">Ocean Color Data</h2>
<p>NASA ocean color data :https://oceancolor.gsfc.nasa.gov/</p>
<p>Earthdata website:https://earthdata.nasa.gov/</p>
<p>GOCI data:http://kosc.kiost.ac.kr/eng/</p>
<p>Maine production(standard VGPM):http://kosc.kiost.ac.kr/eng/</p>
<p>Japan GCOM-C/SGLI:https://gportal.jaxa.jp/gpr/</p>
<p>China GF satellite :http://www.hbeos.org.cn/</p>
<p>Earthexplore： https://earthexplorer.usgs.gov/</p>
<p>EUMETSAT:https://www.eumetsat.int/website/home/index.html</p>
<h2 id="other-data">Other data:</h2>
<p>GHRSST:https://www.ghrsst.org/</p>
<p>China Argo:www.argo.org.cn/</p>
<p>Other Argo:http://www.argodatamgt.org/</p>
<p>Asia-Pacific Data Research Center,:http://apdrc.soest.hawaii.edu/index.php</p>
<p>AVISO:https://www.aviso.altimetry.fr/en/data/products.html</p>
<p>Japan Meteorological Agency:www.jma.go.jp/jma/menu/menureport.html</p>
<p>REMSS:http://www.remss.com/</p>
<p>Jet Propulsion Lab：https://podaac.jpl.nasa.gov/</p>
<p>KNMI Climate Explorer,：https://climexp.knmi.nl/start.cgi?id=someone@somewhere</p>
<p>ECMWF:https://apps.ecmwf.int/datasets/data/interim-full-daily/levtype%3Dsfc/</p>
<p>OUC ocean &amp; atmosphere data center:http://coadc.ouc.edu.cn/index.php/Index</p>
<p>China Center For Resources Satellite Data and Application:http://218.247.138.119:7777/DSSPlatform/index.html</p>
<p>Geospatial Data Cloud:https://www.gscloud.cn/</p>
<p>FAO Fishery data:http://www.fao.org/fishery/statistics/en</p>
<p>ESSD:https://essd.copernicus.org</p>
<p>SeaBASS: https://seabass.gsfc.nasa.gov</p>
<p>Marine Optical BuoY</p>
<p>Aerojet: https://aeronet.gsfc.nasa.gov</p>
<p>PANGAEA: https://www.pangaea.de</p>
<p>NOMAD: https://seabass.gsfc.nasa.gov/wiki/NOMAD</p>
<p>Valente et al., 2019: https://doi.pangaea.de/10.1594/PANGAEA.898188</p>
<p>BOUSSOLE : http://www.obs-vlfr.fr/Boussole/html/home/home.php</p>
<p>More at IOCCG: https://ioccg.org/resources/data/</p>
<h1 id="famous-lab-all-over-the-world">Famous Lab all over the world</h1>
<p>Lov, france: http://omtab.obs-vlfr.fr/index.htm</p>
<p>PHYTOOPTICS Group, AWI, Germany: https://www.awi.de/en/science/climate-sciences/physical-oceanography/main-research-focus/ocean-optics.html</p>
<p>Plymouth, UK: https://www.pml.ac.uk/Research/Projects/Ocean_color_and_biogeochemistry</p>
<p>UCSD, Scripps,US: https://rfrouin.scrippsprofiles.ucsd.edu/, https://oceanoptics.ucsd.edu/</p>
<p>USF, Hu Chuanmin,US: https://optics.marine.usf.edu/</p>
<p>UMB. Lee Zhongping,US: http://oceanoptics.umb.edu/</p>
<p>Joji, Ishizaka, Japan: http://co2.hyarc.nagoya-u.ac.jp/</p>
<p>Takafumi, Hirata, Japan: https://pft.arc.hokudai.ac.jp/hirata/index.shtml</p>
<p>Toru, Hiratake, Japan: http://odyssey.fish.hokudai.ac.jp/</p>
<p>Emmanuel Boss, USA : http://misclab.umeoce.maine.edu/</p>
<p>David Antoine, Australia: http://rssrg.org/</p>
<p>Water Institute, USA: https://thewaterinstitute.org/</p>
<p>OOMG, USA，http://oomg.meas.ncsu.edu/</p>
<h1 id="ph.d-tips">Ph.D tips</h1>
<p>Ph.D. Advising Statement: https://favonia.org/advising.htmlv</p>
<p>Managing Your Advisor: https://greatresearch.org/2013/08/14/managing-your-advisor/</p>
<p>One year to dissertation: https://livefreeordichotomize.com/2018/09/14/one-year-to-dissertate/</p>
<p>下面的来自于榛子的封面故事</p>
<h2 id="第一类书单经历流水账">第一类书单：经历流水账</h2>
<p>最长最详细的PhD生涯回忆录：UCSD的网红教授Philip Guo的 The PhD Grind <span class="exturl" data-url="aHR0cHM6Ly93ZWIuYXJjaGl2ZS5vcmcvd2ViLzIwMjAwMzA1MDgyNzUyL2h0dHA6Ly9wZ2JvdmluZS5uZXQvUGhELW1lbW9pci9wZ3VvLVBoRC1ncmluZC5wZGY=">PDF<i class="fa fa-external-link-alt"></i></span>.</p>
<p>CMU的教授Jean Yang的博文 What My PhD Was Like <span class="exturl" data-url="aHR0cDovL2p4eXphYmMuYmxvZ3Nwb3QuY29tLzIwMTYvMDIvbXktcGhkLWFicmlkZ2VkLmh0bWw=">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>Amazon的机器学习研究院李沐，“博士这五年” <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNTA5OTYzOA==">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<h2 id="第二类书单生存技巧指南">第二类书单：生存技巧&amp;指南</h2>
<p>特斯拉(Tesla)人工智能组的主管Andrej Karpathy写的A Survival Guide to a PhD <span class="exturl" data-url="aHR0cDovL2thcnBhdGh5LmdpdGh1Yi5pby8yMDE2LzA5LzA3L3BoZC8=">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>Facebook 人工智能组的田渊栋写的“博士五年总结” <span class="exturl" data-url="aHR0cDovL3l1YW5kb25nLXRpYW4uY29tL2ZpdmVfeWVhcl9zdW1tYXJ5X29mX1BoRC5wZGY=">PDF<i class="fa fa-external-link-alt"></i></span>.</p>
<p>北大读博手记：怎样完成自己的博士生涯？<span class="exturl" data-url="aHR0cHM6Ly93d3cuc29odS5jb20vYS8yNTM1NTQ3OTNfNDgxNzQxP19mPWluZGV4X2NoYW4yNW5ld3NfMTIz">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>MIT的博士毕业生Adam Marcus写的 The N=1 guide to grad school <span class="exturl" data-url="aHR0cDovL21hcmN1YS5uZXQvd3JpdGluZy9ncmFkc2Nob29sLWd1aWRlLw==">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>知名教授Matt Might的 10 easy ways to fail a Ph.D. <span class="exturl" data-url="aHR0cDovL21hdHQubWlnaHQubmV0L2FydGljbGVzL3dheXMtdG8tZmFpbC1hLXBoZC8=">HTML<i class="fa fa-external-link-alt"></i></span>. 封面经典的PhD的示意图就是出自于他）</p>
<p>前哈佛CS终身教授，现Google研究员 Matt Welsh, So, you want to go to grad school? <span class="exturl" data-url="aHR0cDovL21hdHQtd2Vsc2guYmxvZ3Nwb3QubXkvMjAxMC8wOS9zby15b3Utd2FudC10by1nby10by1ncmFkLXNjaG9vbC5odG1s">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>Stanford教授 Peter Bailis: I Loved Graduate School <span class="exturl" data-url="aHR0cDovL3d3dy5iYWlsaXMub3JnL2Jsb2cvaS1sb3ZlZC1ncmFkdWF0ZS1zY2hvb2wv">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>《A PhD is not enough》书内有很多好建议，包括如何做presentation、如何找postdoc和postdoc的project，面试的准备、更长远的职业发展。</p>
<p>CMU教授 Jonathan Aldrich: How Do Professors Spend Their Time? <span class="exturl" data-url="aHR0cHM6Ly9qb25hdGhhbmFsZHJpY2guZ2l0aHViLmlvLzIwMTcvMTIvMjgvaG93LWRvLXByb2Zlc3NvcnMtc3BlbmQtdGhlaXItdGltZS1hLXBlcnNvbmFsLXBlcnNwZWN0aXZlLmh0bWw=">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>MIT政治学博士，UCSD政治系任助理教授的徐轶青<span class="exturl" data-url="aHR0cDovL3lpcWluZ3h1Lm9yZy9hcnRpY2xlcy8yMDE2MDUxNF9DTnBvbGl0aWNzX2ludGVydmlldy5wZGY=">《读博那些事儿》<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="第三类书单">第三类书单</h2>
<p>毕业后没当教授也没去研究院：Farewell to MIT <span class="exturl" data-url="aHR0cDovL3d3dy5ldmFuam9uZXMuY2EvZmFyZXdlbGwtbWl0Lmh0bWw=">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>matplotlib-subplot</title>
    <url>/posts/bf6c0df1.html</url>
    <content><![CDATA[<p>今天发现的一些东西</p>
<a id="more"></a>
<h1 id="子图间距调整">子图间距调整</h1>
<p>来自 https://blog.csdn.net/qq_33039859/article/details/79424858</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplots_adjust(left=<span class="literal">None</span>, bottom=<span class="literal">None</span>, right=<span class="literal">None</span>, top=<span class="literal">None</span>,</span><br><span class="line">                wspace=<span class="literal">None</span>, hspace=<span class="literal">None</span>)<span class="number">12</span></span><br><span class="line">left  = <span class="number">0.125</span>  <span class="comment"># the left side of the subplots of the figure</span></span><br><span class="line">right = <span class="number">0.9</span>    <span class="comment"># the right side of the subplots of the figure</span></span><br><span class="line">bottom = <span class="number">0.1</span>   <span class="comment"># the bottom of the subplots of the figure</span></span><br><span class="line">top = <span class="number">0.9</span>      <span class="comment"># the top of the subplots of the figure</span></span><br><span class="line">wspace = <span class="number">0.2</span>   <span class="comment"># the amount of width reserved for blank space between subplots,</span></span><br><span class="line">               <span class="comment"># expressed as a fraction of the average axis width</span></span><br><span class="line">hspace = <span class="number">0.2</span>   <span class="comment"># the amount of height reserved for white space between subplots,</span></span><br><span class="line">               <span class="comment"># expressed as a fraction of the average axis height</span></span><br></pre></td></tr></table></figure>
<h1 id="共享坐标轴">共享坐标轴</h1>
<p>当你通过<code>pyplot.subplot()</code>、<code>pyplot.axes()</code>函数或者<code>Figure.add_subplot()</code>、<code>Figure.add_axes()</code>方法创建一个<code>Axes</code>时，你可以通过<code>sharex</code>关键字参数传入另一个<code>Axes</code>表示共享X轴；或者通过<code>sharey</code>关键字参数传入另一个<code>Axes</code>表示共享Y轴。<strong>共享轴线时，当你缩放某个<code>Axes</code>时，另一个<code>Axes</code>也跟着缩放。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig =plt.figure()</span><br><span class="line">ax1 =fig.add_subplot(<span class="number">211</span>)</span><br><span class="line">ax1.plot([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">ax2 =fig.add_subplot(<span class="number">212</span>,sharex=ax1)</span><br><span class="line">ax2.plot([<span class="number">7</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/1252882-20191225232904746-1316411337.png" alt="1252882-20191225232904746-1316411337"><figcaption aria-hidden="true">1252882-20191225232904746-1316411337</figcaption>
</figure>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title>Cousera机器学习基石第六周笔记 Machine Learning Foundation Week 6 Note in Cousera</title>
    <url>/posts/da4d42a2.html</url>
    <content><![CDATA[<p>Theory of Generalization</p>
<p>test error can approximate training error if there is enough data and growth function does not grow too fast</p>
<a id="more"></a>
<h1 id="restriction-of-breaking-point">Restriction of Breaking Point</h1>
<h2 id="the-four-breaking-points">The Four Breaking Points</h2>
<p>growth function <span class="math inline">\(m_\H(N)\)</span>:max number of dichotomies</p>
<ul>
<li>positive rays: <span class="math inline">\(m_\H(N)=N+1\)</span></li>
<li>positive intervals: <span class="math inline">\(m_\H(N)=\frac{1}{2}N^2+\frac{1}{2}N+1\)</span></li>
<li>convex sets: <span class="math inline">\(m_\H(N)=2^N\)</span></li>
<li>2D perceptrons :<span class="math inline">\(m_\H(N)&lt;2^N\)</span> in some cases</li>
</ul>
<h2 id="restriction-of-breaking-point-1">Restriction of Breaking Point</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190512171932.png"></p>
<h1 id="bounding-functionbasic-cases">Bounding Function:Basic Cases</h1>
<h2 id="bounding-function">Bounding Function</h2>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>note for ocean optic web book：Liaght and Radiometry</title>
    <url>/posts/80897339.html</url>
    <content><![CDATA[<p>Souce: http://www.oceanopticsbook.info/</p>
<a id="more"></a>
<h1 id="unit">UNIT</h1>
<p>All other quantities are derivable from these units.</p>
<table>
<thead>
<tr class="header">
<th>Physical quantity</th>
<th>Base Unit</th>
<th>Symbol</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>length</td>
<td>meter</td>
<td>m</td>
</tr>
<tr class="even">
<td>mass</td>
<td>kilogram</td>
<td>kg</td>
</tr>
<tr class="odd">
<td>time</td>
<td>second</td>
<td>s</td>
</tr>
<tr class="even">
<td>electric current</td>
<td>ampere</td>
<td>A</td>
</tr>
<tr class="odd">
<td>temperature</td>
<td>kelvin</td>
<td>K</td>
</tr>
<tr class="even">
<td>amount of substance</td>
<td>mole</td>
<td>mol</td>
</tr>
<tr class="odd">
<td>luminous intensity</td>
<td>candela</td>
<td>cd</td>
</tr>
<tr class="even">
<td></td>
<td>Supplementary Units</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
        <tag>bookreading</tag>
      </tags>
  </entry>
  <entry>
    <title>np.ma.mask</title>
    <url>/posts/39e89397.html</url>
    <content><![CDATA[<p>自己前几天一直在跟mask斗争，中文网站上也没什么好的资料，就索性自己整理一下。</p>
<a id="more"></a>
<h1 id="创建">创建</h1>
<p>官方提供了三种方法来创建mask，第一种是直接指定mask的位置</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numpy.ma <span class="keyword">as</span> ma</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = ma.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], mask = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(data=[1, --, 3],
             mask=[False,  True, False],
       fill_value=999999)</code></pre>
<p>第二种是用ma.MaskedArray类，这个不是很常用</p>
<p>x = MaskedArray(data, mask=nomask, dtype=None, copy=False, subok=True, ndmin=0, fill_value=None, keep_mask=True, hard_mask=None, shrink=True, order=None)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">np.ma.MaskedArray(data, mask=[[<span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">                              [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>]])</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(
  data=[[0, --, 2],
        [3, 4, --]],
  mask=[[False,  True, False],
        [False, False,  True]],
  fill_value=999999)</code></pre>
<p>这种方法可以直接给整个数组上mask</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.ma.MaskedArray(data, mask=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_array(</span><br><span class="line">  data=[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]],</span><br><span class="line">  mask=[[<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">        [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]],</span><br><span class="line">  fill_value=<span class="number">999999</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.ma.MaskedArray(data, mask=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_array(</span><br><span class="line">  data=[[--, --, --],</span><br><span class="line">        [--, --, --]],</span><br><span class="line">  mask=[[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">        [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>]],</span><br><span class="line">  fill_value=<span class="number">999999</span>,</span><br><span class="line">  dtype=int64)</span><br></pre></td></tr></table></figure>
<p>官方给出的第三种原文和事例如下，但是我始终没有特别理解</p>
<p>A third option is to take the view of an existing array. In that case, the mask of the view is set to nomask if the array has no named fields, or an array of boolean with the same structure as the array otherwise.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.view(ma.MaskedArray)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_array(data=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">             mask=<span class="literal">False</span>,</span><br><span class="line">       fill_value=<span class="number">999999</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([(<span class="number">1</span>, <span class="number">1.</span>), (<span class="number">2</span>, <span class="number">2.</span>)], dtype=[(<span class="string">&#x27;a&#x27;</span>,int), (<span class="string">&#x27;b&#x27;</span>, float)])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.view(ma.MaskedArray)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_array(data=[(<span class="number">1</span>, <span class="number">1.0</span>), (<span class="number">2</span>, <span class="number">2.0</span>)],</span><br><span class="line">             mask=[(<span class="literal">False</span>, <span class="literal">False</span>), (<span class="literal">False</span>, <span class="literal">False</span>)],</span><br><span class="line">       fill_value=(<span class="number">999999</span>, <span class="number">1.e+20</span>),</span><br><span class="line">            dtype=[(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;&lt;f8&#x27;</span>)])</span><br></pre></td></tr></table></figure>
<p>对于我来说我的需求基本就是构造一个和已有mask array相同的数组，对我来说可以用以下方法得到</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ma.array(np.zeros_like(y),mask=y.mask)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_array(data=[<span class="number">0</span>, --, <span class="number">0</span>],</span><br><span class="line">             mask=[<span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">       fill_value=<span class="number">999999</span>)</span><br></pre></td></tr></table></figure>
<p>除此之外，还有一些函数可以完成效果，比较常用的是这几个</p>
<p>masked_equal(x, value[, copy])</p>
<p>masked_greater(x, value[, copy])</p>
<p>masked_greater_equal(x, value[, copy])</p>
<p>masked_invalid(a[, copy])</p>
<p>masked_less(x, value[, copy])</p>
<p>masked_less_equal(x, value[, copy])</p>
<p>masked_not_equal(x, value[, copy])</p>
<p>masked_where(condition, a[, copy])</p>
<p>这里masked_where()和masked_invalid()最好用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">4</span>)</span><br><span class="line">ma.masked_where(a &lt;= <span class="number">2</span>, a)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_array(data=[--, --, --, <span class="number">3</span>],</span><br><span class="line">             mask=[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">       fill_value=<span class="number">999999</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=np.asarray([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,np.inf,np.nan])</span><br><span class="line">ma.masked_invalid(a)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_array(data=[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, --, --],</span><br><span class="line">             mask=[<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">       fill_value=<span class="number">1e+20</span>)</span><br></pre></td></tr></table></figure>
<p>在创建里面还有一个事情是比较重要的，那就是fill_value</p>
<p>在创建的时候可以指定fill_value，除此之外，可以通过这个函数来查看fill_value</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.ma.array([<span class="number">0</span>, <span class="number">1.</span>], fill_value=-np.inf)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.fill_value</span><br><span class="line">-inf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.fill_value = np.pi</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.fill_value</span><br><span class="line"><span class="number">3.1415926535897931</span> <span class="comment"># may vary</span></span><br></pre></td></tr></table></figure>
<p>对于已经设置好fill_value的，可以用这个函数来改变fill_value</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy.ma <span class="keyword">as</span> ma</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.arange(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = ma.masked_where(a &lt; <span class="number">3</span>, a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">masked_array(data=[--, --, --, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">             mask=[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">       fill_value=<span class="number">999999</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ma.set_fill_value(a, <span class="number">-999</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">masked_array(data=[--, --, --, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">             mask=[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">       fill_value=<span class="number">-999</span>)</span><br></pre></td></tr></table></figure>
<p>Nothing happens if a is a not masked array</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = list(range(<span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ma.set_fill_value(a, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.arange(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ma.set_fill_value(a, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<p>在创建完之后，大部分运算都只会针对没有被mask的地方。一些函数可能会出问题，所以像min/max/average这种函数推荐使用np里的函数而不是python内置函数</p>
<h1 id="索引">索引</h1>
<p>如果索引的地方没有被mask的话，返回值和普通的array一样。</p>
<p>如果是被masked，返回值是masked。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = ma.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], mask=[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">-1</span>]</span><br><span class="line">masked</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">-1</span>] <span class="keyword">is</span> ma.masked</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h1 id="取消">取消</h1>
<p>常用的是这个</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = ma.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], mask=[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">masked_array(data=[<span class="number">1</span>, <span class="number">2</span>, --],</span><br><span class="line">             mask=[<span class="literal">False</span>, <span class="literal">False</span>,  <span class="literal">True</span>],</span><br><span class="line">       fill_value=<span class="number">999999</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.mask = ma.nomask</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">masked_array(data=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">             mask=[<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">       fill_value=<span class="number">999999</span>)</span><br></pre></td></tr></table></figure>
<p>这样就可以获取被mask地方的值了，但是要注意的是其实这个返回的array还是带mask的，就是mask全是False罢了，想让他完全变成nomask可以用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.data                                                                                                              </span><br><span class="line">Out[<span class="number">6</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<p>这个 返回值就是只有array</p>
<h1 id="参考">参考</h1>
<p>https://numpy.org/doc/stable/reference/maskedarray.generic.html</p>
<p>https://www.numpy.org.cn/reference/arrays/maskedarray.html</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas cheat sheet</title>
    <url>/posts/da4a7e8b.html</url>
    <content><![CDATA[<p>和matplotlib一样pandas也有cheatsheet</p>
<a id="more"></a>
<p>地址https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00020924161352046.png"></p>
<p>另外顺手立个flag，每周在博客更新 Annotated Bibliography</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>Basis for subplot2grid, ticker, enumerate, seaborn, plt/ax/fig</title>
    <url>/posts/bebb8f89.html</url>
    <content><![CDATA[<p>一些在读别人代码的时候发现自己还没有掌握的东西。</p>
<a id="more"></a>
<h1 id="matplotlib.ticker">matplotlib.ticker</h1>
<h2 id="定位">定位</h2>
<h3 id="tick-locating">Tick locating</h3>
<p>The Locator class is the base class for all tick locators. The locators handle autoscaling of the view limits based on the data limits, and the choosing of tick locations. A useful semi-automatic tick locator is <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MultipleLocator"><code>MultipleLocator</code></a>. It is initialized with a base, e.g., 10, and it picks axis limits and ticks that are multiples of that base.</p>
<p>The Locator subclasses defined here are</p>
<ul>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.AutoLocator"><code>AutoLocator</code></a></p>
<p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MaxNLocator"><code>MaxNLocator</code></a> with simple defaults. This is the default tick locator for most plotting.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MaxNLocator"><code>MaxNLocator</code></a></p>
<p>Finds up to a max number of intervals with ticks at nice locations.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LinearLocator"><code>LinearLocator</code></a></p>
<p>Space ticks evenly from min to max.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogLocator"><code>LogLocator</code></a></p>
<p>Space ticks logarithmically from min to max.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MultipleLocator"><code>MultipleLocator</code></a></p>
<p>Ticks and range are a multiple of base; either integer or float.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FixedLocator"><code>FixedLocator</code></a></p>
<p>Tick locations are fixed.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.IndexLocator"><code>IndexLocator</code></a></p>
<p>Locator for index plots (e.g., where <code>x = range(len(y))</code>).</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.NullLocator"><code>NullLocator</code></a></p>
<p>No ticks.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.SymmetricalLogLocator"><code>SymmetricalLogLocator</code></a></p>
<p>Locator for use with with the symlog norm; works like <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogLocator"><code>LogLocator</code></a> for the part outside of the threshold and adds 0 if inside the limits.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogitLocator"><code>LogitLocator</code></a></p>
<p>Locator for logit scaling.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.OldAutoLocator"><code>OldAutoLocator</code></a></p>
<p>Choose a <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MultipleLocator"><code>MultipleLocator</code></a> and dynamically reassign it for intelligent ticking during navigation.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.AutoMinorLocator"><code>AutoMinorLocator</code></a></p>
<p>Locator for minor ticks when the axis is linear and the major ticks are uniformly spaced. Subdivides the major tick interval into a specified number of minor intervals, defaulting to 4 or 5 depending on the major interval.</p></li>
</ul>
<p>There are a number of locators specialized for date locations - see the <code>dates</code> module.</p>
<p>You can define your own locator by deriving from Locator. You must override the <code>__call__</code> method, which returns a sequence of locations, and you will probably want to override the autoscale method to set the view limits from the data limits.</p>
<p>If you want to override the default locator, use one of the above or a custom locator and pass it to the x or y axis instance. The relevant methods are:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.xaxis.set_major_locator(xmajor_locator)</span><br><span class="line">ax.xaxis.set_minor_locator(xminor_locator)</span><br><span class="line">ax.yaxis.set_major_locator(ymajor_locator)</span><br><span class="line">ax.yaxis.set_minor_locator(yminor_locator)</span><br></pre></td></tr></table></figure>
<p>The default minor locator is <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.NullLocator"><code>NullLocator</code></a>, i.e., no minor ticks on by default.</p>
<h2 id="格式">格式</h2>
<h3 id="tick-formatting">Tick formatting</h3>
<p>Tick formatting is controlled by classes derived from Formatter. The formatter operates on a single tick value and returns a string to the axis.</p>
<ul>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.NullFormatter"><code>NullFormatter</code></a></p>
<p>No labels on the ticks.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.IndexFormatter"><code>IndexFormatter</code></a></p>
<p>Set the strings from a list of labels.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FixedFormatter"><code>FixedFormatter</code></a></p>
<p>Set the strings manually for the labels.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FuncFormatter"><code>FuncFormatter</code></a></p>
<p>User defined function sets the labels.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.StrMethodFormatter"><code>StrMethodFormatter</code></a></p>
<p>Use string <a href="https://docs.python.org/3/library/functions.html#format"><code>format</code></a> method.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FormatStrFormatter"><code>FormatStrFormatter</code></a></p>
<p>Use an old-style sprintf format string.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.ScalarFormatter"><code>ScalarFormatter</code></a></p>
<p>Default formatter for scalars: autopick the format string.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatter"><code>LogFormatter</code></a></p>
<p>Formatter for log axes.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatterExponent"><code>LogFormatterExponent</code></a></p>
<p>Format values for log axis using <code>exponent = log_base(value)</code>.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatterMathtext"><code>LogFormatterMathtext</code></a></p>
<p>Format values for log axis using <code>exponent = log_base(value)</code> using Math text.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatterSciNotation"><code>LogFormatterSciNotation</code></a></p>
<p>Format values for log axis using scientific notation.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogitFormatter"><code>LogitFormatter</code></a></p>
<p>Probability formatter.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.EngFormatter"><code>EngFormatter</code></a></p>
<p>Format labels in engineering notation</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.PercentFormatter"><code>PercentFormatter</code></a></p>
<p>Format labels as a percentage</p></li>
</ul>
<p>You can derive your own formatter from the Formatter base class by simply overriding the <code>__call__</code> method. The formatter class has access to the axis view and data limits.</p>
<p>To control the major and minor tick label formats, use one of the following methods:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.xaxis.set_major_formatter(xmajor_formatter)</span><br><span class="line">ax.xaxis.set_minor_formatter(xminor_formatter)</span><br><span class="line">ax.yaxis.set_major_formatter(ymajor_formatter)</span><br><span class="line">ax.yaxis.set_minor_formatter(yminor_formatter)</span><br></pre></td></tr></table></figure>
<p>See <span class="exturl" data-url="aHR0cHM6Ly9tYXRwbG90bGliLm9yZy8zLjEuMS9nYWxsZXJ5L3RpY2tzX2FuZF9zcGluZXMvbWFqb3JfbWlub3JfZGVtby5odG1s">Major and minor ticks<i class="fa fa-external-link-alt"></i></span> for an example of setting major and minor ticks. See the <a href="https://matplotlib.org/3.1.1/api/dates_api.html#module-matplotlib.dates"><code>matplotlib.dates</code></a> module for more information and examples of using date locators and formatters.</p>
<p>参考</p>
<p>https://matplotlib.org/3.1.1/api/ticker_api.html</p>
<p>https://matplotlib.org/3.1.1/api/ticker_api.html</p>
<h1 id="enumerate">enumerate</h1>
<h2 id="描述">描述</h2>
<p>enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p>
<p>Python 2.3. 以上版本可用，2.6 添加 start 参数。</p>
<h3 id="语法">语法</h3>
<p>以下是 enumerate() 方法的语法:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">enumerate(sequence, [start=<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h3 id="参数">参数</h3>
<ul>
<li>sequence -- 一个序列、迭代器或其他支持迭代对象。</li>
<li>start -- 下标起始位置。</li>
</ul>
<h3 id="返回值">返回值</h3>
<p>返回 enumerate(枚举) 对象。</p>
<hr>
<h2 id="实例">实例</h2>
<p>以下展示了使用 enumerate() 方法的实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;seasons = [<span class="string">&#x27;Spring&#x27;</span>, <span class="string">&#x27;Summer&#x27;</span>, <span class="string">&#x27;Fall&#x27;</span>, <span class="string">&#x27;Winter&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(enumerate(seasons))</span><br><span class="line">[(<span class="number">0</span>, <span class="string">&#x27;Spring&#x27;</span>), (<span class="number">1</span>, <span class="string">&#x27;Summer&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;Fall&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;Winter&#x27;</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(enumerate(seasons, start=<span class="number">1</span>))       <span class="comment"># 下标从 1 开始</span></span><br><span class="line">[(<span class="number">1</span>, <span class="string">&#x27;Spring&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;Summer&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;Fall&#x27;</span>), (<span class="number">4</span>, <span class="string">&#x27;Winter&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<h3 id="普通的-for-循环">普通的 for 循环</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;i = <span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>seq = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> element <span class="keyword">in</span> seq:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">print</span> i, seq[i]</span><br><span class="line"><span class="meta">... </span>    i +=<span class="number">1</span></span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">0</span> one</span><br><span class="line"><span class="number">1</span> two</span><br><span class="line"><span class="number">2</span> three</span><br></pre></td></tr></table></figure>
<h3 id="for-循环使用-enumerate">for 循环使用 enumerate</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;seq = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i, element <span class="keyword">in</span> enumerate(seq):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">print</span> i, element</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">0</span> one参考</span><br><span class="line"><span class="number">1</span> two</span><br><span class="line"><span class="number">2</span> three</span><br></pre></td></tr></table></figure>
<p>参考</p>
<p>https://www.runoob.com/python/python-func-enumerate.html</p>
<h1 id="subplot2grid">subplot2grid</h1>
<p>这个可以自定义子图的位置，并且可以跨越原来大小。</p>
<p>原文https://wizardforcel.gitbooks.io/matplotlib-user-guide/content/3.3.html</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">GridSpec</span><br></pre></td></tr></table></figure>
<p>指定子图将放置的网格的几何位置。 需要设置网格的行数和列数。 子图布局参数（例如，左，右等）可以选择性调整。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">SubplotSpec</span><br></pre></td></tr></table></figure>
<p>指定在给定<code>GridSpec</code>中的子图位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">subplot2grid</span><br></pre></td></tr></table></figure>
<p>一个辅助函数，类似于<code>pyplot.subplot</code>，但是使用基于 0 的索引，并可使子图跨越多个格子。</p>
<h2 id="subplot2grid基本示例">subplot2grid基本示例</h2>
<p>要使用subplot2grid，你需要提供网格的几何形状和网格中子图的位置。 对于简单的单网格子图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = plt.subplot2grid((<span class="number">2</span>,<span class="number">2</span>),(<span class="number">0</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">       nRow=<span class="number">2</span>, nCol=<span class="number">2</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">0</span>) +-------+-------+</span><br><span class="line">      |   <span class="number">1</span>   |       |</span><br><span class="line">      +-------+-------+</span><br><span class="line">      |       |       |</span><br><span class="line">      +-------+-------+</span><br></pre></td></tr></table></figure>
<p>要注意不像<code>subplot</code>，<code>gridspec</code>中的下标从 0 开始。</p>
<p>为了创建跨越多个格子的子图，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax2 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>, <span class="number">0</span>), colspan=<span class="number">2</span>)</span><br><span class="line">ax3 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>, <span class="number">2</span>), rowspan=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>例如，下列命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax1 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">0</span>,<span class="number">0</span>), colspan=<span class="number">3</span>)</span><br><span class="line">ax2 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>,<span class="number">0</span>), colspan=<span class="number">2</span>)</span><br><span class="line">ax3 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>, <span class="number">2</span>), rowspan=<span class="number">2</span>)</span><br><span class="line">ax4 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">ax5 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">2</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>会创建：</p>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec01.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="gridspec和subplotspec">GridSpec和SubplotSpec</h2>
<p>你可以显式创建<code>GridSpec</code>并用它们创建子图。</p>
<p>例如，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = plt.subplot2grid((<span class="number">2</span>,<span class="number">2</span>),(<span class="number">0</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line">gs = gridspec.GridSpec(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">ax = plt.subplot(gs[<span class="number">0</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p><code>gridspec</code>示例提供类似数组（一维或二维）的索引，并返回<code>SubplotSpec</code>实例。例如，使用切片来返回跨越多个格子的<code>SubplotSpec</code>实例。</p>
<p>上面的例子会变成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">ax1 = plt.subplot(gs[<span class="number">0</span>, :])</span><br><span class="line">ax2 = plt.subplot(gs[<span class="number">1</span>,:<span class="number">-1</span>])</span><br><span class="line">ax3 = plt.subplot(gs[<span class="number">1</span>:, <span class="number">-1</span>])</span><br><span class="line">ax4 = plt.subplot(gs[<span class="number">-1</span>,<span class="number">0</span>])</span><br><span class="line">ax5 = plt.subplot(gs[<span class="number">-1</span>,<span class="number">-2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec02.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="调整-gridspec布局">调整 GridSpec布局</h2>
<p>在显式使用<code>GridSpec</code>的时候，你可以调整子图的布局参数，子图由<code>gridspec</code>创建。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs1 = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">gs1.update(left=<span class="number">0.05</span>, right=<span class="number">0.48</span>, wspace=<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<p>这类似于<code>subplots_adjust</code>，但是他只影响从给定<code>GridSpec</code>创建的子图。</p>
<p>下面的代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs1 = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">gs1.update(left=<span class="number">0.05</span>, right=<span class="number">0.48</span>, wspace=<span class="number">0.05</span>)</span><br><span class="line">ax1 = plt.subplot(gs1[:<span class="number">-1</span>, :])</span><br><span class="line">ax2 = plt.subplot(gs1[<span class="number">-1</span>, :<span class="number">-1</span>])</span><br><span class="line">ax3 = plt.subplot(gs1[<span class="number">-1</span>, <span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">gs2 = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">gs2.update(left=<span class="number">0.55</span>, right=<span class="number">0.98</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line">ax4 = plt.subplot(gs2[:, :<span class="number">-1</span>])</span><br><span class="line">ax5 = plt.subplot(gs2[:<span class="number">-1</span>, <span class="number">-1</span>])</span><br><span class="line">ax6 = plt.subplot(gs2[<span class="number">-1</span>, <span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<p>会产生</p>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec03.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="使用-subplotspec创建-gridspec">使用 SubplotSpec创建 GridSpec</h2>
<p>你可以从<code>SubplotSpec</code>创建<code>GridSpec</code>，其中它的布局参数设置为给定<code>SubplotSpec</code>的位置的布局参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs0 = gridspec.GridSpec(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">gs00 = gridspec.GridSpecFromSubplotSpec(<span class="number">3</span>, <span class="number">3</span>, subplot_spec=gs0[<span class="number">0</span>])</span><br><span class="line">gs01 = gridspec.GridSpecFromSubplotSpec(<span class="number">3</span>, <span class="number">3</span>, subplot_spec=gs0[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec04.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="使用subplotspec创建复杂嵌套的gridspec">使用SubplotSpec创建复杂嵌套的GridSpec</h2>
<p>这里有一个更复杂的嵌套<code>gridspec</code>的示例，我们通过在每个 3x3 内部网格中隐藏适当的脊线，在 4x4 外部网格的每个单元格周围放置一个框。</p>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec06.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="网格尺寸可变的gridspec">网格尺寸可变的GridSpec</h2>
<p>通常，<code>GridSpec</code>创建大小相等的网格。你可以调整行和列的相对高度和宽度，要注意绝对高度值是无意义的，有意义的只是它们的相对比值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs = gridspec.GridSpec(<span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">                       width_ratios=[<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">                       height_ratios=[<span class="number">4</span>,<span class="number">1</span>]</span><br><span class="line">                       )</span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(gs[<span class="number">0</span>])</span><br><span class="line">ax2 = plt.subplot(gs[<span class="number">1</span>])</span><br><span class="line">ax3 = plt.subplot(gs[<span class="number">2</span>])</span><br><span class="line">ax4 = plt.subplot(gs[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec05.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h1 id="seaborn">seaborn</h1>
<p>seaborn是对matplotlib进一步的封装，简单点来说就是更简单了。</p>
<p>官网https://seaborn.pydata.org/</p>
<p>我这里放几个我感觉用得上的代码。</p>
<h2 id="lineplot">lineplot</h2>
<p>seaborn.lineplot(x=None, y=None, hue=None, size=None, style=None, data=None, palette=None, hue_order=None, hue_norm=None, sizes=None, size_order=None, size_norm=None, dashes=True, markers=None, style_order=None, units=None, estimator='mean', ci=95, n_boot=1000, seed=None, sort=True, err_style='band', err_kws=None, legend='brief', ax=None, **kwargs)</p>
<p>https://seaborn.pydata.org/generated/seaborn.lineplot.html</p>
<h2 id="heatmap">heatmap</h2>
<p>seaborn.heatmap(data, vmin=None, vmax=None, cmap=None, center=None, robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', cbar=True, cbar_kws=None, cbar_ax=None, square=False, xticklabels='auto', yticklabels='auto', mask=None, ax=None, **kwargs)</p>
<p>https://zhuanlan.zhihu.com/p/35494575</p>
<h2 id="implot">implot</h2>
<p>eaborn.lmplot(<em>x</em>, <em>y</em>, <em>data</em>, <em>hue=None</em>, <em>col=None</em>, <em>row=None</em>, <em>palette=None</em>, <em>col_wrap=None</em>, <em>size=5</em>, <em>aspect=1</em>, <em>markers='o'</em>, <em>sharex=True</em>, <em>sharey=True</em>, <em>hue_order=None</em>, <em>col_order=None</em>, <em>row_order=None</em>, <em>legend=True</em>, <em>legend_out=True</em>, <em>x_estimator=None</em>, <em>x_bins=None</em>, <em>x_ci='ci'</em>, <em>scatter=True</em>, <em>fit_reg=True</em>, <em>ci=95</em>, <em>n_boot=1000</em>, <em>units=None</em>, <em>order=1</em>, <em>logistic=False</em>, <em>lowess=False</em>, <em>robust=False</em>, <em>logx=False</em>, <em>x_partial=None</em>, <em>y_partial=None</em>, <em>truncate=False</em>, <em>x_jitter=None</em>, <em>y_jitter=None</em>, <em>scatter_kws=None</em>, <em>line_kws=None</em>)</p>
<p>https://zhuanlan.zhihu.com/p/25909753</p>
<p>常见统计图片基本都可以在这里面看到</p>
<p>https://seaborn.pydata.org/examples/index.html</p>
<h2 id="subplot_adjust">subplot_adjust</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">matplotlib.pyplot.subplots_adjust(*args, **kwargs)</span><br><span class="line">subplots_adjust(left=<span class="literal">None</span>, bottom=<span class="literal">None</span>, right=<span class="literal">None</span>, top=<span class="literal">None</span>,wspace=<span class="literal">None</span>, hspace=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">left  = <span class="number">0.125</span>  <span class="comment"># 子图(subplot)距画板(figure)左边的距离</span></span><br><span class="line">right = <span class="number">0.9</span>    <span class="comment"># 右边</span></span><br><span class="line">bottom = <span class="number">0.1</span>   <span class="comment"># 底部</span></span><br><span class="line">top = <span class="number">0.9</span>      <span class="comment"># 顶部</span></span><br><span class="line">wspace = <span class="number">0.2</span>   <span class="comment"># 子图水平间距</span></span><br><span class="line">hspace = <span class="number">0.2</span>   <span class="comment"># 子图垂直间距</span></span><br></pre></td></tr></table></figure>
<h1 id="pltaxfig">plt/ax/fig</h1>
<figure>
<img src="https://pic2.zhimg.com/80/v2-6e4429872eeb8a155433c0ee7c75b6ea_720w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>尽量避免直接使用plt</p>
<p>https://zhuanlan.zhihu.com/p/93423829</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>retrieving Scdm using uv propoteis</title>
    <url>/posts/750388a9.html</url>
    <content><![CDATA[<p>Spectral slopes of the absorption coefficient of colored dissolved and detrital material inverted from UV-visible remote sensing reflectance(Wei et al., 2016)</p>
<p>A new algorithm to retrieve chromophoric dissolved organic matter (CDOM) absorption spectra in the UV from ocean color(Cao and Miller, 2015)</p>
<p>A model for remote estimation of ultraviolet absorption by chromophoric dissolved organic matter based on the global distribution of spectral slope(Swan et al.,2016)</p>
<p>Pan-Arctic distributions of continental runoff in the Arctic Ocean(Fiche et al., 2013)</p>
<p>Algorithm development and validation ofCDOMproperties for estuarine and continental shelfwaters along the northeastern U.S. coast(Mannino er al., 2014)</p>
<p>Retrieval of phytoplankton and colored detrital matter absorption coefficients with remote sensing reflectance in an ultraviolet band(Wei and Lee, 2015)</p>
<a id="more"></a>
<h1 id="s_cdm"><span class="math inline">\(S_{cdm}\)</span></h1>
<p>There are not so much analytical or semi-analytical algorithm to estimate <span class="math inline">\(S_{cdm}\)</span>(Spectral slope of cdom and detriutus absorption)</p>
<p>One thing need to notice is that the <span class="math inline">\(S_{cdm}\)</span> is not strictly power-law.</p>
<p>Wei et al just stress the importanct of uv band. The approach is HOPE.</p>
<p>Wei and Lee, 2015 <span class="math display">\[
S=0.00854+\frac{0.005055}{0.2236+r_{rs}(380)/r_{rs}(440)}
\]</span> It is same with lee 2002 using lee 1998 data. Not so strong relationship</p>
<p>But it might could be used.</p>
<p>Mannino et al., 2014, just cdom and the slope of cdom <span class="math display">\[
ln(S)=B_0+B_1X_1+B_2X_2+B_3X_3+\cdots+B_nX_n
\]</span> <span class="math inline">\(X_{i..n}=ln[R_{rs}(\lambda_1...\lambda_n)]\)</span></p>
<p>emprical</p>
<p>Fiche et al 2013</p>
<p>Also cdom slope</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030126195045610.png" alt="image-00030126195045610"><figcaption aria-hidden="true">image-00030126195045610</figcaption>
</figure>
<p>Swan et al., 2013</p>
<p>Just cdom</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030126195239868.png" alt="image-00030126195239868"><figcaption aria-hidden="true">image-00030126195239868</figcaption>
</figure>
<p>Cao and William., 2014</p>
<p>Just CDOM</p>
<p>PCA+MLR</p>
<p>I need to read HOPE</p>
<h1 id="cdom-concentration">CDOM concentration</h1>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Remote Sensing</tag>
        <tag>Inversion</tag>
        <tag>CDOM</tag>
      </tags>
  </entry>
  <entry>
    <title>Correlation metrics</title>
    <url>/posts/e45539ea.html</url>
    <content><![CDATA[<p>本科毕设就没搞懂的两个r现在终于弄明白了</p>
<p>大部分内容来自于维基百科</p>
<p>主要讲Brewin 2015里面用到的metrics</p>
<a id="more"></a>
<h1 id="pearsons-r">Pearson's r</h1>
<p>在<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv57uf6K6h5a2m">统计学<i class="fa fa-external-link-alt"></i></span>中，<strong>皮尔逊积矩相关系数</strong>（英语：Pearson product-moment correlation coefficient，又称作 <strong>PPMCC</strong>或<strong>PCCs</strong>[<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv55qu5bCU6YCK56ev55+p55u45YWz57O75pWwI2NpdGVfbm90ZS0x">1]<i class="fa fa-external-link-alt"></i></span>, 文章中常用r或Pearson's r表示）用于度量两个变量X和Y之间的<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv55u45YWz">相关<i class="fa fa-external-link-alt"></i></span>程度（线性相关），其值介于-1与1之间。</p>
<h2 id="定义">定义</h2>
<p>两个变量之间的皮尔逊相关系数定义为两个变量的<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5Y2P5pa55beu">协方差<i class="fa fa-external-link-alt"></i></span>除以它们<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5qCH5YeG5beu">标准差<i class="fa fa-external-link-alt"></i></span>的乘积： <span class="math display">\[
\rho_{X,Y}=\frac{cov(X,Y)}{\sigma_X\sigma_Y}=\frac{E[(X-\mu_x)(Y-\mu_Y)]}{\sigma_{X}\sigma{Y}}
\]</span></p>
<p>这个是总体相关系数，对于我们抽样的样本，我们可以得到样本相关系数 <span class="math display">\[
r=\frac{\sum_{i=1}^{n}(X_i-X)\sum_{i=1}^{n}(Y_i-Y)}{\sqrt{\sum_{n=1}^{n}}(X_i-\bar{X})^2\sqrt{\sum_{n=1}^{n}}(Y_i-\bar{Y})^2}
\]</span></p>
<p>其中<span class="math inline">\(\bar{X}\)</span>代表样本平均值</p>
<h2 id="数学特性">数学特性</h2>
<p>总体和样本皮尔逊系数的绝对值小于或等于1。如果样本数据点精确的落在直线上（计算样本皮尔逊系数的情况），或者双变量分布完全在直线上（计算总体皮尔逊系数的情况），则相关系数等于1或-1。皮尔逊系数是对称的：corr(X,Y) = corr(Y,X)。</p>
<p>皮尔逊相关系数有一个重要的数学特性是，因两个变量的位置和尺度的变化并不会引起该系数的改变，即它该变化的<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5LiN5Y+Y6YeP">不变量<i class="fa fa-external-link-alt"></i></span> (由符号确定)。也就是说，我们如果把X移动到a + bX和把Y移动到c + dY，其中a、b、c和d是常数，并不会改变两个变量的相关系数（该结论在总体和样本皮尔逊相关系数中都成立）</p>
<h2 id="与相关系数">与相关系数</h2>
<p>这个是最容易混淆的，首先明确<span class="math inline">\(R^2\not=r^2\)</span>并不一直成立，最简单的可以从计算方式来看。</p>
<p><strong>决定系数</strong>（英语：coefficient of determination，记为<em>R</em>2或<em>r</em>2）在<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv57uf6K6h5a2m">统计学<i class="fa fa-external-link-alt"></i></span>中用于度量因变量的变异中可由自变量解释部分所占的比例，以此来判断<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv57uf6K6h5qih5Z6L">统计模型<i class="fa fa-external-link-alt"></i></span>的解释力。</p>
<p>对于简单<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv57ea5oCn5Zue5q24">线性回归<i class="fa fa-external-link-alt"></i></span>而言，决定系数为样本<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv55u45YWz57O75pWw">相关系数<i class="fa fa-external-link-alt"></i></span>的平方。[<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5Yaz5a6a57O75pWwI2NpdGVfbm90ZS1EZXZvcmUtNA==">4]<i class="fa fa-external-link-alt"></i></span>当加入其他回归自变量后，决定系数相应地变为多重相关系数的平方。</p>
<p>假设一数据集包括<span class="math inline">\(y_1,...,y_n\)</span><em>共</em>n<em>个观察值，相对应的模型预测值分别为</em><span class="math inline">\(f_1,...,f_n\)</span>。定义<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3cvaW5kZXgucGhwP3RpdGxlPeaui+W3riZhbXA7YWN0aW9uPWVkaXQmYW1wO3JlZGxpbms9MQ==">残差<i class="fa fa-external-link-alt"></i></span><span class="math inline">\(e_i = y_i − f_i\)</span>，平均观察值为 <span class="math display">\[
\bar{y}=\frac{1}{n}\sum_{i=1}^{n}y_i,
\]</span> 于是可以得到总平方和 <span class="math display">\[
SS_{tot}=\sum_{i}(y_i-\bar{y})^2,
\]</span> 回归平方和 <span class="math display">\[
SS_{reg}=\sum_{i}(f_i-\bar{y})^2,
\]</span> 残差平方和 <span class="math display">\[
SS_{res}=\sum_{i}{(y_i-f_i})^2=\sum_ie_{i}^2,
\]</span> 由此，决定系数可以定义为 <span class="math display">\[
R^2=1-\frac{SS_{res}}{SS_{tot}}
\]</span> 简单点说r计算是在xy之间，R^2计算是在y y_fit之间。</p>
<p>所以R^2的理论范围是<span class="math inline">\((-\infty,1]\)</span>，并不是<span class="math inline">\([0,1]\)</span></p>
<p>只有对于线性回归的最小二乘拟合才有<span class="math inline">\(\rho(x,y)=\pm\sqrt{R^2}\)</span></p>
<p>证明如下 <span class="math display">\[
\rho(x,y)=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{n=1}^{n}}(x_i-\bar{x})^2\sqrt{\sum_{n=1}^{n}}(y_i-\bar{y})^2}
\]</span></p>
<p><span class="math display">\[
\rho(\hat{y},y)=\frac{\sum_{i=1}^{n}(\hat{y}_i-\bar{y})(y_i-\bar{y})}{\sqrt{\sum_{n=1}^{n}}(\hat{y}_i-\bar{y})^2\sqrt{\sum_{n=1}^{n}}(y_i-\bar{y})^2}\\
=\frac{\beta_1\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\beta_1\sum_{n=1}^{n}}(x_i-\bar{x})^2\sqrt{\beta_1\sum_{n=1}^{n}}(y_i-\bar{y})^2}\\
=sgn(\beta_1)\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{n=1}^{n}}(x_i-\bar{x})^2\sqrt{\sum_{n=1}^{n}}(y_i-\bar{y})^2}\\
=sgn(\beta_1)\rho(x,y)
\]</span></p>
<p>在特殊情况下，<strong>带有截距项的线性最小二乘多元回归中</strong>，<img src="https://www.zhihu.com/equation?tex=R%5E2" alt="[公式]">等于实测值<img src="https://www.zhihu.com/equation?tex=y" alt="[公式]">和拟合值<img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]">的相关系数的平方。</p>
<p>另一个特殊情况是，<strong>带有截距项的线性最小二乘简单回归中</strong>，<img src="https://www.zhihu.com/equation?tex=R%5E2" alt="[公式]">等于自变量<img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">和因变量<img src="https://www.zhihu.com/equation?tex=y" alt="[公式]">的相关系数的平方</p>
<p>主要来自https://www.zhihu.com/question/32021302</p>
<p>scikit-learn里的r2是R2</p>
<h1 id="rmsebias-urmse">RMSE,Bias, uRMSE</h1>
<p>这几个都是y和y_fit，很简单，直接上截图吧懒得写</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021216221344982.png" alt="image-00021216221344982"><figcaption aria-hidden="true">image-00021216221344982</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021216221433256.png" alt="image-00021216221433256"><figcaption aria-hidden="true">image-00021216221433256</figcaption>
</figure>
<p>Bias有时也用Relative bias或者MAPE</p>
<h1 id="slope-and-intercept">Slope and Intercept</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021216221526273.png" alt="image-00021216221526273"><figcaption aria-hidden="true">image-00021216221526273</figcaption>
</figure>
<p>Type-2用的是这个包https://github.com/OceanOptics/pylr2</p>
<p>我觉得没啥问题 一看就很专业</p>
<h1 id="log-transfermation">Log transfermation</h1>
<p>主要是要搞明白这个</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030609133319132.png" alt="image-00030609133319132"><figcaption aria-hidden="true">image-00030609133319132</figcaption>
</figure>
<p>图里两条虚线分别是Y=2X和Y=X/2。</p>
<p>X轴每一个大tick代表的是log10(in situ Chla), Y轴代表的是log10(Chla OC3M)，标注的数字是in situ Chla和Chla OC3M</p>
<p>这也是为啥 那条Regression line是Log(y)=a*log(x)+b。</p>
<p>调换一下 就是 y=x10^a + 10^b。</p>
<p>虽然X轴和Y轴标注的数字就是那个In situ Chla，但是实际上每一格对应的数字是1,2,3,4，标注的对应的是10^1, 10^2, 10^3, 10^4，这也是那个Minor tick会先大间隔后小间隔的原因。</p>
<p>但是y=2x和y=x/2这两条线代表的还是Chla OC3M=2 in situ Chla这种的情况</p>
<p>但是在Linear的里面这仨不是平行线，在这里平行了</p>
<p>是因为实质上 画的这两条线是log chla oc3m=log2 +login situ Chla</p>
<p>log2大概是0.3，对应的就是10</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Statistics</tag>
      </tags>
  </entry>
  <entry>
    <title>uv properties 1</title>
    <url>/posts/68e8e2be.html</url>
    <content><![CDATA[<p>主要是从15年开始的四篇论文</p>
<p>An ultraviolet to visible scheme to estimate chromophoric dissolved organic matter absorption in a Case-2 water from remote sensing reflectance</p>
<p>Extending satellite ocean color remote sensing to the near-blue ultraviolet bands</p>
<p>Characteristics of water leaving reflectance at ultraviolet wavelengths: radiative transfer simulations</p>
<p>Retrieval of phytoplankton and colored detrital matter absorption coefficients with remote sensing reflectance in an ultraviolet band</p>
<a id="more"></a>
<h1 id="retrieval-of-phytoplankton-and-colored-detrital-matter-absorption-coefficients-with-remote-sensing-reflectance-in-an-ultraviolet-band">Retrieval of phytoplankton and colored detrital matter absorption coefficients with remote sensing reflectance in an ultraviolet band</h1>
<p>Briefly, this almost same with QAA</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030102133300111.png" alt="image-00030102133300111"><figcaption aria-hidden="true">image-00030102133300111</figcaption>
</figure>
<ol type="1">
<li><p>our analyses indicate that QAA-UV can improve the retrieval of aph and adg, although the improvement in accuracy is not significant for values at 440 nm.</p></li>
<li><p>the separation of adg and aph is highly dependent on the accuracy of the ocean color measurements and the estimated total absorption coefficient.</p></li>
</ol>
<h1 id="characteristics-of-water-leaving-reflectance-at-ultraviolet-wavelengths-radiative-transfer-simulations">Characteristics of water leaving reflectance at ultraviolet wavelengths: radiative transfer simulations</h1>
<ol type="1">
<li>remote sensing reflectance (Rrs) in the UV bands decreased rapidly with the increase in chlorophyll concentration (Chl) and colored dissolved organic matter (CDOM).</li>
<li>In clean waters, Rrs in the UV bands was relatively large and sensitive to changes in Chl and CDOM, which could be of benefit for satellite retrieval of water organic matter.</li>
<li>In eutrophic water, Rrs in the UV bands was quite low, and thence the UV bands could be used as a reference band for atmospheric correction. Compared</li>
<li>Compared to the monotonic decreasing effects of Chl and CDOM, concentration of non-algal particles (NAP) had a complex effect on Rrs in the UV bands, i.e., increase and decrease in Rrs in low-moderately and highly turbid waters, respectively.</li>
<li>the traditional model for the relationship between Rrs and inherent optical properties (IOPs) could be applied to the UV bands in clean waters; in highly turbid waters, however, its deviation increases and empirical coefficients in the model should be improved.</li>
</ol>
<p>I think this three figure is very usefull</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030102142549021.png" alt="image-00030102142549021"><figcaption aria-hidden="true">image-00030102142549021</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030102142611946.png" alt="image-00030102142611946"><figcaption aria-hidden="true">image-00030102142611946</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030102142632252.png" alt="image-00030102142632252"><figcaption aria-hidden="true">image-00030102142632252</figcaption>
</figure>
<h1 id="an-ultraviolet-to-visible-scheme-to-estimate-chromophoric-dissolved-organic-matter-absorption-in-a-case-2-water-from-remote-sensing-reflectanc">An ultraviolet to visible scheme to estimate chromophoric dissolved organic matter absorption in a Case-2 water from remote sensing reflectanc</h1>
<p>This use PCA</p>
<p>Usefull information is this</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030102143447440.png" alt="image-00030102143447440"><figcaption aria-hidden="true">image-00030102143447440</figcaption>
</figure>
<h1 id="extending-satellite-ocean-color-remote-sensing-to-the-near-blue-ultraviolet-bands">Extending satellite ocean color remote sensing to the near-blue ultraviolet bands</h1>
<p>This is also another method that could increase the UV wavelengths.</p>
<p>But it do not discuss the UV properties.</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Inherent Optical Properties</tag>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>《文凭社会》</title>
    <url>/posts/8aa48f64.html</url>
    <content><![CDATA[<p><span class="exturl" data-url="aHR0cHM6Ly9ib29rLmRvdWJhbi5jb20vc3ViamVjdC8zMDE0MzIzNi8v">《文凭社会--教育与分层的历史社会学》<i class="fa fa-external-link-alt"></i></span></p>
<p>（感觉这本书写的并不好？感觉就像那种每个字都看得懂，合在一起就看不懂；读完觉得恍然大悟，合上书又讲不出来它在说什么的书。我也不是社会学的，我尽量总结每章的主要观点）</p>
<a id="more"></a>
<h1 id="第一章-技术管治的迷思">第一章 技术管治的迷思</h1>
<p>受教育的人不管从总量还是质量上来说都呈现越来越多的趋势，同时雇主似乎也越来越强调对雇员专业性的要求。对这一趋势的一个通常解释是：</p>
<ol type="1">
<li><p>当前社会的发展是由科学技术发展引领的，即标题里所提到的“技术管制”。</p></li>
<li><p>教育会帮助学生获得工作所需要的技能，得到社会不能层级所需要的不同技能。</p></li>
<li><p>技能是决定事业成功与否的主要因素。</p></li>
</ol>
<p>这就是通常所提到的技术管制模型。也是第一章和后面几章所论述的主要对象。这一章主要围绕在第二点上，即：教育是如何导致社会的分层的？以及这种分层为什么会出现，存在，和存在差异。</p>
<h2 id="教育的技术相关性">教育的技术相关性</h2>
<p>教育的技术功能理论可以表述为以下命题。</p>
<ol type="1">
<li>工业社会中工作多教育的要求之所以不断提高，是因为技术的变化。这其中涉及两个过程：</li>
</ol>
<p>（a）低技能的工作比例下降，高技能的工作比例上升。</p>
<p>（b）同样的工作在技能要求方面升级了。</p>
<ol start="2" type="1">
<li>正式教育以培养特定技能或普遍能力的方式，提供了胜任最高技能工作所必需的训练。</li>
<li>因此，工作对教育水平的要求不断提高，越来越多。</li>
</ol>
<h3 id="证据与反例">证据与反例</h3>
<p>1.(a): 这一过程仅能解释教育升级中的很小一部分，尤其是对于渡过初级工业化阶段的社会来说是如此。大部分教育升级都发生在工作种类内部。</p>
<p>1.(b): 目前还没有太多的证据能够证明，尤其是我们很难讲量化教育中究竟包含了多少教育所需要的技能，也很难量化这种升级是因为工作技能水平的变化而不是其他原因。</p>
<p>2: 这一命题可以用两种方法来检验：</p>
<p>（1）教育水平更高的雇员比教育水平更低的雇员有更高的生产力。</p>
<p>很多实证数据并不支持这一假设。目前更可能的假设是：工作技能与教育水平不一定呈简单的线性相关，在某一水平之下（例如识字或者高中教育水平）可能工作技能会随着教育水平上升，但是在某一水平之上，二者之间的关系很可能会反转。</p>
<p>（2）职业技能主要是在学校中习得，而非工作中。</p>
<p>很遗憾我们很难找到一组未经教育的工作人员来比较。作为替代，我们可以研究以下两个问题：在学校里能学到什么？学校成绩对工作之后的表现影响如何？</p>
<p>Q1:在学校里能学到什么？</p>
<p>作者把教育分为了三类：职业教育，再培训和我们一般意义上的高中（大学）教育。</p>
<p>职业教育是普通高中教育的替代品，但是很多证据表明，职业教育项目毕业生事业的可能性并不低于高中辍学生。职业教育失败的原因之一，是因为职业高中被视为收容爱惹麻烦的年轻人的地方。就算职业学校的学生碰巧学到了有用的技能，他们曾上过职业高中的经历也可能会被敏锐的雇主是为品行不端的信号。</p>
<p>再教育培训并没有想象中那么难，绝大部分机构都可以在三个月内对其员工进行再教育。很多研究已经表明了，仅仅为了应对技术变革而进行培训是相对容易的。</p>
<p>反而几乎没有人研究在学校里究竟能学到什么，以及学到的东西能记多久。但是很多证据证明学校是个在学习效率上很低的地方。作者认为，比起工具性和认知上的技能，在学校中学到的更多是传统标准下的社交礼节和技能。</p>
<p>Q2:成绩和成功有什么关系？</p>
<p>大量研究证明学校成绩和工资并没有太多的相关性。相关性最大的一个领域是，成绩可以很好地预测接下来的学术表现。作者认为成绩之所以和职业成功相关，主要是因为教育学位的文凭价值，而不是他们本身可能展示的技能。并且，在一些分析中，当把阶级因素保持不变时，学校之间因为教学质量，设施或资金投入上的差别而带来的成绩差异也随之消失了。这意味着学校对学习的影响相对较小，它们只是在塑造上层社会中早已根深蒂固的顺从文化；成绩只不过是用来奖赏和证明中产阶级的自律而已。</p>
<h2 id="总结">总结</h2>
<ol type="1">
<li>高技能工作和低技能工作比例的转变，无法解释我们所观察到的美国劳动力中的教育水平升级</li>
<li>经济上的证据显示，教育在提高大众是自律之后对经济发展并没有很明确的贡献。</li>
<li>特定的职业教育训练主要来自于工作经验，而是不是正式的学校训练。</li>
<li>学生们的在校表现，评分制度的本质及其与职业成功无关的事实，以及学生中的主流思潮，无不表明学校教育作为工作技能训练的手段是效率很低的。</li>
</ol>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>社会学</tag>
      </tags>
  </entry>
  <entry>
    <title>人生实验室</title>
    <url>/posts/c17fab82.html</url>
    <content><![CDATA[<p>前排预警：这篇博客有我大量的个人牢骚和负能量。</p>
<p>面对职业选择哭闹的我被朋友推荐的一本书，附上朋友讲的话。</p>
<blockquote>
<h2 id="人生实验室职涯难题的逻辑图解说明书">《人生实验室：职涯难题的逻辑图解说明书》</h2>
<p>可以在这里试读和购买电子书：https://readmoo.com/book/210118075000101</p>
<p>推荐这本书有三大原因，</p>
<ul>
<li>简明易懂</li>
<li>实用操作性强</li>
<li>有启发性</li>
</ul>
<p>全书一共十六个章节，每个章节由一个图文小故事和一个实验构成，聚焦一个职业生涯发展中常见的问题。作者用小故事把道理讲得深入浅出，微简报很好消化。而实验提供的是工具，引导读者根据具体的步骤来分析自己的问题。</p>
<p>这本书的内核就是教读者运用科学研究的方法来分析自己的问题。我对科学方法的理解是有目的地搜集信息并在此基础上推理来解决特定的问题（作为一名科研人员，老实说我在看这本书的过程中非常汗颜。方法都熟悉，但是从来没有想到过把这一套系统的分析方法应用在解决人生困惑上）。</p>
<p>如果你看这本书的期望是只要看完这本书，你的关于职涯的烦恼统统都会解决，那很抱歉你一定会失望。我不相信世界上存在一纸通用的治疗烦恼的配方，就算有，得到它的人也不会单是因为读完就会瞬间脱离烦恼的纠缠。但是我可以保证，无论你的烦恼是哪一种，在这本书里都会找得到一些启发，帮助你去面对和处理你的烦恼，并且让你对自己做出的选择更有信心。</p>
<p>在考虑人生的重大抉择上，我认为掌握好的分析方法并不难，难的是收集到真实有效的信息作为分析的前提和基础。前提错了，哪怕方法再对，也不能保证得到正解。人往往以为最了解自己的人是自己。诚然，一个人会拥有许多他人没有的关于自己的信息，例如内心活动，感受，情绪等等。但是人也会因为局限于自身的认知和反应模式而看不清关于自己的很多东西。许多世俗眼光中的人生赢家所经验到的是空虚，虽然拥有了人人羡慕的外在之物，还是不知道自己真正想要的是什么。我们能够做的也许就是在搜集这些信息的时候尽可能地对自己诚实。如果你觉得了解自己很困难，那我的建议第一条永远是求助专业人士。</p>
<p>读完这本书，我最深刻的体会是要有求证的实践和付出代价的准备。如果你属于逻辑能力不错的人，那么我相信，如果给你一组命题的真值，你一定能推断出待判命题的真假。然而逻辑强大的人可能反而会经验到更多的内在的冲突并且为此而苦恼。因为现实中面临抉择的时候作为前提的命题很少会全部已知TRUE or FALSE，你遇到最多的很可能是NA。正因为严谨，所以努力把所有因素纳入考虑范围，生怕漏掉任何一种可能性。正因为缜密，所以不会擅自把NA改成TRUE或FALSE，生怕会武断。变量一多就很容易纠结在某些细节上而分不清主次（我举个现实的例子：撒明灯。对不起，太严肃了忍不住不正经一下。）那么一些关键命题的真值能不能通过科学的方法找出来或者逼近？获取信息必须要付出代价，无论是通过实验还是模拟。实现梦想更需要付出代价。</p>
</blockquote>
<p>看这本书的时候带入两个岗位选择，一个是以yk姐姐为参考的公务员，另一个是搞科研。</p>
<p>反正平时也没有人看我的博客，嘿嘿。</p>
<a id="more"></a>
<h1 id="实验001-方向-人生的目标是什么">实验001 方向-人生的目标是什么？</h1>
<blockquote>
<p>工作除了薪水，还有他更重要的意义。这份意义，是你人生真正追求的目标；这份意义，拥有比薪水更重要的价值；这份意义。才是你人生要坚持的方向。不知道努力有什么意义，那你一定要赶快把它找出来。</p>
<p>没有目标的努力，只会让你不断在原地踏步；定清你的方向，让每一步前进都更有意义。</p>
</blockquote>
<p>很遗憾这本书并没有回答，我反而需要不断的问自己，人生的目标是什么？</p>
<p>也许讲人生的目标太遥远，那我，30岁，6年内的目标是什么，或者再退一步，我对我30岁的生活状态有什么要求？</p>
<p>我好像没有什么要求</p>
<p>让我来慢慢的把我理想中的工作/生活细化一下，具体化一下。</p>
<ul>
<li>Work-life balance</li>
</ul>
<p>这条代表了不加班，或者我做科研的话就是凭我自己时间管理能力能做到WLB。</p>
<ul>
<li>小米全家桶的家居</li>
</ul>
<p>这条代表了我有买房的能力，因为组的房子不可能让我这么乱收拾。</p>
<ul>
<li>PS/Swicth/主机齐全，新游戏发售不会因为硬件条件/软件条件玩不了</li>
</ul>
<p>这条代表了，我有足够的经济实力，能自由的翻墙而且不被担心查水表。</p>
<ul>
<li>去过纳米比亚,看过极光</li>
</ul>
<p>这两条代表了我能请下假，并且有长达半个月甚至一个月的年假。</p>
<p>似乎除了做学术或者在国外工作之外，并没有其他的办法能满足了。</p>
<p>其实这些是我2.24晚上更新的，后面的内容，可以不用看了。</p>
<p>我发现我目前的不开心似乎都是来源于我自己。</p>
<p>我自己需要很多的改变。</p>
<ul>
<li>提高效率，干活和其它时间分开</li>
<li>专注干活不分心</li>
<li>早睡早起，养成习惯，坚持运动</li>
<li>提高写代码的规范</li>
<li>多和老板交流</li>
</ul>
<p>我觉得我不是不可能在三年内毕业，不就两篇文章。</p>
<p>那就读吧。</p>
<p>我又在反复横跳了。</p>
<p>后面可以不用看了，暂时。</p>
<p>2021.2.26</p>
<p>自己不要把很多事情想得太美好。</p>
<p>自己读了博，就一定会找到合适的教职吗？</p>
<p>不一定。</p>
<p>哪怕是在日本，也很难。</p>
<p>好累。</p>
<p>自己不要过分美化这个选项。</p>
<p>感觉自己这个是另一个版本的Ph.D Grind</p>
<p>虽然那本书我也没有读完。</p>
<p>自己更大的概率，是像Fukutomi一样。</p>
<p>四十岁也只能当个博后，</p>
<p>每次被老板否定总会抑郁一段时间。</p>
<p>就是自己把研究，把别人对自己的评价看得太重了。</p>
<p>自己还不够强大。</p>
<p>暂时好像就这些？</p>
<p>2021.3.8</p>
<p>再次反复横跳</p>
<p>记住 你自己是一个普通人</p>
<p>哪怕读博，你可能也会没有时间出去玩</p>
<p>而且事业单位也是要上交护照的</p>
<p>我读完博之后那么多压力也可能很难有心情去玩</p>
<p>我又开始迷茫了。</p>
<p>那感觉，自己唯一需要考虑的事情，就是自己对搞研究有没有兴趣了。</p>
<p>如果自己能提出来，偏向science的课题。</p>
<p>自己就很大概率会去读了。</p>
<p>至于读完之后去哪里...</p>
<p>可是自己真的喜欢这种这么富有挑战性的工作吗？</p>
<p>不，自己的本质是不喜欢的。</p>
<p>自己时常性因为各种没有做出来好的结果而失眠。</p>
<p>也常常因为各种问题而焦虑。</p>
<p>自己可能喜欢做一些理论的前沿的事情。</p>
<p>但是可能自己并不适合。</p>
<p>主要是自己的心态太差。</p>
<p>或者如果能有女朋友分担和支持，至少让自己的未来不那么模糊就好了</p>
<p>如果自己能在未来的一段时间里改掉心态的问题，可能会好一些吧？</p>
<p>搞科研可以不焦虑吗？</p>
<p>另一个方向是，正如自己和心理咨询师聊到的。</p>
<p>自己似乎更多的执念都是在那两个愿望上。</p>
<p>对自己别要求太高。</p>
<p>全世界哪里的星星和极光都是一样的。</p>
<p>那些技能 与人交流组织之类的</p>
<p>或许自己可以学？</p>
<p>但是自己擅长吗？</p>
<blockquote>
<p>大量的人在读完博，做完post，甚至到了AP之后都有转行的</p>
<p>https://www.zhihu.com/question/33784042</p>
</blockquote>
<p>自己也就不要想太多</p>
<p>慢慢走才会走的最快</p>
<p>步子大了反而会把自己扯到</p>
<p>而且自己需要调整自己的节奏</p>
<p>如果自己忙到每天搞完研究就没有别的事情。</p>
<p>那就不是 科研 的问题了</p>
<p>而是自己的问题</p>
<p>自己去做什么都会这样</p>
<p>自己可以接受 未来五到十年的不稳定 甚至三十岁才能定下来自己未来的方向吗？</p>
<p>未来五到十年，没有女朋友。</p>
<p>自己 更喜欢什么样的生活？</p>
<p>就拿</p>
<p>不要对自己抱有太多期望。</p>
<p>做好自己眼前能做的事情。</p>
<p>不要对自己抱有太多期望。</p>
<p>做好自己眼前能做的事情。</p>
<p>不要对自己抱有太多期望。</p>
<p>做好自己眼前能做的事情。</p>
<p>我居然没有把结婚孩子房子写在里面。</p>
<h1 id="实验002-稳定-对你来说什么叫做稳定">实验002 稳定-对你来说，什么叫做稳定？</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224154526555.png" alt="image-00030224154526555"><figcaption aria-hidden="true">image-00030224154526555</figcaption>
</figure>
<p>我有喜欢做的事情吗？</p>
<p>我有喜欢做的事情吗？</p>
<p>我有喜欢做的事情吗？</p>
<p>我有喜欢做的事情吗？</p>
<p>我有喜欢做的事情吗？</p>
<p>我有喜欢做的事情吗？</p>
<p>我有喜欢做的事情吗？</p>
<p>我有喜欢做的事情吗？</p>
<p>没有。</p>
<p>哪怕是打游戏，打多了我也会腻。</p>
<p>对我来讲我更多的处于“条件”和“目标”的中间，那就是：我不会因为有个工作可以满足稳定的条件就去做那个工作，但是我也不知道我喜欢什么。我更倾向于，有一个满足稳定条件的工作，同时我又不讨厌。</p>
<p>换而言之，我还是想要一个稳定 条件 的工作。因为我不知道我喜欢什么，想要做什么，也就没有办法让自己喜欢做的事情变得有价值。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224155250373.png" alt="image-00030224155250373"><figcaption aria-hidden="true">image-00030224155250373</figcaption>
</figure>
<p>我在B。</p>
<p>其实这个过程对我来讲挺没意思的，因为我设置的两个选项都是稳定条件。</p>
<p>但是我也列一下吧。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224155358512.png" alt="image-00030224155358512"><figcaption aria-hidden="true">image-00030224155358512</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224155417293.png" alt="image-00030224155417293"><figcaption aria-hidden="true">image-00030224155417293</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224155446374.png" alt="image-00030224155446374"><figcaption aria-hidden="true">image-00030224155446374</figcaption>
</figure>
<h1 id="实验003-盲点-爽到底是什么">实验003 盲点-爽，到底是什么？</h1>
<p>这一章讲 用别人的角度来给自己挑毛病。</p>
<p>虽然很有用，但是对现在的我完全没用。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224155637057.png" alt="image-00030224155637057"><figcaption aria-hidden="true">image-00030224155637057</figcaption>
</figure>
<h1 id="实验004-烦恼-什么才是对的选择">实验004 烦恼-什么才是对的选择？</h1>
<blockquote>
<p>你要花时间的，不是决定要不要做这个选择；</p>
<p>你要花时间的，是把它变成好的选择。</p>
<p>人生最痛苦的，其实不是失败。</p>
<p>人生最痛苦的，是我本来可以。</p>
<p>比作出错误选择更严重的，是明明对现状不满意，却又不敢做出选择。</p>
<p>人生只有一次，别让未来充满后悔；勇敢做出行动，让你的决定成为最佳选择。</p>
</blockquote>
<blockquote>
<p>两难问题：我在考虑要不要OOO，但是我也有点担心XXX</p>
<p>OOO：对原定的前进方向，一直以来的环境状况做出的改变</p>
<p>XXX：期待另一个未来的机会，但是没有把握结果会怎样</p>
<p>也就是说，OOO是“要不要改变状况”, XXX是“担心改变会不如预期”的问题。</p>
</blockquote>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224164811495.png" alt="image-00030224164811495"><figcaption aria-hidden="true">image-00030224164811495</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th>OOO：不读博，回去考公务员需要面对的付出</th>
<th>XXX：担心不读博未来出现的结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>从今年十月到明年八九月份的GAP</td>
<td>可能考错了地方 或者考了之后变得很忙</td>
</tr>
<tr class="even">
<td>准备考试</td>
<td>工资很低，房子买不起</td>
</tr>
<tr class="odd">
<td>搜集资料</td>
<td>可能考不上</td>
</tr>
<tr class="even">
<td>准备面试</td>
<td>可能30岁的时候的收入还很低</td>
</tr>
<tr class="odd">
<td>备战考试</td>
<td>可能会做很多面子工作，对自己来讲很没意义的事情</td>
</tr>
<tr class="even">
<td>学习社交，说话，公文等一系列我不喜欢的事情</td>
<td>可能会后悔，很难再次跳出来读博</td>
</tr>
<tr class="odd">
<td></td>
<td>可能我的脑子会生锈，再也没有机会沉下心学习数学物理文学</td>
</tr>
</tbody>
</table>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224165536748.png" alt="image-00030224165536748"><figcaption aria-hidden="true">image-00030224165536748</figcaption>
</figure>
<p>其实这个图分类的不是很合理，我是可以改变，但是还没有下定决心，应该在D那里而不是E那里。很多时候不是想改变想决定就能改变能决定的。</p>
<blockquote>
<p>这种时候要考虑的是，有没有另外的解法。</p>
</blockquote>
<p>诚实地说，没有。</p>
<p>我只能做两个选择。非此即彼。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224170001363.png" alt="image-00030224170001363"><figcaption aria-hidden="true">image-00030224170001363</figcaption>
</figure>
<p>原来我是在这里</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224170059171.png" alt="image-00030224170059171"><figcaption aria-hidden="true">image-00030224170059171</figcaption>
</figure>
<p>做学术算是自己的理想吗？</p>
<p>不算。</p>
<p>但是自己不去尝试一下做学术会后悔吗？</p>
<p>会。</p>
<p>自己宁愿尝试后再后悔还是后悔没有尝试？</p>
<p>后悔没有尝试。</p>
<p>但是我觉得人还是要现实一点。</p>
<h1 id="实验005-因果-学位与证照那是什么">实验005 因果-学位与证照，那是什么？</h1>
<blockquote>
<p>读博唯一无法取代的，是它的毕业证书。</p>
<p>你的价值，非要毕业证书才能证明吗？</p>
<p>研究所，只是一条路。</p>
<p>这条路，你可以走，也可以不走。</p>
<p>可以大学毕业就走，也可以改天想走再走。</p>
<p>你不会因为念了研究所就脱胎换骨。</p>
<p>你也不会因为没念研究所就矮人一截。</p>
<p>人生不需要急着应在起跑线。</p>
<p>只要赢在终点，哪里是起点有谁会在乎。</p>
<p>人生的路很多条，每一条都是不同选择。</p>
<p>认真走好选择的路，每一条都会是最好的路。</p>
</blockquote>
<p>其实这段话有点废话和心灵鸡汤。</p>
<p>这里面的读博，换成考公务员也是一样的。</p>
<p>但是很多时候不是想走就走，不是想怎么样就怎么样。</p>
<p>的确有人这么做成了，但是我只是一个普通人，我不能对自己要求太多。</p>
<p>我能走好一条路就很不错了。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030224212928778.png" alt="image-00030224212928778"><figcaption aria-hidden="true">image-00030224212928778</figcaption>
</figure>
<p>所以这个其实也跟我现在的问题没啥关系。</p>
<p>我的目标 并不是什么直接的东西</p>
<h1 id="section">2021.2.26</h1>
<p>(进行一下时间标注，上面的都是2.25写的)</p>
<p>自己不要把很多事情想得太美好。</p>
<p>自己读了博，就一定会找到合适的教职吗？</p>
<p>不一定。</p>
<p>在日本，就很难。</p>
<p>刘老师当了那么多年博后。</p>
<p>Aiki当了那么多年博后。</p>
<p>好累。</p>
<p>自己不要过分美化这个选项。</p>
<p>感觉自己这个是另一个版本的Ph.D Grind</p>
<p>虽然那本书我也没有读完。</p>
<p>自己更大的概率，是像Fukutomi一样。</p>
<p>四十岁也只能当个博后，</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>博客第三方插件和图片问题解决</title>
    <url>/posts/361a6d0d.html</url>
    <content><![CDATA[<p>啊四月份本咸鱼赏(da)樱(you)花(xi)和搞毕业论文去了，五月份滚回来更新。争取在没有你的五月（误）把机器学习基石的上更新完，然后把毕业论文的代码发到github。</p>
<p>这一篇包括第三方功能（评论、站点地图、阅读量、统计分析、分享）和图片问题的彻底解决。</p>
<a id="more"></a>
<h1 id="评论">评论</h1>
<p>我采用的评论系统是gitalk，因为这个系统不用注册什么乱七八糟的网站，支持github登录，搞起来很方便。</p>
<p>gitalk详情参见<span class="exturl" data-url="aHR0cHM6Ly9naXRhbGsuZ2l0aHViLmlvLw==">https://gitalk.github.io/<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="注册应用">注册应用</h2>
<p>在GitHub上注册新应用，点击<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NldHRpbmdzL2FwcGxpY2F0aW9ucy9uZXc=">这里<i class="fa fa-external-link-alt"></i></span>。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509163920.png"></p>
<p>网址就填你网站的母页面(像我的是lifeodyssey.github.io)，callback URL也是这个，剩余的随意即可。</p>
<p>点击注册之后页面跳转，其中Client ID和Client Secret在后面用到的时候复制粘贴即可。</p>
<h2 id="gitalk.swig">gitalk.swig</h2>
<p>新建<code>/layout/_third-party/comments/gitalk.swig</code>文件，并添加内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> page.comments &amp;&amp; theme.gitalk.enable %&#125;</span><br><span class="line">  &lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;</span>&gt;</span><br><span class="line">  &lt;script src=<span class="string">&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">   &lt;script <span class="built_in">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><br><span class="line">        var gitalk = new Gitalk(&#123;</span><br><span class="line">          clientID: <span class="string">&#x27;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&#x27;</span>,</span><br><span class="line">          clientSecret: <span class="string">&#x27;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&#x27;</span>,</span><br><span class="line">          repo: <span class="string">&#x27;&#123;&#123; theme.gitalk.repo &#125;&#125;&#x27;</span>,</span><br><span class="line">          owner: <span class="string">&#x27;&#123;&#123; theme.gitalk.githubID &#125;&#125;&#x27;</span>,</span><br><span class="line">          admin: [<span class="string">&#x27;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&#x27;</span>],</span><br><span class="line">          id: location.pathname,</span><br><span class="line">          distractionFreeMode: <span class="string">&#x27;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&#x27;</span></span><br><span class="line">        &#125;)</span><br><span class="line">        gitalk.render(<span class="string">&#x27;gitalk-container&#x27;</span>)           </span><br><span class="line">       &lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<h2 id="comments.swig">comments.swig</h2>
<p>修改<code>/layout/_partials/comments.swig</code>，添加内容如下，与前面的<code>elseif</code>同一级别上：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% elseif theme.gitalk.enable %&#125;</span><br><span class="line"> &lt;div id=<span class="string">&quot;gitalk-container&quot;</span>&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<h2 id="index.swig">index.swig</h2>
<p>修改<code>layout/_third-party/comments/index.swig</code>，在最后一行添加内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% include <span class="string">&#x27;gitalk.swig&#x27;</span> %&#125;</span><br></pre></td></tr></table></figure>
<h2 id="gitalkt.styl">gitalkt.styl</h2>
<p>新建<code>/source/css/_common/components/third-party/gitalk.styl</code>文件，添加内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.gt-header a, .gt-comments a, .gt-popup a</span><br><span class="line">  border-bottom: none;</span><br><span class="line">.gt-container .gt-popup .gt-action.is--active:before</span><br><span class="line">  top: 0.7em;</span><br></pre></td></tr></table></figure>
<h2 id="third-party-styl">third-party-styl</h2>
<p>修改<code>/source/css/_common/components/third-party/third-party.styl</code>，在最后一行上添加内容，引入样式：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@import <span class="string">&quot;gitalk&quot;</span>;</span><br></pre></td></tr></table></figure>
<h2 id="config.yml">_config.yml</h2>
<p>在主题配置文件<code>next/_config.yml</code>中添加如下内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  githubID: github帐号  <span class="comment"># 例：asdfv1929   </span></span><br><span class="line">  repo: 仓库名称   <span class="comment"># 例：asdfv1929.github.io</span></span><br><span class="line">  ClientID: Client ID</span><br><span class="line">  ClientSecret: Client Secret</span><br><span class="line">  adminUser: github帐号 <span class="comment">#指定可初始化评论账户</span></span><br><span class="line">  distractionFreeMode: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>参考<span class="exturl" data-url="aHR0cHM6Ly9hc2RmdjE5MjkuZ2l0aHViLmlvLzIwMTgvMDEvMjAvZ2l0YWxrLw==">https://asdfv1929.github.io/2018/01/20/gitalk/<i class="fa fa-external-link-alt"></i></span>的教程。</p>
<h1 id="站点地图">站点地图</h1>
<p>俗话说得好，酒香害怕巷子深，自己做的宝贝当然是想让别人也看到的。站点地图提交到搜索引擎之后就可以被搜索引擎搜索到了。不过我这里只写了怎么提交谷歌搜索，百度站长所需要的个人信息资料太多太私密，让我不寒而栗，因此我自己不做提交，也不做讲解。</p>
<p>谷歌提交之后还可以通过analytics平台分析访客数据。</p>
<h2 id="开启seo优化">开启SEO优化</h2>
<p>打开主题配置文件，找到seo选项改为true</p>
<h2 id="生成sitmap地图">生成sitmap地图</h2>
<p>先，安装插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br></pre></td></tr></table></figure>
<p>在博客配置文件中改url为你自己的地址</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="comment">## If your site is put in a subdirectory, set url as &#x27;http://yoursite.com/child&#x27; and root as &#x27;/child/&#x27;</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">https://lifeodyssey.github.io/</span></span><br><span class="line"><span class="attr">root:</span> <span class="string">/</span></span><br><span class="line"><span class="comment"># permalink: :year/:month/:day/:title/</span></span><br><span class="line"><span class="attr">permalink:</span> <span class="string">post/:abbrlink.html</span></span><br><span class="line"><span class="attr">permalink_defaults:</span></span><br></pre></td></tr></table></figure>
<p>并添加</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">sitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">sitemap.xml</span></span><br></pre></td></tr></table></figure>
<p>之后hexo d -g，这时在public目录下会生成sitemap.xml。这个之后需要提交给谷歌</p>
<h2 id="提交给谷歌">提交给谷歌</h2>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS93ZWJtYXN0ZXJzLw==">点这里<i class="fa fa-external-link-alt"></i></span></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509182929.png"></p>
<p>点击添加资源</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509183019.png"></p>
<p>选择网址前缀验证，里面选标签验证，在主题配置文件中修改</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Google Webmaster tools verification setting</span><br><span class="line"># See: https:&#x2F;&#x2F;www.google.com&#x2F;webmasters&#x2F;</span><br><span class="line">google_site_verification: xxxxxxxxxxxxx # 此处改为google提供给你的HTML标签content后的内容</span><br></pre></td></tr></table></figure>
<p>这里也可以使用analytics验证，我自己用的是analytics，但是因为时间太久了我忘了怎么做了......没有特别麻烦总之。</p>
<p>回到search consle，点击左侧sitemap<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509183405.png"></p>
<p>输入站点地图的网址并提交，例如https://xxx.github.io/sitemap.xml，接下来就可以谷歌搜一下你自己的博客看看有没有被收录了。</p>
<p>参考：<span class="exturl" data-url="aHR0cHM6Ly9sdWFuemh1eGlhbi5naXRodWIuaW8vcG9zdC84MmQ5MmFkNC5odG1s">https://luanzhuxian.github.io/post/82d92ad4.html<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="robots协议">Robots协议</h2>
<p>为了防止自己的网站被恶意爬取，这一步是必须的。</p>
<p>在站点<code>source</code>文件夹下新建<code>robots.txt</code>文件，文件内容如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Allow: &#x2F;</span><br><span class="line">Allow: &#x2F;archives&#x2F;</span><br><span class="line">Allow: &#x2F;tags&#x2F;</span><br><span class="line">Allow: &#x2F;categories&#x2F;</span><br><span class="line"></span><br><span class="line">Disallow: &#x2F;vendors&#x2F;</span><br><span class="line">Disallow: &#x2F;js&#x2F;</span><br><span class="line">Disallow: &#x2F;css&#x2F;</span><br><span class="line">Disallow: &#x2F;fonts&#x2F;</span><br><span class="line">Disallow: &#x2F;vendors&#x2F;</span><br><span class="line">Disallow: &#x2F;fancybox&#x2F;</span><br><span class="line"></span><br><span class="line">Sitemap: http:&#x2F;&#x2F;yoursite.com&#x2F;sitemap.xml</span><br></pre></td></tr></table></figure>
<p><code>Allow</code>字段的值即为允许搜索引擎爬区的内容，<code>/</code>表示网站首页，<code>/categories/</code>为分类页面，如果菜单栏还有其他选项都可以按照格式自行添加。</p>
<h1 id="阅读量与字数统计">阅读量与字数统计</h1>
<p>阅读量统计我用的是leancloud。<span class="exturl" data-url="aHR0cHM6Ly9sZndlbi5zaXRlLzIwMTYvMDUvMzEvYWRkLWNvdW50LWZvci1oZXhvLW5leHQv">https://lfwen.site/2016/05/31/add-count-for-hexo-next/<i class="fa fa-external-link-alt"></i></span>这篇文章讲的贼详细我就不再赘述了。</p>
<p>字数统计我用的https://github.com/theme-next/hexo-symbols-count-time，也是特别详细，没啥好讲的，需要注意的是这个可能需要一段时间才能显示出来效果。</p>
<h1 id="分享">分享</h1>
<p>同样是出于对隐私的担心和对国产厂商的不信任，没有采用ShareSDK和百度分享，用的AddThis，不知道啥时候会被屏蔽掉。可以直接关联到google。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509184840.png"></p>
<p>进去之后点share button，选一个你喜欢的样式，右上角可以切换PC和Phone显示，点continue可以选择平台，都选完了点Activate Tool,然后获取代码ID</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1557399873308.png"></p>
<p>即public后面的，接着编辑主题配置文件，知道关键字add_this_id,添加即可</p>
<p>参考：<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC80ZWYzNTUyMWZlZTk=">https://www.jianshu.com/p/4ef35521fee9<i class="fa fa-external-link-alt"></i></span></p>
<p>以下更新于2019.5.11。</p>
<p>最后发现其实这个并没有那么好用，自己测试了一下如果是分享到微信的话，只会生成一个链接或者二维码。看了一下主题配置文件中有官方支持的三方插件，发现百度share的隐私要求没有那么严格，但是不支持https协议因此放弃。最后采用likely的方案，具体参见https://ilyabirman.net/projects/likely/。缺点就是不支持微信。不过也就这样吧，做这个博客并不是为了想要多少人看到，想要赚什么钱，只是想记录下自己成长的点点滴滴。</p>
<h1 id="图片问题的彻底解决">图片问题的彻底解决</h1>
<p>我上一篇一直没能把图片问题解决，本地插件一直不成功，然后想注册图床又因为隐私泄露的问题望而却步，突然想到github既然能作为评论系统的载体，能不能作为我图片系统的载体呢？网上一搜果然有人做过了。点击<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL01vbHVuZXJmaW5uL1BpY0dv">这里<i class="fa fa-external-link-alt"></i></span>即可开启PicGo的丝滑体验。</p>
<p>下一篇：定制优化，包括版权页、右下角的猫、升级与备份、背景图片、代码复制、文章连接唯一化、语法优化，pdf。其他花里胡哨但是我没有放到博客里的内容会统一整理出链接放在下一篇里。</p>
]]></content>
      <categories>
        <category>资料贴整理</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>博客更换主题、页面设置及问题解决</title>
    <url>/posts/aaf90768.html</url>
    <content><![CDATA[<p>上一篇解决了博客的生成、部署和更新的问题，实现了基本的功能。这一篇主要来解决更换主题、子页面设置和乱码三个问题。<a id="more"></a></p>
<h3 id="hexo博客主题更换">hexo博客主题更换</h3>
<p>hexo官网就提供了大量的可用<span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3RoZW1lcy8=">主题<i class="fa fa-external-link-alt"></i></span>，我们要做的就是把主题克隆过来。我这里用的是<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lmlpc3NuYW4uY29tLw==">next主题<i class="fa fa-external-link-alt"></i></span>。</p>
<p>其实next主题的文档已经写的很清楚了，我这里主要写一下我对next主题所做的修改。</p>
<p>在这里先区分两个概念，站点配置文件是指根目录下的＿config.yml 文件，主题配置文件是指themes目录下的_config.yml文件。</p>
<h3 id="next主题安装">next主题安装</h3>
<p>唤出gitbash，进入站点目录，输入以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> your-hexo-site</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
<p>即可下载next主题。然后打开站点配置文件,ctrl+f找到theme字段，将它的值改为next</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">theme:　next</span><br></pre></td></tr></table></figure>
<p>接下来输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g -d</span><br></pre></td></tr></table></figure>
<p>即可在网页中看到站点的外观。</p>
<h3 id="next主题设定">next主题设定</h3>
<p>这里<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lmlpc3NuYW4uY29tL2dldHRpbmctc3RhcnRlZC5odG1s">next主题文档<i class="fa fa-external-link-alt"></i></span>写的十分详细，我选用的是mist主题，并且进行了<strong>选择Scheme</strong>、<strong>设置语言</strong>、<strong>设置菜单</strong>、<strong>设置侧栏</strong>、<strong>设置作者昵称</strong>，在这里写一下除了官方文档之外我做的修改。</p>
<h4 id="文章摘要设置">文章摘要设置</h4>
<p>打开主题配置文件，找到如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Automatically Excerpt. Not recommend.</span></span><br><span class="line"><span class="comment"># Please use &lt;!-- more --&gt; in the post to control excerpt accurately.</span></span><br><span class="line">auto_excerpt:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">false</span></span><br><span class="line">  length: 150</span><br></pre></td></tr></table></figure>
<p>把这里的False改为true就可以启动文章显示预览了length是显示预览的长度。</p>
<p>这里我们可以通过在文章使用<!-- more -->标志来精确控制文章的摘要预览，比如这篇文章就是在这个段落的末尾添加了该标志，所以本文在首页的预览就会显示到这个段落为止。 强烈推荐使用该<!-- more -->标志来控制文章的摘要预览，因为这种方式可以让摘要也按照css文件中的样式来渲染。如果使用了自动摘要的功能，你会发现文章摘要是一大团没有样式的文本，很是难看。</p>
<h3 id="hexo页面设置">hexo页面设置</h3>
<p>这里包括添加标签、分类、404页面、关于、代码高亮、社交、数学公式、建立时间、搜索工具，站点地图等到后面添加第三方服务的时候再讲，日程这个我还没弄明白（雾）。</p>
<p>在讲之前先说一下，标签、分类、关于、404需要在主题配置文件中的menu进行开启</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  首页: / || home</span><br><span class="line">  关于: /about/ || user</span><br><span class="line">  标签: /tags/ || tags</span><br><span class="line">  分类: /categories/ || th</span><br><span class="line">  归档: /archives/ || archive</span><br><span class="line">  日程: /schedule/ || calendar</span><br><span class="line">  站点地图: /sitemap.xml || sitemap</span><br><span class="line">  公益站点: /404/ || heartbeat</span><br></pre></td></tr></table></figure>
<h4 id="标签分类关于页面">标签、分类、关于页面</h4>
<p>这三个都是一样的，标签和分类页面<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lmlpc3NuYW4uY29tL3RoZW1lLXNldHRpbmdzLmh0bWw=">next主题文档<i class="fa fa-external-link-alt"></i></span>写的很清楚，我写一下关于页面和多标签的方法。</p>
<p>唤出gitbash，在站点根目录下输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new page <span class="string">&quot;about&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后在source目录下会有一个新的about文件夹，打开可以看到index.md，进行修改。</p>
<p>由于主题配置文件已经修改了，直接进行<code>hexo g -d</code>即可看到效果。</p>
<p>如果想给一篇文章天假多个标签的话，可以有以下两种方式</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">tags:</span><br><span class="line"><span class="bullet">-</span> PS3</span><br><span class="line"><span class="bullet">-</span> Games</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">tags: [标签1,标签2,标签3]</span><br></pre></td></tr></table></figure>
<h4 id="社交建立时间代码高亮数学公式">404、社交、建立时间、代码高亮、数学公式</h4>
<p>前四个next主题文档也都讲的很清楚，这里写一下数学公式。</p>
<p>打开主题配置文件，找到math并作如下修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Math Equations Render Support</span></span><br><span class="line">math:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Default(true) will load mathjax/katex script on demand</span></span><br><span class="line">  <span class="comment"># That is it only render those page who has &#x27;mathjax: true&#x27; in Front Matter.</span></span><br><span class="line">  <span class="comment"># If you set it to false, it will load mathjax/katex srcipt EVERY PAGE.</span></span><br><span class="line">  per_page: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  engine: mathjax</span><br><span class="line">  <span class="comment">#engine: katex</span></span><br></pre></td></tr></table></figure>
<p>另外，在写文章的时候也需要打开mathjax开关，以加快渲染速度</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: index.html</span><br><span class="line">date: 2019-03-07 12:01:30</span><br><span class="line">tags:</span><br><span class="line">mathjax: true</span><br><span class="line">--</span><br></pre></td></tr></table></figure>
<h4 id="搜索工具">搜索工具</h4>
<p>安装npm install hexo-generator-search:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure>
<p>在配置文件中加入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">search:</span><br><span class="line">        path: search.xml</span><br><span class="line">        field: post</span><br></pre></td></tr></table></figure>
<p>即可启用。</p>
<h3 id="常见问题解决">常见问题解决</h3>
<p>常见问题都可以在<span class="exturl" data-url="aHR0cDovL3d3dy5haWNoZW5neHUuY29tL290aGVyLzI1Mzg0NDYuaHRt">这个博客<i class="fa fa-external-link-alt"></i></span>中找到解决方案。我这里主要说一下中文乱码的解决方案。</p>
<p>中文乱码的原因一般是没有采用utf-8编码，我自己测试了一下发现是站点配置文件没有采用utf-8。用notepad++打开，在编码选项中选择转为utf-8即可。</p>
<h3 id="结尾">结尾</h3>
<p>下一期将说明第三方服务的使用，包括评论、站点地图、阅读量、统计分析、分享等功能。</p>
<p>这一期主要参考了官方文档，因此这里不再另外写明参考文献。</p>
]]></content>
      <categories>
        <category>资料贴整理</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
        <tag>进阶</tag>
      </tags>
  </entry>
  <entry>
    <title>我为什么喜欢做科研</title>
    <url>/posts/490b1360.html</url>
    <content><![CDATA[<p>大概是最近拷问自己内心的结果。</p>
<a id="more"></a>
<h1 id="华罗庚">华罗庚</h1>
<p>自己对科研最开始的印象，或许要追溯到这本<span class="exturl" data-url="aHR0cHM6Ly9ib29rLmRvdWJhbi5jb20vc3ViamVjdC8xMDQ3MDI3Lw==">《华罗庚传》<i class="fa fa-external-link-alt"></i></span>。</p>
<figure>
<img src="https://img9.doubanio.com/view/subject/l/public/s1252320.jpg" alt="我看的那个版本的华罗庚传的封面，现在不知道还有没有卖的，也不知道还在不在家里"><figcaption aria-hidden="true">我看的那个版本的华罗庚传的封面，现在不知道还有没有卖的，也不知道还在不在家里</figcaption>
</figure>
<p>小时候家里没钱，书也少，我不知道这本书是谁买的，但是我翻来覆去的看了很多遍，在我心里留下了很深的影响。</p>
<p>我因为这本书开始对数学感兴趣。而且因为这本书介绍了华罗庚杯数学竞赛，我也从小时候开始买了一些竞赛的书开始看着玩，虽然最后因为各种各样的原因没有参与，但是有些东西还是至今难忘。比如抽屉问题，比如数论。</p>
<p>说不上来为什么，自己现在提到这本书的时候脑子里还会有各种各样的影子，比如那句“教授教授，越教越瘦”，比如那个灵感来了在车上推公式的人，比如一个瘦骨嶙峋但是还在坚持在防空洞里面做研究的人，最后，那个在东京大学讲学的身影。</p>
<p>年少的自己完全没有考虑过钱啊什么的，只是觉得这样的生活很好，很吸引人，特别是这种沉浸的状态。</p>
<p>我当时大概是想成为这样的人的。</p>
<h1 id="你这样的学生适合搞研究">你这样的学生适合搞研究</h1>
<p>这是我在高中的时候在一些老师那里收到的评价。</p>
<p>高中的我其实并不出众，成绩没有特别好，竞赛也没考很高。说勤奋努力吧，其实自己内心也清楚自己到底摸了多少鱼。</p>
<p>高中对自己影响深刻的东西大概是《你凭什么上北大》，《花开不败》，还有那个化学竞赛高三转文的学生。自己经常把这些文章打印出来，激励自己好好学习。</p>
<p>但我还真不清楚为什么会在老师那里收获这样的评价。</p>
<p>或许是成绩好，或许是好多时候题目有自己的解题思路，或许是很多时候会因为题目不合适跟老师直接吵起来。</p>
<p>但是总体来讲，我还是觉得，自己高中是一个很平庸的人。</p>
<p>感觉自己高中做的唯一一些对自己的未来有很大影响的事情，就是提前学了高数。我还记得我一开始用的也是一个特别老的版本的高数，我都不知道家里哪儿来这些书，我家里父辈们都没上过大学。</p>
<p>后来换了同济第六版。</p>
<p>自己当时自学了几乎全部的高数上的内容，而这，对我的未来造成了很大的影响，或许一直持续到现在。</p>
<h1 id="你很有自己的想法">你很有自己的想法</h1>
<p>这是我大学老师对我的评价，我的班主任跟我讲了好多次，刘老师似乎也说过。田老师和张老师似乎也讲过。</p>
<p>也许有想法是一个好的评价，但是有想法的人可能并不适合搞科研，因为他会按照自己的想法来，而这个想法，由于在开始做科研之前接受的并不是系统的训练，只看到了大的东西，而根据这个大的东西所找到的喜欢的东西，往往并不是真正有人在做的科研方向，而且因为教材已经过时很多年了，很多东西已经到了一个dead end。</p>
<p>一开始上大学的我，因为高中的时候就学完了一半的高数，所以就跨校区选课选了最难的高数，然后还顺带着选了其他的课。</p>
<p>这导致我到了大四才认全我们班里的同学，也让我认识了很多到现在我还在联系的好朋友。</p>
<p>最重要的，是他让我对模型和量化产生了极大的兴趣。</p>
<p>当时自己专业的专业课大部分都是背背背，而自己选的课很多都需要计算推公式。两相对比起来，自己的专业课很多都没有逻辑，或者说无法进行推导，自己背诵的时候也很痛苦，分数考得很差；相比起来自己选的很多课都考的相当出色。</p>
<p>《普通动物学》这门课我背了很久，但是还是背不下来，最后只考了六十多分。</p>
<p>这门课考完之后，我基本就确定了，我要转行。</p>
<p>中间一个可能去做的方向是生物信息学，班主任曾经给我推荐过他老公海洋所的机会，辩论队的师姐也给我推荐过农科院的机会。说实话，我当时的生物信息学知识还是在北大的生信课程上学的，他们做的还比较偏数学，偏基础和人体，但是我自己并没有非常好的学好这门课。</p>
<p>我当时脑子里对于生物信息学的印象，就是通过一个基因序列我能推导出蛋白质性状，一篇正儿八经的生物信息学的paper应该有大量的公式来定量描述这个过程。</p>
<p>当时的自己，因为没有好好学北大的生物信息学，并没有认识到生物信息学的本质是分析生物信息的大量数据，本质是Informatics，而非Model或者Algorithm。所以在大概看了农科院和海洋所老师的论文之后，惊异的发现他们paper里面一句公式都没有，就放弃了这一方向。</p>
<p>而在生态系统，或者说生态模型，或者说现在自己在做的遥感方向，每个paper都有大量的公式，自己最终也选择了这里。</p>
<h1 id="why-i-want-to-do-research">Why I want to do research</h1>
<p>讲了那么久终于要切到正题了。</p>
<p>之前在跟心理咨询师交流的时候，咨询师问我，为什么你想做科研。</p>
<p>我说：“我脑子里还有想做的事情，虽然我不知道我能不能做出来，也不知道能不能做出来有什么实际的意义，但是这种感觉就像一本小说被翻开一半，后面不再继续跟你讲了一样，会让人异常难受。”</p>
<p>现在看来，或许做研究的想法在我小的时候就开始成形了。</p>
<p>自己脑子里也确实有很多想法，比如检测水质的手机App（国内被空天院做了），比如研究潮间带的变化（被发了RSE），比如苏轼诗词的NLP和地图可视化（到现在还懒癌没有动手做），比如the impact of marine heat wave on phytoplantkon comminity，比如phone LiDAR remote sensing，比如渔业养殖池塘的遥感监测，比如kelp culture carbon emissions，比如自己之前做了一半终止的SSTfusion。</p>
<p>我还可以列举出来我脑子里大量的想法，但是自己的问题是，想的太多了，行动力不足。</p>
<p>自己更像是一个想法的生产者，而在执行想法上，自己还远远不足。</p>
<p>其实到了现在这个阶段，读博，做研究，要更多的考虑现实因素了。而无论怎么看，读博都不是一个经济上高收益的选择。</p>
<p>那自己为什么还想读博？</p>
<p>或许我觉得更多的，还是因为，自己这一路走来，浑然不知自己已经慢慢走到了这条路上。</p>
<p>自己已经走了很长，很久，或许从自己反复看了很多遍华罗庚传开始，就已经在这条路上了。</p>
<p>主动放弃，真的就是不甘心。</p>
<p>但是也许，自己最后也会放弃吧。</p>
<p>生死有命，富贵在天。</p>
<p>也希望自己能早日从抑郁症里面出来。</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>文献管理</title>
    <url>/posts/4ce7830b.html</url>
    <content><![CDATA[<p>mendely停止移动端服务之后发生的事情</p>
<a id="more"></a>
<h1 id="315"><a class="markdownIt-Anchor" href="#315"></a> 3.15</h1>
<p>2021.3.15号mendely停止服务，其实我在一段时间之前就注意到这个事情了。但是今天晚上睡前拿出Ipad打开mendeley一看，打不开，哦，这才发现要处理这个问题了。</p>
<p>我对文献管理软件的要求是：</p>
<ol>
<li>能适配word，并且自动更改引用格式。</li>
</ol>
<p>其实这一条就应该去掉Mendeley了，他的格式识别很有问题，并且这个东西经常在Mac的Word上卡顿；除此之外,Word对公式和图片的支持也不是很好，所以最好他能导出Biblitex或者直接支持Latex。</p>
<ol start="2">
<li>不要让我操太多心，付费可以。</li>
</ol>
<p>这条去掉zotero和Marginote。</p>
<p>其实我非常羡慕Marginote的那个脑图，很符合人脑的思维模式。我现在脑子里就有更新之前的几篇AB的想法，但是直接更新的话长年累月就变成了粪坑，开新的话就搞得太多了写论文的时候也很难找。最直接的做AB的办法就是直接在文献管理软件里直接Annotate。</p>
<p>但是Marginote就太小作坊了，很容易出问题，zotero则跟python一样要搞各种插件，算了算了累了累了。</p>
<ol start="3">
<li>全平台同步</li>
</ol>
<p>其实文件同步很容易，重要的是Annotation的同步，这条直接去掉Marginote。</p>
<ol start="4">
<li>插入文献搜索的时候能搜索到我的Annotation。。</li>
</ol>
<p>这条好像真的挺难的。</p>
<ol start="5">
<li>能自动提取文献相关信息</li>
</ol>
<p>查了好多测评，papers似乎是准确率最高的那个</p>
<p>这么查来查去，好像就剩下Papers能用了。好在他还有个三十天付费，先试试吧。</p>
<p>对了，Mendeley转到其他平台的话，还要记得先降级，真的是垃圾软件。果然世界上没有免费的午餐。而且我这么一转的话之前做的好多标记也都没了。还好我读的文献也不多，而且很多我觉得重要的文献要么打印要么做了AB。</p>
<p>猛然发现自己做AB的Flag已经倒了好久了，哎，自己最近状态确实不好，最近两个月大概。</p>
<h1 id="321更新"><a class="markdownIt-Anchor" href="#321更新"></a> 3.21更新</h1>
<p>自己大概一共有一千多篇文献，导入速度还是挺快的，尤其好评的是如果自己用的是Mendeley导出的带Annotation版本的文献，那么导入到Papers里面也会有。而且文献识别非常准确</p>
<p>唯一麻烦的地方就是因为这个东西全程联网，并不是调用本地的papers软件来插入，而是利用你帐号的数据库，在用Word插入的时候非常慢，而且不能通过搜索Annotation来进行插入，并且还不能离线。</p>
<p>这好像已经不是唯一的麻烦了hhhh，特别是只能在线这一条，真的就很烦。</p>
<p>那这样和我用Latex写有啥区别，速度还快。</p>
<p>别骂了别骂了，已经在安装Latex了。大概是这个https://humanlee1011.github.io/2019/02/25/MacTex/</p>
<p>所以我最后大概可能的流程是</p>
<p>Mendeley 读论文。</p>
<p>Onedrive/papership同步。</p>
<p>导出Bibtex。</p>
<p>VScode写论文</p>
<h1 id="331"><a class="markdownIt-Anchor" href="#331"></a> 3.31</h1>
<p>在实验室不想干活的下午收拾笔记应用。</p>
<p>对我而言,onenote已经完全沦为我的日记软件了，上面有着我从本科开始的所有日记（几乎）</p>
<p>另外一部分在手机便签上，但是这种便签最大的不方便的地方就是你换了手机就很难同步。</p>
<p>这次找笔记应用主要是为了以下几个方面</p>
<ol>
<li>看论文。方便我写Annotation，最好能导出Markdown，这样我可以直接发到博客里面。</li>
<li>支持多端同步，这样我在手机上想起来论文的时候也可以查一下，正好也可以替代本地的便签。</li>
<li>支持全局搜索和双向链接，这是因为看了notion和marginote非常眼馋。</li>
</ol>
<p>最后决定用了思源笔记，别的不说，就发布在github上面的这个调性就非常对我胃口。</p>
<p>反正免费版看起来就很不错了。先试试吧。</p>
<p>不过说真的 上手难度真的有点高</p>
<h1 id="528"><a class="markdownIt-Anchor" href="#528"></a> 5.28</h1>
<p>前几天发生了一件让我大无语的事，某天打开mendeley的时候所有论文都变成这样的了<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030528150841441.png" alt="image-00030528150841441"></p>
<p>这意味着这些论文都不在本地了。而我去检查了一下我放参考文献的那几个文件夹，一点事都没有。</p>
<p>被迫转到zotero了。</p>
<p>Papers必须在线使用这一点真的太烦人了，如果不介意这个用Papers还是很舒服的。</p>
<p>mendely转移到zoetero的步骤</p>
<h2 id="1下载好mendely里面的文献"><a class="markdownIt-Anchor" href="#1下载好mendely里面的文献"></a> 1.下载好mendely里面的文献</h2>
<p>因为我的文献都被搞出本地了，所以我必须得先把它们下回来，参照<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLm1lbmRlbGV5LmNvbS8yMDE4LzA3LzE4L2hvdy10by1yZWNvdmVyLXlvdXItZmlsZXMtYW5kLWFubm90YXRpb25zLWluLW1lbmRlbGV5LWRlc2t0b3AtanVseS0yMDE4Lw==">这个<i class="fa fa-external-link-alt"></i></span>的方法，先装好对应版本的mendely，再去全选，点Edit settings，把那个同步所有文件Synchronize attached files都给选上。</p>
<h2 id="2导出"><a class="markdownIt-Anchor" href="#2导出"></a> 2.导出</h2>
<p>看了一圈感觉还真的没一个能打的，侧面反映了搞科研的都是穷鬼，所以我还是得用zotero。为了导出我之前做的注解和标记，在这一步需要把他降级到1.19.4或者更以前的。在这个版本之后的mendely会把你的注解和标记以另外的格式存储，而不是放在pdf里面。</p>
<p>弄完了之后全选，然后选那个export with annotation。</p>
<h2 id="3导入"><a class="markdownIt-Anchor" href="#3导入"></a> 3.导入</h2>
<p>我跟的的<span class="exturl" data-url="aHR0cHM6Ly9mb3J1bXMuem90ZXJvLm9yZy9kaXNjdXNzaW9uLzMyNTAwL21pZ3JhdGluZy1mcm9tLW1lbmRlbGV5LXRvLXpvdGVybw==">这个<i class="fa fa-external-link-alt"></i></span>方法，虽然我也不是很懂RIS到底是啥</p>
<h1 id="617完全导入方法"><a class="markdownIt-Anchor" href="#617完全导入方法"></a> 6.17完全导入方法</h1>
<p>终于搞定了就zotero的完全导入。</p>
<p>首先把你库里的东西全都同步到账户上，然后卸载，安装1.17或者更以前版本的mendely，接着登陆你的账号把库里的东西同步下来，然后在help里backup一次，最后打开zotero, import里面import from mendely。</p>
<p>这个可以保持你在mendely里的所有东西，包括subfolder啥的之类的</p>
<h1 id="zotero-插件"><a class="markdownIt-Anchor" href="#zotero-插件"></a> Zotero 插件</h1>
<p>所有的插件基本都能在<span class="exturl" data-url="aHR0cHM6Ly93d3cuem90ZXJvLm9yZy9zdXBwb3J0L3BsdWdpbnM=">这里<i class="fa fa-external-link-alt"></i></span>找到</p>
<h2 id="zotfile"><a class="markdownIt-Anchor" href="#zotfile"></a> Zotfile</h2>
<p>下完之后打开tools-add on，小齿轮install add on from files，选择下好那个就行了。</p>
<p>然后tool那里选择zotfile设置一下，最后全选然后右键manage attachment选rename即可</p>
<h2 id="zotero-storage-scanner"><a class="markdownIt-Anchor" href="#zotero-storage-scanner"></a> zotero storage scanner</h2>
<p>跟上面一样的安装方法，安装完之后去tool那里选一下storage scanner就会自动运行</p>
<h2 id="zotero-scholar-citations-zsc"><a class="markdownIt-Anchor" href="#zotero-scholar-citations-zsc"></a> Zotero Scholar Citations (ZSC)</h2>
<p>跟上面一样，装完点一下就行</p>
<p>自己后来又装了几个，不太需要进行特别的设置，我截个图吧。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030619224704905.png" alt="image-00030619224704905"></p>
<h1 id="榛子分享会"><a class="markdownIt-Anchor" href="#榛子分享会"></a> 榛子分享会</h1>
<p>安利一下<span class="exturl" data-url="aHR0cHM6Ly90cmVsbG8uY29tL2IvaUh1VmlGd3EvJUU2JUE2JTlCJUU1JUFEJTkwJUU5JTk5JUFBJUU0JUJEJUEwJUVGJUJDJTlBem9vbSVFNCVCQSU5MSVFOCU4NyVBQSVFNCVCOSVBMCVFNSVBRSVBNHN0dWR5LXdpdGgtbWUtb24tem9vbQ==">榛子的自习室<i class="fa fa-external-link-alt"></i></span></p>
<p>让我来试着做个课代表</p>
<p>来晚了呜呜呜</p>
<p>榛子计算机功底好好，但是感觉她有点暴躁怎么回事。</p>
<h2 id="查文献"><a class="markdownIt-Anchor" href="#查文献"></a> 查文献</h2>
<p>这里榛子在疯狂推荐Research Rrabbi</p>
<p>u1s1我也觉得这个非常好用</p>
<p>然后还推荐了一下Aminer，我用了一下这个<span class="exturl" data-url="aHR0cHM6Ly90cmVuZC5hbWluZXIuY24v">trend<i class="fa fa-external-link-alt"></i></span></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030619000903616.png" alt="image-00030619000903616"></p>
<p>感觉还挺准的，虽然我还真不知道12年那里出现了啥</p>
<p>我有点怀疑他是某个组的学生</p>
<p>草 他说了句是我老板的一个东西，怀疑对了</p>
<p>Research Rabbit导出Bib，zotero直接import nib，然后右键find available PDF</p>
<h3 id="看论文"><a class="markdownIt-Anchor" href="#看论文"></a> 看论文</h3>
<ol>
<li>
<p>看intro和con知道他在讲什么</p>
</li>
<li>
<p>看TOC知道我们应该看那一部分</p>
</li>
<li>
<p>如果Ref是用数字引用的，几乎可以通过看Ref看出来这篇论文在讲什么。看他们Intro引用了什么你用引用啥的</p>
</li>
</ol>
<p>读东西一定要写东西，consume一定要produce</p>
<h2 id="写论文"><a class="markdownIt-Anchor" href="#写论文"></a> 写论文</h2>
<p>Digital Gardern,</p>
<p>用思源笔记来写Ano. B, 想他们会怎么用，直接在Obsidian里做链接</p>
<p>榛子真厉害！</p>
<h1 id="disable-mendely-plugin"><a class="markdownIt-Anchor" href="#disable-mendely-plugin"></a> Disable Mendely plugin</h1>
<p>我把mendely卸载了之后，那个plugin还在word里，搞得word崩溃了好几次，我查了查卸载它还需要在mendeley里卸载，但是我都卸载了？？？您搁着隔着呢？</p>
<p>查了查，就只能这样了，但是记得要重新安装1.18以上的版本。</p>
<p>真的有点恶心。</p>
]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>日本留学申请经验贴（一）之留学机构</title>
    <url>/posts/27dde70e.html</url>
    <content><![CDATA[<p>其实很早之前就想写这个帖子了。自己从去年这个时候到现在花了整整一年时间经历了留学的大大小小的事情，但是不知道从哪里讲起来。就想到哪里讲哪里吧。带有一定的主观性，仅供参考。</p>
<a id="more"></a>
<h2 id="我要不要找留学机构">我要不要找留学机构</h2>
<p>留学这件事，无论是去哪儿，很多人想到的第一件事就是要不要花钱找留学机构，其实这个答案很多，因人而异，而且现在各种机构除了传统的文书服务之外还打出了各种背景提升服务，什么跟哈佛斯坦福的线上研究、世界五百强的内推之类的，具体适不适合就更难说了。这里需要先厘清几个概念。</p>
<h2 id="中介与咨询机构">中介与咨询机构</h2>
<p>我发现很多人都很难分清中介这个概念。拿房屋中介举例子，卖房子的人给中介钱让中介帮忙卖，买房子的人给中介钱来获取信息。放到留学上，留学中介在这里一方面收外国学校的钱来给他们招生，另一方面收学生和家长的钱来帮助他们申请。显而易见，这种概念下的中介对绝大多数人来说都毫无意义，因为国外的好学校不需要中介来帮他们招生。我们平时所找的一些“中介”，更多的是指留学咨询机构。</p>
<h2 id="留学需要的材料">留学需要的材料</h2>
<p>在说要不要找留学机构之前，我想先说明留学需要什么，然后再来说明留学机构能不能帮我们完成这些东西。</p>
<p>对于绝大多数学校的申请来说，需要的硬核材料无非以下几项： - 语言成绩 - 简历 - 成绩单、在读证明、毕业证明 - 推荐信 - Paper - 陶瓷信 - Personal Statement或Statement of Purpose - Writing Sample或Research Proposal</p>
<p>申请的整个过程中还需要做的事有</p>
<ul>
<li><p>查找学校和老师信息</p></li>
<li><p>合理选校定位</p></li>
<li><p>小蜜沟通</p></li>
<li><p>填写网申</p></li>
<li><p>材料寄送</p></li>
<li><p>offer选择</p></li>
<li><p>签证、租房</p></li>
</ul>
<p>前面那一栏是申请的硬实力，也是最能决定你申请结果的因素；而后面这一栏则是申请中的细节问题，但是同样至关重要，因为选校定位不合理、材料寄送不及时而导致全聚德的人每年都有。我接下来将分开说明这两项。</p>
<p>硬核材料</p>
<p>这些材料里，在读证明和毕业证明属于学校开具的材料，只要你递交的时候注意以下几点 （1）英文翻译 （2）学校公章 （3）密封 就不会因为这两个卡你。 ### 语言成绩、简历、成绩单、推荐信、Paper 这五个材料很大程度上其实取决于你自己。无论你是想保研、考研、找工作还是出国，几乎都要用到这五个材料（或者其中一部分）。因此如果大一的学弟学妹们感到很迷茫没有目标，我建议你们就把目标定为出国，因为在我看来这是最难的。到了大三下学期的暑假，如果你成绩好有paper，但是突然不想出国了，那么去保研也是没有任何问题的；对于商科来说，有一份好的实习，不想出国去找工作也很容易。 说远了，这五个材料里，语言成绩和你的成绩单需要你自己去考，留学机构能帮到的无非是指导一下选课（对于想转专业的同学还是很有必要的，因为有些学校写明了如果想申请某个项目必须修读什么课程，但是这个去搜索名校培养方案、录取要求或者询问学长学姐也可以得到）或者提供语言培训（大多数需要收费），最后三维高不高还是看你自己的努力。 简历、推荐信、Paper这三者取决于你之前的科研、实习、竞赛以及其他一些活动（推荐信如果找任课老师写的话需要看你课堂表现），当然了简历的撰写还是有门道的，这个可以重开一个帖子，这里就不多说了。这些活动你自己不努力不积极就拿不到一个足够有分量的推荐信，发表不了Paper，也没有一个丰富的简历。留学机构在这里能做的就是所谓的背景提升项目，给你提供实习内推和科研的资源，或者帮你申请暑研，具体能帮到多少其实情况非常复杂。如果你本身非常优秀但是缺少相关的信息和资源的话，或许对你来说有很深刻的意义；除此之外，就算你通过机构的帮助去了世界五百实习强或者顶尖名校做科研，最后的结果不好，没有什么好的成果，依然不能给你的留学提供太大的帮助；更何况机构提供的这些机会并不是你报名就能够通过，同样存在着竞争，同样需要你本身足够优秀。 ### Personal Statement或Statement of Purpose＼Writing Sample或Research Proposal 这两个的话，前者其实取决于你的语言水平，后者取决于你的科研实力，关于如何撰写这两个材料可以说很长很长时间，这里先聚焦于机构。前者对于大多数学校都是很重要的材料，留学机构能够帮你最多的也是这一个材料，因此我强烈建议就算是DIY的同学也可以找一些机构进行Personal Statement或Statement of Purpose修改润色，我这里推荐一下<span class="exturl" data-url="aHR0cDovL3d3dy5wYWxtZHJpdmUuY24v">棕榈大道<i class="fa fa-external-link-alt"></i></span>，绝对物超所值。而后一个材料，文科有一些专业要求写Writing Sample，我不是很了解，因此在这里不做评论；对于大多数日本申请而言，Research Proposal绝对是最重要的材料没有之一，但是这个材料太过专业和学术化，大多数留学机构只能帮你修改语法、单词错误和一些句式，内容上只有和你申请的老师是同一个方向的在读研究生或博士生才能给出意见（当然了，很多时候你要申请的老板也会给你的Research Proposal一些修改意见），因此Research Proposal去找你的师兄师姐或者关系好的老师修改可能更好一点。有一些机构会说他们可以提供Research Proposal的修改或者代写，如果你因为这个而想和他们签约的话，请一定确认好合同条款和申请辅导老师的水平。</p>
<h3 id="申请细节">申请细节</h3>
<p>相较于硬核材料，在申请细节这一方面留学辅导机构由于有过去学生的申请数据和申请辅导经验，反而能发挥很大作用。但是另一方面，这些也可以通过学长学姐和自己去论坛、官网查询而得到。如果你所在的学校出国氛围比较浓厚的话，留学机构能够在这一项上提供的帮助反而不是很多。</p>
<h2 id="diy的判断标准">DIY的判断标准</h2>
<p>前面说了这么多，接下来我来说一个我认为的DIY理想状态。</p>
<p>如果在大四上学期刚开学的时候，你不打算跨专业申请，语言已经满足要求或者距离很小，已经确定了要申请的项目/学校/导师，手握两到三段拿得出手的科研实习经历，那么你完全不需要找辅导机构，DIY就可以，除非你想申请一些录取难度极高的项目。</p>
<p>现在就可以评判一下自己的实力，看看自己大四上学期的时候能不能达到这个标准。</p>
<h2 id="怎么选择机构">怎么选择机构</h2>
<p>如果你想选择机构的话，还会面临一个怎么选择机构的问题。相信很多人都听说过被某些留学机构坑钱的事情，我认为选择机构主要要有以下几个标准：</p>
<ol type="1">
<li>网申账号、邮箱必须掌握在你自己的手里</li>
<li>合同里有明确的退款政策</li>
<li>学生有权利主动更换导师，并且给出更换所需时间</li>
<li>该机构过往无重大黑历史（这一条在知乎、微信、微博搜一下就能知道）</li>
</ol>
<p>下一期将聚焦于日本研究生申请制度的介绍。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>日本留学申请（四）：经管类申请</title>
    <url>/posts/40e83800.html</url>
    <content><![CDATA[<p>［本文由人美心善的小姑娘蓝田双慕所著］ 本文主要介绍经管类的日本留学申请。笔者自身在申请学校的时候主要是奔着经济系去的，对日本商学院的了解不够深入，因此，笔者只能尽己所能提供自身了解的相关信息，并不能保证信息的完全囊括和绝对准确，希望此文能给有志于申请日本经管类研究生的同学带来一些帮助。</p>
<p>笔者申请的是sgu英文硕士项目，对日语入学的流程和要求不太了解，因此本文主要介绍日本经管类硕士英文项目的申请。</p>
<a id="more"></a>
<p>根据笔者主观判断，将经管类申请分为二类，一是MBA类申请，二是经营或经济类申请。</p>
<h1 id="mba-类申请">MBA 类申请</h1>
<h2 id="ｍｂａ类介绍">ＭＢＡ类介绍</h2>
<p>MBA类申请的典型特点是所需材料较简单，流程比较便捷，基本不需要撰写研究计划书，结业时应该也不需要撰写毕业论文，大致可以类比为国内的专业硕士。</p>
<p>例如，早稻田大学的商学院，除了需要提交雅思，GMAT，成绩单，推荐信外，基本只需要在系统上填写给出的五六个开放性问题。早稻田商学院大致分为金融硕士和MBA硕士，分五轮进行申请。和英美商学院相比，早稻田商学院对雅思，GMAT的硬性要求不是很高，申请难度适中。当然，商学院对费用的要求很高。早稻田商学院学制两年，预计费用600万日元，差不多35万到40万人民币。</p>
<p>除早稻田商学院外，早稻田的亚洲大平洋项目申请过程也不复杂，也不需要撰写研究计划书，同时项目费用也较高。如果希望得到早稻田大学的学历，这个项目也可以考虑考虑。</p>
<p>同为私立高校的庆应义塾大学也开设MBA项目，但其开学日期是每年的四月份,而且可能会要求申请者具有两年或两年以上的工作经验。此外，七所帝国大学也可能会有相应的MBA项目，笔者未能深入查找，读者可以登录大学的官方网站，查看学校的招生项目。</p>
<p>还有需要注意的是，东京大学的MPP项目也值得关注。MPP又称公共政策硕士，也是一种非研究型的硕士项目。MPP的申请好像也不需要撰写研究计划书。对于有志于从日本回国的同学，东京大学的声望还是具有优势的，同时东京大学作为国立高校，学费的负担较小。同时，一桥大学的MPP项目也是很好的。一桥大学在日本声望很高，但由于其规模小，因此声名局限在日本国内。此外，神户，明治，横滨等大学应该也有开设MPP项目，读者在浏览官网时可以稍稍关注一下。</p>
<h2 id="申请所需要的准备">申请所需要的准备：</h2>
<p>对于商学院申请，成绩，语言，实践经历这三项自然是越优秀越好。同时，出身校也会占一部分权重。但如果你背景不强，语言成绩不好，或是实践经历单薄，也不要气馁。在达到学校对语言等的最低标准后，你可以认真地申请一下，想办法展示你好的地方，认真地填写开放性问题，也是很有可能成功的。</p>
<h1 id="经营或经济类研究生申请">经营或经济类研究生申请</h1>
<h2 id="经管或经济类介绍">经管或经济类介绍</h2>
<p>不同于我国的管理学院和经济学院，日本将经管类分为经营部和经济部。经营部大致包括会计，审计，财务管理，市场营销，金融等。经济部大致包括微观经济，宏观经济，产业经济，城市经济，博弈论，计量经济等。有的大学将经营部和经济部合在了一个部门，有的大学将经营部和经济部分开为两个部门。</p>
<p>与理工科申请不同，理工科申请一定要套瓷，即你看到哪个教授不错，就去给他发邮件，简单介绍一下自己，说一下自己对教授的研究方向很感兴趣，希望教授收我为学生。对经管类来说，如果项目的guideline有说需要提前联系导师，即 prospective tutor， 那就提前联系；如果没有提及的话，那就可以不联系。当然，无论有无要求，提前发邮件给喜欢的导师都是有帮助的。</p>
<p>这类研究生申请一般都需要撰写研究计划书。研究计划书类似于大学毕业论文的开题报告，找一个你感兴趣的问题，写出你研究这个问题的计划。研究计划书在这类申请上发挥的作用很大，它名义上表示你未来两年研究的规划。一个可行的，有意义的研究计划书表示你未来两年不会虚度，学校给你的这个名额不会被浪费。所以一定要重视研究计划书，在撰写研究计划书的时候，请务必多找学长，学姐或老师进行参谋。</p>
<p>从我个人观点，写研究计划书前，应该先浏览学校官方网站的老师介绍，看看喜欢老师的研究方向。因为撰写研究计划书消耗精力还是比较大的，所以在选择研究课题时，可以选一些适用性较强，范围较广的研究方向。因为你喜欢的老师可能因为种种原因今年不收学生，所以保险起见，最好让自己的研究计划可以适用于多个导师。</p>
<p>以我个人的经验，申请经管类的时间跨度是很大的，同时申请难度也有点高。另外，因为各个大学开设英语项目的不一致，有时候需要从夹缝里找合适的项目。</p>
<p>首先，东京大学的经济英文项目(UTIPE项目)好像申请比较早。如果2019年十月入学（为方便，下列皆以2019年入学为准）的话，2018年8,9月好像就可以申请。但东京大学对硬件要求很高，一般都需要很好的语言和GRE成绩，申请者的素质也都很优秀，同时招生人数很少，申请难度较高。东京大学还有一个农业经济的项目，分为两轮申请，最后一轮是2019年的2,3月份。京都大学的东亚经济项目同样招生人数较少，竞争激烈。京都大学是需要你填写一个意向导师的，这里强烈推荐填写项目内的教授，不要填写属于经济部但不属于这个项目的导师。</p>
<p>除了东大，京大以外，其他帝国大学开设的英文项目种类不同。大阪大学和北海道好像是没有开设经管类的英文项目。但是我听一位学长介绍，北海道大学可以从食品工程这一类项目中找到经济学方向的导师，有心者应该可以通过此项目来学习经济。名古屋大学开设的英文项目范围较广，涵盖经济，经营项目，同时申请系统设计得比较成熟，可以进行申请。东北大学和九州大学均有经济，经营类项目，需要注意的是东北大学的会计大学院项目好像已经停办，但GPEM经济项目仍然正常运行。九州大学和东北大学的申请时间较晚，如九州大学，好像是2019年4月开始申请。私立大学中，早稻田大学的经济项目从2019年1,2月开始，但据说录取offer一直到5月才能发放。庆应义塾大学的经济项目好像从2019年5,6月开始，但可能需要到日本面试。庆应大学SFC的申请时间较早，SFC中的两个学部（综合政策学部和环境情报学部）看似与经管无关，但其中有经管的细分方向，有经济方面的优秀导师。</p>
<p>如果申请者为了多增加选择，可以申请一些综合性强的项目。比如说农业大类下有农业经济，亚太研究，东亚研究下有区域经济，公共政策下应该有宏观经济。也可以转专业申请，比如说本科商科申请个公司法方向，申请个经济学方向，都是可以的。</p>
<h2 id="申请前需要的准备">申请前需要的准备</h2>
<p>研究型硕士主要看重科研成果，对实习的看重没有那么高。但是本科没有科研成果的也不要灰心，好好写研究计划书，成功的几率还是不错的。</p>
<p>总体来说，评判标准可以分为研究计划书，绩点，语言，出身校。研究计划书是很重要的。同时，经管类研究型硕士一般都是有面试的，通过Skype等，面试的内容基本上围绕研究计划书和personal statement，需要好好准备。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>本科总结</title>
    <url>/posts/726664aa.html</url>
    <content><![CDATA[<p>写在最前面：虽然我明年才毕业，虽然还有毕业认定等等一堆事情要做，但是我所有的理论课程都结束了，大四一年就是申请、科研、语言、毕业事宜，怎么看怎么不像一个本科生的生活，所以就提前总结了吧，而且也免得明年这个时候再忘记了。</p>
<a id="more"></a>
<h2 id="我自己">我自己</h2>
<p>先来写一下我自己。</p>
<p>其实我自己是一个非常容易犹豫不决选择困难的人，同时自己非常懦弱，一直害怕和别人不一样而不被认可，害怕别人的目光。大一入学之前我就想转专业，暑假里联系好了要换宿舍，却在选课前夕放弃；经过了大一一年的摧残，背普动背的要死了，终于又想转专业，和班主任说明了心思，却又在选课的时候踟蹰犹豫，最后决定先选两门课上上看看——上完之后，我真的后悔真的想转了，而且变成了想转数学；但是却不想延期毕业——虽然其实我可以不延期毕业的；现在我大三结束了，在选秋季学期课程的时候，我认认真真的算了一下学分，发现我是可以延期两年辅修CS，可是我已经没有勇气了啊，两年，说出去大学本科六年才能毕业，怕不是要成为别人口中的笑料——我跟我爸妈解释专业到底是干什么，都花了很长时间，在爸妈眼里，辅修和没有辅修看起来是一样的，反而后者代表着我儿子没有能力正常毕业。当然也是因为一直不喜欢海大和青岛，我想我毕业的时候一点都不会不舍，反而非常解脱，我终于能走了，我终于能离开这个让我讨厌了这么久的地方了。</p>
<p>这还表现在我对于出国的决定上，我很早很早就开始想出国了，但是只有在分手之后才真正的下定决心，飞速签了棕榈定了雅思，阻断了自己所有的退路，申请季拿不到offer，就等着灰头土脸的回家吧。</p>
<p>我还是一个自制力、意志力都很差的人。最突出的表现就是，我大学三年没有一个我全身心投入进去的事情。自学CS就学了一点皮毛，甚至皮毛都算不上，专业课不好好听全靠背背背，看paper就拿谷歌翻译一下一目十行，做项目就想着抄代码，借来的书从来没有好好读过，走马观花地看了很多领域的东西，没有坚持完成过任何一个计划。这么说似乎不是特别好理解，拿数字说话，Ubhind(一个手机使用的监控软件)告诉我，我平均五分钟解锁一次手机。我一直想努力改掉这个毛病，但是似乎毫无成效。</p>
<p>我大学里唯一坚持下来的两件事情，就是国赛和美赛。从一开始坚持到最后，美赛论文截止提交两小时前坐在那里静下心来认认真真的改latex代码的我，简直不像是我。感谢陪我做这两次比赛的队友，你们让我感受到了同伴的力量，让我坚持下来。希望未来的路上，我能找到像你们一样好的同伴。</p>
<p>这是我这个人性格里，最能影响我的两点了。</p>
<p>大学里只是简简单单的有一点点成绩，接下来就写一下经验吧。</p>
<h2 id="关于方向">关于方向</h2>
<p>很多老师和同学都说我适合去搞研究，从高中开始，多到我觉得，是不是我除了学习/科研之外，没有任何长处，所以他们想夸我的话，就只能说这个了2333.我在定方向的时候，反而没有受到这个的太多影响，因为我并没有找到一个能让我热爱的的问题或者方向，让我如饥似渴的去学习相关知识迫不及待的去解决它。</p>
<p>每个人来到大学都会有一个问题：我毕业之后究竟要干什么？可能很多人到了毕业也没想清楚，说实话我也不清楚，但我知道了我喜欢的事情究竟是什么样子，和我不喜欢什么事情。</p>
<p>大学毕业的方向，可以大概的分为四类：考研保研、出国留学、考公务员、自主创业、直接就业这几条，大一一年少去参加各种无意义的活动。前两者都需要你去实验室，创业就业需要你的实习经历，不要把宝贵的时间浪费在毫无意义的各种活动上。如果你的目标只是正常毕业，那么修读完所有学分+不违反校规校纪就可以了，剩下的所有被强制要求的活动你都可以不去。</p>
<h2 id="关于课程与培养方案">关于课程与培养方案</h2>
<p>我这个人记忆力不是特别好，我个人喜欢推理、运算与逻辑。数学吸引我的一个方面就是他的完整性，最为人知的比如欧式几何，从五个基本公理就可以推出剩下所有的东西。如果说一门课程能够用一条清晰的线索从头穿到尾，一条做不到三四条也行，那么我非常喜欢学习这种课程并且记忆效果会非常好；但是我所学的大多数专业课，都不能做到这一点，例如普通动物门这门课，我丝毫看不出上一个门的动物特点和下一个门的动物特点有任何逻辑上的联系。我知道这门课只能这样讲，我不觉得孙老师和艾老师讲课讲的不好水平不行，只是我真的很难记下这种结构的东西。就像我的手里只能拿一条线，不管这条线多长多粗，我都能很好的掌握它，但是现在这门课需要我同时拿着十条线，我强行去做的后果要么是只能拿一根背不完，要么只能从每根线上截一部分接到另一个地方——例如背混了桡足类里面哲水蚤、猛水蚤、剑水蚤的区别，考试现场创造出来一只第一触角长度和体长差不多的猛水蚤，手动狗头。</p>
<p>说完了我自己，再来说说培养方案和它的课程。现行培养方案里面的课程安排我相信已经是老师能够做到的最好的情况了，自己不在其位不谋其政，可能下面的意见有点何不食肉糜。</p>
<p>1.专业课导论。</p>
<p>已经上完所有理论课的我已经能够用一条线将所有的课程穿起来，虽然不知道对不对，但是在专业课导论上我没有听见过类似的描述。下列描述单指现在的（2018.7.8）中国海洋大学水产学院海洋资源与环境专业：</p>
<p>海洋资源与环境是海洋学下属的一门应用型学科，学科的基本问题是渔业资源问题。具体到中国渔业资源衰退的背景，就是渔业资源衰退的问题，渔业资源衰退到什么程度，渔业资源为什么会衰退，怎么样恢复渔业资源，怎么样维持渔业资源长期稳定的开发利用，是这个问题的四个方面。</p>
<p>如果老师能在专业课导论上先说明这个，然后再按照这四个方面去引出各个实验室来介绍自己的东西，我们就会对本专业有一个很好的了解。</p>
<p>2.通识教育</p>
<p>中国海洋大学一直坚持“通识为体，专业为用”，那我也分开说好了。先说通识教育部分。</p>
<p>我和行远书院的想法不谋而合，通识教育不是说 你一个学理工科的学点文科的东西，学文学点理工科的就叫通识教育，而是说我在本科毕业以后的生活中，当我需要去学习之前没有教过的东西的时候，我有这一份学习的能力。接下来具体说一下什么样的通识教育才是我眼里的通识教育。</p>
<p>（1）认识事物需要一定的认知方式和精神，例如批判能力、实证能力、推理能力等等</p>
<p>（2）人们已经很少用到能用单一的能力或知识来解决一个特定的问题</p>
<p>（3）黑箱式的工具会越来越多，但是了解背后的原理就用这些工具会产生错误</p>
<p>所以，通识教育应该有三个方面的特点。第一点是对于思维方式的培养，第二点是对于知识和技能的培养。其中知识和技能的培养，不要求精深，但是要求广博和基础。广博至理工农医文商艺体，基础可以视专业而定，但是体系一定要搭建好。例如正确的分辨朋友圈谣言，理解国家政策对于房价的影响，看得懂渔业资源评估论文里面的数学公式。</p>
<p>3.专业课</p>
<p>专业既然为用，就是说我们学到的东西里，肯定有应用型的技能或者技术（插播一句,我觉得科学、技术和工程的区别，应该给每个高考完填报志愿的人好好讲一下）。这个技能或者技术可以是针对于实际问题，例如软件的开发，也可以是针对科学研究中遇到的问题，例如生物统计学。我的意见是，既然是针对问题的课程，那就针对问题去考核。在课程开始之初就确定问题，例如布置一个小组任务或者个人任务，期末的时候通过看同学们问题解决的怎么样来看学习的情况。例如我们很多课程里有针对分类的知识，如果实验条件允许的话，把这些东西让同学们实际去分类鉴定，能够分出来多少就给多少分，学习的效果会比单纯的期末考和好得多。</p>
<p>4.我眼里一个好的培养方案</p>
<p>（1）公共基础比重增加且不设具体课程要求，只设置课程门类和总学分要求，例如总共要学40个学分的课，19个学分的数学，10个学分的化学物理，10个学分的英语，剩余10个学分任意选择。</p>
<p>（2）对于有联系的专业课，安排在相邻学期，例如植物学与藻类学，水生生物学与海洋浮游生物学，渔业资源与渔场学和生物资源评估。</p>
<p>（3）增加项目考核的方式。</p>
<p>5.学习这么多课程的意义</p>
<p>常常有人说学这个有什么用，我也在想到底有什么用。有用是绝对有用的，但是很难体会到。比如我在餐桌上已经可以讲一下吃的是什么东西，看文献的时候专业名次可以不依靠翻译，给身边的人科普海洋生态文明建设；那一大堆公共基础课呢能让我遇见不懂得东西的时候，知道我该去翻偏微分方程的数值解法、数量经济学还是拉汉世界鱼类系统名典。这或许就是学习这些东西的意义吧。</p>
<h2 id="关于本科生科研与竞赛">关于本科生科研与竞赛</h2>
<p>这一部分我一直不知道该怎么去讲，就索性想到啥写啥。</p>
<p>1.比起经历，更重要的是结果。</p>
<p>2.发论文不是目的，体验完整的科研流程才是目的。</p>
<p>3.当你不知道要选择哪个实验室的时候，可以先排除不喜欢的方向，或者去和每个实验室的PI聊天了解情况。</p>
<p>4.大胆的勾搭老师，即便你什么都不会。谁不是从零基础过来的呢。</p>
<p>5.一定要以解决问题为目标。看到一篇论文的方法可以应用在你的问题上面时就去用，不要把时间浪费在学习各种论文的方法上。</p>
<p>6.不要把竞赛当成项目，不要把时间浪费在参加竞赛上，竞赛只是锦上添花的东西。</p>
<p>7.通过本研和竞赛掌握一定的技能和方法。</p>
<p>8.通过这些活动，你会遇见和你一样的人，大神见大神。常有人问我各种队友怎么找啊，我只能说，你想成为什么样的人，你就会遇见什么样的人。</p>
<p>9.申请旁听所在实验室的组会让你对于科研有更明确的认识。</p>
<p>10.没有见到过凌晨四点五点学校的本科生活，才是不完整的本科生活。</p>
<h2 id="结语">结语</h2>
<p>时间过得好快，希望我的最后一年，能够不再像前三年一样，充满遗憾。</p>
<p>如果有错误或者冒犯之处还请海涵，如果有能帮到你的地方，不胜荣幸。</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第二周笔记 Machine Learning Foundation Week 2 Note in Cousera</title>
    <url>/posts/2c9001a2.html</url>
    <content><![CDATA[<p>Learning to Answer Yes/No <a id="more"></a></p>
<h1 id="perceptron-hypothesis-set">Perceptron Hypothesis Set</h1>
<p>Example:Credit Approval Problem Revisited</p>
<h2 id="a-simple-hypothesis-setthe-perceptron">A Simple Hypothesis Set:the 'Perceptron'</h2>
<ul>
<li><p>For <strong>x</strong>=<span class="math inline">\((x_1,x_2,...,x_d)\)</span> 'feature of customer',compute a weighted'score' and</p>
<p>&lt;center&gt; <span class="math inline">\(approve \quad credit\quad if \sum_{i=1}^{d} w_i x_i&gt;threshold\)</span>&lt;center&gt;</p>
<p>&lt;center&gt; <span class="math inline">\(deny \quad credit\quad if \sum_{i=1}^{d} w_i x_i&lt;threshold\)</span>&lt;center&gt;</p></li>
<li><p><span class="math inline">\(y:\{+1(good),-1(bad)\}\)</span>,0 ignored-linear formula<span class="math inline">\(h\in H\)</span>are</p>
<p>&lt;center&gt;<span class="math inline">\(h(x)=sign((\sum_{i=i}^{d}w_i x_i)-threshold)\)</span>&lt;center&gt;</p></li>
</ul>
<p>this is called'<strong>perceptron</strong>'hypothesis histroically</p>
<h2 id="vector-form-of-perceptron-hypothesis">Vector Form of Perceptron Hypothesis</h2>
$$
<span class="math display">\[\begin{split}
h(x)&amp;=sign((\sum_{i=1}^{d}w_i x_i)-threshold)\\
   
    &amp;=sign((\sum_{i=1}^{d}w_i x_i)+\underbrace{(threshold)}_{w_0}\cdot\underbrace{(+1)}_{x_0})\\
   
    &amp;=sign(sum_{i=0}^{d}w_i x_i)\\
    &amp;=sign(W^T x)
\end{split}\]</span>
<p>$$</p>
<ul>
<li>each'tall'<strong>w</strong> represents a hypothesis <em>h</em> &amp;is multiplied with 'tall' <strong>x</strong>——will use tall versions to simplify notation</li>
</ul>
<p>Q:What does <em>h</em> look like</p>
<h2 id="perceptrons-in-r2">Perceptrons in <span class="math inline">\(R^2\)</span></h2>
<p><strong>perceptrons<span class="math inline">\(\Leftrightarrow\)</span>linear(binary) classifiers</strong></p>
<h1 id="perceptron-learning-algorithm-pla">Perceptron Learning Algorithm (PLA)</h1>
<h2 id="select-g-from-h">Select <em>g</em> from H</h2>
<ul>
<li>want: g<span class="math inline">\(\approx\)</span>f(hard when f unkown)</li>
<li>almost necessary:g<span class="math inline">\(\approx\)</span>f on D,ideally <span class="math inline">\(g(x_n)=f(x_n)=y_n\)</span></li>
<li>difficult:H is of infinite size</li>
<li>idea: start from some <span class="math inline">\(g_0\)</span>,and 'correct' its mistakes on D</li>
</ul>
<h2 id="perceptron-learning-algorithm">Perceptron Learning Algorithm</h2>
<p>For t=0,1,...</p>
<p>1. find a mistake of <span class="math inline">\(w_t\)</span> called<span class="math inline">\((x_{n(t)},y_{n(t)})\)</span></p>
<p>sign<span class="math inline">\((W^{T}_t X_{n(t)})\not=y_{n(t)}\)</span></p>
<p>2. (try to) correct the mistake by</p>
<p><span class="math inline">\(w_{t+1}\leftarrow w_t+y_{n(t)}x_{n(t)}\)</span></p>
<p>...until no more mistakes</p>
<p>return last <strong>w</strong> (called <span class="math inline">\(w_{PLA}\)</span> )as <em>g</em></p>
<p>My question:why determinant is like vector</p>
<h2 id="pratical-implementation-of-pla">Pratical implementation of PLA</h2>
<h3 id="cyclic-pla">Cyclic PLA</h3>
<h2 id="some-remaning-issues-of-pla">Some Remaning issues of PLA</h2>
<p>###　Algorithmic:halt(no mistake)? - naive cyclic:?? - random cyclic:?? - other variant:??</p>
<h3 id="learninggapprox-f">Learning:<span class="math inline">\(g\approx f\)</span> ?</h3>
<ul>
<li>on D, if halt,yes(no mistake)</li>
<li>outside D:??</li>
<li>if not halting:??</li>
</ul>
<h1 id="guarantee-of-pla">Guarantee of PLA</h1>
<h2 id="linear-separability">Linear Separability</h2>
<ul>
<li>if PLA halts(i.e. no more mistakes), (necessary condition)D allows some <strong>w</strong> to make no mistakes</li>
<li>call such D linear separable</li>
</ul>
<h2 id="pla-fact-w_tgets-more-aligned-with-w_f">PLA Fact: <span class="math inline">\(w_t\)</span>Gets More Aligned with <span class="math inline">\(w_f\)</span></h2>
<ul>
<li><p><span class="math inline">\(w_f\)</span> perfect hence every <span class="math inline">\(x_n\)</span> correctly away from line: <span class="math inline">\(y_{n(t)}w_f^T x_{n(t)}\ge \underset{n}{min} y_{n(t)}w_f^T x_{n(t)}&gt;0\)</span></p></li>
<li><p><span class="math inline">\(w_f^T w_t\uparrow\)</span>by updating with any<span class="math inline">\((x_{n(t)},y_{n(t)})\)</span> <span class="math display">\[
\begin{split}
w_f^Tw_{t+1}&amp;=w_f^T(w_t+y_{n(t)}x_{n(t)})\\
&amp;\ge w_f^Tw_{t}+\underset{n}{min}  y_{n(t)}w_f^T x_{n(t)}\\
&amp;&gt; w_f^Tw_{t}+0
\end{split}
\]</span></p></li>
</ul>
<p><span class="math inline">\(w_t\)</span> appears more algned with <span class="math inline">\(w_f\)</span></p>
<p>Q:the length of vector</p>
<h2 id="pla-fact-w_t-does-not-grow-too-fast">PLA fact: <span class="math inline">\(w_t\)</span> Does Not Grow Too Fast</h2>
<p><span class="math inline">\(w_t\)</span> changed only when mistake</p>
<p><span class="math inline">\(\Leftrightarrow sign(w_t^Tx_{n(t)})\not=y_{n(t)}\Leftrightarrow y_{n(t)}w_t^Tx_{n(t)}\le 0\)</span></p>
<ul>
<li>mistake ‘limits’<span class="math inline">\(||w_t||^2\)</span> growth,even when updating with’longest’ <span class="math inline">\(x_n\)</span> <span class="math display">\[
\begin{split}
||w_{t+1}||^2&amp;=||w_t+y_{n(t)}x_{n(t)}||^2\\
&amp;=||w_t||^2+2y_{n(t)}w_t^Tx_{n(t)}+||y_{n(t)}x_{n(t)}||^2\\
&amp;\le ||w_t||^2+0+||y_{n(t)}x_{n(t)}||^2\\
&amp;\le||w_t||^2+\underset{n}{max}||y_nx_n||^2
\end{split}
\]</span></li>
</ul>
<p>start from <span class="math inline">\(w_0=0\)</span>,after<em>T</em> mistake corrections, <span class="math display">\[
\frac{w_f^T\quad w_T}{||w_f||\quad||w_T||}\ge \sqrt{T}\cdot constant
\]</span></p>
<h2 id="novikoff-theorem">Novikoff theorem</h2>
<p>ref:Lihang<statistic learning approach>page 31</statistic></p>
<p>设训练数据集<em>T</em>=<span class="math inline">\({(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}\)</span>是线性可分的，其中<span class="math inline">\(x_i\in\mathcal{X}=R^n,y_i\in\mathcal{Y}={-1,+1},i=1,2,...,N\)</span>,则</p>
<p>（1）存在满足条件<span class="math inline">\(||\hat{w}_{opt}||=1\)</span>的超平面<span class="math inline">\(\hat{w}_{opt}\cdot\hat{x}+b_{opt}=0\)</span>将训练数据集完全正确分开，且存在<span class="math inline">\(\gamma&gt;0\)</span>，对所有<span class="math inline">\(i=1,2,...,N\)</span> <span class="math display">\[
y_i(\hat{w}_{opt}\cdot\hat{x}_i)=y_i(\hat{w}_{opt}\cdot\hat{x}_i+b_{opt}\ge\gamma
\]</span></p>
<p>(2)令<span class="math inline">\(R=\underset{1\le i\le N}{max}||\hat{x}_i||\)</span>,则感知机算法在训练数据集上的误分类次数<em>k</em>满足不等式 <span class="math display">\[
k\le (\frac{R}{\gamma})^2
\]</span></p>
<h1 id="non-separable-data">Non-Separable Data</h1>
<h2 id="more-about-pla">More about PLA</h2>
<p>CONS:maybe not’linnear separable’,and not fully sure how long halting takes</p>
<h2 id="learning-with-noisy-data">Learning with Noisy Data</h2>
<h2 id="line-with-noise-tolerance">Line with Noise Tolerance</h2>
<p>NP-hard</p>
<h2 id="pocket-algorithm">Pocket Algorithm</h2>
<p>Find the least mistakes until iterations</p>
<h1 id="summary">Summary</h1>
<ul>
<li><p>Perceptron Hypothesis Set</p>
<p>hyperplanes/linear classifiers in <span class="math inline">\(\mathcal{R}^d\)</span></p></li>
<li><p>Perceptron Learning Algorithm(PLA)</p>
<p>correct mistakes and improve iteratively</p></li>
<li><p>Guarantee of PLA</p>
<p>no mistake eventually if linear separable</p></li>
<li><p>Non-Separable Data</p>
<p>hold somewhat’best’weights in pocket</p></li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>清华大学《研究生学位论文的选题方法》讲座实录</title>
    <url>/posts/307feb93.html</url>
    <content><![CDATA[<p>讲座地址：https://www.bilibili.com/video/av94346515</p>
<a id="more"></a>
<h1 id="学位论文">学位论文</h1>
<p>博士学位论文要求</p>
<ol type="1">
<li>掌握坚实宽广的基础理论和系统深入的专门知识</li>
<li>具有独立从事科学研究工作的能力</li>
<li>在科学或专门技术上做出创造性的成果</li>
</ol>
<p>硕士学位论文要求</p>
<ol type="1">
<li>掌握坚实的基础理论和系统的专门只是</li>
<li>具有独立从事科学研究工作或独立担负专门技术工作的能力</li>
</ol>
<p>研究生培养时间表：</p>
<table>
<thead>
<tr class="header">
<th>时间</th>
<th>博士生</th>
<th>硕士生</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>课程学习，了解本学科基础知识</td>
<td>同左</td>
</tr>
<tr class="even">
<td>2</td>
<td>选定学位论文研究题目，开展研究工作</td>
<td>同左</td>
</tr>
<tr class="odd">
<td>3</td>
<td>开展研究工作</td>
<td>学位论文答辩</td>
</tr>
<tr class="even">
<td>4</td>
<td>开展研究工作</td>
<td></td>
</tr>
<tr class="odd">
<td>5</td>
<td>学位论文答辩</td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="选题的重要性">选题的重要性</h1>
<p>##　科研三观</p>
<ol type="1">
<li>学术界的发展规律是什么？：推陈出新，创新至上</li>
<li>研究生阶段要实现的目标是什么？：追求卓越，锻炼能力</li>
<li>什么样的科学研究是有价值的：创造知识，服务国家</li>
</ol>
<p>##　科研问题</p>
<p>科学研究围绕着提出问题和回答问题而展开</p>
<p>评价研究问题的标准</p>
<ul>
<li>重要性：是否是学科中的重要问题</li>
<li>创新性：是否为学科创造新的知识</li>
<li>前沿性：是否有可能引领未来潮流</li>
<li>探索性：是否尚未得到充分的探索</li>
<li>基础性：是否对相关方向产生影响</li>
<li>复杂性：是否具备三年探索的体谅</li>
<li>系统性：是否可分解为多个子问题</li>
<li>可行性：是否具备短期实现可能性</li>
<li>承接性：是否具有良好的前期积累</li>
<li>适合性：是否能够发挥自己的能力</li>
</ul>
<p>###　重要性</p>
<p>评估一下该问题在学科发展主脉络上的问题</p>
<p>If you do not work on an important problem, it is unlikely you will do important work--Richard Hamming</p>
<ol type="1">
<li>悬而未决的重要挑战</li>
<li>制约发展的关键瓶颈</li>
</ol>
<h3 id="创新性">创新性</h3>
<p>研究该问题应该突破人类知识的边界，创造新知识</p>
<h3 id="前沿性">前沿性</h3>
<p>判断该问题当前在本学科发展大潮中的位置</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309121010.png"></p>
<p>###　探索性</p>
<p>评估目前问题的解决程度和未来可能的创新空间</p>
<h3 id="基础性">基础性</h3>
<p>该问题对于本学科和相关学科产生广泛深远的影响</p>
<h3 id="复杂性">复杂性</h3>
<p>该问题有足够的体量，可拆分为若干个创新点</p>
<p>###　系统性</p>
<p>各个子问题之间密切关联、有机衔接、浑然一体</p>
<h3 id="可行性">可行性</h3>
<p>该问题应该具备在短期内被解决的可能性</p>
<h3 id="承接性">承接性</h3>
<p>课题组有良好的工作积累，能够提供最大的助力</p>
<p>###　适合性</p>
<p>自己对该问题感兴趣，能够充分发挥出自己的优势</p>
<h1 id="如何进行选题">如何进行选题</h1>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309135345.png"></p>
<h2 id="文献调研">文献调研</h2>
<p>勤读文献，及时更新知识结构，站在领域前沿</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309171527.png"></p>
<h3 id="经典著作">经典著作</h3>
<p>每个都要读，一个读三遍才读懂(ORZ)</p>
<h3 id="期刊杂志">期刊杂志</h3>
<p>同时阅读领域内外的期刊杂志，注意学科交叉</p>
<h3 id="会议论文集">会议论文集</h3>
<p>时效性高、质量上乘，是最佳平衡点</p>
<h3 id="学者主页">学者主页</h3>
<p>了解本学科顶级学者目前正在研究的问题</p>
<h3 id="社交媒体">社交媒体</h3>
<p>Twitter, blog, FB, BBS</p>
<h3 id="预印网站">预印网站</h3>
<p>实效性最高，质量最参差不齐</p>
<h3 id="粗度与精读">粗度与精读</h3>
<p>80%的文章看标题</p>
<p>14%的文章阅读标题和摘要</p>
<p>5%正文</p>
<p>1%所有细节</p>
<h3 id="深入思考">深入思考</h3>
<p>去粗取精，构建知识体系，找到关键文献节点，形成个人思考</p>
<p>##　独立性</p>
<p>坚持独立自主，不要老是问老师师兄师姐做啥，别把希望寄托在别人身上</p>
<h2 id="勇气">勇气</h2>
<p>不畏风险，做具有挑战性的问题</p>
<p>高风险=高回报</p>
<p>高门槛=低竞争</p>
<p>One of the characteristics of successful scientists is having courage. Once you get your courage up and believe that you can do important problems, then you can. If you think you can’t,almost surely you are not going to.</p>
<p>如果你觉得你做不出来，就基本做不出来了</p>
<p>曲高和寡，领先于时代的人往往不被理解</p>
<h2 id="理性选择">理性选择</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309173654.png"></p>
<p>承接性跟合适性不重要，因为你把它做出来你就有能力和基础了（也许这就是大佬吧）</p>
<p>问题更重要</p>
<h1 id="总结与qa">总结与Q&amp;A</h1>
<h2 id="总结">总结</h2>
<ul>
<li>选择学位论文题目是研究生阶段的重大战略性决策，必须高度重视。越早越好，定了就不要换，后面基本上就不要变了</li>
<li>弄懂什么才是好的研究题目，通过充分的调研和思索，尽可能多找出候选题目，</li>
<li>独立思考，理性决策，有勇气选择有挑战性的题目</li>
</ul>
<h2 id="qa">Q&amp;A</h2>
<ol type="1">
<li>怎么找1%值得精读的文献？</li>
</ol>
<p>一开始100%都要读标题，然后再选14%读摘要，慢慢往下漏；另一种策略是找师兄和老师推荐文献，把他们作为入口。读经典的文章，读大佬的文章，读新的文章</p>
<ol start="2" type="1">
<li>如果实验室没有基础怎么办？</li>
</ol>
<p>看研究性质，计算机方向很多数据都是公开的，开辟新方向问题不大；生物、机械等领域需要大型仪器设备的研究，实验室基础就很重要。</p>
<ol start="3" type="1">
<li>社会科学的选题方式和理工科一样吗？</li>
</ol>
<p>没有太大区别</p>
<ol start="4" type="1">
<li>如果课题难度过大，进展缓慢，需要换课题吗？</li>
</ol>
<p>和时间点相关，如果刚开始，用十条原则打分，觉得确实不行，那就换吧；第四年第五年就要慎重，换课题可能延期。</p>
<ol start="5" type="1">
<li>如何平衡文献调研、理论学习和实际搞科研的时间？</li>
</ol>
<p>也取决于时间点，一二年级文献调研和理论学习比较重要，70%+，三四年50%</p>
<ol start="6" type="1">
<li>三五年研究生生涯怎么规划？</li>
</ol>
<p>看个人的基础。最好按照标准模式来，第二年一定要把题目定下来，第一二年学完所有基础知识，二三四五进行创造知识。</p>
<ol start="7" type="1">
<li>先看论文再提问题还是先提问题再看论文？</li>
</ol>
<p>两种都是，可以看文章来想idea；也可以先想idea，想自己该怎么解决，避免自己的思维被束缚，再去读文章验证自己的idea，看看自己想的别人有哪些没做过，如果都没做过，那就去做吧233。</p>
<h1 id="附录如何阅读文献">附录：如何阅读文献</h1>
<p>(这个好像是知乎还是微博某位老师写的)</p>
<p>最近很多人问我该如何阅读文献，才能提高速度和效率，然后做文献综述。其实读文献是一件很枯燥的事情，而且往往走进迷宫，比如会经常在一个相关的领域里越看越多，走向枝节，往往花费掉一两周的时间，把握不好和自己选题的关系，觉得进度很慢。其实这是每个人都会遇到的困境，有的时候很难取舍。</p>
<p>我个人的体会是：本科生、硕士生和博士生采取不同的阅读方式和文献梳理方式。阅读英语文献第一点是英文要足够好，靠大量阅读，英语的水平也可得到实质性的提高。</p>
<p>本科生阅读相对简单，如果你给本科生上过课，或者经常看一些教授的本科生讲义，你会发现，一般推荐的必读文献都是一些写的很经典的教材（通俗易懂，英语写得很朴实，不是拽文采那种），或者引用率非常高的一些学术论文。我建议本科生的涉猎广一些，学科内部每个领域都尝试读一下，不求多么高深的领悟，但要明白每个故事的完整性。有时候“浅尝辄止”也不是一无是处的，在有限的时间，多读一些topic，这样以后读研究生才会发现自己的兴趣点。</p>
<p>硕士生是初级研究阶段，一般硕士生周期很短，毕业之后也未必做学术。但是作为初级研究者我建议在老师的指导下，选定一个合适的题目，然后开始选文献。这个阶段选文献就像捡树叶，要懂得取舍。这个过程可以发挥导师的作用让老师推荐（实际老师在上课的时候也会提供一些参考文献目录），也可以从本专业最基本的几本期刊入手，比如先选择3－5本期刊把最近10年的相关研究先找出来，然后根据和自己研究的亲疏程度进行精读和囫囵吞枣式阅读的分类。这个时候就像捡树叶不能只看脚底下，要看清这片叶子是从哪棵树掉下来的。这棵树就是你的研究领域，这里面有你的研究主题。换句话说，硕士生可以“只见树木，不见森林”。</p>
<p>博士生是独立研究阶段的开始，这时候和导师是合作关系。这个阶段，了解一个概念，一般会从实证文章入手，但初始很难判断文章好坏，大概读10-20篇，对概念理论脉络可形成初步认识（从树叶到树枝）。100篇是质变阶段可以把概念讲清楚（看清树干轮廓），这时候文献的好坏你会很快区分。读到500篇却会变茫然，因发现树根了，一个概念所依赖土壤都在这里，这就是地理哲学部分。 我建议优秀的博士生一定要从本源上看清楚问题，忽视本体论的做法，认识论容易出现偏差，因为理论有不同的内生性背景因素。并且博士生不能只爱一棵树，博士生读文献有个tool是专业的Handbook，这是比较general的了解一个专业的方法，我认为博士的阅读要广度和深度兼顾。树与树之间成长的环境差异可以是很大的，这时候很考验对交叉学科的了解和哲学流派的掌控。我认为一周期的PhD，大概是2年在阅读（我默认此人对这个领域在硕士阶段已经有初步了解）。厚积薄发的好处不像处理数据可直接看出效果，但是我想这种受益是一生的。</p>
<h1 id="附录2-文献阅读的三个阶段">附录2: 文献阅读的三个阶段</h1>
<p>(这个似乎也是微博某个老师写的)</p>
<p>今天Academic English在讲《如何成为学术论文写作高手》第二节（P53）时讲到文献综述的重要性。说到阅读文献一般分三个阶段：</p>
<ol type="1">
<li>First stage：开始阶段我们主要通过文献阅读来学习，并不能很好地评估文献及批判性思考。此时的我们，开始通过文献了解一些大牛，了解学术研究中的矛盾、争论点。</li>
<li>Second stage：此时你会非常了解文献中做的实验，就像自己的实验一样。在看文献时，除了结果，更注重他们发现这个结果的过程。 关注他们的假设，寻找不同文献间理论的异同而不是表述的异同。对这个问题的未来走向有一个大致把握。</li>
<li>Final stage：找到文献与自己研究工作的相关点，发现自己的工作可以为以往的某些争论提供证据。</li>
</ol>
<p>其中，从第一阶段过渡到第二阶段，就是需要我们批判性地去思考文献所讲的内容，虽然这个过程很难，但我们依然要在边读边学的同时去思考这个。 唯有在实践中，才能提高自己评估文献、批判性思考的能力。此处，本书提供了几个有助于我们评估文献质量的问题，如下：</p>
<ul>
<li>是否有给出清晰的科学问题？</li>
<li>理论基础是否清晰？</li>
<li>陈述的实验结果是否新颖？</li>
<li>该研究是否具有影响力，使得其他人继续做下去？</li>
<li>研究的样本是多少？是否足够大？</li>
<li>论据是否可信？</li>
<li>结果是如何分析得到的？</li>
<li>他们是从什么角度出发提出这个观点的？</li>
<li>他们的总结是否可以被文中提出的证据论证？</li>
<li>研究的可行度有多少？</li>
<li>研究背后的假设是什么？</li>
<li>该研究所采用的研究方法是否是最好最合适的方法？</li>
<li>很多年轻的学者总是会质疑自己的工作是否值得发表。工作的可信度、创新性、数据、模式？此时，please appreciate your tiny achievement</li>
<li>写论文的时候，记得要站在审稿人、读者的角度，想想他们在看到这篇文章时会提出什么问题。</li>
<li>审稿人总是会比较焦躁、不耐烦的，偏见也总是存在的</li>
<li>为了发表几张图片，你可能需要画一大堆图，并可能需要花很长的时间去分析一张图</li>
<li>你的文章最好能让别人感兴趣并留下深刻印象，不要让别人读着读着睡着了</li>
<li>充分理解要呈现的结果。Always create an outline。写文章时最先准备的是图表和图注</li>
<li>文章被拒的多数是因为重复度太高，所以在写文章时避免重复性或与其他文章类似的表述</li>
<li>注意投稿期刊的格式，不同期刊的格式要求不同，例如副标题的点、作者名字、引言格式</li>
<li>写文章用新罗马字体（字号12），双倍行距，表上页码和行数；但在做PPT时用Arial字体，此外，在做PPT时注意变换图片形式，以吸引观众</li>
<li>写文章避免长度超过四行的长句以及不必要的词句和重复。</li>
<li>表述不要过于绝对或强烈，但也不要过于平淡。</li>
<li>避免一张图一句话，避免一段话只有一句话。</li>
<li>避免在没有陈述他人研究成果的前提下引用过多文献。</li>
<li>不要使用太多缩略语，不要过分夸大特征，不要随意评判别人的研究成果（他可能是你的审稿人），不要在一个句子中重复使用同一个单词</li>
<li>强调研究结果的重要影响，但也要对研究结果的caveats诚实。</li>
<li>你的图是否清晰，特征是否明显标注，你的图对读者是否友</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>狼总访谈</title>
    <url>/posts/6ff151e3.html</url>
    <content><![CDATA[<p>最近看到杨振宁在国科大的访谈上说“一个年轻的研究生最重要的一件事情是什么？其实不是你学到哪些技术，而是要使你自己走进未来五年、十年有大发展机会的领域，这才是你做研究生时所要达到的目标”，想起来自己大一找狼总访谈时，狼总说自己做出退博的一个重要原因就是能看到教培行业存在的问题，并且知道自己能够解决这个问题。</p>
<p>因此重新把这篇当时的访谈作业发出来，希望自己未来再站在十字路口时能够做出一个不令自己后悔的决定，也希望能帮到看这篇文章的你。</p>
<p>写的比较粗浅，切莫见笑。</p>
<a id="more"></a>
<p>朱宇,现担任北京<em>新东方</em>学校优能一对一部总监、<em>新东方</em>迅程K12项目部总监和<em>新东方</em>东方优播公司CEO</p>
<h1 id="p1学习及工作经历">P1学习及工作经历</h1>
<h2 id="学校经历">学校经历</h2>
<p>2004年竞赛保送到清华大学材料科学与工程系，大一主要忙于学业，绩点排名全系第二。第二年竞选为学生会副主席，大三周转于学校各类社团活动并参与了团委的志愿者活动，大四直博到系主任张政军（教育部长江学者特聘教授，现任清华大学材料科学与工程学院院长）的科研团队，同时由于由宿舍朋友推荐08年3月开始在新东方兼职</p>
<p>08年9月到10年9月一边在张政军的团队中从事材料科学基础研究，一边在新东方任职，10年9月从清华博士退学，在新东方全职工作</p>
<h2 id="新东方工作经历">新东方工作经历</h2>
<p>开始时初中数学物理老师</p>
<p>08年9月成为初中物理组组长</p>
<p>09年4月成为高中物理组组长</p>
<p>09年9月开始负责北京新东方优能中学初中部所有数理化生四科老师的招聘和培训</p>
<p>10年4月成为北京新东方优能中学高中数学组的组长 同时负责招聘培训的统一协调工作</p>
<p>11年3月成为优能中学初中数理化部分项目的主管，独立负责初中数理化的运营</p>
<p>12年4月成为优能中学高中所有科目项目的经理</p>
<p>14年4成为整个北京所有校区优能中学的主管，负责招生运营主管工作</p>
<p>15年4月调任北京优能一对一部，成为整个北京新东方优能一对一部的总监至今</p>
<p>成名作《教育培训行业现状分析十五篇》，系统分析了新东方、学而思、学大的不同，各自的发展营销模式以及互联网+的局势下传统教培行业的发展方向。并借由此建立了一套行之有效的制度，使得新东方优能中学从星星之火成燎原之势，完美反杀学而思</p>
<h1 id="p2qa">P2Q&amp;A</h1>
<p>##放弃清华博士去新东方的原因</p>
<ol type="1">
<li><p>能够看出来新东方这个教配行业背后的大量隐患以及机会</p></li>
<li><p>当时新东方中学部处于蓬勃发展状态，优秀的数学物理老师急缺，会在新东方获得更多发展机会</p></li>
<li><p>由于在新东方的两年兼职，对新东方产生了情感‘</p></li>
<li><p>在科研阶段个人想法兴趣的改变，不适应国内的科研环境。相比之下觉得在教培行业能让自身获得更大发展</p></li>
</ol>
<h2 id="教培行业的待遇">教培行业的待遇</h2>
<p>优能中学部老师平均年薪25万，大量30万，而且每年会有二十人左右八十万，两人超过百万，老师之外的基层人员每年五万到六万</p>
<p>一对一部的基层人员十万到十五万</p>
<p>顶层总监年薪一百万以上</p>
<h2 id="最希望招聘员工所具有的特点">最希望招聘员工所具有的特点</h2>
<p>1） 执行力强。没有拖延症说干就干干净利落</p>
<p>2） 责任心强。具有对团队和自己负责任的想法。</p>
<p>3） 进取心强。能够自我学习自我发展，有强烈的进步意愿</p>
<h2 id="八十万以上名师的特点">八十万以上名师的特点：</h2>
<p>进入新东方时间较早，具有强大的人格魅力，能够带动学生情绪，课堂具有感染力，知识储备丰富，博闻强识，博古通今，课程结构严谨讲述设计巧妙。</p>
<h2 id="学生会和社团工作对于现在工作的影响">学生会和社团工作对于现在工作的影响</h2>
<p>在学生会和社团的工作中学会了如何和别人打交道，如何管理一群人为共同目标努力、如何计划、组织，如何培训、指导，如何监督、反馈、总结，这些都是管理能力的很重要的一部分，这些能力只有在时间和经验的积累才能提升——初中物理组组长的敲门砖</p>
<h2 id="工作对自己的改变">工作对自己的改变</h2>
<p>自己在工作中变得更成熟 能够清晰地判断一件事情的收获与损害，遇事不在慌张手足无措而是能够沉着冷静，将意外的损失降到最小，学会了如何更好地解决问题，提升了跟别人打交道的熟练程度，提高了研究事物规律、公开演讲、管理培训的能力，学会了如何在自己的领域产生影响力</p>
<h2 id="工作之余的提升途径">工作之余的提升途径</h2>
<p>阅读，偏重于数理方面的书籍教材，例如经济学、运营学、管理学相关的西方教材，以及博弈论、运筹学，策略决策方面的书籍帮助自己去理解行业、公司的发展规律</p>
<p>文科方面主要是是专业性历史书，比如欧洲史，美国经济史、西方国家科学技术发展史及政治经济制度发展史、哲学发展史，帮助自己理解公司的制度、理解人的行为</p>
<h2 id="文科与理科思维的差异">文科与理科思维的差异</h2>
<p>文科思维-感性，直接</p>
<p>理科思维-长线，间接寻找事物规律</p>
<p>例如新东方和学而思，新东方就是典型的文科思维，他看到了中考高考补习这个刚需，于是就专心去研究中考与高考。而学而思则是典型的理科思维，看到了背后的规律，不是从中考高考开始做起而是从初一高一开始，这样学员上完初一高一的课程之后升入初二高二，学而思就会顺势推出下一阶段的补习班，利用之前建立起的口碑来招收学员。</p>
<h1 id="对我们想说的话">对我们想说的话</h1>
<p>针对刚刚踏入大学生活的大一学生我有非常多的心里话想跟你们分享。</p>
<p>大学四年时间是非常宝贵，但是对于目前中国绝大多数大学生而言这四年都是荒废过去的，这非常的可惜。因为这四年，说实在的，是从中学阶段那种强压式的学习，转换到了一种自我学习、自我提升、自我成长，从中学阶段那种考试成绩作为唯一目标和唯一方向的学习，变成大学里的多样化目标和多样化标准，是一种非常突兀的转变，大学新生对此会非常的不适应。哪怕是在清华也有将这四年荒废过去的同学，他到了打死的时候人生一片茫然，对于未来怎么发展心里没底。</p>
<p>而能在如果大一大二时给自己选定一个发展方向，提前进行规划和准备，对于未来能够走好这条路是非常有好处的。现在的发展方向基本上就是从五条路中挑出来一个两个来。</p>
<p>如果你想保研考研，那么就要抓好分数、了解导师及研究方向、尽早进入实验室。</p>
<p>如果你打算考公务员，那么就要掌握公务员考试的应试知识以及公务员所需的人际交往能力、政治敏感性和管理能力，而且需要更多参与团委工作，因为现团委会跟中国的政治体系靠的更加紧密</p>
<p>如果你打算出国留学，那么现在就要开始准GRE托福雅思考试了，同时了解国外大学的院系、方向、导师，提前准备推荐材料，掌握学术英语以及论文写作的能力</p>
<p>如果你打算就业，那么就尽可能多参加学生会社团活动，有机会的话去实习、参观中小型公司或创业公司，了解公司内部的礼仪制度，以及成为公司员工所需的执行力和管理能力，最好能够参加企业设立在学校内的企业俱乐部，我的一位同学在大学时期成为了保洁俱乐部的主席，毕业之后年薪三十万，超过了绝大部分清华毕业同学的工资。</p>
<p>如果你打算创业，那么需要准备的东西就更多了，需要提前找好创业方向，了解怎么去融资，了解投资人的心态，积累人脉，寻找合伙人例如技术人员、市场人员、设计人员、推销人员、推广人员、运营人员。而且要找到自己的特点，在创业团队中是作为主要角色还是帮扶角色，同时去参加创业创新大赛，获取有经验的创业者和从业者的指导和建议，为未来的项目打下基础，也通过创业的竞赛把自己名声推广出去。当你有了好的项目、有了创业的基础和人脉，那么创业成功的可能性就会高很多。</p>
<p>总而言之，大学的四年时间不像中学六年小学六年，是别人帮你规划好了的，用条条框框限制住了你的所有时间和精力。大学时期的所有精力与时间，都是把握在每一个大学生自己手上的，如果你抓不好，你到了大四的时候你完全不知道自己应该走哪条路，要是随便的选择考研保研工作，那么这条路一定会比别人走的更加曲折。</p>
]]></content>
      <categories>
        <category>学习经验</category>
      </categories>
      <tags>
        <tag>作业</tag>
        <tag>警醒</tag>
      </tags>
  </entry>
  <entry>
    <title>硕士一年</title>
    <url>/posts/577f7527.html</url>
    <content><![CDATA[<p>终于把博客恢复过来了，一边听着2020年lpl夏季赛常规赛的最后一个饭堂，一边写点感想。</p>
<a id="more"></a>
<h1 id="关于博客">关于博客</h1>
<p>其实自己本来是想把这个博客替代成微信公众号，所以早期的一些文章都是一些个人想法和乱七八糟的文章，后来在《数字图像处理》的时候查到了这个大佬的<span class="exturl" data-url="aHR0cHM6Ly9iYWlkdXQuZ2l0aHViLmlvL2Fib3V0Lw==">博客<i class="fa fa-external-link-alt"></i></span>，才有了把自己的博客改编成自己的简历的想法。</p>
<p>前几天在想有没有about页面的的模版，搜了搜发现了这个hugo<span class="exturl" data-url="aHR0cHM6Ly90aGVtZXMuZ29odWdvLmlvL2FjYWRlbWljLw==">主题<i class="fa fa-external-link-alt"></i></span>，花了两三天的时间迁移了过去，然后发现这个主题并不合适我这种经常写自己的想法笔记的人，更适合那种专门的学术主页，所以就又迁移回来了。</p>
<h1 id="关于硕士">关于硕士</h1>
<p>自己的硕士一年级就这么过去了，回想起来我过去这一年的好多事情，都让我尴尬到脚趾抠出来一个阿房宫，自己在这里第一年搞了好多笑话。</p>
<p>因为自己性格的原因，自己的日语并没有得到很好的进步，在这里呆一年，并没有像刚进大学的自己一样，像一只饥饿的狼。</p>
<p>自己在这里一年，做出来的东西，感觉真的就只有半年的量，一年前拿到的很多关于学术写作演讲发表和海洋光学海洋遥感水色遥感的资料，到现在也就学习了20%。</p>
<p>其实很多东西真的一点都不难，就是自己很难静下心来去思考。</p>
<p>自己真的太心急了，急于求成追求短平快，就比如现在写个总结，还想着赶紧写完。</p>
<h1 id="关于精力">关于精力</h1>
<p>自己这一年最大的一个感受就是好多时候精力和体力明显跟不上，比如最近这几天吃完饭就忍不住的犯困一睡俩小时，比如看一会论文写一会代码就觉得累，比如早上起不来，比如很难集中精力。看看老板六十多还健步如飞似少年自己是真的羡慕。身体素质真的肉眼可见的退化。</p>
<p>一些不好的习惯是真的需要改了。</p>
<h1 id="关于未来">关于未来</h1>
<p>其实到现在我还对未来要做什么很不确定，尤其是最近这个国际环境动荡的情况下。</p>
<p>但是最近慢慢地越来越感觉自己就是太不能吃苦了，自己每天养尊处优，不经风吹日晒，还喊着累。</p>
<h1 id="第二年">第二年</h1>
<p>希望明年这个时候，不管我做了什么选择，都能问心无愧的说，自己这个第二年，做到了自己能做的所有事情。</p>
<p>静下心来，认认真真去学习，不要怕前路未卜。</p>
<p>分携如昨。人生到处萍飘泊。偶然相聚还离索。多病多愁，须信从来错。尊前一笑休辞却。天涯同是伤沦落。故山犹负平生约。西望峨嵋，长羡归飞鹤。</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>经验贴（三）申请流程及准备</title>
    <url>/posts/751458a5.html</url>
    <content><![CDATA[<p>拖更了这么久主要是不知道下一步该说什么，索性以我去年的整个申请节点来写。这里以2020年申请的为例，方便对照。另外我这里给出的只是一个理想情况，实际可以根据自身情况调整。</p>
<a id="more"></a>
<h1 id="材料准备">材料准备</h1>
<p>关于怎么写材料，知乎和寄托很多帖子写的很好，请自行搜集和学习。</p>
<h2 id="招生指南">招生指南</h2>
<p>这一点对于申请G30/SGU的学生来说尤为重要，因为G30只能在一小部分教授里面申请，这个名单会随着招生指南一起发布。提前搜集了招生指南的话，陶瓷的时候不至于是无头苍蝇。</p>
<p>如果要申请2020年10月入学的话，2019年11月份就可以去院校官网搜集指南了，同时自2020年3月起，可以去寄托论坛关注offer情况，看看有没有申请你想去的项目的学长学姐。 ## 语言成绩 ### 日语</p>
<p>申请G30/SGU是不需要日语的，虽然你可以交这个材料。至于这个材料究竟占多大分量，笔者到现在也不是很明确。如果能考出来就考，考不出来也不必太过担心。</p>
<p>申请研究生可以不用日语，只用英语，但是用日语可以扩大你申请老师的范围。理工科的话，一般N2就足够了，文科可能会有一些实地调查的项目所以要N1。至于自己想申请的老师对日语究竟有没有要求，可以从老师实验室组成人员上来看。如果老师实验室里留学生比较多，一般不需要日语也可以申请；如果老师实验室里留学生较少甚至没有留学生，那一般就一定要日语了。至于这项考试的时间节点，如果你申请的老师对日语有要求的话，我推荐在19年7月考过Ｎ2。在后面和老师套瓷用日语交流的时候，老师也可以判断出你的日语水平。</p>
<h3 id="英语">英语</h3>
<p>在我申请时查阅的学校（七帝大+东工大），都是可以用雅思的，但是我个人比较推荐考托福。托福的分数在日本知名度比较高，不仅留学，日后如果进入对英语有要求的企业时也可以使用。最迟要在2019年10月份考出来。至于成绩，如果你想申请东大、京大的G30/SGU，托福100+甚至105+才算一个比较有竞争力的分数；申请其他学校的G30/SGU一般95+就够用了；申请研究生的话，90+就可以，不过我也推荐考到95+。值得一提的是，托福成绩可以在修士入学考试中折换成英语考试的成绩，我见到的一个说法是托福100对应修士入学考试的英语满分，在这之下的对应换算过去，不知道是不是真的。另外，我没有见过学校对小分有要求。</p>
<p>另外，如果你考的是雅思，请注意不能选择电子寄送成绩单。 ### GRE/GMAT</p>
<p>这个只有在申请G30/SGU的时候才用到，如果申请东大、京大，即使有的项目是非必需材料，我也推荐考出来。至于分数要求、科目和节点，请参照往年的申请指南。</p>
<h2 id="ps">PS</h2>
<p>这个我只在京都大学AAO的时候用到过。所以更具体的我想放到AAO的时候在讲。大阪大学也有类似的预审核制度，但是我没有申请大阪大学，因此对大阪大学的龙门制度并不是很了解，就不再介绍了。</p>
<h2 id="研究计划书">研究计划书</h2>
<p>一般来说，你第一封套辞信发过去之后，导师如果对你感兴趣就会接着回复问你的研究计划书是什么，因此最好在套辞前准备好。申请研究生的话，研究计划书不用特别详细，一张A4纸就好；G30/SGU最好发一个比较完善的版本。</p>
<p>我觉得日本老师是不见兔子不撒鹰，如果你非常想申请的老师不回复你邮件的话，很有可能是因为他没看到你的研究计划书。我就遭遇到了这样的情况，在我把研究计划书发过去之后老师才回复我并且说“直到现在我才看到你申请的决心”。</p>
<h2 id="成绩单推荐信简历summary-of-thesis">成绩单、推荐信、简历、Summary of Thesis</h2>
<p>和研究计划书一样，老师对你感兴趣的话在回复你第一封陶瓷信的时候就会问你要这些，因此最好在套辞前准备好。第一封套辞信可不放简历。</p>
<h2 id="在读证明毕业证明护照">在读证明、毕业证明、护照</h2>
<p>如果是申请Ｇ30/SGU的话，这些在申请指南上都有写，按照指南来准备就好；研究生可以等2020年开学在办。</p>
<h1 id="时间流程">时间流程</h1>
<p>这里所介绍的时间流程全是研究生的，G30/SGU由于不同学校差别过大（例如九大有的19年10月入学的项目19年3月才开始申请），请按照招生指南上所说的自行安排。</p>
<h2 id="套辞">套辞</h2>
<h3 id="时间安排">时间安排</h3>
<p>在2019年八九月份就可以开始套辞了，之前可以选择导师。 最迟也一定要在2019年12月份套辞，2020年1月份开始，大部分导师的研究生名额都已经被申请完了。</p>
<h3 id="导师搜索及选择">导师搜索及选择</h3>
<p>我这里以东大为例来讲一下导师搜索和选择的整个流程。</p>
<h4 id="导师搜索">导师搜索</h4>
<p>打开东京大学主页，这里有一个“教员检索”</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/jingyantie3fi.png"></p>
<p>点进去，在检索这一栏里输入你读研时想做的<strong>研究的关键词</strong>,例如“phytoplankton”,“machine learning”,“image process”，不要写太宽泛的单词；如果没有的话就减少关键词的数量。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/e3f2.png"></p>
<p>出来结果之后就可以查看导师具体信息了，一般情况下只有Professor和Associate Professor有招生资格。</p>
<p>其他学校大同小异。</p>
<h4 id="导师选择">导师选择</h4>
<h5 id="对中国人的友好程度">对中国人的友好程度</h5>
<p>确定好导师之后，找到他的实验室主页，看一下学生组成和往届学生，一般可以分为以下几种情况：</p>
<p>1. 学生全是日本人。这种导师可能是名气比较小或者只是没有开始收中国人而已，可以试试申请。</p>
<p>2. 有外国人，但是没有一个中国人。这种老师可能就对中国人有偏见，不建议申请。毕竟中国人那么多，如果能申请进去的话不早就进去了。</p>
<p>3. 有中国人。这种导师一般对中国人比较友好，可以尝试联系一下组里中国人查看情况。</p>
<h5 id="学术水平">学术水平</h5>
<p>最直观的可以通过Google scholar的H-index看出来，但是出于某些原因，不是特别方便。这里推荐另外两个网站，<span class="exturl" data-url="aHR0cHM6Ly93d3cucmVzZWFyY2hnYXRlLm5ldC8=">research gate<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly93d3cuc2NvcHVzLmNvbS9mcmVlbG9va3VwL2Zvcm0vYXV0aG9yLnVyaT96b25lPSZhbXA7b3JpZ2luPU5PJTIwT1JJR0lOJTIwREVGSU5FRA==">scopus<i class="fa fa-external-link-alt"></i></span>。后者比前者要更全。这两个网站上都有计算的一些学术评价指数，根据这个来判断就好。但是要注意，不同学科之间的指数差距比较大，如果你申请的老师中有不在同一个大方向的，这个指数并不能反映出老师的相对水平。</p>
<h5 id="毕业生去向">毕业生去向</h5>
<p>这个一般在导师实验室网站上都会放出来，如果没放出来，抱歉，我也不知道了。</p>
<h5 id="地理位置">地理位置</h5>
<p>有很多学校都是有分校区的，例如东大。东大海洋与大气研究中心的老师实验室我印象中都设立在千叶柏市，而不在东京。同时可以用谷歌地图查一下坐电车花费的时间，这个在你想出去玩或者求职的时候还是挺重要的。</p>
<p>除此之外，可以通过Dark sky map这个APP 的夜光指数来看你的实验室在不在市中心。但是说实话，除了东京和大阪，日本的其他地方都可以看成村。</p>
<h2 id="入学手续">入学手续</h2>
<p>套辞成功叫拿到内诺，内诺之后就要申请入学了，拿到小蜜给你发过来的研究生的入学通知才叫offer。这个申请只是走过场，一般在2020年四月开始，三月就可以去学校官网查看申请的指南了。由于我还没到这一步，略去不表。</p>
<h1 id="关于aao的小尾巴">关于AAO的小尾巴</h1>
<p>在这里就不介绍AAO是什么了，我个人推荐9月份最迟十月份提交AAO，AAO可能会需要一个月的时间。同时因为AAO只有一次机会,如果失败了只能通过直接考试的方法进入京大，因此在进行AAO之前最好能先得到你想申请的导师的回复。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>经验贴（二）日本留学制度介绍</title>
    <url>/posts/c7945378.html</url>
    <content><![CDATA[<p>不同于欧洲、北美、香港等国家，日本拥有极其独特的留学制度。如果一个国内的本科生想去日本攻读研究生的话，大致可以分为语言学院、研究生（research student）、直接考试和申请英语项目（G30/SGU）这几种，相较其他国家复杂了很多。需要注意的使，即使是同一个学校，不同的学院之间的入学制度也会有很大不同，包括申请时间、申请材料、考试方式等等，一定要认真核实。</p>
<a id="more"></a>
<h1 id="我为什么不推荐你来日本留学">我为什么不推荐你来日本留学</h1>
<p>在正式开始之前我先来劝退一波。</p>
<p>不同于欧美国家有授课型硕士（taught-lesson）的存在，日本几乎没有授课型硕士，几乎所有的硕士都是研究型硕士，硕士期间就要跟着老师做实验做课题了。因此在申请的时候老师会更看重你做研究的能力，这个能力很大程度上由你的研究计划书（research proposal）来体现。显而易见，你没有办法像申请美国英国一样，不同学校的personal statement或者statement of purpo只改一个why school就可以重复套用，你的research proposal和其他文书必须针对你要申请的导师的研究方向来针对的写，而我在申请寻找导师的时候几乎没有看到两位导师的研究方向有很大相似度的情况。俗话说得好，同一个实验室的两个博士都不一定能真正理解彼此做的课题，更别提不同实验室的导师了。所以你的research proposal和其他文书几乎没有多少可以在不同学校间重复套用的东西，看过上一篇博文的同学可以知道，research proposal是一个很难由咨询机构写好的东西，除非给你写的人是和你申请的老师一个方向的硕士或者博士。因此在准备申请材料时，相比申请其他地区，就算你找了咨询机构，也会花费你很多很多的精力。</p>
<p>说完了申请材料，再来说申请的目的。</p>
<p>如果你出国留学是为了在日本工作的话，其实还算一个比较好的选择。在日本影响你工作好坏的因素，据我了解，主要有以下几点：</p>
<p>1. 学校所在位置。日本绝大多数工作机会都在东京与大阪这两座城市里。如果不是在这两座城市里上学，找工作的时候还要舟车劳顿去参加招聘会。</p>
<p>2. 日语水平。这一条其实取决于个人，如果走研究生考修士或者语言学校来读研的话，日语水平一般还可以，但是G30/SGU的学生相对就会差一点。</p>
<p>3. 同一个实验室的前辈所去的公司。在日本内推对求职成功的影响是很大的。</p>
<p>因为我还没有到找工作的时候，以上三条仅为个人看法。从这方面来看，你的个人能力反而没有那么重要。日本社会擅长把每个人打造成螺丝钉，不需要你有很大的创新很强的能力，只要你按照上级的交代像个螺丝钉一样被锤子锤在合适的地方就可以了。同时职位的晋升也很大程度上依赖于你进入公司有多久，而不是你的业绩。</p>
<p>如果你想回国找工作，那么对不起，我强烈不推荐你去。虽然有很多公司都有海外招聘，但是他们都有目标院校——即所谓的target school。抛去这些不谈，如果你拿着毕业证书打算回国工作的话，很多公司单位很有可能都不知道你的学校是个什么水平。大多数中国人只知道东大和早大这两所学校，其他的学校在国内都不是很出名，你花了两年（半）以及更多的精力去日本读研，最后回国工作可能还比不过香港的一年制硕士。</p>
<p>如果你想搞研究的话，认真的说，读博还是去美国好，甚至一些国内的院校例如清华的计算机，北大的物理化学，都能赶超很多世界名校。读博最重要的是你跟的导师和你自己是不是努力，在导师这一方面美国有着天然的优势，汇集着最顶尖的科研人才。可能还有一部分同学的想法是日本读研当跳板再去美国读博，这个面临的问题一个是你会比直接申请美国花费更多的时间毕业，另一个是在日本期间无论如何你的英语都会受到影响，其实不是很利于你申请。 除此之外，如果你直接申请美国的博士，自带的奖学金基本可以cover你全部的学费和生活费，但是日本的奖学金需要你入学之后再去申请，存在着很大的不确定性。</p>
<p>综上所述，我并不是很推荐你来日本留学。</p>
<h1 id="研究生制度起源">研究生制度起源</h1>
<p>日本传统的的一个学年开始并不是在秋季，而是在春季。多说一句，日本的樱花之所以会被视为离别的象征（就比如AKB48就很多人的毕业曲就和樱花有关），就是因为3-4月份是日本传统的学生毕业的时间。美国的GRE一样研究生入学考试一年可以考好几次，然后由每个学生拿着考试成绩去申请，但是日本的研究生入学考试是由每个学校甚至每个院系单独举行的，只有考试通过才能去读他们的研究生。这样的话，其他很多国家的学生毕业的时间大多数在夏季，没有办法去参加入学考试（当然现在也有秋季入学的考试，这个到后面的制度介绍的时候具体去讲），这中间就隔了大半年的时间，因此日本很多学校就设立了研究生（research student）制度来让外国学生先以旁听生的身份入学，等到来年三四月开春了再去考试成为正式学生。</p>
<h1 id="研究生research-student和直接考试">研究生（research student）和直接考试</h1>
<p>在接着往下讲之前先明确研究生（research student）和修士（master）的概念。</p>
<p>研究生在日本其实是一种非正式学生，真的就是字面上的意思——做研究的学生，读研究生没有办法获得硕士学位，需要经过入学考试才能称为正式的学生——修士，修士毕业才能获得硕士学位。简单来说，可以把研究生看作是硕士预科生，修士看成硕士生，从这里开始提到的研究生和修士都是这个概念。</p>
<p>前文已经提到了，研究生是修士之前的一个过渡阶段，需要通过入学考试才能称为正式学生。但是这个入学考试并不像国内考研和美国GRE一样，对分数有着很高的要求，你最终能不能通过考试成为修士，更多的是看你申请的老师想不想要你。换句话说，决定你能否成为修士的并不是你修士考试考了多少分，而是你在研究生阶段给你申请的老师留下的印象如何。如果老师特别想要你来读的话，还会给你划重点什么的。同样的，由于研究生阶段并不是一个正式的学生，你考修士的时候选择考另一个老师的修士也是可以的。</p>
<p>总的来说，申请到了研究生并不一定能保证你一定能成为修士。所以有一些导师就大量收研究生，但是只通过一部分，来给他打工。相信我这样的导师是很少的。研究生期间很难申请到奖学金补助，而且也无法选课获得学分，但是可以打工来弥补一下费用。</p>
<p>需要说明的是，研究生并不是成为修士必须要经过的阶段。只要你通过修士入学考试，那你就可以成为修士。所以有一些院校是不收研究生的，这样的话你只能通过直接考试的方式来成为他们的修士。我前面也说了，能够决定你能否通过考试的是你申请的老师对你的印象</p>
<p>最后说一下修士入学考试的时间问题。现在一些学校存在着秋季入学的修士考试，但是由于日本大部分学生都是在春季毕业，所以如果你秋季入学的话，和很多招聘活动都是错开的，非常不利于你求职，因此一般情况下我不推荐参加秋季入学的研究生入学考试。</p>
<h1 id="g30sgu">G30/SGU</h1>
<p>很多大学排行榜上都有国际化率这一项指标，日本学校特殊的制度使得日本大学里的外国人并没有特别的多，因此在这一项指标上比较吃亏。为了改变这一现象，很多学校开设了G30/SGU项目。这个项目和欧美的申请就比较一致了，只是有的学校还会有考试这一项，像我知道的考试方式的话有的有开着Skype监考，有的有去国内某个地方参加考试，有的会在面试的时候举个小黑板让你做题。因为我自己研究生和G30/SGU都有申请，更具体的我想放到后面再说。在这里我想强调以下几点：</p>
<ul>
<li>G30/SGU项目依然很大程度上取决于你要申请的导师对你的印象</li>
<li>几乎全部是研究型硕士</li>
<li>申请难度比研究生高的多</li>
</ul>
<h1 id="语言学校">语言学校</h1>
<p><strong>语言学校，真的就是学语言的学校，而不是修士入学考试的辅导班。</strong></p>
<p><strong>语言学校自己申请就好，不需要找中介。</strong></p>
<p><strong>上来就让你读语言学校的机构就是在坑你钱。</strong></p>
<p>说到语言学校这里忽然间不知道该从哪儿下手了。因为我觉得对于硕士的申请来说这是一个很坑的东西。如果你真的要读语言学校，请记住以上三条。</p>
<h1 id="日本留学机构中介会怎么坑你">日本留学机构（中介）会怎么坑你</h1>
<p>写完上一条忍不住来总结一下我遇见或者听说过日本留学中介或者机构的坑钱方法。</p>
<p>1. 申请账号、邮箱不公开</p>
<p>2. 只帮你申请学校列表里最差的学校</p>
<p>3. 给你申请你不喜欢但是招人多的老师</p>
<p>4. 花式诱导你读语言学校</p>
<p>5. 申请材料不向你公开</p>
<p>6. 申请到奖学金额外收钱，申请到好大学额外收钱</p>
<p>7. 霸王条款，无明确退款政策</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 10.5-10.11</title>
    <url>/posts/3d8d27aa.html</url>
    <content><![CDATA[<p>Annotated Bibliography 2020 10.5-10.11</p>
<p>Next Monday I will do a book reading presentaion. So this post will mainly include the book reading and some other oceanography quick look.</p>
<p>And from this semester, I think I'd better make some notes for seminar to keep myself concentrated.</p>
<a id="more"></a>
<h1 id="book-reading">Book reading</h1>
<p>Ch. 1.1-1.2.2 of book &lt;Emery, William, and Adriano Camps. <em>Introduction to satellite remote sensing: atmosphere, ocean, land and cryosphere applications</em>. Elsevier, 2017.&gt;</p>
<h2 id="the-definition-of-remote-sensing">The definition of Remote Sensing</h2>
<p>Remote sensing: a measurement made by some indirect or “remote” means rather than by a contact sensor.</p>
<p>In its application to satellite and aircraft instrumentation, remote sensing relied primarily upon either reflected or emitted electromagnetic radiation (optical and mi- crowave) from the Earth to infer changes on the Earth’s surface or in the overlying atmosphere.</p>
<p>The fact that these inferences must be made from a by-product (either the reflected or the emitted radiation) of the surface or atmospheric process qualifies satellite data collection as “remote sensing.”</p>
<p>Other applications such as the use of acoustic signals to map the internal character of the ocean and the solid Earth are often also considered as a remote sensing. In the past few decades, however, satellite and aircraft data analyses have become even more closely associated with the term remote sensing.</p>
<h2 id="the-history-of-satellite-remote-sensing">The History of Satellite Remote Sensing</h2>
<h3 id="the-nature-of-light-and-the-development-of-aerial-photography">The Nature of Light and the Development of Aerial Photography</h3>
<p>Early work by Sir Isaac Newton: white light is not a single entity</p>
<p>In optics, chromatic aberration (CA), also called chromatic distortion and spherochromatism, is a failure of a lens to focus all colors to the same point. It is caused by dispersion: the refractive index of the lens elements varies with the wavelength of light.</p>
<figure>
<img src="https://ipt.imgix.net/203320/x/0/chromatic-aberration-ndash-what-it-is-and-how-to-avoid-it-2.jpg?auto=compress%2Cformat&amp;ch=Width%2CDPR&amp;dpr=1&amp;ixlib=php-3.3.0&amp;w=883" alt="Chromatic Aberration – What it is and How to Avoid It"><figcaption aria-hidden="true">Chromatic Aberration – What it is and How to Avoid It</figcaption>
</figure>
<p>When he passed a thin beam of sunlight through a glass prism, Newton noted the spectrum of colors that was formed. Newton argued that white light is really a mixture of many different types of rays, which are refracted at slightly different angles, and that each different type of ray produces a different spectral color. Newton was led by this reasoning to the erroneous conclusion that telescopes using refracting lenses would always suffer chromatic aberration. He therefore proposed and constructed a reflecting telescope (i.e., using mirrors).</p>
<p>Maxwell:</p>
<p>Phenomenon of light is therefore an electromagnetic phenomenon</p>
<p>Daguerre:</p>
<p>first photographic plate, which consisted of a thin film of polished silver on a copper base</p>
<p>Nie ́pce: reduced the exposure time from 8 h down to half an hour.</p>
<p>topographic mapping was first suggested in 1849</p>
<p>Balloonist F. Tournachon undertook initial attempts in 1858 from a captive balloon a few hundred meters over Petit Bicetre in France using large silver plates as the camera</p>
<p>Balloon photographs of Confederate positions during the American Civil War represent the first practical use of aerial photography.</p>
<p>Maddox, in 1871, film</p>
<p>Triboulet used dry plates in 1879 to photograph Paris from a free balloon. The size of the camera was also reduced which opened more opportunities for photography.</p>
<p>English meteorologist E. Archibald: first kite photographs in 1882</p>
<p>In 1889, R. Thiele, from Russia, mounted cameras on seven unmanned kites to produce a “panaramograph.”</p>
<p>In 1885, W. A. Eddy, an American meteorologist in New Jersey, reported the first kite photograph taken in the western hemisphere</p>
<p>kite-camera system, which proved a useful supplement to balloon photography during the Spanish-American war. G. R. Lawrence, referred to as the “King of Kite Photography,” used kite systems with cameras weighing up to 454 kg and negatives as large as 1.35 m  2.4 m. He is particularly noted for his photograph of San Francisco just after the earthquake of 1906</p>
<p>the attachment of cameras to carrier pigeons at the 1909 world’s fair in Dresden,which would then be developed and printed for sale to the attendees at the fair that can see themselves and the overall fairgrounds.</p>
<p>In 1908 a passenger appropriately collected the first aircraft still photographs with Wilbur Wright flying on a test flight in France (Fig. 1.6), while another passenger took the first aerial movies with Wilbur in the following year.</p>
<p>Samuel Goddard collected the first rocket photos in 1926 during his experiments with rocketry.</p>
<h3 id="the-birth-of-earth-orbiting-satellites">The Birth of Earth-Orbiting Satellites</h3>
<p>In 1903, Konstantin Tsiolkovsky (1857e1935) published Exploring Space Using Jet Propulsion Devices: first academic treatise on the use of rocketry to launch spacecraft.</p>
<p>He calculated the orbital speed required for a minimal orbit around the Earth at 8 km/s, and that a multistage rocket fueled by liquid propellants could be used to achieve this. He proposed the use of liquid hydrogen and liquid oxygen, though other combinations can be used.</p>
<p>In 1928, Slovenian Herman Potocnik (1892e1929) published his sole book, The Problem of Space TraveldThe Rocket Motor (German: Das Problem der Befahrung des Weltraumsdder Raketen- Motor): a plan for a breakthrough into space and a permanent human presence there.</p>
<p>He conceived a space station in detail and calculated its geostationary orbit. He described the use of orbiting spacecraft for detailed peaceful and military observation of the ground and described how the special conditions of space could be useful for scientific experiments. The book described geostationary satellites (first put forward by Tsiolkovsky) and discussed communication between them and the ground using radio, but fell short of the idea of using satellites for mass broadcasting and as tele- communications relays.</p>
<p>In a 1945 Wireless World article, the English science fiction writer Arthur C. Clarke (1917e2008) described in detail the possible use of communications satellites for mass communications</p>
<p>examined the logistics of satellite launch, possible orbits, and other aspects of the creation of a network of world-circling satellites, pointing to the benefits of high-speed global communications. He also suggested that three geostationary satellites would provide coverage over the entire planet.</p>
<p>October 4, 1957 with the successful launch and operation of the Russian Sputnik satellite, which was the first human created instrument to orbit the Earth.</p>
<p>the start of the space age and the USeUSSR space race.</p>
<p>carried no Earth-oriented sensors and only really sent out radio signals that were used to communicate with the satellite. It did demonstrate, however, that satellites could be launched from the Earth and operated on a continuous basis.</p>
<p>on November 3, Sputnik II was launched, carrying a much heavier payload, including a dog named Laika. Table 1.1 lists all of the first satellites launched by 12 different countries starting with the Soviet Union launch of Sputnik-1 in 1957.</p>
<p>There were also a number of attempted first launches by many of these same countries before they were successful at launching a satellite and inserting it in to Earth orbit. Several other countries, including Brazil, Argentina, Pakistan, Romania, Taiwan, Indonesia, Australia, New Zealand, Malaysia, Turkey, Spain, Japan, India, Israel, France, Germany, and Switzerland (and others) are at various stages of development of their own small-scale launcher capabilities. This list grows a lot longer when you include nations and satellites that were launched by the capabilities of other nations.</p>
<p>Today with the advent of small satellites such as “CubeSats” almost anyone can get a satellite payload into space. It is something the commercial remote sensing companies are taking a very close look at.</p>
<p>US: how Earth-orbiting satellites could benefit the meteorological forecasting community in monitoring conditions on the Earth</p>
<p>the first TIROS (Television and Infrared Observation Satellite) was launched and made operational in April of 1960. This satellite was spin stabilized which led to the fact that the Earth-oriented sensor (aligned with the spin access) could view only a limited portion of the Earth’s latitude</p>
<p>The primary sensor was the wide-angle TV camera, which collected images of the Earth at approximately 750 km orbital altitude. A small infrared (IR) system was also used to collect some limited measurements through the narrow angle TV camera that also collected radiation in visible wavelengths. The receiving and transmitting antennas are shown, and all data collected were transmitted as analog signals down to the ground. A tape recorder on board was used to store these analog data so that they could be downlinked to the ground when the satellite was in view of a tracking ground station.</p>
<p>Thus, the TIROS satellites were incapable of observing the entire globe. This was a limitation of the spin stabilization at least as it was deployed in this fashion.</p>
<p>These early satellite designs were driven primarily by meteorological considerations and the need for improved forecasting.</p>
<p>Since all of the TIROS imagery were analog the correction of these geometric distortions was not possible using digital methods and mapping was done by overlaying “warped grids” that best matched the orientation of the global features. This type of mapping approach determined the lines on</p>
<p>Land surface features were also apparent in the early TIROS imagery when cloud cover was sufficiently low to make it possible to view the surface.</p>
<p>Here the lake covers a number of satellite passes each of which has a slightly different exposures. This produces artificial striping in the image. Earth surface distortion continues to be a problem as shown by the elongated part of the lake in the southwest portion of the image. The presence of clouds in this same portion of the image also obscures the surface of the lake. Discontinuities in the cloud cover are introduced by the fact that the image is made up of sequential passes, which are not truly synoptic in coverage.</p>
<p>The initial TIROS satellites were relatively short-lived with satellites lasting only a few months each. By the end of the series, however, the satellites were lasting approximately a year and continuing to report data over this entire period.</p>
<p>To overcome the viewing limitations of the original TIROS series of satellites the next generation of spinning satellites was changed to have the camera pointing radially outward and the spin axis of the satellite turned 90 degrees relative to the original TIROS satellites. This new configuration was called the “wheel” satellite and a consequence of this change was the ability to collect a series of circular images that over the period of a day covered the entire surface of the Earth.</p>
<p>The next development in the evolution of operational weather satellites was the incorporation of spacecraft stability control.Developed as part of the ballistic missile program during the “cold war,” three-axes stability systems were now available to control the pointing of the spacecraft without the need to spin the spacecraft. With this three-axes stabilization, it was possible to keep the Earth sensors always pointing at the Earth regardless of its position in the orbit. This made it possible to collect imagery over the entire Earth’s surface from the same sensors at the same resolution.</p>
<p>Called the Improved TIROS Observing Satellite, or ITOS, this family of satellites brought in a new era of remote sensing. In addition to the three-axes stabilization, these satellites carried a new suite of optical radiometers which were scanning systems that collected reflected and emitted radiation from the Earth’s surface line by line as the satellite moved along in its polar orbit. These first radiometers (Fig. 1.17) ushered in the new era of improved capabilities that became a standard approach to viewing the Earth.</p>
<p>The ITOS scanning radiometers were those that became the primary instruments for future satellites.</p>
<p>The first ITOS satellite demonstrated the utility of these new technologies and began a longer time series of polar-orbiting spacecraft, which were now called NOAA satellites after the name of the agency that operated them. A series of eight satellites with approximately the same suite of equipment filled in the years between 1970 and 1976. The practice was to designate the satellites as NOAA a, b, c, etc. when they were built, and then transition them to NOAA 1, 2, 3.etc. once they were operating on orbit. The fact that not all of the NOAA satellites achieved orbit or failed early on orbit led to the fact that alpha and numeric designations do not map one to one.</p>
<p>Now the orbital altitude is about 1271 km and the orbit is Sun-synchronous with an 80-degree inclination in a retrograde orbit with a period of about 111 min.</p>
<p>A big change over this evolution of satellite capabilities was the size and weight of the spacecraft. The original TIROS satellites weighed about 150 kg, which increased to 250 kg with the change to the ESSA wheel satellites. The shift to three-axes stabilization increased the ITOS satellite up to 400 kg, which then increased by over a factor of three to the modern NOAA and Defense Meteorological Satellite Program (DMSP) satellites that weigh about 1500 kg.</p>
<p>The analog radiometer data from the NOAA satellites were digitized on the ground so that the images could be digitally processed and enhanced to geometrically correct the image geolocation and bring out various features in the atmosphere and on the ground. The geometric corrections for Earth curvature and rotation compensated for the distortions of satellite viewing. Additional corrections were also needed for satellite attitude and time, which influences the viewing angle.</p>
<p>Radiance enhancement was needed to bring out the weaker gradients in some of the radiometer channels such as the thermal IR patterns in the ocean. An example is shown here in Fig. 1.19, which is an image of the Gulf of Mexico and the east coast of Florida, which shows the warm water (dark gray shades) associated with the loop current in the Gulf of Mexico and the subsequent Gulf Stream off the east of Florida. The colder water closer to the shore off Florida represents the colder “shelf water” that flows southward inshore of the Gulf Stream. Colder waters also bound the dark pattern of the loop current in the center of the Gulf of Mexico.</p>
<p>This image has been remapped to correct for geometric distortion, which can be seen in the appearance of Florida at the edge of the image, which would be highly distorted if seen in satellite perspective. It is very difficult to quantitatively study features in satellite imagery without being able to “navigate” the imagery, which includes the geometric corrections for Earth curvature and rotation as well as corrections for spacecraft attitude and timing errors.</p>
<p>The ITOS and NOAA satellites carried two different radiometers. The primary instrument was the scanning radiometer (SR), which had an 8 km resolution and was limited to only three channels: (1) a wide band visible, (2) a near-IR channel (0.7e1.1 mm), and (3) a thermal IR (11 mm) channel. The instrument was used to map clouds and later applied to the mapping of sea surface temperature (SST) using the 11 mm channel. A sophisticated processing system was developed that used a histogram method to filter out pixels dominated by clouds to produce SST over large 50 km boxes. This system was found to introduce a lot of errors by letting some cloudy pixels slip through and used an objective analysis (Cressman, 1959) routine that “filled” in erroneous data.</p>
<p>Another instrument flown on the NOAA satellites was the very high resolution radiometer (VHRR), which was the first instrument to demonstrate a real capability for being able to map SST. It had channels in the visible, the near-IR wavelengths, and the midrange IR and the thermal IR wavelengths (again 11 mm). Using the visible and near-IR channels for cloud clearing the VHRR data were then used to produce a 1 km resolution SST, which was the native resolution of the instrument. The image in Fig. 1.19 is from the VHRR sensor.</p>
<p>The biggest change in satellites and sensors came in the fall of 1978 with the advent of TIROS-N (“N” for new). An advanced version of this series of NOAA polar-orbiting satellites the last of which is still operating as this text is being written. These are the 1500 kg spacecraft referred to earlier where the added weight reflects greatly increased capabilities with these new spacecraft. They were fully digital systems that downlinked their data digitally. A new imager called the advanced very high resolution radiometer (AVHRR) became the workhorse radiometer on this spacecraft. With its basic 1 km footprint in four channels the AVHRR data have been used for a wide range of studies of ocean, land, and atmospheric processes. Over the subsequent three decades, this instrument has evolved from having only four channels to one that now has six different channels, is called AVHRR-3, and has the characteristics as described in Table2.</p>
<p>The original four channels covered the visible ( channel 1), the near-IR (channel 2), the mid- range IR (channel 3 only at 3.7 mm), and the 11 mm (channel 4) thermal IR. The first improvement in this sensor led to the AVHRR-2, which added the fifth channel at 12 mm. This channel was added to provide a “split-window” in the thermal IR to ma ke it possible to correct for atmospheric water vapor attenuation of the thermal IR signal i n computing SST. The nominal sensor spatial resolution of 1.09 km meant that all of the channe ls delivered images with essentially the same resolution.</p>
<p>Channel 3 is now broken into two parts. The approximately 3.7 mm channel (now called channel 3B) is continued at night, but during the day this channel shifts over to 1.6 mm to better resolve at- mospheric aerosols and clouds. The visible and near-IR channels are widely used for mapping vegetation, snow cover, and atmospheric aerosols. These channels are also used for mapping snow and ice cover. The thermal IR channels are also used to compute land surface temperature in addition to SST.</p>
<p>The TIROS-N satellites also carried a variety of other instruments. The high-resolution IR sounder is the primary sensor in the TIROS operational sounder system that also includes data from the British stratospheric sounding unit , and the microwave sounding unit (MSU). Together these three in- struments are used to retrieve atmospheric temperature and water vapor profiles for use in numerical model assimilation. Actually it was learned that it was better to directly assimilate satellite instrument radiances from this system into the numerical weather forecast models than it would be to retrieve temperature and water vapor profiles to be assimilated into the models.</p>
<p>Other instruments on TIROS-N (Fig. 1.20) are the search and rescue (SAR in Fig. 1.20B) and Argos data collection system (UHF data collection system antenna in Fig. 1.20A). Both of these systems collect data transmitted from the Earth’s surface and use the Doppler shift of these signals to accurately locate these platforms. The Argos system also has the capability of collecting a limited amount (approximately 256 data words) of geophysical data collected on the platform.</p>
<p>This diagram shows how this spacecraft has considerable extra capacity and other sensors of opportunity have been flown on this satellite such as the Earth Radiation Budget Experiment in- struments that flew only on NOAA-9. These TIROS-N satellites continued to carry the name of NOAA satellites. A picture of a TIROS-N satellite being worked on in storage is shown in Fig. 1.21, to give the reader a better appreciation of the size of these satellites.</p>
<p>A summary of the evolution of polar-orbiting environmental satellite (POES) weather satellites is given here in Fig. 1.22, which contains pictures of the important satellites and the relevant characteristics.</p>
<h1 id="paper-quick-look">Paper quick look</h1>
<h2 id="sarma-v.-v.-s.-s.-et-al.-influence-of-eddies-on-phytoplankton-composition-in-the-bay-of-bengal.-continental-shelf-research-2020-104241.">Sarma, V. V. S. S., et al. "Influence of eddies on phytoplankton composition in the Bay of Bengal." <em>Continental Shelf Research</em> (2020): 104241.</h2>
<p>A in-situ study. Phytoplankton composition measured by HPLC</p>
<p>Picoplankton was high in the entire study region with dominant nanoplankton in the cyclonic eddies and microplankton in anticyclonic eddies.</p>
<h2 id="effects-of-changing-phytoplankton-species-composition-on-carbon-and-nitrogen-uptake-in-benthic-invertebrates">Effects of changing phytoplankton species composition on carbon and nitrogen uptake in benthic invertebrates</h2>
<p>We found that all three macrofauna species fed on both diatoms and cyanobacteria. A linear pattern was found for all three species in assimilation of carbon and nitrogen from diatoms, with increasing assimilation associated with higher proportion of diatoms. There was no clear pattern found between proportion of cyanobacteria and assimilation of carbon and nitrogen for any of the species. This study shows that the investigated macrofaunal species display a selective feeding behavior with preference for spring‐bloom associated diatoms. Thus, changes in phytoplankton bloom composition are likely affecting benthic species composition and production.</p>
<h2 id="seasonal-physical-fronts-and-associated-biogeochemicalecological-effects-off-the-jiangsu-shoal-in-the-western-yellow-sea-china">Seasonal physical fronts and associated biogeochemical‐ecological effects off the Jiangsu Shoal in the western Yellow Sea, China</h2>
<p>Due to favorable conditions, the frontal region off the shoal is prone to high chlorophyll‐a (Chl‐a) and may act as oases in either summer or winter. A conceptual diagram is assembled to provide an overview of physical‐biogeochemical‐ecological interactions off the Jiangsu Shoal in the western YS.</p>
<h2 id="decreasing-phytoplankton-size-adversely-affects-ocean-food-chains">Decreasing phytoplankton size adversely affects ocean food chains</h2>
<p>An increase in the proportion of primary production by nano‐ and picophytoplankton has qualitative as well as quantitative consequences for future food production from the oceans, since this is where the biosynthesis of important components of our diet takes place.</p>
<h2 id="seasonal-and-spatial-variability-in-surface-pco2-and-airwater-co2-flux-in-the-chesapeake-bay">Seasonal and spatial variability in surface <em>p</em>CO2 and air–water CO2 flux in the Chesapeake Bay</h2>
<p>our observations showed higher river discharge could decrease CO2 efflux. In contrast to many other estuaries worldwide that are strong sources of CO2 to the atmosphere, the Chesapeake Bay and potentially other large estuaries are very weak CO2 sources in dry years, and could even turn into a CO2 sink in wet years.</p>
<h2 id="composite-of-typhooninduced-sea-surface-temperature-and-chlorophylla-responses-in-the-south-china-sea">Composite of Typhoon‐Induced Sea Surface Temperature and Chlorophyll‐a Responses in the South China Sea</h2>
<p>Decreases in SST and increases in Chl‐a occur after 73% and 70% of the typhoons, respectively, with overall averaged changes equal to −0.42 ± 0.015°C and 0.056 ± 0.003 log10 mg/m3, respectively.</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Remote Sensing</tag>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 11.17-11.20</title>
    <url>/posts/179aa5a3.html</url>
    <content><![CDATA[<p>虽然自己还有好几个没有更新完，但是为了组会和AWOC就先把这个做出来吧。。。</p>
<a id="more"></a>
<h1 id="iop-reflectance-relationships-revisited-accepted">IOP-Reflectance relationships revisited Accepted</h1>
<p>doi: 10.1029/2020JC016661.</p>
<h2 id="introduction">Introduction</h2>
<p>The quasi-single scattering approximation (QSSA) (Gordon 1973; Gordon et al., 1975) models are widely employed in standard ocean colour processing and applications because they provide an explicit relationship between IOPs and rrs(λ), as formulated by Gordon et al. (1988), coupled with a simple relationship for converting Rrs(λ) to rrs(λ) (Lee et al., 2002). The weakness of QSSA models is their inability to account for multiple scattering effects and their lower accuracy, compared to radiative transfer (RT) codes (Werdell et al., 2018).</p>
<p>On the other hand, <strong>forward RT model</strong>s such as HydroLight (Sequoia Scientific, Inc.) can provide the full radiance distribution below and above the water, as a direct solution to the RT equation (Mobley, 1994). Therefore, given a set of <strong>input IOPs</strong> and appropriate boundary conditions, it is possible to generate <strong>precise estimates of a full set of AOPs</strong>, including rrs(0-, λ) and Rrs(0+, λ).</p>
<p>However, the <strong>inverse problem</strong> of determining <strong>IOPs from AOPs</strong> is not straightforward and relies on empirical and/or semi-analytical relationships.</p>
<p>Early work in this area focused on irradiance reflectance below the sea surface, R(0-,λ) (nondim), defined as the ratio of the upwards to downwards planar irradiances, Eu(0-,λ) (Wm-2nm-1)/ Ed(0-,λ) (Wm-2nm-1), as this was both practically measureable with available instrumentation and computationally convenient (e.g. Kirk, 1984).</p>
<p>At least two different expressions are found to approximate the relationship between R and absorption and backscattering coefficients</p>
<p>Morel and Prieur (1977), modelling the results from radiative transfer calculations, found that <span class="math display">\[
R(0^{-},\lambda)=f\frac{b_{b}(\lambda)}{a(\lambda)},
\]</span> while Gordon et al. (1975) showed that <span class="math display">\[
R(0^{-},\lambda)=F(\frac{b_b(\lambda)}{a(\lambda)+b_b(\lambda)})
\]</span> while <em>f</em> in Eq(1) is a variable in natural conditions(Morel &amp; Gentili 1991; 1996) accounting for most of the directional effects due to changes in the light field, degrees of multiple scattering and in water bio-optical characteristics. <em>F</em> in Eq(2) represents a polynomial function with factors for up to 3rd order given in the original paper.</p>
<p>The exact form of F in Equation 2 (2nd or 3rd order polynomial) and the associated polynomial coefficients have not been unambiguously established for all situations, though in several cases a second order polynomial has been adopted (e.g. Feng et al., 2005).</p>
<p>Rrs(0+,<span class="math inline">\(\lambda\)</span>) measurements are converted to below surface rrs(0-,<span class="math inline">\(\lambda\)</span>)using <span class="math display">\[
R_{rs}(0^+,\lambda)=T.r_{rs}(0^-,\lambda)
\]</span> where <em>T</em> is a transmission factor incorporating information including the Fresnel transmittance from water to air, the refractive index of seawater (invoking the n2 law of radiances) and several additional factors to deal with propagation of downwards irradiance (see Mobley 1999 and IOCCG 2019 for more details). The resulting conversion factor T exhibits only limited variability (0.50 &lt; T &lt; 0.57) and is usually assumed to have a value of 0.54.</p>
<p>Morel and Prieur (1977) adapted equation (1) to express sub-surface remote sensing reflectance rrs(0-,λ) as a function of the ratio bb(λ)/a(λ) (wM from here onward): <span class="math display">\[
r_{rs}(0^-,\lambda)=\frac{L_u(0^-,\lambda)}{E_d(0^-,\lambda)}=\frac{R(0^-,\lambda)}{Q}=\frac{f}{Q}\frac{b_b(\lambda)}{a(\lambda)}=\frac{f}{Q}w_M
\]</span> where Q (sr) is the bidirectional function defined by Morel and Gentili (1996) as the ratio of upwards irradiance Eu(0-,λ) to upwards radiance, Lu(0-,λ), and expresses the non-isotropic character of the radiance distribution<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>In contemporary ocean colour processing (Werdell et al., 2018), rrs(0-,λ) is more often expressed as a function of IOPs following the approach of Gordon et al. (1988) using the ratio of bb(λ)/[a(λ)+bb(λ)] (wG from here onward) <span class="math display">\[
r_{rs}(0^-,\lambda)=\frac{L_u(0^-,\lambda)}{E_d(0^-,\lambda)}=\frac{R(0^-,\lambda)}{Q}=g_0w_G+g_1w_G^2
\]</span> Taking Equations 3, 4 and 5 together, it is clear that Rrs(0+,λ) can be related to IOPs through either wG or wM. However, the apparently simple form of equations 4 and 5 is <strong>deceptive</strong>. <em>f</em> and <em>Q</em> are variables from a series of paper.</p>
<p>Morel and Gentili (1991, 1993, 1996) explored variability in f and Q, with the f/Q factor found to be variable in the range 0.075- 0.12 in oceanic (Case 1) waters and affected by solar zenith angle, sensor viewing geometry, in- water constituent concentrations and wavelength.</p>
<p>Furthermore, in coastal (Case 2) waters, additional concentrations of CDOM and mineral particles that do not co-vary with the chlorophyll concentration were expected to influence the variability of f/Q, though this variability was found to be minimal in the nadir viewing direction and the f/Q factor was almost insensitive to different wavelengths when the Sun is at the zenith (Loisel &amp; Morel, 2001)</p>
<p>One possible reason for the relative popularity of IOP-reflectance relationships operating on wG is that the quadratic form expressed in Equation 5 captures some of the nonlinear behavior in the relationship with IOPs that is less obviously elucidated in the LUT approach for f/Q. The limiting factor for Gordon-style versions of the relationship with IOPs stems from failure to achieve consensus on a single form or set of coefficients that performs equally well across the known range of variability for natural waters.</p>
<p>Gordon et al. (1988) suggested a quadratic form with g0=0.0949 and g1=0.0794 for Case 1 waters, while for highly scattering coastal waters Lee et al. (1999) suggested g0=0.084 and g1=0.17. Later Lee et al. (2002), aiming at applying the forward model to both coastal and open-ocean waters, proposed average values of the coefficients from previous studies, g0=0.0895 and g1=0.1247.</p>
<p>Subsequently, focusing on above surface Rrs, Albert and Mobley (2003) and Park and Ruddick (2005) developed 4th order polynomial relationships in deep and shallow waters, while more recently Lee et al. (2011) and Hlaing et al. (2012) presented 2nd and 3rd order polynomial variants respectively.</p>
<p>Whilst there has been considerable improvement in our understanding of IOP-reflectance relationships since the pioneering studies by Morel and Gordon, there remains confusion in the field about the relative merits of wM and wG approaches. Moreover, there is an outstanding requirement to develop easily implemented relationships that permit end users to relate IOPs and reflectance values for both above and below surface reflectances corresponding to remote sensing and in situ applications. Most importantly, it is essential that the performance of any such relationship is equivalent across the wide range of concentrations of optical constituents found in natural waters and can be applied equally well in both clear Case 1 waters and optically complex Case 2 waters.</p>
<p>Aim of this study</p>
<p><strong>Exploit the strength of forward RT modelling to generate a consistent set of IOPs and corresponding simulated rrs and Rrs values which enables investigation of IOP-reflectance relationships across a wide variety of optically complex water conditions. </strong></p>
<h2 id="material-and-method">Material and method</h2>
<h3 id="field-data">Field data</h3>
<h3 id="in-situ-optical-measurements">In situ Optical Measurements</h3>
<p>All in situ data used in this study were collected in March 2009 during the BP09 cruise in the Ligurian Sea (Figure 1). Located in the northwest part of the Mediterranean Sea, this area includes both deep clear oceanic waters (considered Case 1) and shallow turbid coastal waters (considered Case 2). Among 60 sampled stations, 11 offshore stations and 23 onshore stations returned sufficient data set for the purpose of this work. A detailed description of the sampling location, data and methods can be found in McKee et al. (2014), Bengil et al. (2016) and Ramírez- Pérez et al. (2018)</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117160903264.png" alt="image-00021117160903264"><figcaption aria-hidden="true">image-00021117160903264</figcaption>
</figure>
<h3 id="laboratory-measurement">Laboratory measurement</h3>
<h3 id="bio-optical-model-developement">Bio-optical model developement</h3>
<p>Following the methodology reported in Ramírez-Pérez et al. (2018) for Case 2 waters, each total IOP can be considered as the sum of partial IOPs, and each partial IOP can be expressed as the product of SIOPs, and associated constituent concentrations:</p>
<p><span class="math display">\[
a_{Tot}(\lambda)=a_{ph}^{*}(\lambda)CHL+a_{bdet}^{*}(\lambda)CHL+a_{ndet}^{*}(\lambda)MSS+a_{cdom}^{*}(\lambda)CDOM+a_w(\lambda)
\]</span></p>
<p><span class="math display">\[
b_{Tot}(\lambda)=b_{ph}^{*}CHL+b_{ndet}^{*}(\lambda)MSS+b_w(\lambda)
\]</span></p>
<p><span class="math display">\[
c_{Tot}(\lambda)=a_{Tot}(\lambda)+b_{Tot}(\lambda)
\]</span></p>
<p><span class="math display">\[
b_{b \ Tot}=b_{bph}^{*}(\lambda)CHL+b_{bndet}^{*}(\lambda)MSS+b_{b \ w}{\lambda}
\]</span></p>
<p>where the subscripts represent the following five bio-optical constituents: phytoplankton (ph), <strong>biogenic detritus (bdet)</strong>, <strong>non-biogenic detritus (ndet)</strong>, coloured dissolved organic material (cdom) and pure water (w). The constituent concentrations are: chlorophyll, CHL, absorption of coloured dissolved organic material at 440 nm, CDOM, and mineral suspended solids, MSS (the non- biogenic detrital component of total suspended solids). Here</p>
<p>Here the detrital particulate absorption has been considered as the sum of two separate biogenic and non-biogenic components. Unfortunately it is <strong>not possible</strong> to experimentally partition scattering and backscattering measurements so the level of discrimination possible for these parameters is reduced.</p>
<p><strong>Biogenic partial IOPs are assumed to co-vary with CHL, while the non-biogenic partial IOPs are assumed to co-vary with MSS</strong></p>
<p>In this study, only values at each standard AC-9 wavelength have been considered.</p>
<p>These SIOPs have been determined by simple linear regressions forced through zero of partitioned IOPs against associated constituent concentrations from surface water samples.</p>
<p>The optimal SIOP value has been estimated using the linear regression slope with the 95% Confidence Interval (CI) representing the associated uncertainty (Figure 2, red dashed lines).</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/20201117154622.png"></p>
<p>Figure 2. Material-specific IOPs (black lines) with 95% confidence bounds (red dashed lines) obtained by linear regression at 9 wavelengths. (a) CHL-specific phytoplankton absorption – full data set. (b) CDOM absorption normalised at the signal at 440 nm – full data set. (c) CHL-specific biogenic detrital absorption – offshore data set. (d) CHL-specific phytoplankton scattering – offshore data set. (e) MSS-specific nonbiogenic detrital absorption coefficient – onshore data set. (f) MSS-specific nonbiogenic detrital scattering coefficient – onshore data set. SIOPs in (a)-(f) are recalculated SIOPs from Ramírez-Pérez et al. (2018) after further quality control measures were implemented. (g) the CHL-specific phytoplankton backscattering coefficient has been determined by linear regression forced through zero applied to the offshore data set, and (h) MSS-specific non biogenic detrital backscattering coefficient has been determined with the same methodology. Regressions on backscattering coefficients returned average R2 values of 0.78</p>
<p>In addition to the previously provided SIOPs for partitioned absorption and scattering coefficients, the material-specific backscattering coefficients are presented here following the same methodology. The chlorophyll-specific phytoplankton backscattering coefficient, shown in Figure 2g, was determined using data from offshore stations (considered Case 1 waters), where the particle population is assumed to be biogenic in origin. However,<strong>it is assumed to be representative of algal and biogenic detrital backscattering for all stations,</strong> offshore and onshore.</p>
<p>For onshore stations (considered Case 2 waters) it is assumed that there will be an additional non-biogenic contribution, <span class="math inline">\(b_{bndet}(\lambda)\)</span>, that can be found after subtraction of the water and biogenic contribution $(b_{bph}^{<em>}()</em>CHL) $ from <span class="math inline">\(b_{bTot}(\lambda)\)</span>. The MSS-∗ specific non biogenic detrital backscattering coefficient, <span class="math inline">\(b_{bpndet}^{*}(\lambda)\)</span>shown in Figure 2h was obtained by regressing <span class="math inline">\(b_{bpndet}(\lambda)\)</span> against MSS.</p>
<h3 id="radiative-transfer-simulations">Radiative transfer simulations</h3>
<p>Input IOPs for the simulations were generated by populating the bio-optical model, described in the previous section at 9 standard AC-9 wavelengths(412, 440, 488, 510, 532, 555, 650, 676, and 715 nm). A total of 1690 unique combinations of constituent concentrations and associated IOPs were calculated from log-spaced distributions of constituent concentrations in specific ranges (0.01&lt;CHL&lt;100 mg/m3, n = 13; 0.01&lt;MSS&lt;100 g/m3, n = 13; 0.01&lt;CDOM&lt;10 m- 1, n = 10)).</p>
<p>The data set of modeled IOPs was arranged in the form of 1690 virtual AC-9 and BB- 9 type files in the Matlab® environment (MathWorks Inc.).</p>
<p>The radiative transfer numerical model HydroLight 5.2 (Sequoia Scientific Inc.) was used to process the input IOP data and generate a synthetic dataset of remote sensing reflectance spectra, both below and above the sea-air interface, rrs(0-, λ) and Rrs(0+, λ) respectively.</p>
<p><strong>Flow of this simulation: SIOP-&gt;IOP-&gt;AOP, the first step just randomly input, the second step is using Hydrolight, this process is reversion/forward</strong></p>
<p>Based on the considered constituent concentration ranges, the total absorption at 412 nm, a(412), <strong>was in the range 0.0218–27.1346 m−1</strong>, while the total backscattering coefficient, bb(412),<strong>varied from 0.0036 to 2.3240 m−1</strong>, where the minimum (maximum) values represent the total IOPs when all the constituent concentrations are at their lowest (highest). Pure water absorption and scattering values were taken from Pope and Fry (1997) and Smith and Baker (1981).</p>
<p>Sky radiance was modelled using RADTRAN-X (Gregg &amp; Carder, 1990) with no wind and the mean Earth-Sun distance was employed.</p>
<p>Other atmospheric conditions such as sea-level pressure, relative humidity, horizontal visibility, and ozone concentration were set at default values, which are described in the HydroLight 5 technical documentation (Mobley &amp; Sundman, 2008).Raman (inelastic) scattering by water itself is ubiquitous and was considered since it is easy to model without any extra information, while <strong>fluorescence</strong> emissions due to chlorophyll and CDOM were not included, <strong>due to lack of information about fluorescence quantum yields</strong>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<h2 id="result">Result</h2>
<h3 id="establishing-the-nature-of-iop---reflectance-relationships">Establishing the nature of IOP - reflectance relationships</h3>
<h4 id="fq-and-t">f/Q and T</h4>
<p>Variations in the bidirectional properties of the radiant flux leaving the water and returned toward the atmosphere have been extensively studied (Morel &amp; Gentili, 1991, 1993, 1996; Morel et al., 2002). The term f/Q in Equation 4 implicitly describes the magnitude of these variations, mainly due to changes in the light field geometry and bio-optical characteristics of the water body. Figure 3 shows distributions of f/Q as obtained in this study from RT simulations, calculated from Equation 4.<strong>These results are broadly consistent with Morel and Gentili (1993) who found values in the range 0.075 – 0.12.</strong> f/Q also influenced by variations in sun angles and viewing geometries. This is confirmed in Figures 4c and 4d where it can be seen that changing solar zenith angle has a <strong>small but defined</strong> impact on relationships between Rrs and both wM and wG.</p>
<p>In the present study, unless otherwise stated, the results refer only to a zenith Sun and a vertical viewing direction, <strong>meaning that the variability of the f/Q factor here is due mainly to differences in water constituent concentrations</strong></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117172752050.png" alt="image-00021117172752050"><figcaption aria-hidden="true">image-00021117172752050</figcaption>
</figure>
<p>Figure 3. Frequency distribution (in the range 0-1, with 1 corresponding to 100%) of the ratio f/Q at 4 different wavelengths (440, 510, 555 and 676 nm), as in Figure 9(b) of Morel and Gentili (1993). Values of f/Q have been estimated from Equation 4.</p>
<p>The radiative transfer simulations can also be used to assess variability in the transmission factor T by rearranging Equation 3. Mobley (1999) suggested a range between 0.50 - 0.57 for typical ocean waters and solar and sensor geometries. In this study, T was found to vary in the range 0.52 - 0.63 considering the Sun at the zenith and the sensor in the vertical direction,with the differences in ranges between the two studies presumably associated with the range of water conditions (and therefore IOPs) considered.</p>
<p><strong>Overall, it is reasonable to suggest that the variability described by f/Q and T factors observed in this study are broadly consistent with previous studies.</strong></p>
<h4 id="rrs-and-iop">rrs and IOP</h4>
<p><strong>This study investigates relationships between IOPs and both rrs(λ) and Rrs(λ) considering both wM and wG forms, and also considers both forward and inverse directions.</strong></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117173724526.png" alt="image-00021117173724526"><figcaption aria-hidden="true">image-00021117173724526</figcaption>
</figure>
<p>Plotting the HydroLight output rrs(λ) values against the input IOP terms, wM and wG,(Figure 4a and 4b), the relationships between rrs(λ) and either wM or wG are found to be non-linear but, crucially, monotonic.</p>
<p>Whereas the frequency distributions shown in Figure 3 do not offer any means of predicting a particular value of f/Q, Figure 4 suggests the possibility of establishing relationships between rrs and either wM or wG with strong predictive power in both the forward and reverse directions.</p>
<ul>
<li>both approaches (wM and wG) are equivalently valid</li>
<li>dependence of the sub-surface remote sensing reflectance on wavelength (400 nm &lt; λ &lt; 700 nm) is minimal in Case 2 waters(in fig. a and fig.b, different wavelength almost in same curve)</li>
<li>Changing the solar zenith angle (θs=0⁰; 30⁰; 60⁰) generates similar but non-identical nonlinear, monotonic relationships (Figures 4c and 4d) #### Rrs and IOP</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117192242014.png" alt="image-00021117192242014"><figcaption aria-hidden="true">image-00021117192242014</figcaption>
</figure>
<ul>
<li>Rrs and w_m/w_G has analogous behavior compared to the corresponding case of sub-surface reflectance, with slightly less sensitivity to changing solar angles.</li>
</ul>
<h3 id="determination-of-optimal-iop-rrs-relationships">Determination of optimal IOP-rrs relationships</h3>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117193004264.png" alt="image-00021117193004264"><figcaption aria-hidden="true">image-00021117193004264</figcaption>
</figure>
<ul>
<li>significant divergence in the performance of each best- fit polynomial for low values of both wM and wG, and similarly when these parameters are derived from rrs(λ).</li>
<li>performance for high values of rrs(λ), wM and wG is less sensitive to choice of polynomial</li>
</ul>
<p><strong>It is therefore important to consider performance over all relevant ranges of signal strength when attempting to establish a set of optimal empirical relationships.</strong></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117193140185.png" alt="image-00021117193140185"><figcaption aria-hidden="true">image-00021117193140185</figcaption>
</figure>
<p>When estimating rrs(λ) from wM or wG (Figure 7a and 7b) it is possible to directly compare the two approaches because the derived term in both cases is rrs(λ). However, when comparing retrievals of bb(λ)/a(λ) and bb(λ)/[a(λ)+bb(λ)], <strong>it is important to bear in mind that the two variables are not numerically equivalent (Figure 7c and 7d).</strong></p>
<ul>
<li>The results of this systematic exercise show that higher order polynomial models provide better performance than second order models to ensure similar goodness of fit across all decades of signal variation.</li>
<li>recommended relationships in retrieving rrs(λ) from wM and vice versa are 6th and 5th order polynomials respectively (Figure 7a and 7c)</li>
<li>A 3rd order polynomial is the suggested choice for retrieving rrs(λ) from wG, (Figure 7b),</li>
<li>while a 6th order polynomial is needed for estimating wG from rrs(λ) (Figure 7d).</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117194324597.png" alt="image-00021117194324597"><figcaption aria-hidden="true">image-00021117194324597</figcaption>
</figure>
<p>It is interesting to note that wM and wG approaches produce similar levels of MAE if sufficiently well-tuned polynomials are selected.</p>
<p>Overall there is no significant accuracy benefit of one form of IOP expression over the other.</p>
<p>The results of this exercise show that with suitably careful selection of empirical relationship, using wM or wG is broadly equivalent.</p>
<h3 id="determination-of-optimal-iop-rrs-relationshops">Determination of optimal IOP-Rrs relationshops</h3>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117200844135.png" alt="image-00021117200844135"><figcaption aria-hidden="true">image-00021117200844135</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117200909132.png" alt="image-00021117200909132"><figcaption aria-hidden="true">image-00021117200909132</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117200924727.png" alt="image-00021117200924727"><figcaption aria-hidden="true">image-00021117200924727</figcaption>
</figure>
<p>This part is almost the same with previous one. Here is the summary.</p>
<ul>
<li>higher order polynomials are suggested to ensure similar goodness of fit across all decades of signal variation, with the greatest impact occurring at small data values.</li>
<li>the recommended relationships in retrieving Rrs(λ) from wM and vice versa are the 5th order polynomials in both case</li>
<li>for retrieving Rrs(λ) from wG, a 4th order polynomial is the suggested choice (Figure 9b), while a 7th order polynomial is needed for estimating wG from Rrs(λ) (Figure 9d).</li>
<li>Rrs(λ) can be expressed as a function of the absorption and backscattering coefficients of the water and it is equally valid to represent the IOPs using wM or wG.</li>
<li>The limiting factor is not choice of either wM or wG, rather it is in selecting an appropriate formulation to represent variation the non-linear relationship with IOPs.</li>
</ul>
<h3 id="comparison-with-previous-studies">Comparison with previous studies</h3>
<p>the existing established models for representing rrs(λ) (Gordon et al., 1988 and Lee et al., 2002, 2004) or Rrs(λ), based on low order polynomial relationships, are unable to fully account for the effect of multiple scattering which is particularly relevant in Case 2 waters (Wong et al., 2019).</p>
<p>Interestingly, the results presented above suggest that the <strong>performance of low-order polynomials tends to be worst for clear waters.</strong> It is clear from this analysis that higher order polynomials are generally necessary in order to achieve optimal performance across the full range of natural variability.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117202129722.png" alt="image-00021117202129722"><figcaption aria-hidden="true">image-00021117202129722</figcaption>
</figure>
<ul>
<li><p>Poly5 model is very close to the version of Gordon’s model with coefficients suggested by Lee et al. (2002) which was intended to be applicable to both Case 1 and Case 2 waters.</p></li>
<li><p>Applying the Wong et al. (2019) approach to our data set presents smaller MAEs for lower values of wG, but higher MAE for higher values of wG.</p></li>
<li><p>It is important to note that the family of curve models shown in Figure 10a falls within the 95% confidence bounds of the proposed Poly5 relationship at the high end of the range (Figure 10c) while the 95% confidence bounds at the low end (Figure 10d) are an order of magnitude greater than the MAE differences between the various proposed relationships for the equivalent range in Figure 10b.</p></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117202148259.png" alt="image-00021117202148259"><figcaption aria-hidden="true">image-00021117202148259</figcaption>
</figure>
<h2 id="discussion-and-conclusion">Discussion and conclusion</h2>
<p>In this paper</p>
<ul>
<li><p>a series of radiative transfer simulations across a very broad range of optical conditions has been conducted using the HydroLight RT code.</p></li>
<li><p>Input IOPs have been supplied through a linear spectral bio-optical model, varying the concentrations of in-water optical constituents across a wide range of concentrations to simulate natural variability</p></li>
<li><p>The resulting set of synthetic above and below surface reflectances have enabled investigation of relationships with IOPs expressed as either wM or wG.</p></li>
<li><p>The results demonstrate that the relationship between IOPs and either rrs or Rrs are highly predictable and can be well modelled by a non-linear but monotonic curve, which is not significantly wavelength dependent for 400nm&lt;λ&lt;700nm.</p></li>
<li><p>However, it has been shown here that in order to achieve consistent levels of prediction performance across the broad range of optical coastal water conditions considered, it is generally necessary to consider higher order polynomial relationships.</p></li>
<li><p>Comparison of wM and wG variants demonstrate effectively equivalent performance: there is no immediate advantage or disadvantage to use of either form in coastal waters.</p></li>
<li><p>The general proposition that either combination of absorption and backscattering contains sufficient relevant information to both predict and interpret remote sensing signals.</p></li>
<li><p>There may be situations where future end users may have reason to prefer use of one form over another and this study suggests there is no reason to be concerned over either</p></li>
</ul>
<h2 id="annotation">Annotation</h2>
<p>This is a very fundamental paper related to the relationship between IOP and AOP. Specifically, this paper examine two relationship, f/Q and polynomial. I do not tend to make a summary for this paper all.</p>
<p>One thing I can learn from this paper is that how f/Q and polynomial effected by the environment. f/Q is mainly influenced by the water constitution, and small influenced by the sun angles, viewing geometries and solar zenith. It is in the range of 0.075 – 0.12.</p>
<p>For the relationship between rrs and IOP, the author examined different order of polynimal. The poly5 the author used seems slightly better than Lee 02 and Wong 2019, but the author said that this conclusion might be only true in the area they collected data. The poly5 is difficult to solve in the inversion problem, but I can try it in the reversion problem.</p>
<p>One interested thing is that the author use SIOP to generate IOP dataset. I'm wondering what could influence SIOP.</p>
<h1 id="algorithm-to-derive-inherent-optical-properties-from-remote-sensing-reflectance-in-turbid-and-eutrophic-lakes">Algorithm to derive inherent optical properties from remote sensing reflectance in turbid and eutrophic lakes</h1>
<p>10.1364/ao.58.008549</p>
<p>This paper is just to explore the failure and effort could do to improve QAA. So I haven't read it totally.</p>
<p>There are several things need to be noticed in this algorithm.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021118153124186.png" alt="image-00021118153124186"><figcaption aria-hidden="true">image-00021118153124186</figcaption>
</figure>
<ol type="1">
<li><p>This paper changed the refferenced band to 750</p></li>
<li><p>First use emprical method to estimated ap750, and treat it as a constant value. Here is use ad750 from other paper</p></li>
<li><p>Then use analytical to built bbp750</p></li>
<li><p>Then an optimized parameter to get Y, the power exponent of bop shape</p></li>
<li><p>Then retrieve <span class="math inline">\(a_{nw}\)</span>, non-water absorption.</p></li>
<li><p>At last it retrieve <span class="math inline">\(a_{ph}\)</span> first, then get<span class="math inline">\(a_{dg}\)</span></p>
<p>The most important contribution I think is 2 4 6</p></li>
</ol>
<h1 id="modeling-the-remote-sensing-reflectance-of-highly-turbid-waters">Modeling the remote-sensing reflectance of highly turbid waters</h1>
<p>This paper acutually similar with the first one I read. He made a ploy4 model from IOP to rrs</p>
<h1 id="variability-in-the-chlorophyll-specific-absorption-coefficients-of-natural-phytoplankton-analysis-and-parameterization">Variability in the chlorophyll-specific absorption coefficients of natural phytoplankton: Analysis and parameterization</h1>
<p>https://doi.org/10.1029/95JC00463</p>
<p>I finally know how band shifting using that equation to estimate <span class="math inline">\(a_{ph}\)</span> at different wavelength.</p>
<p>Actually I think I need to check the SIOP paper Ramírez- Pérez et al. (2018), I really think.</p>
<p>In this paper, the author parameteration the app spectra shape by the following formula: <span class="math display">\[
a_{ph}^{*}(\lambda)=A(\lambda)*CHL^{-B(\lambda)}
\]</span> Although in the table they attached, they found in some wavelength the r^2 is relative low, they still use this.</p>
<p>Substitute the SIOP by IOP, we can get another form of the former equation: <span class="math display">\[
a_{ph}(\lambda)=A(\lambda)*CHL^{1-B(\lambda)}
\]</span></p>
<p>After using QAA, we can got <span class="math inline">\(a_{ph}(443)\)</span></p>
<p>So for <span class="math inline">\(a_{ph}(443)\)</span>, we can know that <span class="math display">\[
a_{ph}(443)=A(443)*CHL^{1-B(443)}
\]</span> Just divide these two equations.</p>
<p>And maybe I can found some other parameteration in coastal area for a ph spectra shape.</p>
<h1 id="section"></h1>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>R(0-,λ) (nondim), defined as the ratio of the upwards to downwards planar irradiances,R(0-,λ)= Eu(0-,λ)/ Ed(0-,λ);Q=Eu(0-,λ)/Lu(0-,λ);so Lu(0-,λ)=Eu(0-,λ)/Q, substitute and get<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The detailed information about phytoplankton fluorescence is in the Book 'Real-time Coastal Observing Systems <em>for</em> Marine Ecosystem Dynamics <em>and</em> Harmful Algal Blooms', Chapter 7, 'Phytoplankton fluorescence: theory, current literature and <em>in situ</em> measurement'<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Inherent Optical Properties</tag>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2021 1.8-1.15</title>
    <url>/posts/ff413d6a.html</url>
    <content><![CDATA[<p>Book Reading Ch. 3.9-3.10 of book &lt;Emery, William, and Adriano Camps. <em>Introduction to satellite remote sensing: atmosphere, ocean, land and cryosphere applications</em>. Elsevier, 2017.&gt;</p>
<p>Effects of forward models on the semi-analytical retrieval of inherent optical properties from remote sensing reflectance</p>
<a id="more"></a>
<h1 id="book-reading">Book Reading</h1>
<h2 id="light-detection-and-ranging">3.9 LIGHT DETECTION AND RANGING</h2>
<p>Light detection and ranging (LIDAR) is sometimes called “laser radar” in an abuse of language because its principles are similar to those of the radar systems that will be discussed later in this text.</p>
<p>LIDAR is an optical remote sensing technique that measures the properties of scattered light to find the range or speed of distant targets, or the backscattering and attenuation of volume targets such as the atmosphere or the sea water.</p>
<p>As in radar systems, the range to an object is determined by measuring the time delay between transmission of a (light) pulse and the detection of the reflected signal. LIDAR technology was first used in 1962 by Fiocco and Smultin reflecting a laser beam off the surface of the Moon and studying the turbidity in upper atmospheric layers.</p>
<p>Later, in 1963 it was used by Ligda to perform the first cloud height and aerosols measurements.</p>
<p>LIDAR has seen applications in archeology, geography, geology, geomorphology, seismology, remote sensing, and atmospheric physics.</p>
<h3 id="physics-of-the-measurement">3.9.1 Physics of the measurement</h3>
<p>The main difference between LIDAR and radar is that LIDAR operates with much shorter wavelengths of the EM spectrum, in atmospheric transmission windows in the ultraviolet (UV), visible, and near-IR (e.g., 0.4-0.7, 0.7-1.5, 3-5, and 9-13 mm) (http://en.wikipedia.org/wiki/lidar).</p>
<p>Thus, in general it is possible to detect a feature or object, which is about the size of the wavelength or larger.</p>
<p>Thus, LIDAR is very sensitive to atmospheric aerosols and cloud particles and has many applications in atmosphere research and meteorology.</p>
<p>However, an object needs to produce a dielectric discontinuity to reflect the transmitted wave.</p>
<p>At radar (microwave or radio) frequencies, a metallic object produces a significant reflection. However nonmetallic objects, such as rain and rocks produce weaker reflections and some materials may produce nondetectable reflection at all, meaning some objects or features are effectively invisible at radar frequencies. This is especially true for very small objects (such as single molecules and aerosols).</p>
<p>Lasers provide one solution to these problems. The beam densities and coherency are excellent, and the wavelengths are much smaller. The basic atmospheric LIDAR equation (volumetric target) is given by <span class="math display">\[
P(\lambda,R)=P_0*\frac{c\tau}{2}*\beta(\lambda,R)*\frac{A_r}{R^2}*exp(-2\int_0^R\alpha(\lambda,R)dr)*\xi(\lambda)*\xi(R)
\]</span></p>
<p><span class="math inline">\(P(\lambda,R)\)</span> is the received power at a wavelength <span class="math inline">\(\lambda\)</span> from a range R, which is associated with a time delay <span class="math inline">\(t=2*R/c\)</span>,<span class="math inline">\(P_0\)</span> is the transmitted pulse power, <span class="math inline">\(\tau\)</span> is the pulse duration, <span class="math inline">\(c*\tau/2\)</span> is the pulse "duration" is the range direction, <span class="math inline">\(\beta(\lambda,R)\)</span> is the backscattering coefficient, <span class="math inline">\(A_\tau\)</span> is the effective area of the receiving system(typically a telecope), <span class="math inline">\(\alpha(\lambda,R)\)</span> is the absorption coefficient of the atmosphere, <span class="math inline">\(\xi(\lambda)\)</span> is the transmissivity of the receiver optics, and <span class="math inline">\(\xi(R)\)</span> is the so-called overlapping factor, which accounts for the volume intersection between the transmitted lase beam and the receiving cone, as illustrated in thies figure 3.32</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110132631195.png" alt="image-00030110132631195"><figcaption aria-hidden="true">image-00030110132631195</figcaption>
</figure>
<p>The detected output voltage of the LIDAR returns at each range gate is proportional to the received power</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110133056244.png" alt="image-00030110133056244"><figcaption aria-hidden="true">image-00030110133056244</figcaption>
</figure>
<p>Where <span class="math inline">\(G_T\)</span> is the amplifier's voltage gain, <span class="math inline">\(P_{back}\)</span> is the background power (power collected from the amibient light), S stands for the siganl term, <span class="math inline">\(V_{off}\)</span> stands for the offset term(to be compensated for), and all other terms have been previously defined.</p>
<p>The noise associated to the LIDAR measurements has three different contributions: the “shot” noise associated with the signal power (P), the “shot” noise associated to the background power, and the thermal noise（<span class="math inline">\(\sigma^2_{thermal}\)</span>）</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110133803818.png" alt="image-00030110133803818"><figcaption aria-hidden="true">image-00030110133803818</figcaption>
</figure>
<p>Since the SNR is typically very low, long incoherent averaging is required to increase it as in radar systems.</p>
<p>Different types of scattering are used for different LIDAR applications, most common are Rayleigh scattering, Mie scattering, and Raman scattering as well as fluorescence. The wavelengths are ideal for making measurements of smoke and other airborne particles (aerosols), clouds, and air molecules. A laser typically has a very narrow beam, which allows the mapping of physical features with very high resolution compared with radar. In addition, many chemical compounds interact more strongly at visible wavelengths than at microwaves, resulting in a stronger image of these materials. Suitable combinations of lasers can allow for remote mapping of atmospheric contents by looking for wavelength-dependent changes in the intensity of the returned signal.</p>
<p>LIDAR has been used extensively for atmospheric research and meteorology. With the deployment of the global positioning systems (GPS) in the 1980s precision positioning of aircraft became possible.</p>
<p>GPS-based surveying technology has made airborne surveying and mapping applications possible and practical. Many have been developed, using downward-looking LIDAR instruments mounted in aircraft or satellites.</p>
<h3 id="optical-and-technological-considerations">3.9.2 OPTICAL AND TECHNOLOGICAL CONSIDERATIONS</h3>
<p>There are in general two kinds of LIDARs: “incoherent” or direct detection of the power return, mainly an amplitude measurement, and “coherent” which uses the Doppler shift and must keep track of the phase information in each laser pulse. Coherent systems generally use optical heterodyne detection which is more sensitive than direct detection and allows operation at a much lower power levels, but at the expense of having more complex transceiver requirements.</p>
<p>In both coherent and incoherent LIDARs, there are two types of pulse models: micropulse and high-energy LIDARs. Micropulse systems have been developed as a result of the ever-increasing computer power available to process the sensor data combined with marked advances in laser tech- nology. Micropulse systems typically operate at power levels that are “eye safe” meaning that they can operate without any additional safety precautions. High-power systems are common in atmospheric research where they are widely used for measuring atmospheric parameters such as cloud height, layering and densities of clouds, cloud particle properties, temperature, pressure, wind, humidity, trace gas concentrations (ozone, methane, nitrous oxide, etc.), aerosols.</p>
<p>The components of a typical LIDAR are as follows:</p>
<ol type="1">
<li><p><strong>Laser</strong>. 600e1000 nm lasers are most common for nonscientific applications. They are inexpensive, but since they can be focused and easily absorbed by the eye the maximum power is limited by the need to make them eye-safe. Eye safety is often a requirement for most applications. A common alternative, the 1550 nm lasers are eye-safe at much higher power levels since this wavelength is not focused by the eye, but the detector technology is less advanced in this spectral region, so these wavelengths are generally used at longer ranges and lower accuracies. Airborne topographic mapping LIDARs generally use 1064 nm diodeepumped YAG lasers, while bathymetric systems generally use 532 nm frequency doubled diodeepumped YAG lasers because 532 nm penetrates water with much less attenuation than does 1064 nm. Variables in the individual systems include the ability to set the number of passes required through the gain (YAG, YLF, etc.) and Q-switch speed. Shorter pulses achieve better target resolution provided the LIDAR receiver detectors and electronics have sufficient bandwidth.</p></li>
<li><p><strong>Scanner and optics</strong>. How fast images can be developed is also affected by the speed at which they can be scanned into the system. There are several different ways to scan the azimuth and elevation, including dual oscillating plane mirrors, a combination with a polygon mirror, a dual axes scanner. Optic choices affect the angular resolution and range that can be detected. A hole- mirror or beam splitter can be used to collect a laser return signal.</p></li>
<li><p><strong>Photodetector and receiver electronics</strong>. Two different photodetector technologies are used in today’s LIDARs: solid-state photodetectors, such as silicon avalanche photodiodes, or photomultipliers. The sensitivity of the receiver is another parameter that has to be balanced in a LIDAR design.</p></li>
<li><p><strong>Position and navigation systems</strong>. LIDAR sensors mounted on mobile platforms such as airplanes or satellites require instrumentation to determine the absolute position and orientation (pointing angle) of the sensor. GPS and inertial measurement unit systems are primary types of systems used for this purpose.</p></li>
</ol>
<h3 id="application-of-lidar-systems">3.9.3 APPLICATION OF LIDAR SYSTEMS</h3>
<p>There are many different applications of LIDAR systems, but we will concentrate on those primarily in meteorology, which was one of the earliest applications of LIDAR remote sensing. The first LIDARs were used for studies of atmospheric composition, structure, clouds, and aerosols. Initially based on rube lasers, LIDARs for meteorology were constructed shortly after the invention of the laser.</p>
<p>Some modern LIDARs are as follows:</p>
<ol type="1">
<li><p>Elastic backscatter LIDAR is the simplest form of LIDAR and is typically used for studies of aerosols and clouds. The backscattered wavelength is identical to the transmitted wavelength, and the magnitude of the received signal at a given range depends on the backscatter coefficient of scatterers at that range and the extinction coefficients of the scatterers along the path to that range. The extinction coefficient is typically the quantity of interest.</p></li>
<li><p>Differential absorption LIDAR (DIAL) is used for range-resolved measurements of a particular gas in the atmosphere, such as ozone, carbon dioxide, or water vapor. The LIDAR transmits two wavelengths: an “on-line” wavelength that is absorbed by the gas of interest and an off-line wavelength that is not absorbed. The differential absorption between the two wavelengths is a measure of the concentration of the gas as a function of range. DIAL LIDARs are essentially dual-wavelength elastic backscatter LIDARs.</p></li>
<li><p>Raman LIDAR is also used for measuring the concentrations of atmospheric gases, but can also be used to retrieve aerosol parameters as well. Raman LIDAR exploits inelastic scattering to single out the gas of interest from all other atmospheric constituents. A small portion of the energy of the transmitted light is deposited in the gas during the scattering process, which shifts the scattered light to a longer wavelength by an amount that is unique to the species of interest. The higher the concentration of the gas, the stronger the magnitude of the backscattered signal.</p></li>
<li><p>Doppler LIDAR is used to measure wind speed along the beam by measuring the frequency shift of the backscattered signal. Scanning LIDARs have been used to measure atmospheric wind velocity in a large three-dimensional core. ESA’s wind mission Atmospheric Dynamics Mission Aeolus (ADM-Aeolus) will be equipped with a Doppler LIDAR system to provide global measurements of vertical wind profiles. Doppler LIDAR systems are now beginning to be successfully applied in the renewable energy sector to acquire wind speed, turbulence, wind veer, and wind shear data. Both pulse and continuous wave systems are being used for these applications.</p></li>
<li><p>The number of spaceborne LIDARs has been very limited because of the reliability of lasers. So far,</p></li>
</ol>
<p>the only LIDAR-based mission is the NASA/CNES cloud-aerosol LIDAR and infrared pathfinder satellite observation (CALIPSO) mission, which belongs to the A-TRAIN constellation. CALIPSO combines an active LIDAR instrument with passive IR and visible imagers to probe the vertical structure and properties of thin clouds and aerosols over the globe.</p>
<p>CALIPSO was launched on April 28, 2006, with the cloud profiling radar system on the CloudSat satellite. Fig. 3.33 shows an artist’s view of the CALIPSO mission in the A-TRAIN constellation, a picture and a drawing of it, and sample LIDAR returns from the sea surface up to 30 km height. The dark blue regions underneath the high- reflectivity regions (in pink) correspond to regions where the SNR is too low because of the increased attenuation of the signal in previous regions. The main engineering parameters of the CALIPSO LIDAR are listed in Table 3.4.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110135016406.png" alt="image-00030110135016406"><figcaption aria-hidden="true">image-00030110135016406</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110135103603.png" alt="image-00030110135103603"><figcaption aria-hidden="true">image-00030110135103603</figcaption>
</figure>
<h3 id="wind-lidar">WIND LIDAR</h3>
<p>As just mentioned a wind LIDAR is a Doppler LIDAR that uses the frequency shift of the back- scattered signal to determine the wind velocity. This concept is depicted here in Fig. 3.34 adapted from Dobler et al., 2002.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110135148162.png" alt="image-00030110135148162"><figcaption aria-hidden="true">image-00030110135148162</figcaption>
</figure>
<p>This coherent Doppler wind LIDAR measures the frequency of the beat signal obtained by optically mixing the return signal with the local oscillator. As a consequence, both the local oscillator and the return signal must have narrow bandwidths to have sufficient coherent lengths. Thus, coherent LIDAR detection relies of the aerosol scattering with very narrow Doppler broadening meaning the LIDAR wind measurements apply only to those atmospheric regions with adequate aerosol loading.</p>
<p>Since the Mie scattering due to aerosols is better suited to frequency analysis than is the molecular Rayleigh scattering the choice of LIDAR wavelength depends on the expected return signal and the expected ratio of aerosol-to-molecular backscatter. The molecular scattering cross-section is proportional to <span class="math inline">\(\lambda^{-4}\)</span>, and the aerosol signal is proportional to between <span class="math inline">\(\lambda^{-2}\)</span> and <span class="math inline">\(\lambda^{+1}\)</span>, depending on the wavelength and particle size and shape.</p>
<p>Even if the aerosol returns decrease with increasing wavelength, the molecular background de- creases much faster, so that the aerosol-to-molecular backscatter ratio becomes more favorable to the measurement. Therefore, longer wavelengths are desirable to minimize the influence of molecular (Rayleigh) scattering. Coherent Doppler LIDARs use laser wavelengths between 1 and 11 mm.</p>
<h4 id="vector-wind-velocity-determination">Vector Wind Velocity Determination</h4>
<p>Vector wind measurements require radial velocity measurements from three independent “lines-of- sight” meaning you must have three LIDARs. If it can be assumed that there is no vertical velocity (W 1⁄4 0), then only two LIDARs are needed. If horizontal homogeneity of the wind field can be assumed, then a LIDAR beam scanning technique can be used to determine the wind velocity.</p>
<p>The two main techniques are the velocity azimuth display (VAD) which is a conical scan LIDAR beam at a fixed elevation angle, and the Doppler beam swinging (DBS) which is a LIDAR pointing in the vertical which is tilted east and tilted north. These two methods are graphically displayed in Fig. 3.35.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110140901580.png" alt="image-00030110140901580"><figcaption aria-hidden="true">image-00030110140901580</figcaption>
</figure>
<h5 id="velocity-azimuth-display-lidar-vector-wind-method">Velocity Azimuth Display LIDAR Vector Wind Method</h5>
<p>The VAD scheme is a conical scan LIDAR beam at a fixed elevation angle (Fig. 3.35). For a ground-based LIDAR, positive <span class="math inline">\(u,b,w\)</span> are are defined as the wind blowing toward the East, North, and upward, and the positive radial wind <span class="math inline">\(\vec{V}_R\)</span> as the wind blowing away from the LIDAR. <span class="math inline">\(\vec{V}_R\)</span> consists of the following <span class="math inline">\(u,v,w\)</span> components:</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110141442337.png" alt="image-00030110141442337"><figcaption aria-hidden="true">image-00030110141442337</figcaption>
</figure>
<p><span class="math inline">\(\theta\)</span> is the azimuth angle clockwise from the north, and <span class="math inline">\(\varphi\)</span> is the elevation angle.</p>
<p>For each VAD scan the elevation angle <span class="math inline">\(\varphi\)</span> is fixed and known, the azimuth angle <span class="math inline">\(\theta\)</span> is varied, but is also known. <span class="math inline">\(\vec{V}_R\)</span> is measured so the three unknowns u, v and w can be derived directly from fitting the data with the above Eq. (3.15).</p>
<h5 id="doppler-beam-swinging-lidar-vector-wind-method">Doppler Beam Swinging LIDAR Vector Wind Method</h5>
<p>The DBS technique consists of pointing a LIDAR in the vertical up, and then tilting it east and north</p>
<p>If <span class="math inline">\(\gamma\)</span> is the off-zenith angle , then:</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110142318552.png" alt="image-00030110142318552"><figcaption aria-hidden="true">image-00030110142318552</figcaption>
</figure>
<p>Then:</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110142347164.png" alt="image-00030110142347164"><figcaption aria-hidden="true">image-00030110142347164</figcaption>
</figure>
<p>Where <span class="math inline">\(V_{Rz},V_{RE},V_{RN}\)</span> are the vertical, tilted east, and tilted north radial velocities, respectively.</p>
<h5 id="direct-detection-doppler-wind-lidar">Direct Detection Doppler Wind LIDAR</h5>
<p>Direct Detection Doppler (DDL) uses incoherent detection to measure the spectrum of returned sig-nals. DDL can use aerosol/molecular scattering and/or resonance fluorescence to measure the wind from the ground to the upper atmosphere. There are several different ways to do the spectral analysis for the DDL method:</p>
<ul>
<li>Resonance fluorescence Doppler LIDAR uses the atmospheric atomic or molecular absorption lines as the frequency analyzer/discriminator.</li>
<li>Direct detection Doppler LIDAR is based on molecular absorption edge filter, e.g., iodine (I2) vapor filter, Na or K magnetooptic filter.</li>
<li>Direct detection Doppler LIDAR is based on optical interferometer edge-filter, e.g., FabryePerot etalon transmission edge.</li>
<li>Direct detection Doppler LIDAR is based on fringe patter imaging of an optical interferometer, e.g., FPI imaging.</li>
</ul>
<h5 id="lidar-wind-summary">LIDAR Wind Summary</h5>
<p>Doppler wind techniques measure the wind velocity along the LIDAR beam requiring three independent radial velocity measurements from three independent lines of sight.</p>
<p>Rather than point three different LIDARs in three different directions, we assume horizontal homogeneity of the wind field over the volume we are sensing and employ scanning LIDAR techniques to determine the vector wind.</p>
<p>The two main scanning techniques are the VAD and the DBS methods. There are different wavelength requirements for coherent and incoherent detection LIDARs.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110143939300.png" alt="image-00030110143939300"><figcaption aria-hidden="true">image-00030110143939300</figcaption>
</figure>
<p>Fig. 3.37 shows a commercial buoy carrying a VAD wind LIDAR (principles of operation explained below) to measure wind profiles up to 200 m height to optimize the selection of offshore aerogenerators</p>
<p>An example of a spaceborne wind LIDAR is the upcoming ESA ADM-Aeolus that will be launched in 2017 and will provide for the first time global observation of wind profiles from space to further our knowledge of Earth’s atmosphere and weather systems. Aeolus carries a single payload, the atmospheric laser Doppler instrument (ALADIN), a direct detection Doppler wind LIDAR operating at near UV wavelengths (355 nm).</p>
<p>It comprises two main assemblies: (1) Transmitter: diode lasere pumped Nd:YAG laser, frequency tripled to 355 nm at 150 mJ pulse energy, 100 Hz pulse repetition and (2) Receiver: 1.5 m diameter SiC telescope, Mie channel (aerosol and water droplets) with Fizeau spectrometer, Rayleigh channel (molecular scattering). Fig. 3.38 shows an artist’s view of the satellite ADM-Aeolus and its different subsystems.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030110144044613.png" alt="image-00030110144044613"><figcaption aria-hidden="true">image-00030110144044613</figcaption>
</figure>
<h1 id="effects-of-forward-models-on-the-semi-analytical-retrieval-of-inherent-optical-properties-from-remote-sensing-reflectance">Effects of forward models on the semi-analytical retrieval of inherent optical properties from remote sensing reflectance</h1>
<p>Six FMs</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030114135629507.png" alt="image-00030114135629507"><figcaption aria-hidden="true">image-00030114135629507</figcaption>
</figure>
<p>Result for Rrs</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030114143116363.png" alt="image-00030114143116363"><figcaption aria-hidden="true">image-00030114143116363</figcaption>
</figure>
<p>I think in the coastal area, G88 works best, briefly.</p>
<p>Result for inversion</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030114163438001.png" alt="image-00030114163438001"><figcaption aria-hidden="true">image-00030114163438001</figcaption>
</figure>
<p>This is just total absorption, I think.</p>
<p>For descriptive purposes, the results from QAA with the six FMs are denoted as QG88, QJ96, QM02, QA03, QL04, and QP05, and their retrievals are termed aQAA_FM and bb_QAA_FM, respectively.</p>
<p>Fucking these abbreviations.</p>
<p>L04 works best. J96 P05 G88 are similar.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115104711298.png" alt="image-00030115104711298"><figcaption aria-hidden="true">image-00030115104711298</figcaption>
</figure>
<p>For bbp, J96 works best. L04 worst.</p>
<p>终于懂了那个看论文只需要看图到底是啥意思。</p>
<p>The results showed that different FMs can have quite different effects on the computed Rrs?λ?, and, in particular, the effects are not necessarily uni- form. For this synthetic data set and for the six FMs evalu- ated, G88 and P05 provided the best estimates of Rrs?λ? for the given IOPs at 350, 440, and 550 nm. Additionally, G88 and P05 performed similarly in both the oceanic and coastal conditions, and were relatively weakly influenced by the change in particle PF. M02 also provided good estimation but only at 440 nm, and L04 performed well only in the oceanic condition.</p>
<p>In the coastal sub-dataset, QAA and GIOP combined with G88 or P05 provided slightly better quality IOPs compared with the other four FMs. Compared with GIOP in the coastal condition, QAA in the coastal con- dition combined with G88 or P05 always performed better at retrieving a?λ? but was weaker at retrieving bbp?λ?. It must be noted that only effective retrievals from each FM-GIOP were considered for comparison; about 18%–25% of retrievals from GIOP were filtered out in advance due to bad performance.</p>
<h1 id="water-classification-combined-inversionretrieval">Water Classification Combined Inversion/Retrieval</h1>
<p>A hybrid algorithm for estimating the chlorophyll-<em>a</em> concentration across different trophic states in Asian inland waters</p>
<p>Optical water type discrimination and tuning remote sensing band-ratio algorithms: application to retrieval of chlorophyll and kd (490) in the Irish and Celtic seas</p>
<p>Influence of a red band-based water classification approach on chlorophyll algorithms for optically complex estuaries</p>
<p>A soft-classification-based chlorophyll-a estimation method using MERIS data in the highly turbid and eutrophic Taihu Lake</p>
<p>A system to measure the data quality of spectral remote-sensing reflectance of aquatic environments</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Optics</tag>
        <tag>Remote Sensing</tag>
        <tag>Book Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>MODIS水色数据处理教程</title>
    <url>/posts/ce08f3a2.html</url>
    <content><![CDATA[<p>这个教程主要分为两部分：</p>
<ol>
<li>应用python分析MODIS水色遥感数据</li>
<li>SeaDAS OCSSW的安装与应用</li>
</ol>
<p>2021.8.12更新SNAP相关</p>
<p>（最近来看这篇文章的小伙伴好多，可以跟我打个招呼让我认识一下同行么哈哈。</p>
<p>邮箱zhenjiazhou0127@outlook.com，任何问题都可以，欢迎交流）</p>
<a id="more"></a>
<h1 id="应用python分析modis水色遥感数据"><a class="markdownIt-Anchor" href="#应用python分析modis水色遥感数据"></a> 应用python分析MODIS水色遥感数据</h1>
<h2 id="程序包及工作环境"><a class="markdownIt-Anchor" href="#程序包及工作环境"></a> 程序包及工作环境</h2>
<p>如果这个步骤你花了很久才搞定的话，去用R吧，我朋友想跟我学python的都让我劝退学R了。</p>
<h3 id="anaconda和-pycharm"><a class="markdownIt-Anchor" href="#anaconda和-pycharm"></a> Anaconda和 pycharm</h3>
<p>Anaconda里涵盖了很多科学计算要用到的包，同时也给了一个很好用的包管理工具。下载地址https://www.anaconda.com/；如果在国内的话，推荐使用清华镜像进行下载https://mirror.tuna.tsinghua.edu.cn/help/anaconda/，然后再更换为国内源https://www.cnblogs.com/yikemogutou/p/11396045.html。</p>
<p>下载完anaconda之后，打开anaconda navigator把Jupyter notebook(或者Jupyter lab)安装好，我个人通常会用这个用一张遥感数据进行程序的调试，然后在pycharm里改成批处理。</p>
<p>pycharm是一个编辑器，同时支持python,R和markdown。对于本菜鸡来说，这个编辑器可以很方便的打开Terminal和python console，添加TODO和利用git备份，最重要的是管理环境方便，不用每次都active啥啥啥。下载地址https://www.jetbrains.com/pycharm/。</p>
<h3 id="环境创建"><a class="markdownIt-Anchor" href="#环境创建"></a> 环境创建</h3>
<h4 id="地理信息数据分析环境"><a class="markdownIt-Anchor" href="#地理信息数据分析环境"></a> 地理信息数据分析环境</h4>
<p>打开pycharm，新建一个项目或者打开你之前的项目，然后preference-project interpreter-show all，右下角小加号添加一个python interpreter，选择Conda Environment，用你刚刚安装好的anaconda来创建一个新的环境。</p>
<p>结束之后回到编辑器界面，最下面有四个选项 TODO,Version Control,Terminal,Python Console。这四个东西和刚才那个project interpreter基本是我平时比较喜欢用pycharm的最主要原因了。在写程序时#TODO然后写上要做的事情，就可以在下面TODO页面里看到要做的东西;Version Control 可以提供本地或者github的版本控制，具体设置方法可以参考https://www.jetbrains.com/help/pycharm/manage-projects-hosted-on-github.html；Terminal其实就是一个bash，并且是在你刚才创建的环境里面，不需要去确认环境啥的，也不用添加全局变量，就相当于一个anaconda prompt; python console就相当于一个命令行的python，在右上角绿色小三角附近点下拉菜单Edit configuration，然后选择run in python console，就可以在右边框里看到变量，比较适合我这种从matlab迁移过来的人。</p>
<p>先打开Terminal，依次运行</p>
<p><code>conda install -c conda-forge numpy h5py netcd4 opencv-python requests matplotlib pandas scipy scikit-learn</code></p>
<p><code>conda update -all</code></p>
<p>在这里一般不会出问题，-c conda-forge可以安装由大佬在开源社区里上传的程序包</p>
<p><code>conda install -c conda-forge pyresample</code></p>
<p>这里可能会遇到问题，这里有可能有两种问题，一个是C语言编译器的问题，下载安装Microsoft Visual Studio Community 2017然后再运行一下这句话就好了；另一种就是GDAL的问题。</p>
<p>GDAL(Geospatial Data Abstraction Library)是一个在X/MIT许可协议下的开源栅格空间数据转换库，可以参考大佬翻译的这份中文教程https://www.osgeo.cn/python_gdal_utah_tutorial/index.html来学习一下。之前电脑上没有安装过python相关的东西的话一般不会遇到这个问题。如果你是在windows平台，那么我推荐你来安装OSGeo4W来搞定这个问题https://trac.osgeo.org/osgeo4w/；除此之外，还有两种方法，一个是你重新搞个环境，不要加入之前的包再来安装一次，另一个是下载whl文件来安装。</p>
<p>记得每次装完新的都来个conda update -all。</p>
<p>最后</p>
<p><code>conda install -c conda-forge basemap basemape-data-hires</code></p>
<p><code>conda install -c conda-forge gdal</code></p>
<p><code>conda update -all</code></p>
<p>如果一切顺利，恭喜你完成了最麻烦的一步。</p>
<p>之后可以参照我之前写过的这篇文章里面的python包，<a href="https://lifeodyssey.github.io/post/3aa0ed1a.html">https://lifeodyssey.github.io/post/3aa0ed1a.html</a> ,这些包都安装之后基本够用了。</p>
<p>其实环境这个问题可以用Docker来解决，之前有看到过这个大佬https://zhuanlan.zhihu.com/p/108012664的文章，我也还在研究，争取尽快搞出来一个水色人的Docker。</p>
<h4 id="pycharm及jupyter插件"><a class="markdownIt-Anchor" href="#pycharm及jupyter插件"></a> pycharm及Jupyter插件</h4>
<p>这个是属于个人喜好。</p>
<p>在pycharm-preference-plugins里可以安装插件，我安装了.*ignore,Dart,Kite和Material Theme UI，因为我有的时候还会用R，虽然R studio更好用，但是我也装了R Language for IntelliJ这个，来进行一些小的调试。</p>
<p>Jupyter个人一般只用来学习新的知识、调试和改bug，或者用来教别人的时候用，所以我这里用的还是Jupyter notebook,没有升级到Jupyterlab，安装教程可见https://github.com/ipython-contrib/jupyter_contrib_nbextensions。</p>
<p>在Terminal里依次输入</p>
<p><code>conda install -c conda-forge jupyter_contrib_nbextensions</code></p>
<p><code>jupyter contrib nbextension install --user</code></p>
<p><code>conda update -all</code></p>
<p>然后在Terminal里输入</p>
<p><code>Jupyter notebook</code></p>
<p>就可以看到浏览器里蹦出来一个Jupyter notebook</p>
<p>点开Configurable nbextensions中勾选variable inspector，然后随便新建一个notebook，点开那个小瞄准镜就可以看到变量了。我平时没事就只用这个了。</p>
<h2 id="modis-数据读取-重投影及绘图"><a class="markdownIt-Anchor" href="#modis-数据读取-重投影及绘图"></a> MODIS 数据读取、重投影及绘图</h2>
<p>数据的下载可以参考https://lifeodyssey.github.io/post/8636bca2.html</p>
<p>直接上我写的代码，造福千万家，但是希望你直接用的时候能够知其然也知其所以然。感谢实验室之前毕业的前辈给我提供的代码样本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> netCDF4 <span class="keyword">as</span> nc4</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> geo_Collection <span class="keyword">import</span> geo_web <span class="keyword">as</span> gs</span><br><span class="line"><span class="keyword">from</span> QAAV6 <span class="keyword">import</span> QAAv6</span><br><span class="line">minlat = <span class="number">32.5</span></span><br><span class="line">minlon = <span class="number">130.5</span></span><br><span class="line">maxlat = <span class="number">35</span></span><br><span class="line">maxlon = <span class="number">136</span></span><br><span class="line"><span class="comment"># area of full seto-inland sea</span></span><br><span class="line">x = np.arange(minlon, maxlon, <span class="number">0.01</span>)  <span class="comment"># 1 km grid,</span></span><br><span class="line">y = np.arange(maxlat, minlat, <span class="number">-0.01</span>)</span><br><span class="line">nc_file = nc4.Dataset(filename, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">lon = nc_file.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;longitude&#x27;</span>][:]</span><br><span class="line">lat = nc_file.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;latitude&#x27;</span>][:]</span><br><span class="line">variables = nc_file.groups[<span class="string">&#x27;geophysical_data&#x27;</span>].variables</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> variables:</span><br><span class="line">    var = variables[i][:]</span><br><span class="line">    np.where(var &lt;= <span class="number">0</span>, var, np.nan)</span><br><span class="line">    <span class="keyword">if</span> i != <span class="string">&#x27;l2_flags&#x27;</span>:</span><br><span class="line">        var_re, grid = gs.swath_resampling(var, lon, lat, x, y, <span class="number">5000</span>)  <span class="comment"># 1 km grid</span></span><br><span class="line">        <span class="comment"># var_re=var_re.filled()</span></span><br><span class="line">        <span class="keyword">if</span> np.ma.is_mask(var_re):</span><br><span class="line">            var_re.mask=np.ma.nomask</span><br><span class="line">            var_re[var_re==<span class="number">-32767.0</span>]=np.nan</span><br><span class="line">         variables[i] = var_re</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># var_re = var_re.filled()</span></span><br><span class="line">          variables[i] = var</span><br><span class="line">lons = grid.lons</span><br><span class="line">lats = grid.lats</span><br><span class="line"><span class="comment">#以叶绿素为例</span></span><br><span class="line">chl = variables[<span class="string">&#x27;chlor_a&#x27;</span>]</span><br><span class="line">plot_geo_image(chl, lon, lat, label=<span class="string">&#x27;CHL [mg/m$^3$]&#x27;</span>,</span><br><span class="line">               title=os.path.basename(file))</span><br><span class="line">ncfile.close()<span class="comment">#一定要记得这句</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>同时给出这里面用到的两个子函数和QAA的代码。</p>
<p>（QAA的代码还需要一些改进）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pyresample</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.basemap <span class="keyword">import</span> Basemap</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> colors</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> RectSphereBivariateSpline</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> LogNorm</span><br><span class="line"><span class="comment">#from  deco import *</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">swath_resampling</span>(<span class="params">src_data: np.ma.array, src_lon: np.array, src_lat: np.array,</span></span></span><br><span class="line"><span class="function"><span class="params">                     trg_lon: np.array, trg_lat: np.array, search_radius: float</span>):</span></span><br><span class="line">    <span class="keyword">if</span> len(trg_lon.shape) == <span class="number">1</span>:</span><br><span class="line">        grid_def = pyresample.geometry.SwathDefinition(*np.meshgrid(trg_lon, trg_lat))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        grid_def = pyresample.geometry.SwathDefinition(lons=trg_lon, lats=trg_lat)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#source grid with original swath data</span></span><br><span class="line">    <span class="comment"># if len(src_lon.shape) == 1:</span></span><br><span class="line">    <span class="comment">#     swath_def = pyresample.geometry.SwathDefinition(*np.meshgrid(src_lon, src_lat,sparse=True))</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment">#     swath_def = pyresample.geometry.SwathDefinition(lons=src_lon, lats=src_lat)</span></span><br><span class="line"></span><br><span class="line">    swath_def = pyresample.geometry.SwathDefinition(lons=src_lon, lats=src_lat)</span><br><span class="line">    <span class="comment"># resample (here we use nearest. Bilinear, gaussian and custom defined methods are available)</span></span><br><span class="line">    <span class="comment"># for more, visit https://pyresample.readthedocs.io/en/latest/</span></span><br><span class="line">    result = pyresample.kd_tree.resample_nearest(swath_def, src_data, grid_def, epsilon=<span class="number">0.5</span>,</span><br><span class="line">                                                 fill_value=np.nan, radius_of_influence=search_radius)</span><br><span class="line">    <span class="keyword">return</span> result, grid_def</span><br><span class="line"></span><br><span class="line"><span class="comment">#@concurrent</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_geo_image</span>(<span class="params">sds: np.ma.array, lon: np.ndarray, lat: np.ndarray, log10: bool = True, title: str = None,</span></span></span><br><span class="line"><span class="function"><span class="params">                   label: str = None,</span></span></span><br><span class="line"><span class="function"><span class="params">                   caxis: list = None, lon_range: list = None, lat_range: list = None, save_image: str = None,</span></span></span><br><span class="line"><span class="function"><span class="params">                   dpi: int = <span class="number">400</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> len(lon.shape) == <span class="number">1</span>:</span><br><span class="line">        print(<span class="string">&#x27;MeshGridding...&#x27;</span>)</span><br><span class="line">        lon, lat = np.meshgrid(lon, lat)</span><br><span class="line"></span><br><span class="line">    lon_0 = (lon.min() + lon.max()) / <span class="number">2</span></span><br><span class="line">    lat_0 = (lat.min() + lat.max()) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">f&#x27;Lat: [<span class="subst">&#123;lat.min():<span class="number">.3</span>f&#125;</span>, <span class="subst">&#123;lat.max():<span class="number">.3</span>f&#125;</span>] | &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Lon: [<span class="subst">&#123;lon.min():<span class="number">.3</span>f&#125;</span>, <span class="subst">&#123;lon.max():<span class="number">.3</span>f&#125;</span>] | &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;SDS: [<span class="subst">&#123;sds.min():<span class="number">.3</span>f&#125;</span>, <span class="subst">&#123;sds.max():<span class="number">.3</span>f&#125;</span>]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lon_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (lat_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">        m = Basemap(llcrnrlon=min(lon_range), llcrnrlat=min(lat_range),</span><br><span class="line">                    urcrnrlon=max(lon_range), urcrnrlat=max(lat_range),</span><br><span class="line">                    resolution=<span class="string">&#x27;f&#x27;</span>, lon_0=lon_0, lat_0=lat_0, projection=<span class="string">&#x27;tmerc&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        m = Basemap(llcrnrlon=lon.min(), llcrnrlat=lat.min(),</span><br><span class="line">                    urcrnrlon=lon.max(), urcrnrlat=lat.max(),</span><br><span class="line">                    resolution=<span class="string">&#x27;f&#x27;</span>, lon_0=lon_0, lat_0=lat_0, projection=<span class="string">&#x27;tmerc&#x27;</span>)</span><br><span class="line">    x2d, y2d = m(lon, lat)</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span> * m.aspect))</span><br><span class="line">    ax = fig.add_axes([<span class="number">0.08</span>, <span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.7</span>], facecolor=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">    <span class="comment"># changed to facecolor 8 October 2019</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lon_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (lat_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">        parallels = np.arange(min(lat_range), max(lat_range), <span class="number">3</span>)</span><br><span class="line">        meridians = np.arange(min(lon_range), max(lon_range), <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        parallels = meridians = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> caxis <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        cmn, cmx = min(caxis), max(caxis)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cmn, cmx = sds.min(), sds.max()</span><br><span class="line">    <span class="comment"># m.drawparallels(parallels, fontsize=10, linewidth=0.25, dashes=[7, 15],</span></span><br><span class="line">    <span class="comment">#                  color=&#x27;k&#x27;, labels=[1, 0, 1, 1])</span></span><br><span class="line">    <span class="comment"># m.drawmeridians(meridians, fontsize=10, dashes=[7, 15],</span></span><br><span class="line">    <span class="comment">#                  linewidth=0.3, color=&#x27;k&#x27;, labels=[1, 1, 0, 1])</span></span><br><span class="line">    <span class="comment">#ncl = 150</span></span><br><span class="line">    <span class="comment">#if log10 is True:</span></span><br><span class="line">    <span class="comment">#    norm = colors.LogNorm(vmin=cmn, vmax=cmx)</span></span><br><span class="line">    <span class="comment">#else:</span></span><br><span class="line">     <span class="comment">#   bounds = np.linspace(cmn, cmx, ncl)</span></span><br><span class="line">     <span class="comment">#   norm = colors.BoundaryNorm(boundaries=bounds, ncolors=ncl)</span></span><br><span class="line"></span><br><span class="line">    p = m.pcolor(x2d, y2d, sds, vmin=cmn,vmax=cmx, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># divider = make_axes_locatable(ax)</span></span><br><span class="line">    <span class="comment"># cax = divider.append_axes(&#x27;vertical&#x27;, size=&quot;3%&quot;, pad=0.05)</span></span><br><span class="line">    <span class="comment">#cax = plt.axes([cmn, 0, cmx])  # setup colorbar axes</span></span><br><span class="line"></span><br><span class="line">    cb = m.colorbar(p,location=<span class="string">&quot;right&quot;</span>,size=<span class="string">&quot;5%&quot;</span>,pad=<span class="number">0.1</span>)  <span class="comment"># draw colorbar</span></span><br><span class="line">    <span class="comment">#if label is not None:</span></span><br><span class="line">    <span class="comment"># cb.set_label(&quot;%s&quot; % label)</span></span><br><span class="line">    <span class="comment"># plt.sca(ax)  # make the original axes current again</span></span><br><span class="line">    <span class="comment"># plt.clim(cmn, cmx)</span></span><br><span class="line">    <span class="comment">#unit=&#x27;Elevation to the sea level&#x27;</span></span><br><span class="line">    <span class="comment">#cb.set_label(unit, rotation=270, labelpad=10.0, fontsize=10)</span></span><br><span class="line">    cb.ax.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    m.drawcoastlines()</span><br><span class="line">    m.drawcountries()</span><br><span class="line">    m.fillcontinents()</span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> save_image <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.savefig(save_image, dpi=dpi, facecolor=<span class="string">&#x27;w&#x27;</span>, edgecolor=<span class="string">&#x27;w&#x27;</span>, orientation=<span class="string">&#x27;portrait&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        plt.close()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creategrid</span>(<span class="params">min_lon, max_lon, min_lat, max_lat, cell_size_deg, mesh=False</span>):</span></span><br><span class="line"><span class="comment">#Output grid within geobounds and specifice cell size</span></span><br><span class="line"><span class="comment">#cell_size_deg should be in decimal degrees’’’</span></span><br><span class="line"></span><br><span class="line">    min_lon = math.floor(min_lon)</span><br><span class="line">    max_lon = math.ceil(max_lon)</span><br><span class="line">    min_lat = math.floor(min_lat)</span><br><span class="line">    max_lat = math.ceil(max_lat)</span><br><span class="line">    lon_num = (max_lon - min_lon)/cell_size_deg</span><br><span class="line">    lat_num = (max_lat - min_lat)/cell_size_deg</span><br><span class="line">    grid_lons = np.zeros(lon_num) <span class="comment"># fill with lon_min</span></span><br><span class="line">    grid_lats = np.zeros(lat_num) <span class="comment"># fill with lon_max</span></span><br><span class="line">    grid_lons = grid_lons + (np.assary(range(lon_num))*cell_size_deg)</span><br><span class="line">    grid_lats = grid_lats + (np.assary(range(lat_num))*cell_size_deg)</span><br><span class="line">    grid_lons, grid_lats = np.meshgrid(grid_lons, grid_lats)</span><br><span class="line">    grid_lons = np.ravel(grid_lons)</span><br><span class="line">    grid_lats = np.ravel(grid_lats)</span><br><span class="line">    <span class="comment">#if mesh = True:</span></span><br><span class="line">    <span class="comment"># grid_lons = grid_lons</span></span><br><span class="line">    <span class="comment"># grid_lats = grid_lats</span></span><br><span class="line">    <span class="keyword">return</span> grid_lons, grid_lats</span><br></pre></td></tr></table></figure>
<p>QAAv6</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> Akima1DInterpolator <span class="keyword">as</span> Akima</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> deco <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> math <span class="keyword">as</span> m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># wavelengths = &#123;</span></span><br><span class="line"><span class="comment">#     &#x27;OLI&#x27;   : [442.98, 482.49, 561.33, 654.61],</span></span><br><span class="line"><span class="comment">#     &#x27;MSI&#x27;   : [443.93, 496.54, 560.01, 664.45],</span></span><br><span class="line"><span class="comment">#     &#x27;OLCI&#x27;  : [411.3999939, 442.63000488, 490.07998657, 510.07000732, 560.05999756, 619.97998047, 664.85998535, 673.61999512, 681.15002441], # 9 band insitu</span></span><br><span class="line"><span class="comment">#     &#x27;OLCI2&#x27; : [400, 412.5, 442.5, 490, 510, 560, 620, 665, 673.75, 681.25, 708.75, 753.75, 761.25, 764.375, 767.5, 778.75], # 16 band LUT</span></span><br><span class="line"><span class="comment">#     &#x27;VI&#x27;    : [412.49, 444.17, 486.81, 549.99, 670.01],</span></span><br><span class="line"><span class="comment">#     &#x27;AER&#x27;   : [412, 442, 490, 530, 551, 668],</span></span><br><span class="line"><span class="comment">#     &#x27;MOSIA&#x27; : [412, 443, 469,488,531,547,555,645,667,678],</span></span><br><span class="line"><span class="comment">#     &#x27;GOCI&#x27;  : [412, 443, 490, 555, 660, 680],</span></span><br><span class="line"><span class="comment">#     &#x27;SGLI&#x27;  : [380,412,443,490,530,565,673.5]</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"><span class="comment">#@concurrent</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">QAAv6</span>(<span class="params">Rrs</span>):</span></span><br><span class="line">    <span class="comment">#acording to Lee,QAAv6</span></span><br><span class="line">    <span class="comment">#write by Zhou,20191130</span></span><br><span class="line">    <span class="comment">#Input data need to be an arrary that contain 10 bands Rrs of MODIS,from short wavelength to long wavelength in a certain station</span></span><br><span class="line">    <span class="comment">#Output is a tuple, first array is aph,second array is bbp</span></span><br><span class="line">    <span class="comment">#use as import QAAV6</span></span><br><span class="line"><span class="comment"># B1: 412 nm 0</span></span><br><span class="line"><span class="comment"># B2: 443 nm 1</span></span><br><span class="line"><span class="comment"># B3: 469 nm 2</span></span><br><span class="line"><span class="comment"># B4: 488 nm 3</span></span><br><span class="line"><span class="comment"># B5: 531 nm 4</span></span><br><span class="line"><span class="comment"># B6: 547 nm 5</span></span><br><span class="line"><span class="comment"># B7: 555 nm 6</span></span><br><span class="line"><span class="comment"># B8: 645 nm 7</span></span><br><span class="line"><span class="comment"># B9: 667 nm 8</span></span><br><span class="line"><span class="comment"># B10: 678 nm 9</span></span><br><span class="line"></span><br><span class="line">    Lambda=np.array([<span class="number">412</span>, <span class="number">443</span>, <span class="number">469</span>,<span class="number">488</span>,<span class="number">531</span>,<span class="number">547</span>,<span class="number">555</span>,<span class="number">645</span>,<span class="number">667</span>,<span class="number">678</span>])</span><br><span class="line">    nbands=np.shape(Lambda)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    IOPw=np.array([[<span class="number">0.003344468</span>,<span class="number">0.004572564</span>],</span><br><span class="line">    [<span class="number">0.00244466</span>,<span class="number">0.00635</span>],</span><br><span class="line">    [<span class="number">0.001910803</span>,<span class="number">0.010483637</span>],</span><br><span class="line">    [<span class="number">0.001609567</span>,<span class="number">0.014361745</span>],</span><br><span class="line">    [<span class="number">0.00111757</span>,<span class="number">0.043747657</span>],</span><br><span class="line">    [<span class="number">0.000983055</span>,<span class="number">0.053262848</span>],</span><br><span class="line">    [<span class="number">0.000923288</span>,<span class="number">0.0595</span>],</span><br><span class="line">    [<span class="number">0.000482375</span>,<span class="number">0.325</span>],</span><br><span class="line">    [<span class="number">0.00041731</span>,<span class="number">0.433497423</span>],</span><br><span class="line">    [<span class="number">0.00038884</span>,<span class="number">0.457440162</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#     if(Rrs=np.nan):</span></span><br><span class="line">    <span class="comment">#     return np.nan</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment"># bbw from Morel (1974).aw  from Pope and Fry (1997)</span></span><br><span class="line">    bbp = np.ones(<span class="number">10</span>)</span><br><span class="line">    adg = np.ones(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">if</span>(np.nan <span class="keyword">in</span> Rrs):</span><br><span class="line">        bbp[:]=np.nan</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bw=IOPw[:,<span class="number">0</span>]<span class="comment">#backscaterring of pure water</span></span><br><span class="line">        aw=IOPw[:,<span class="number">1</span>]<span class="comment">#absorption of pure water</span></span><br><span class="line">        rrs = Rrs / (<span class="number">0.52</span> + <span class="number">1.7</span> * Rrs)</span><br><span class="line">        g0 = <span class="number">0.089</span></span><br><span class="line">        g1 = <span class="number">0.1245</span></span><br><span class="line">        u = (-g0 + ((g0 ** <span class="number">2</span>) + <span class="number">4</span> * g1 * rrs) ** <span class="number">0.5</span>) / (<span class="number">2</span> * g1)</span><br><span class="line"></span><br><span class="line">        aph = np.ones(<span class="number">10</span>)<span class="comment">#adg is the absorption of CDOM and NAP</span></span><br><span class="line">        <span class="keyword">if</span> Rrs[<span class="number">6</span>]&lt;<span class="number">0.0015</span>:<span class="comment">#select 555 as reference</span></span><br><span class="line">            r=<span class="number">550</span></span><br><span class="line">            p1=(rrs[<span class="number">1</span>] + rrs[<span class="number">3</span>])</span><br><span class="line">            p2 = rrs[<span class="number">6</span>] + <span class="number">5</span> * (((rrs[<span class="number">8</span>]) ** <span class="number">2</span>)) / (rrs[<span class="number">3</span>])</span><br><span class="line">            x = np.log10(p1 / p2)</span><br><span class="line">            ar = aw[<span class="number">6</span>] + np.power(<span class="number">10</span>, (<span class="number">-1.146</span> - <span class="number">1.366</span> * x - <span class="number">0.469</span> * (x ** <span class="number">2</span>)))<span class="comment"># step 2</span></span><br><span class="line">            bbpr=((u[<span class="number">6</span>]*ar)/(<span class="number">1</span>-u[<span class="number">6</span>]))-bw[<span class="number">6</span>]<span class="comment">#step3</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r=<span class="number">670</span></span><br><span class="line">            p1 = Rrs[<span class="number">8</span>] / (Rrs[<span class="number">1</span>] + Rrs[<span class="number">3</span>])</span><br><span class="line">            p2 = <span class="number">0.39</span> * (p1 ** <span class="number">1.14</span>)</span><br><span class="line">            ar = (aw[<span class="number">8</span>]) + p2  <span class="comment"># step2</span></span><br><span class="line">            bbpr = (u[<span class="number">8</span>] * ar / (<span class="number">1</span> - (u[<span class="number">8</span>])) - (bw[<span class="number">8</span>]))  <span class="comment"># step3</span></span><br><span class="line">        eta=<span class="number">2</span>*(<span class="number">1</span><span class="number">-1.2</span>*np.exp(<span class="number">-0.9</span>*(rrs[<span class="number">1</span>]/rrs[<span class="number">6</span>]))) <span class="comment">#step4</span></span><br><span class="line"></span><br><span class="line">        zeta = <span class="number">0.74</span> + <span class="number">0.2</span> / (<span class="number">0.8</span> + rrs[<span class="number">1</span>] / rrs[<span class="number">6</span>])<span class="comment">#step 7&amp;8</span></span><br><span class="line">        S = <span class="number">0.015</span> + <span class="number">0.002</span> / (<span class="number">0.6</span> + rrs[<span class="number">1</span>] / rrs[<span class="number">6</span>])</span><br><span class="line">        xi = np.exp(S * (<span class="number">442.5</span> - <span class="number">415.5</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(nbands):</span><br><span class="line">            bbp[i]= bbpr * np.power(r/Lambda[i], eta)<span class="comment">#step5</span></span><br><span class="line">        a = ((<span class="number">1</span> - u) * (bw + bbp)) / u<span class="comment">#step6</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(nbands):</span><br><span class="line"></span><br><span class="line">            ag443=((a[<span class="number">0</span>]-zeta*a[<span class="number">1</span>])/(xi-zeta))-((aw[<span class="number">0</span>]-zeta*aw[<span class="number">1</span>])/(xi-zeta))</span><br><span class="line">            adg[i]=ag443*np.exp(-S*(Lambda[i]<span class="number">-443</span>))</span><br><span class="line">            aph[i]=a[i]-adg[i]-aw[i]</span><br><span class="line">        <span class="keyword">return</span> bbp,a</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>QAA的代码还需要很多的改进，目前正在参考https://github.com/BrandonSmithJ/band-adjustment进行改进，欢迎同行交流。</p>
<h2 id="程序加速"><a class="markdownIt-Anchor" href="#程序加速"></a> 程序加速</h2>
<p>因为python自己的问题，如果你要处理大量遥感图像的话会很慢，这个一方面是matplotlib自己出图慢，另一方面是因为没有充分利用多核cpu。</p>
<p>批量出图可以参考https://cloud.tencent.com/developer/article/1584962 这篇文章。</p>
<p>解决多核cpu最好用的方法是并行。</p>
<p>像上面那个程序，用并行来加速的话可以这么写：</p>
<ol>
<li>把它改写成一个函数，一般是把文件名作为输入，或者是文件在datalist之中的顺序，我用的是后面这种。</li>
<li>a1=np.arange(len(datalist))，创建一个list，并行的时候传入的变量只能是list</li>
<li>将代码改写成如下样子</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>()</span></span><br><span class="line"><span class="function">#这里是你刚才改写的程序</span></span><br><span class="line">pool=mp.Pool(processes=7)#电脑8核，给自己空余了一个核用来处理其他任务</span><br><span class="line">pool.map(main,a1)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以先不做并行查看内存占用情况，如果有很多内存没用的话，开了并行一般都会提速，我的程序需要处理140张卫星图像，缩短到原来的1/3左右。</p>
<h1 id="seadas-ocssw的安装与应用"><a class="markdownIt-Anchor" href="#seadas-ocssw的安装与应用"></a> SeaDAS OCSSW的安装与应用</h1>
<p>SeaDAS是NASA出品的一个水色遥感处理软件，其中的OCSSW更是内置了很多美国发射的卫星的标准处理流程算法（欧洲的那几个用的SNAP，韩国的GOCI用的GDPS，日本的SGLI，也许哪天我用OLCI数据的时候会把SNAP的教程搞一下），我主要是用他的l2gen这个功能。OCSSW只能在Linux或者Mac OS系统下安装。下载地址https://seadas.gsfc.nasa.gov/，这里讲Linux系统下的安装方法，我用的是Ubuntu 18.04LTS.</p>
<h2 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h2>
<p>如果你像我一样肉身翻墙的话，那恭喜你真的是非常方便了。</p>
<h3 id="seadas-安装"><a class="markdownIt-Anchor" href="#seadas-安装"></a> SeaDAS 安装</h3>
<p>NASA官方的tutorial在https://seadas.gsfc.nasa.gov/tutorials/installation_tutorial/</p>
<p>基本按照这个来就可以了，除了Java版本，我第一次装的时候用的是最新版Java，结果SeaDAS无法作为一个独立程序运行（就是在程序页面里找不到这个程序的图标？启动器？本Ubuntu菜鸡虚心求教），最后按照如下方法安装了Java8:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:ts.sch.gr/ppa </span><br><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get install oracle-java8-installer</span><br></pre></td></tr></table></figure>
<h3 id="ocssw安装"><a class="markdownIt-Anchor" href="#ocssw安装"></a> OCSSW安装</h3>
<h4 id="python环境设置"><a class="markdownIt-Anchor" href="#python环境设置"></a> Python环境设置</h4>
<p>我们一般现在用来干活的python一般都是3版本的，但是Ubuntu系统内置的python是2版本，SeaDAS OCSSW会使用默认的内置版本，所以在这里需要搞定一些程序库的问题（如果没搞好的话后面一般会显示你没有requests这个包）。</p>
<p>这时候就用到我刚才安装的Pycharm来手动管理了，打开pycharm-preference-Project Interpreter,如果你没有装别的东西的话，你的电脑里应该就只有几个python的解释器，你刚才通过anacoonda安装的是3版本，在Add Python Interpreter里面，系统自带的解释器一般会在Pipenv、System或者Virtualenv这里找到，通过路径判断出来哪个是系统自带的，创建一个新环境，然后在Terminal里安装requests这个包就可以了</p>
<h4 id="安装-2"><a class="markdownIt-Anchor" href="#安装-2"></a> 安装</h4>
<p>完成这一步之后，如果你肉身翻墙或者依靠金钱的力量翻墙的话，就可以在GUI里面手动点选安装了；如果在国内，可以按照刚才放的官方的页面，把每个Bundle都下载下来离线安装。</p>
<h2 id="应用"><a class="markdownIt-Anchor" href="#应用"></a> 应用</h2>
<p>我这里主要用的是l2gen这个函数，这里放一个在seadas forum找到然后自己修改的脚本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># source /Users/zhenjia/.bash_profile </span></span><br><span class="line"><span class="comment">#先运行上面这个文件来搞定全局变量</span></span><br><span class="line"><span class="comment">#Example script to process L1A files up to L2, put in same directory as </span></span><br><span class="line"><span class="comment"># your L1A files</span></span><br><span class="line"><span class="comment"># Run script by typing on Terminal Command Line: </span></span><br><span class="line"><span class="comment"># bash l1a_to_l2.sh input.txt</span></span><br><span class="line"><span class="comment"># input.txt contains list of files [ create by: ls -1 *L1A_LAC* &gt; input.txt ]</span></span><br><span class="line"></span><br><span class="line">LIST=<span class="variable">$1</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$LIST</span>&quot;</span> ]</span><br><span class="line">  <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;No input file list supplied&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ ! -a <span class="variable">$LIST</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$LIST</span> does not exist!&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">mkdir -p <span class="keyword">done</span></span><br><span class="line">mkdir -p l2_lac</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> FILE <span class="keyword">in</span> $(cat <span class="variable">$LIST</span>);</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Working on <span class="variable">$FILE</span>&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;FILE&#125;</span></span><br><span class="line">    <span class="comment"># get file basename (no file extension)</span></span><br><span class="line">    BASE=`basename <span class="variable">$FILE</span> .L1A_LAC.x.hdf`</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;BASE&#125;</span></span><br><span class="line">    GEOFILE=<span class="variable">$&#123;BASE&#125;</span>.GEO</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;GEOFILE&#125;</span></span><br><span class="line">    L1BFILE=<span class="variable">$&#123;BASE&#125;</span>.L1B_LAC.x.hdf</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;L1BFILE&#125;</span></span><br><span class="line">    L2FILE=<span class="variable">$&#123;BASE&#125;</span>.L2_LAC.x.hdf</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;L2FILE&#125;</span></span><br><span class="line">    ancfile=<span class="variable">$&#123;BASE&#125;</span>.L1A_LAC.x.hdf.anc</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Creating GEOFILE <span class="variable">$GEOFILE</span>&quot;</span></span><br><span class="line">    modis_GEO.py -v <span class="variable">$FILE</span> -o <span class="variable">$GEOFILE</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Creating L1B file&quot;</span></span><br><span class="line">    modis_L1B.py -v <span class="variable">$FILE</span> <span class="variable">$GEOFILE</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Creating anc file&quot;</span></span><br><span class="line">    getanc.py -v <span class="variable">$FILE</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Create L2 file&quot;</span></span><br><span class="line">    l2gen ifile=<span class="variable">$L1BFILE</span> geofile=<span class="variable">$GEOFILE</span> ofile=<span class="variable">$L2FILE</span> par=<span class="variable">$ancfile</span> l2prod=<span class="string">&quot;Kd_490 Rrs_nnn angstrom aot_869 chlor_a ipar nLw_nnn nflh par pic poc rhos_nnn&quot;</span> aer_opt=-2</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Cleaning up&quot;</span></span><br><span class="line">    rm -v <span class="variable">$&#123;BASE&#125;</span>.L1B* <span class="variable">$GEOFILE</span> <span class="variable">$ancfile</span></span><br><span class="line">    <span class="comment">#mv -v $FILE done/</span></span><br><span class="line">    mv -v <span class="variable">$L2FILE</span> l2_lac/</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="snap"><a class="markdownIt-Anchor" href="#snap"></a> SNAP</h1>
<p>最近ESA的SNAP宣布了对SeaDAS OCSSW的支持，这个不需要搞Linux系统啥的了，用起来方便很多。</p>
<p>下载地址：<span class="exturl" data-url="aHR0cHM6Ly9zdGVwLmVzYS5pbnQvbWFpbi9kb3dubG9hZC9zbmFwLWRvd25sb2FkLw==">https://step.esa.int/main/download/snap-download/<i class="fa fa-external-link-alt"></i></span></p>
<p>下载安装之后在<span class="exturl" data-url="aHR0cHM6Ly9zZWFkYXMuZ3NmYy5uYXNhLmdvdi9pbnN0YWxsZXJzL3NuYXAtc2VhZGFzLXRvb2xib3gv">这里<i class="fa fa-external-link-alt"></i></span>下载SeaDAS的插件。然后打开SNAP，打开Plugin Manager，在菜单中依次选择Tools --&gt; Plugins–&gt;Downloaded–&gt; Add Plugins，定位到你解压好的插件的位置，选择好之后点Open，然后Install-&gt;finish即可。</p>
<p>顺带一提，SNAP还支持最近几个比较新的大气校正和IOP反演的算法插件，比如<span class="exturl" data-url="aHR0cDovL3d3dy5ydGF0bW9jbi5jb20vb2Mtc21hcnQv">OC-SMART<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9naXRsYWIuZXVtZXRzYXQuaW50L2V1bWV0bGFiL29jZWFucy9vY2Vhbi1zY2llbmNlLXN0dWRpZXMvb2xjaS1pb3AtcHJvY2Vzc29yLy0vdHJlZS9tYXN0ZXI=">3SAA<i class="fa fa-external-link-alt"></i></span>。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>book reading note 1</title>
    <url>/posts/2adc6f01.html</url>
    <content><![CDATA[<p>Chapter 5.4-5.5 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<h1 id="comparasion-with-the-humboldt-current-system">5.4Comparasion with the Humboldt Current System</h1>
<p>A complex set of flow between the coast and 100km offshore(Alheit and Bernal 1993)</p>
<ol type="1">
<li>Furthest: sluggish wide flow towards the equator: Chile-Peru Oceanic Current</li>
<li>Towards the coast: Peruvian Oceanic Counter-Current</li>
<li>Closer: equatorward-flowing Humboldt Current, the prime driving force for coastal upwelling</li>
</ol>
<p>The area of upwelling migrates north and south with the seasons, but overall extends from about 38° S in central Chile, through northern Chile and the whole of Peru to parts of Ecuador just north of the equator.</p>
<p>Early work on the upwelling system off Peru, recent details of Chilean upwelling system have been added.</p>
<ul>
<li>Off central Peru, upwelling is year-round but reaches a maximum in winter.</li>
<li>Off northern Chile, upwelling peaks during spring</li>
<li>Off central Chile, peaks during late spring and summer</li>
</ul>
<p>JOINT II multidisciplinary cruises studied the Peruvian upwelling system at 15°S in 1976-7.</p>
<p>Three important differences between the upwelling site off Peru and that off northwest Africa.</p>
<ol type="1">
<li><p>The shelf off Peru is narrower(20km A 50) and drops off more steeply(200m versus 110m).</p></li>
<li><p>Deep water off Peru has more nutrient(20-25 vs 5-10) .</p></li>
<li><p>Wind stress is less and more constant(0.79+-0.4 vs 1.55+-1)</p>
<p>Net result(实际效果):</p>
<ul>
<li>When Ekman transport is active, offshore transport occurs mainly in the top 20m.</li>
<li>Shoreward transport is in an intermediate layer over the shelf, at the depth of about 30-80m(in Africa is whole)</li>
<li>Off Peru, the water close to the bottom is relatively still, and there is marked accumulation of organic matter to give chemically reducing sediment.</li>
</ul></li>
</ol>
<p>Two further differences:</p>
<ul>
<li>since the wind stress is less, the wind-induced mixing does not penetrate so deeply. During periods of strong upwelling, phytoplankton is still retained within the euphotic zone→t primary production is maintained at a relatively constant level, whether the wind stress is high or low。</li>
<li>poleward counter- current, flowing beneath the equatorward coastal jet, is situated at intermediate depth over the continental shelf off Peru, whereas off northwest Africa it is located on the shelf slope</li>
</ul>
<p>A detailed analysis of the primary production cycle in a segment at 15° S(MacIsaac et al.1985):</p>
<p>Because the upwelling is relatively constant it is possible to trace a distinct plume of cold water moving out from the coast and to recognize a number of zones along the axis of the plume.</p>
<ul>
<li>Zone I: the area of intense upwelling within about 7 km of the coast, where nutrients are abundant but phytoplankton biomass is relatively low.</li>
<li>Zone II: I the water column is stabilized by solar warming and the phytoplankton cells are found to increase their rates of nutrient uptake, photosynthesis, and synthesis of macro- molecules, a process known as “shift-up.”</li>
<li>Zone III: characterized by the rapid depletion of nutrients by the “shifted-up” phytoplankton, so that there is a rapid accumulation of biomass and all processes occur at maximal rates.</li>
<li>Zone IV nutrient depletion occurs, so that the cells experience nutrient limitation.</li>
</ul>
<p>Using drogues to track water masses, MacIsaac et al. (1985) estimated that phytoplankton cells moved from zone I to zone IV in 8–10 days, during which time they traveled 30–60 km away from the coast. The chlorophyll maximum occurred about 18 km offshore.</p>
<h2 id="interannual-variability-in-the-peruvian-upwelling-system">5.4.1 Interannual variability in the Peruvian upwelling system</h2>
<p>Normal State: the source of upwelled water off Peru in April–May 1977 was at a depth of 30–60 m. The water was at a temperature of 15.5–16.5 °C, and contained 20–25 µg nitrate.</p>
<p>Anomalous State: the trade winds weaken or reverse, thermocline off the coast of Peru sinks to a depth of about 100 m; Ekman transport along this coast continues, but the water that is upwelled is now much warmer and not rich in nutrients.</p>
<p>As a result, there is a sharp reduction in the biomass and productivity of the phytoplankton.</p>
<p>Reason: El Niño – Southern Oscillation (ENSO). t the Peruvian upwelling system seems to be uniquely vulnerable to such drastic changes, so that its interannual variability in productivity is very great.</p>
<p>1982-3: serious in the periodicity of 100 years or more (Rasmusson and Wallace 1983)</p>
<p>the height of the 1982–3 anomaly, in May 1983, the upwelling waters were at 29 °C instead of the usual 16–18 °C, and mean primary productivity was only 10mgCm−3 d−1(Barber et al.1985) Two months later conditions had returned to normal and mean primary productivity was 219 mg C m−3 d−l</p>
<h2 id="total-primary-production-in-the-peruvian-upwelling-system">5.4.2 Total primary production in the Peruvian upwelling system</h2>
<p>Many attempts have been made to calculate the total primary productivity of the Peruvian upwelling system.</p>
<ol type="1">
<li>Lack of agreement about upwelling area leads out many different result. Cushing (1969) used 479,000 km2 in his calculation while Ryther (1969) used 60,000 km2</li>
<li>Chavez and Barber (1987) argued that the offshore dimension of coastal upwelling is limited by the Rossby deformation scale (Section 5.2.3). From Eqn. 5.11 we see that the formula for this scale is (g′ H0 )1/2/f.Thus the radius is a function of the Coriolis force f (which varies with latitude), the depth H0, and the vertical density gradient.</li>
<li>Chavez and Barber (1987) calculated that the width of the Peruvian upwelling system varied from 270 km at 4° S to 60 km at 18° S. Calculating the width at degree intervals they arrived at an area of 182,000 km2, intermediate between the two values quoted above.</li>
<li>The mean of the large number of determinations of primary production in 1983–4, after the recovery from the El Niño event, was 2.28 g C m−2 d−1 or 834 g C m−2 y−1 . This value converted into a total production of 1.52 × 1014 gCy−1 .</li>
<li>With increased availability of satellite pictures of chloro- phyll distribution, it should be possible to refine the estimate of the average area affected by upwelling, and to determine its variability. For example, Carr (2002) defined the area of an upwelling system as the area over which surface chlorophyll concentrations, as estimated by remote sensing, exceeded 1 mg m−3 on average (see Section 5.9).</li>
</ol>
<h2 id="secondary-production-in-the-humboldt-current-system">5.4.3 Secondary production in the Humboldt Current system</h2>
<p>Cushing(1971) the type of fish in HCS is the same in CCS.</p>
<p>The sardines and anchovies usually spawn in the areas of most intense upwelling, close to shore, and Cushing speculated that both the juveniles and the adults make use of the two counter-currents (onshore and poleward) to maintain themselves within the upwelling system.</p>
<p>lack of agreement about whether the anchovies and sardines predominantly consume phytoplankton. It seems that larvae consume mainly microzooplankton, while adults feed mainly on larger phytoplankton.</p>
<p>Barber et al. (1985) showed (Fig. 5.12) that the years of temperature anomalies (El Niño years) were associated with reduced landings of anchoveta Engraulis ringens.</p>
<p>Possible explanations:</p>
<ol type="1">
<li>the adults could have starved for lack of phytoplankton food,</li>
<li>the fish could have migrated away from the areas where they are usually caught</li>
<li>or the larvae could have failed to survive through lack of both phytoplankton and zooplankton.</li>
</ol>
<p>Some Evidence for each hypothesis.</p>
<p>h1: . There were reports of anchoveta having moved to cooler, deeper water at about 100 m, but such water has very little phytoplankton and it seems likely that the fish would not survive there long. Barber et al. (1985)</p>
<p>h2: anchoveta seek out the upwelling areas by exhibiting a preference for water of 16–18 °C. Barber et al. (1985).migration south to find cooler waters may well have been one of the strategies for survival (Valdivia 1978).</p>
<p>h3:</p>
<ul>
<li>The anchovies spread their spawning over 7–8 months of the year, presumably as an adaptation to the occurrence of unfavorable conditions at particular times and places.</li>
<li>However, there are two peak periods: the austral winter–spring spawning (July–September) and the summer spawning (February–March) (Valdivia 1978).</li>
<li>Walsh et al. (1980), investigating the survival of larvae off the northern coast of Peru during winter, found that survival was higher when dinoflagellates in relatively high concentrations were available to the first-feeding larvae. Strong wind events had the effect of dispersing the dinoflagellate concentrations and adversely affected survival. We shall return to this topic in <strong>Section 5.5</strong> on the California Current.(把这个加上)</li>
<li>At the onset of the 1976 El Niño there was a bloom of the dinoflagellate Gymnodinium splendens along 1000 km of the coast from March until the end of May. It was attributable to the stabilization of the water column as the warm water invaded the area. While it provided an excellent feeding environment for the early larvae, it apparently was not a suitable food for the adult fish, which had smaller fat content, a reduced weight at a given length, and reduced length at sexual maturity. The 1977 recruitment of fish spawned in 1976 was extremely poor and the stock along the Peruvian coast fell to the lowest levels ever observed (Barber et al. 1985)</li>
</ul>
<h2 id="exploitation-of-the-humboldt-current-fish-stock">5.4.4 Exploitation of the Humboldt Current fish stock</h2>
<p>History of the anchoveta fishery in Peru was reviewed by Glantz (1985)</p>
<ol type="1">
<li>Mining of bird-drooping</li>
</ol>
<ul>
<li>beginning in the 1840s, the major industrial activity along the Peruvian coast had been the mining of the bird- droppings, guano, from the rocky islands.</li>
<li>Large populations of fish-eating birds are characteristic of upwelling populations worldwide, and prominent white accumulations of droppings at their roosting sites are an inevitable concomitant. As Cushing (1971) remarked, it is no accident that upwelling areas commonly have a Cabo Blanco, Cap Blanc, or Cape Blanc.</li>
<li>The guano of Peru was mined and exported for fertilizer to many parts of the world.</li>
</ul>
<ol start="2" type="1">
<li>Anchoveta fishing</li>
</ol>
<ul>
<li>Beginning in the 1950s, a lucrative industry to harvest the anchoveta and convert them to fishmeal was developed in Peru.</li>
<li>The landings increased rapidly to a peak of about 12 million tons in 1970, then dropped to 2–3 million tons for a few years.</li>
<li>After 1977 the catch hovered around 1 million tons but in 1985 there began a recovery which has persisted into the twenty-first century (Fig. 5.13)</li>
<li>Alheit and Bernal (1993) sug- gested that there may have been massive migrations from the southern part of the Humboldt system.</li>
</ul>
<p>Whether these fluctuations have been part of a natural cycle of events that has occurred many times in the past, or whether they are primarily the result of gross overfishing?</p>
<p>regime shift→</p>
<p>The authors pointed out that anchovy can recover from an ENSO event in 1–2 years (Fig. 5.13). They made a partial recovery after the 1972–3 El Niño, and a full recovery after the 1997–8 event, but the decadal-scale period of warm anomalies, which began in 1968, held the anchovy populations at low levels from 1977 to 1985. Alheit and Niquen (2004) therefore concluded that the well-known crash of the anchovy fishery in the 1970s was caused primarily by the decadal- scale regime shift rather than by the 1972–3 ENSO events</p>
<p>Overfishing</p>
<p>Climate Change(ENSO, regime shift)</p>
<h1 id="the-california-current-system">5.5 The California Current System</h1>
<p>Driven by prevailing northerly winds, and upwelling occurs along the Pacific coast of the United States from the Canadian border south to Baja California and beyond.</p>
<p>The situation of upwelling system off Oregon in several respects resembles that off Peru(这个是谁做的，Huyer1976做的是非洲).The poleward undercurrent appears over the shelf as well as the slope, and the shoreward flow is strongest at mid-depths over the shelf. Upwelling events are less strong and of shorter duration off Oregon than they are off northwest Africa.</p>
<p>Bakun(1973) gave the Bakun upwelling index, a 20-year aver- age of monthly mean Ekman transport for different parts of the coast. The range is from 300 m3 s−1(offshore direction) to −212 m−3 s−1 (onshore).It can be seen that the index indicates year-round upwelling off southern California, with stronger upwelling in summer, but off Oregon and Washington in the north there is strong downwelling in winter, and upwelling is confined to the period April–September.</p>
<p>in summer there is a negative temperature anomaly, indicative of upwelling of cold water, all the way along the coast from Oregon in the north to Baja California in the south, with the exception of a warm anomaly off San Diego. The upwelling is obviously most intense between Cape Mendocino and Monterey. Although the temperature anomaly in Fig. 5.16 shows an apparently uniform area of cold water, this area is an artifact of the method of calculation(why?).</p>
<p>The situation at any one time, as seen by satellite, is extremely com- plex, with coastal upwelling systems tending to be centered on topographical features such as capes and canyons, and with plumes of upwelled water extending far out into the California Current. As in other coastal upwelling systems, the strength of upwelling is strongly dependent on wind speed and direction, and changes from day to day.</p>
<p>Fig. 5.17 shows the distribution of temperature and nitrate off Point Sur, California, on June 9, 1980, as inferred from satellite imagery supplemented by shipboard observations (Traganza et al. 1983). This situation is typical of an early phase of an upwelling event at this site. If the event persists for many days, interaction with the California Current may give rise to a cyclonic structure about 100 km in diameter, with high biological production along the associated fronts, or it may extend into a plume up to 250 km long (Traganza et al.1981, 1987). In summer time, patterns of this kind may be found in various stages of development or decline all the way from Oregon to Baja California. As winter approaches, the upwelling is progressively restricted to the southern portion of the region and in spring the region of upwelling spreads north again.</p>
<p>heterogeneous nature of the California Current, with its admixture of advected and upwelled water.</p>
<p>It is now possible to simulate both physical and biological events in the coastal transition zone, that zone characterized by the presence of highly productive jets, squirts, or filaments of highly productive upwelled water. Moisan and Hofmann (1996) modeled the fate of Lagrangian drifters placed in newly upwelled water and allowed to travel with a filament. Coupled physical and biological models were used, the biological parameters being determined from shipborne observations. The models reproduced well the formation of a subsurface chlorophyll maximum and the changing structure of the food web as the drifters moved offshore. 物理海洋学的东西我就不懂了</p>
<p>Digiacomo (2000) and Digiacomo and Holt (2001) used the latest satellite technology to study the mesoscale and sub-mesoscale eddies in the Southern California Bight. All the eddies were less than 50 km in diameter, and 70% were less than 10 km. They were observed to lie between the equatorward-flowing California Current and the shore, and appeared to be caused by topography (especially islands), wind, and current instabilities. There was also evidence of lateral entrainment of highly productive coastal waters. Associated with the eddies were patches of high chlorophyll density, up to 15 km wide and 60 km long. The authors discussed the potential for influencing nutrient flux, plankton productivity, larval transport and recruitment, and dispersal of pollutants. This smaller-scale pattern was observed to interact with the large-scale variations in time and space of the California Current.</p>
<h2 id="fish-production-in-the-california-current-system">5.5.1 Fish production in the California Current system</h2>
<p>most abundant fishes in the California Current system are sardines, anchovies, hake, jack mackerel, and mackerel.</p>
<ul>
<li>Sardines Sardinops sagax were heavily exploited from 1916 to 1967.. The peak landings were in 1936–7 and exceeded 700,000 tons. The catch fell drastically in the 1950s and 1960s and in 1967 the California state legislature imposed a moratorium on the sardine fishery.</li>
<li>The sardines of the California current system are divisible into four stocks. Of these, the largest by far before overfishing was the one that spawned in the Southern California Bight and migrated to the upwelling areas off northern California to exploit the dense zooplankton stocks that are associated with the coastal upwelling.</li>
<li>biomass of sardines declined, and some postulated that the two were in competition so that the decline of sardine stocks released resources for the anchovies. However, Soutar and Isaacs (1969) studied the 1850-year record of fish scales in the anaerobic sediments off California and concluded that northern anchovy scales were present in large numbers throughout the series, while sardine scales appeared intermittently for periods of 20–150 years, with absences that averaged 80 years in duration. They concluded that the two species were not in competition.</li>
<li>The anchovies also have several subpopulations. The stock off Oregon spawns at about 44–46° N, mainly in July at the time of the northern upwelling. The central subpopulation spawns principally in the Southern California Bight. Eggs and larvae can be found throughout the year, but the peak abundance is in the spring, while the minimum is in the autumn. The fish remain in the Southern California Bight throughout their lives and in recent years this has been the largest stock. There is a southern stock off Baja California, for which peak larval abundance is from January to March.</li>
</ul>
<p>It thus appears that the largest stocks of both sardine and anchovy spawn in the Southern California Bight. Upwelling is relatively weak and phytoplankton production is lower than in the California Current proper. Bakun and Parrish (1982) have suggested that strong offshore flow associated with Ekman transport is likely to carry eggs and larvae too far offshore, to positions from which they may never return, and that the choice of the Southern California Bight for spawning area reflects a need to avoid areas of strong upwelling. They also suggested that areas of strong Ekman transport are areas where there are strong winds that may destroy the fine-scale strata of food organisms needed by first-feeding larvae. This idea, attributable to Lasker (1975), will be examined in more detail in Section 5.5.2.</p>
<ul>
<li>Schwartzlose et al. (1999) showed that the exploitation of sardines in the California Current reached its peak with landings of 700,000 tons in 1936, but was down to extremely low levels by 1952.</li>
<li>From 1916 to 1952 the catches of anchovy were negligible (Fig. 5.18).</li>
<li>From 1952 to 1966 there were small catches of both sardines and anchovies, and in 1967 the sardine fishery was closed.</li>
<li>After 1967 there was an expansion of anchovy populations, resulting in a catch of 310,000 tons in 1981, but in 1990 there was a switch to dominance of sardines once again, with a catch of 110,000 tons in 1997.</li>
<li>The various hypotheses to explain the alternation of species have been discussed, but in the light of the findings of Alheit and Niquen (2004) for the Humboldt Current system, we may expect to find some influence of decadal-scale climate changes.</li>
</ul>
<p>The various hypotheses to explain the alternation of species have been discussed, but in the light of the findings of Alheit and Niquen (2004) for the Humboldt Current system, we may expect to find some influence of decadal-scale climate changes. These will be discussed in Chapter 9</p>
<h2 id="the-survival-of-first-feeding-larvae">5.5.2 The survival of first-feeding larvae</h2>
<p>Anchovy egg are most abundant in the shorthorn California Bight during February, March, and April. 3 day old first-feeding larvae need a very high density of food organisms about 1790 dinoflagellates per liter.</p>
<p>the larvae were stimulated to feed only when the phytoplankton was at a population density of at least 20–30 cells mL−1</p>
<p>The first-feeding larvae rely on high concentrations of phytoplankton such as naked dinoflagellates of a size class close to 40 µm.</p>
<p>To summarize our understanding of factors influencing anchovy and sardine production in the California Current, we see that strong wind stress and associated upwelling, which are the most characteristic features of eastern boundary currents, appear in themselves to be detrimental to the success of the larvae. For good survival the larvae require a well-developed horizontal layer of high phytoplankton density, in which dinoflagellates are the dominant form.</p>
<p>A second factor to be considered in relation to larval survival is the risk that strong offshore transport will carry the larvae away from the favorable coastal environment.</p>
<p>In our present stage of understanding, there is no way to integrate these two mortality factors, beyond pointing out that both sardine and anchovy appear to avoid the regions of strongest upwelling in their choice of spawning location.</p>
<p>The role of environmental controls in determining sardine and anchovy population cycles in the California Current: Analysis of an end-to-end model 这文章可以看看</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>particle backscattering</title>
    <url>/posts/78604782.html</url>
    <content><![CDATA[<p>Spectral variations of light scattering by marine particles in coastal waters, from visible to near infrared</p>
<p>The open-ocean missing backscattering is in the structural complexity of particles</p>
<p>I'm gonna to add more about this.</p>
<a id="more"></a>
<h1 id="spectral-variations-of-light-scattering-by-marine-particles-in-coastal-waters-from-visible-to-near-infrared">Spectral variations of light scattering by marine particles in coastal waters, from visible to near infrared</h1>
<h2 id="theoretical-background-of-particle-backscattering">Theoretical background of particle backscattering</h2>
<p>Light scattering by a single particle depends on its geometrical cross-section (thus shape and size) and on its refractive index relative to that of the surrounding medium (seawater). The refractive index of particles relative to water can be written as: <span class="math display">\[
m=n-in^{&#39;}
\]</span> where <span class="math inline">\(n\)</span> and <span class="math inline">\(n^{&#39;}\)</span> are respectively the real and imaginary parts of the refractive index.</p>
<p>Typical n values vary from 1.03 and a theoretical upper limit of 1.158 for organic particles (Morel and Ahn 1990; Aas 1996), depending on hydration, and from 1.07 to 1.22 for various minerals (Lide 2001).Woz´niak and Stramski (2004) observed general tendency of increasing n with increasing density of minerals. Typical values and spectral variations for n9 have been documented by Patterson et al. (1977), Egan and Higelman (1979), and Stramski et al. (2007).</p>
<p>In estuaries and coastal waters directly influenced by river inputs, single-grain mineral particles may either appear as individual particles in water or as aggregates containing water and organic matter.</p>
<p>Large estuarine aggregates reaching sizes up to 1000 µm have been observed using video cameras (Kranck 1984). When considering a population of particles, their concentration (number of particles per unit volume of water sample containing these particles) and size are taken into account through the particle size distribution (PSD) (Jonasz and Fournier 2007). Different functions can be used to fit actual PSDs, such as exponential, log-normal, phi-normal, or hyperbolic distributions. In natural waters, the size distribution of suspended particles is often assumed to follow a simple power-law function, also called Junge size distribution(Bader 1970): <span class="math display">\[
N(D)=KD^{-j}
\]</span> where N is the number of particles of diameter D per cubic meter and per micrometer, K sets the concentration of particles, and j, often called Junge exponent, is the slope of the distribution.</p>
<p>This exponent varies around a mean value of 4 and typically from 2.5 to 5 (Jonasz and Fournier 2007). For a fixed number of particles, the proportion of small particles increases when the exponent j increases. The use of Junge distributions for marine particles has been criticized (Risovic 2002; Stavn and Keen 2004; Chami et al. 2006).</p>
<p>Although some field measurements carried out in coastal waters suggest PSDs close to a power-law distribution (Boss et al. 2001a), others reveal significant features at any size range on top of a power-law PSD (Bale and Morris 1987; Eisma et al. 1991; Bernard et al. 2001).</p>
<p>Note also that current particle-sizing techniques for discrete and in situ sampling, such as the resistive particle-counting technique (e.g., Coulter counter) or laser diffraction (e.g., the LISST series, Sequoia Scientific), are typically limited to the range 1–200 mm (Agrawal and Pottsmith 2000).</p>
<p>Apart for a few measurements reported by Stramski and Woz´niak (2005) (see their figs. 1, 2), there is currently a lack of information concerning the finest fraction of particles (,1 mm) which, especially when it is mineral, contributes significantly to light scattering (see fig. 4a in Babin et al. 2003a).</p>
<p>Mie theory can be used to compute the optical properties of particles that are assumed homogeneous and spherical. Mie computations notably provide the efficiency factors for scattering and absorption (<span class="math inline">\(Q_b\)</span> and <span class="math inline">\(Q_a\)</span>). The corresponding coefficients are then obtained by integration over the size distribution: <span class="math display">\[
b_{p}(\lambda)=(\frac{\pi}{4})\int_{D_{min}}^{D_{max}}N(D)Q_b(\lambda,D,m)D^2dD
\\
a_{p}(\lambda)=(\frac{\pi}{4})\int_{D_{min}}^{D_{max}}N(D)Q_a(\lambda,D,m)D^2dD
\]</span> where <span class="math inline">\(\lambda\)</span> is the wavelength of light, whereas the minimum and maximum diameters, <span class="math inline">\(D_{min}\)</span> and <span class="math inline">\(D_{max}\)</span>, define the size interval.</p>
<p>Theoretically, the spectral variations of <span class="math inline">\(b_p\)</span>, in the case of <strong>nonabsorbing and homogeneous particles</strong> distributed in size according to Eq.2 with <span class="math inline">\(D_{min}\)</span> and $D_{max} $ respectively equal to 0 and infinity, can be written: <span class="math display">\[
b_{p}(\lambda)=A\lambda^{-\gamma}
\]</span> The exponent of this power law, <span class="math inline">\(\gamma\)</span>, also called scattering spectral slope, is then simply related to the slope of the PSD, j, through (Morel 1973): <span class="math display">\[
\gamma=j-3
\]</span> To verify Eq. 5 with the Mie theory, the actual limits <span class="math inline">\(D_{min}\)</span> and <span class="math inline">\(D_{max}\)</span> chosen for calculations in Eq. 3 must be small and large enough, respectively, to account for most of particle scattering at all wavelengths (Morel 1973; Boss et al. 2001b).</p>
<p>This condition also applies to <span class="math inline">\(a_p(\lambda)\)</span> calculations for the sake of obtaining results independent of <span class="math inline">\(D_{min}\)</span> and <span class="math inline">\(D_{max}\)</span>.</p>
<p>Equations 4 and 5 are no longer valid in the case of <strong>absorbing particles (<span class="math inline">\(n^{&#39;}&gt; 0\)</span>)</strong>. To understand the influence of particulate absorption on <span class="math inline">\(b_p(\lambda)\)</span>, the effect of <span class="math inline">\(n^{&#39;}\)</span> variations both on the real and imaginary parts of m must be considered.</p>
<p>The former phenomenon can be explained and modeled according to the Ketteler–Helmhotz theory of anomalous dispersion (Bricaud and Morel 1986). It is significant in the vicinity of absorption bands such as the major ones observed on phytoplankton cells in the blue and red parts of the spectrum. In the case of detrital and mineral marine particles for which the absorption coefficient generally varies smoothly with wavelength, variations in <span class="math inline">\(n\)</span> resulting from anomalous dispersion are <strong>negligible</strong>.</p>
<p>The effect of absorption on <span class="math inline">\(b_p(\lambda)\)</span> through the contribution of <span class="math inline">\(n^{&#39;}\)</span> to <span class="math inline">\(m\)</span>, which is certainly much more important than the effect of anomalous dispersion even for phytoplankton, is accounted for by the Mie theory and expressed in the computed efficiency factors (Morel and Bricaud 1986).</p>
<p>Typical <span class="math inline">\(b_p(\lambda)\)</span> spectra for phytoplankton cultures and phytoplankton-rich natural waters exhibit troughs at wavelengths corresponding to major peaks in the particle absorption spectrum (Bricaud et al. 1988; Babin et al. 2003a; Snyder et al. 2008). In the case of nonalgal particles found in coastal waters, the <span class="math inline">\(b_p(\lambda)\)</span> spectrum often depicts a decreasing trend at short wavelengths of the blue range (e.g., Fig. 1 and Babin et al. 2003a).</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030128180205500.png" alt="he particulate scattering coefficient of nonabsorbing particles is denoted b_{pna}."><figcaption aria-hidden="true">he particulate scattering coefficient of nonabsorbing particles is denoted <span class="math inline">\(b_{pna}\)</span>.</figcaption>
</figure>
<p>The particulate scattering coefficient of nonabsorbing particles is denoted <span class="math inline">\(b_{pna}\)</span></p>
<h2 id="result-1">Result 1</h2>
<p>It is in this figure.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030128201433945.png" alt="image-00030128201433945"><figcaption aria-hidden="true">image-00030128201433945</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030128201459589.png" alt="image-00030128201459589"><figcaption aria-hidden="true">image-00030128201459589</figcaption>
</figure>
<p>On the basis of these first results, we conclude that particulate absorption effects on the scattering are always significant in the visible, even when wavelengths associated with high particulate absorption are avoided. A unique power-law function (e.g., Eq. 9) cannot be used to model the bp spectral variations from the near IR toward the visible (Eck et al. 1999). Further investigations are needed concerning these particulate absorption effects to propose an improved model of the <span class="math inline">\(b_p(\lambda)\)</span> spectrum in the visible.</p>
<h2 id="result-2">Result 2</h2>
<p>I want to mainly focus on this part.</p>
<p>In this section, the particulate scattering coefficient of nonabsorbing particles is denoted <span class="math inline">\(b_{pna}\)</span>. The <span class="math inline">\(b_{pna}\)</span> values are obtained by assuming that measured near-IR$ b_{p}$ values effectively represent <span class="math inline">\(b_{pna}\)</span> at these wavelengths and Eq. 9 can be used to extrapolate to visible wavelengths.</p>
<p>The particulate scattering coefficient of absorbing particles is denoted by bp, and the difference from Eq. 9 due to absorption effects is written: <span class="math display">\[
\tag{10}
\Delta b_{p}(\lambda)=b_{pna}(\lambda)-b_p(\lambda)=f(a_p)
\]</span> <img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030128202538901.png" alt="image-00030128202538901"></p>
<p>The results clearly show a significant departure, in a range varying from 1% to 35%, that slightly increases with decreasing values of the <span class="math inline">\(b_p\)</span> near-IR spectral slope (Fig. 9). The</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030128202845313.png" alt="image-00030128202845313"><figcaption aria-hidden="true">image-00030128202845313</figcaption>
</figure>
<p>The relationship between (<span class="math inline">\(\Delta b_p : a_p\)</span>)and <span class="math inline">\(\gamma\)</span> is not linear and can be closely reproduced by using the following equation: <span class="math display">\[
\tag{12}
\Delta b_p/a_p=1-tanh(0.5\times\gamma^2)
\]</span> where the 1 and 0.5 constants correspond to a mean value of the real refractive index (n 5 1.10). These constant values are slightly different for n values of 1.05 or 1.18.</p>
<p>写得很好 就是我不想看了QAQ</p>
<p>最终 出来这个式子</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030128203553730.png" alt="image-00030128203553730"><figcaption aria-hidden="true">image-00030128203553730</figcaption>
</figure>
<h1 id="the-open-ocean-missing-backscattering-is-in-the-structural-complexity-of-particles">The open-ocean missing backscattering is in the structural complexity of particles</h1>
<h1 id="retrieval-of-particulate-backscattering-using-field-and-satellite-radiometry-assessment-of-the-qaa-algorithm">Retrieval of Particulate Backscattering Using Field and Satellite Radiometry: Assessment of the QAA Algorithm</h1>
<p>又是这几个老熟人发的文章。</p>
<p>用的是V19+CNR+BOU的数据。V19就是那个公开数据集，CNR是他们自己采集的，曾经发表在Pitarch2016上，看来这个一作也是搞bbp的老熟人了啊，BOU在这http://www.obs-vlfr.fr/Boussole/html/home/home.php，看来想获取还挺麻烦的。一共2881个Rrs+bbp。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402175803772.png" alt="image-00030402175803772"><figcaption aria-hidden="true">image-00030402175803772</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402175821746.png" alt="image-00030402175821746"><figcaption aria-hidden="true">image-00030402175821746</figcaption>
</figure>
<p>Remote Sensing这个期刊真的是越来越垃圾了，这个图都不让作者改一下的</p>
<p>需要注意的是BOU数据集看起来并不是近岸的水，但是bbp也出现那个比例小于1的情况了。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402180808437.png" alt="image-00030402180808437"><figcaption aria-hidden="true">image-00030402180808437</figcaption>
</figure>
<p>这是分别的统计情况，这个是在去除Raman之前的。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402180849916.png" alt="image-00030402180849916"><figcaption aria-hidden="true">image-00030402180849916</figcaption>
</figure>
<p>这个是在去除Raman之后的</p>
<p>这个作者也尝试了改进那个公式。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402181045202.png" alt="image-00030402181045202"><figcaption aria-hidden="true">image-00030402181045202</figcaption>
</figure>
<p>最终结果是</p>
<p>The in situ radiometry-derived spectral backscattering slope (η) has low predictive value as compared to η derived from bbp matchups. In this context, the impact of using the best fitted curve instead of the widely used expression [22] is negligible, thus validating the application of the latter without its retuning.</p>
<h1 id="bbp-shape-function-summary">bbp shape function summary</h1>
<h2 id="类qaa">类QAA</h2>
<p>这个是用来总结见过的，当然了，不包括LS2那篇文章，那个我到现在没看懂。</p>
<p>QAAv6</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402181330460.png" alt="image-00030402181330460"><figcaption aria-hidden="true">image-00030402181330460</figcaption>
</figure>
<p>Joshi and D'sa 2018</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402181425738.png" alt="image-00030402181425738"><figcaption aria-hidden="true">image-00030402181425738</figcaption>
</figure>
<p>Doxaran 2009</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402181510433.png" alt="image-00030402181510433"><figcaption aria-hidden="true">image-00030402181510433</figcaption>
</figure>
<p>Wang 2017</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402181623722.png" alt="image-00030402181623722"><figcaption aria-hidden="true">image-00030402181623722</figcaption>
</figure>
<p>Xue,2019</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402181655057.png" alt="image-00030402181655057"><figcaption aria-hidden="true">image-00030402181655057</figcaption>
</figure>
<p>Chu 2020</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402181821465.png" alt="image-00030402181821465"><figcaption aria-hidden="true">image-00030402181821465</figcaption>
</figure>
<p>其实我感觉我想要的答案在QAA类的文章里都找不到。</p>
<p>那我看看其他的都是怎么搞出来的</p>
<h2 id="ls1-and-ls2">LS1 and LS2</h2>
<p>回头重新看了眼Werdell2018那个综述。里面提到关于不假设bbp shape或者说不假设为power law的只有这个LS1和LS2</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402182653656.png" alt="image-00030402182653656"><figcaption aria-hidden="true">image-00030402182653656</figcaption>
</figure>
<p>这是唯一一种Bulck inversion that do not assign the shape of bbp.</p>
<p>先发个邮件要个代码吧。</p>
<h1 id="bbp-problem-literature-review">bbp problem literature review</h1>
<p><span class="math display">\[
b_{bp}(\lambda)=b_{bp}(\lambda_0)(\frac{\lambda_0}{\lambda})^{\eta}
\]</span></p>
<p><span class="math inline">\(\eta\)</span> Typically varies between 0 and 3, largely driven by varing proportion of large and small particles(Werdell et al 2018)</p>
<p>Reynolds et al 2016: Based on bbp(λ) values from 394 to 852 nm collected in the Arctic, Reynolds et al. (2016) reported the range of Sbp from 0.13 to 3.01 with the majority of data (80%) between 0.5 and 1.5, a median value of 1, and a mean value of 1.5. In</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/lno10341-fig-0011-m.jpg" alt="image"><figcaption aria-hidden="true">image</figcaption>
</figure>
<p>Note that the Slope is contradict</p>
<p>William et al 2007:</p>
<p>They fit by <span class="math display">\[
f(\lambda)=f_{550}(\frac{\lambda}{550})^{\gamma}
\]</span> The <span class="math inline">\(\gamma\)</span> also versus</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505142456457.png" alt="image-00030505142456457"><figcaption aria-hidden="true">image-00030505142456457</figcaption>
</figure>
<p>only slightly higher than 0 (smaller than 0)</p>
<p>Loisel et al 2006</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505142806961.png" alt="image-00030505142806961"><figcaption aria-hidden="true">image-00030505142806961</figcaption>
</figure>
<p>Pitarch et al 2019</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505143158540.png" alt="image-00030505143158540"><figcaption aria-hidden="true">image-00030505143158540</figcaption>
</figure>
<p>some slightly smaller than 0</p>
<p>Shi&amp;Wang 2017:</p>
<p>VIIRS observation</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505145846471.png" alt="image-00030505145846471"><figcaption aria-hidden="true">image-00030505145846471</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505145935635.png" alt="image-00030505145935635"><figcaption aria-hidden="true">image-00030505145935635</figcaption>
</figure>
<p>7 is Meghna River Estuary</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505150111918.png" alt="image-00030505150111918"><figcaption aria-hidden="true">image-00030505150111918</figcaption>
</figure>
<p>2 is Hangzhou Bay 4 is Amazon River Estuary</p>
<p>Finally found some reason</p>
<blockquote>
<p>Power slope g is related to the particle size distributions (PSDs), i.e., f ? g 2 3 (Babin et al., 2003; Kostadinov et al., 2009; Morel, 1973), where f is the power law slope of the Junge-type (Junge, 1963) size distributions (Balder, 1970; Sheldon et al., 1972; Twardowski et al., 2001). In fact, particle backscattering properties are determined by particle size distribution, particle shapes, and composition. However, particle size distribu- tion is the dominant factor in determining the particle scattering features such as the backscattering power law slope and the backscattering ratio (Kostadinov et al., 2009; Ulloa et al., 1994). For most of the satellite- derived global bbp(k) and the available in situ observations, particle backscattering power law slope g is typi- cally positive or close to 0 (Loisel et al., 2006; Reynolds et al., 2016; Stramski et al., 2007; Wozniak &amp; Stramski, 2004). This shows that bbp(k) decreases with the wavelength for VIIRS-derived bbp(410) to bbp(862). However, g may also be negative for large size particles (Kostadinov et al., 2009). Correspondingly, bbp(k) in the NIR wavelengths thus are larger than those in the visible bands. In China’s east coastal region, in situ bbp(k) can indeed increase with the wavelength at some highly turbid locations (Zhang et al., 2010a).</p>
<p>In this study, VIIRS-derived bbp(k) images in the five turbid regions (Figures 3–7) and bbp(k) at the eight sta- tions (Figure 8) show that the particle size distribution in the water column is highly dynamic depending on the regions and the seasons. At Stations 1 and 2 in China’s east coastal region, bbp(k) increases with the increase of the wavelength during the winter season, while bbp(k) decreases with the wavelength during the summer season. This shows that the g is negative in the winter and positive in the summer, and might further suggest that the particle size is bigger in the winter (f&lt;23) than that in the summer (f&gt;23). The seasonal variation of particle size distribution in the water column may be attributed to the seasonal vari- ability of the turbulence and water mixing process driven by the seasonal monsoon in China’s east coastal region (Shi &amp; Wang, 2010a, 2012a).</p>
<p>At Station 4 in the Amazon River Estuary (Figure 8d) and Station 7 in the Meghna River Estuary (Figure 8g), bbp(k) increases with increase of the wavelength for all seasons, while bbp(k) decreases with the increase of the wavelength for all seasons at Station 6 in the La Plata River Estuary (Figure 8f) and Station 8 in Atchafa- laya River Estuary (Figure 8h). This further suggests that the particle sizes at Stations 4 and 7 are generally larger than those at Stations 6 and 8. At Station 3 in Lake Taihu (Figure 8c) and Station 5 in the Amazon Riv- er’s north branch (Figure 8e), bbp(k) is generally flat for all seasons, implying that particle size in the water column is more or less the same even though bbp(k) can vary seasonally at these two stations. It is also noted that bbp(k) power law slope is still positive even though nLw(k) at the NIR bands in the La Plata River Estuary is similar to that in China’s east coastal region (Figure 2). This indicates that bbp(k) power law slope is not only seasonal-dependent, but also regional-dependent. If nLw(k) at the NIR bands is approximated as the surrogate of the TSM concentration, the particle size in the La Plata River Estuary is smaller than that in China’s east coastal region even though the TSM concentration at these two regions is similar</p>
</blockquote>
<p>There are two main refference here</p>
<p>Kostadinov et al., 2009:</p>
<p>This is also satellite observation</p>
<p>This figure is a modeled result</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505152614575.png" alt="image-00030505152614575"><figcaption aria-hidden="true">image-00030505152614575</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505152703215.png" alt="image-00030505152703215"><figcaption aria-hidden="true">image-00030505152703215</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505152744561.png" alt="image-00030505152744561"><figcaption aria-hidden="true">image-00030505152744561</figcaption>
</figure>
<p>Zhang et al 2010</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030505153254194.png" alt="image-00030505153254194"><figcaption aria-hidden="true">image-00030505153254194</figcaption>
</figure>
<p>Measured Spectrum</p>
<p>I think I need a new post to learn the optics of backscattering</p>
<h1 id="light-scattering-properties-of-marine-particles-in-coastal-and-open-ocean-waters-as-related-to-the-particle-mass-concentration">Light scattering properties of marine particles in coastal and open ocean waters as related to the particle mass concentration</h1>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>particle backscattering</tag>
        <tag>Inversion</tag>
      </tags>
  </entry>
  <entry>
    <title>python绘图基础</title>
    <url>/posts/720e5580.html</url>
    <content><![CDATA[<p>这两天在收拾画图的事情，发现我matplotlib这些东西学的真的差，这个笔记用来整理一下自己会用到的东西，除了cartopy之外的。</p>
<a id="more"></a>
<h1 id="matplotlib">matplotlib</h1>
<h2 id="基础知识">基础知识</h2>
<p>Matplotlib最重要一个基础概念就是figure和axes。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/v2-6e4429872eeb8a155433c0ee7c75b6ea_720w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>在Matplotlib中，figure的意思是画板，axes的意思是画布，而axis的意思是坐标轴。比如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">20</span>)  <span class="comment"># 生成数据</span></span><br><span class="line">y = x * x + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure()  <span class="comment"># 新建图形对象</span></span><br><span class="line">axes = fig.add_axes([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.8</span>, <span class="number">0.8</span>])  <span class="comment"># 控制画布的左，下，宽度，高度</span></span><br><span class="line">axes.plot(x, y, <span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>在同一个画板上，我们可以画好几个画布</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()  <span class="comment"># 新建画板</span></span><br><span class="line">axes1 = fig.add_axes([<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.8</span>])  <span class="comment"># 大画布</span></span><br><span class="line">axes2 = fig.add_axes([<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.4</span>, <span class="number">0.3</span>])  <span class="comment"># 小画布</span></span><br><span class="line"></span><br><span class="line">axes1.plot(x, y, <span class="string">&#x27;r&#x27;</span>)  <span class="comment"># 大画布</span></span><br><span class="line">axes2.plot(y, x, <span class="string">&#x27;g&#x27;</span>)  <span class="comment"># 小画布</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/output_80_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>除此之外， 还有一种方法增加画布，就是plt.subplots()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>)  <span class="comment"># 子图为 1 行，2 列</span></span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> axes:</span><br><span class="line">    ax.plot(x, y, <span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/output_86_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>即便是只画一个画布，也建议通过fig,axses=plt.subplots()来生成画布和画板，方便调节，而不是使用plt.plot()</p>
<h2 id="基础样式调整">基础样式调整</h2>
<h3 id="添加图标题图例">添加图标题、图例</h3>
<p>绘制包含图标题、坐标轴标题以及图例的图形，举例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">axes.set_xlabel(<span class="string">&#x27;x label&#x27;</span>)  <span class="comment"># 横轴名称</span></span><br><span class="line">axes.set_ylabel(<span class="string">&#x27;y label&#x27;</span>)</span><br><span class="line">axes.set_title(<span class="string">&#x27;title&#x27;</span>)  <span class="comment"># 图形名称</span></span><br><span class="line"></span><br><span class="line">axes.plot(x, x**<span class="number">2</span>)</span><br><span class="line">axes.plot(x, x**<span class="number">3</span>)</span><br><span class="line">axes.legend([<span class="string">&quot;y = x**2&quot;</span>, <span class="string">&quot;y = x**3&quot;</span>], loc=<span class="number">0</span>)  <span class="comment"># 图例</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_98_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>图例中的 <code>loc</code> 参数标记图例位置，<code>1，2，3，4</code> 依次代表：右上角、左上角、左下角，右下角；<code>0</code> 代表自适应</p>
<h3 id="线型颜色透明度">线型、颜色、透明度</h3>
<p>在 Matplotlib 中，你可以设置线的颜色、透明度等其他属性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">axes.plot(x, x+<span class="number">1</span>, color=<span class="string">&quot;red&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes.plot(x, x+<span class="number">2</span>, color=<span class="string">&quot;#1155dd&quot;</span>)</span><br><span class="line">axes.plot(x, x+<span class="number">3</span>, color=<span class="string">&quot;#15cc55&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_103_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>而对于线型而言，除了实线、虚线之外，还有很多丰富的线型可供选择。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线宽</span></span><br><span class="line">ax.plot(x, x+<span class="number">1</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">0.25</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">2</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">0.50</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">3</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">1.00</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">4</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">2.00</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 虚线类型</span></span><br><span class="line">ax.plot(x, x+<span class="number">5</span>, color=<span class="string">&quot;red&quot;</span>, lw=<span class="number">2</span>, linestyle=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">6</span>, color=<span class="string">&quot;red&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">7</span>, color=<span class="string">&quot;red&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 虚线交错宽度</span></span><br><span class="line">line, = ax.plot(x, x+<span class="number">8</span>, color=<span class="string">&quot;black&quot;</span>, lw=<span class="number">1.50</span>)</span><br><span class="line">line.set_dashes([<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 符号</span></span><br><span class="line">ax.plot(x, x + <span class="number">9</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">10</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">11</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">12</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 符号大小和颜色</span></span><br><span class="line">ax.plot(x, x+<span class="number">13</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">2</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">14</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">4</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">15</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>,</span><br><span class="line">        marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">8</span>, markerfacecolor=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">16</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, markersize=<span class="number">8</span>,</span><br><span class="line">        markerfacecolor=<span class="string">&quot;yellow&quot;</span>, markeredgewidth=<span class="number">2</span>, markeredgecolor=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_106_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="画布网格坐标轴范围">画布网格、坐标轴范围</h3>
<p>有些时候，我们可能需要显示画布网格或调整坐标轴范围。设置画布网格和坐标轴范围。这里，我们通过指定 <code>axes[0]</code> 序号，来实现子图的自定义顺序排列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示网格</span></span><br><span class="line">axes[<span class="number">0</span>].plot(x, x**<span class="number">2</span>, x, x**<span class="number">3</span>, lw=<span class="number">2</span>)</span><br><span class="line">axes[<span class="number">0</span>].grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置坐标轴范围</span></span><br><span class="line">axes[<span class="number">1</span>].plot(x, x**<span class="number">2</span>, x, x**<span class="number">3</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_ylim([<span class="number">0</span>, <span class="number">60</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_xlim([<span class="number">2</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_110_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>除了折线图，Matplotlib 还支持绘制散点图、柱状图等其他常见图形。下面，我们绘制由散点图、梯步图、条形图、面积图构成的子图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">4</span>, figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>].scatter(x, x + <span class="number">0.25</span>*np.random.randn(len(x)))</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;scatter&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">1</span>].step(n, n**<span class="number">2</span>, lw=<span class="number">2</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;step&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">2</span>].bar(n, n**<span class="number">2</span>, align=<span class="string">&quot;center&quot;</span>, width=<span class="number">0.5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes[<span class="number">2</span>].set_title(<span class="string">&quot;bar&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">3</span>].fill_between(x, x**<span class="number">2</span>, x**<span class="number">3</span>, color=<span class="string">&quot;green&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes[<span class="number">3</span>].set_title(<span class="string">&quot;fill_between&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_113_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="图形标注方法">图形标注方法</h3>
<p>当我们绘制一些较为复杂的图像时，阅读对象往往很难全面理解图像的含义。而此时，图像标注往往会起到画龙点睛的效果。图像标注，就是在画面上添加文字注释、指示箭头、图框等各类标注元素。</p>
<p>Matplotlib 中，文字标注的方法由 <code>matplotlib.pyplot.text()</code> 实现。最基本的样式为 <code>matplotlib.pyplot.text(x, y, s)</code>，其中 x, y 用于标注位置定位，s 代表标注的字符串。除此之外，你还可以通过 <code>fontsize=</code> , <code>horizontalalignment=</code> 等参数调整标注字体的大小，对齐样式等。</p>
<p>下面，我们举一个对柱形图进行文字标注的示例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">x_bar = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>]  <span class="comment"># 柱形图横坐标</span></span><br><span class="line">y_bar = [<span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.8</span>]  <span class="comment"># 柱形图纵坐标</span></span><br><span class="line">bars = axes.bar(x_bar, y_bar, color=<span class="string">&#x27;blue&#x27;</span>, label=x_bar, width=<span class="number">2</span>)  <span class="comment"># 绘制柱形图</span></span><br><span class="line"><span class="keyword">for</span> i, rect <span class="keyword">in</span> enumerate(bars):</span><br><span class="line">    x_text = rect.get_x()  <span class="comment"># 获取柱形图横坐标</span></span><br><span class="line">    y_text = rect.get_height() + <span class="number">0.01</span>  <span class="comment"># 获取柱子的高度并增加 0.01</span></span><br><span class="line">    plt.text(x_text, y_text, <span class="string">&#x27;%.1f&#x27;</span> % y_bar[i])  <span class="comment"># 标注文字</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_119_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>除了文字标注之外，还可以通过 <code>matplotlib.pyplot.annotate()</code> 方法向图像中添加箭头等样式标注。接下来，我们向上面的例子中增添一行增加箭头标记的代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">bars = axes.bar(x_bar, y_bar, color=<span class="string">&#x27;blue&#x27;</span>, label=x_bar, width=<span class="number">2</span>)  <span class="comment"># 绘制柱形图</span></span><br><span class="line"><span class="keyword">for</span> i, rect <span class="keyword">in</span> enumerate(bars):</span><br><span class="line">    x_text = rect.get_x()  <span class="comment"># 获取柱形图横坐标</span></span><br><span class="line">    y_text = rect.get_height() + <span class="number">0.01</span>  <span class="comment"># 获取柱子的高度并增加 0.01</span></span><br><span class="line">    plt.text(x_text, y_text, <span class="string">&#x27;%.1f&#x27;</span> % y_bar[i])  <span class="comment"># 标注文字</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 增加箭头标注</span></span><br><span class="line">    plt.annotate(<span class="string">&#x27;Min&#x27;</span>, xy=(<span class="number">32</span>, <span class="number">0.3</span>), xytext=(<span class="number">36</span>, <span class="number">0.3</span>),</span><br><span class="line">                 arrowprops=dict(facecolor=<span class="string">&#x27;black&#x27;</span>, width=<span class="number">1</span>, headwidth=<span class="number">7</span>))</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_122_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>上面的示例中，<code>xy=()</code> 表示标注终点坐标，<code>xytext=()</code> 表示标注起点坐标。在箭头绘制的过程中，<code>arrowprops=()</code> 用于设置箭头样式，<code>facecolor=</code> 设置颜色，<code>width=</code> 设置箭尾宽度，<code>headwidth=</code> 设置箭头宽度，可以通过 <code>arrowstyle=</code> 改变箭头的样式。</p>
<h2 id="cheatsheet">cheatsheet</h2>
<p>matplotlib官方提供了cheatsheets，建议打印下来贴在显眼的地方</p>
<p>https://github.com/matplotlib/cheatsheets</p>
<h2 id="三维图形绘制">三维图形绘制</h2>
<h3 id="基础三维图形">基础三维图形</h3>
<p>前面，我们已经了解了如果使用 Matplotlib 中的 pyplot 模块绘制简单的 2D 图像。其实，Matplotlib 也可以绘制 3D 图像，与二维图像不同的是，绘制三维图像主要通过 <code>mplot3d</code> 模块实现。但是，使用 Matplotlib 绘制三维图像实际上是在二维画布上展示，所以一般绘制三维图像时，同样需要载入 <code>pyplot</code> 模块。</p>
<p><code>mplot3d</code> 模块下主要包含 4 个大类，分别是：</p>
<ul>
<li><code>mpl_toolkits.mplot3d.axes3d()</code></li>
<li><code>mpl_toolkits.mplot3d.axis3d()</code></li>
<li><code>mpl_toolkits.mplot3d.art3d()</code></li>
<li><code>mpl_toolkits.mplot3d.proj3d()</code></li>
</ul>
<p>其中，<code>axes3d()</code> 下面主要包含了各种实现绘图的类和方法。<code>axis3d()</code> 主要是包含了和坐标轴相关的类和方法。<code>art3d()</code> 包含了一些可将 2D 图像转换并用于 3D 绘制的类和方法。<code>proj3d()</code> 中包含一些零碎的类和方法，例如计算三维向量长度等。</p>
<p>一般情况下，我们用到最多的就是 <code>mpl_toolkits.mplot3d.axes3d()</code> 下面的 <code>mpl_toolkits.mplot3d.axes3d.Axes3D()</code> 类，而 <code>Axes3D()</code> 下面又存在绘制不同类型 3D 图的方法。</p>
<p>下面，我们通过几组示例，来学习 Matplotlib 绘制三维图形。首先，是三维散点图的绘制。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># x, y, z 均为 0 到 1 之间的 100 个随机数</span></span><br><span class="line">x = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">y = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">z = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.scatter(x, y, z)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_14_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>三维图形和二维图形在数据上的区别在于，三维图形多了一组数据用于度量多出来的一个维度。</p>
<p>当我们在桌面环境中绘制 3D 图形时，是可以通过鼠标任意拖动角度的，但在 Jupyter Notebook 环境中不支持，只会展示三维图形的默认视角静态图像。</p>
<p>线形图和散点图相似，需要传入 x,y,z<em>x</em>,<em>y</em>,<em>z</em> 三个坐标的数值。详细的代码如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">x = np.linspace(<span class="number">-6</span> * np.pi, <span class="number">6</span> * np.pi, <span class="number">1000</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">z = np.cos(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 3D 图形对象</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.plot(x, y, z)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_19_1_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制完线型图，我们继续尝试绘制三维柱状图，其实它的绘制步骤和上面同样非常相似。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建 3D 图形对象</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据并绘图</span></span><br><span class="line">x = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">    y = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">    z = abs(np.random.normal(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    ax.bar(y, z, i, zdir=<span class="string">&#x27;y&#x27;</span>, color=[<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_22_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>接下来需要绘制的三维曲面图要麻烦一些，我们需要对数据进行矩阵处理。其实和画二维等高线图很相似，只是多增加了一个维度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建 3D 图形对象</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">X = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">Y = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">X, Y = np.meshgrid(X, Y)</span><br><span class="line">Z = np.sqrt(X ** <span class="number">2</span> + Y ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制曲面图，并使用 cmap 着色</span></span><br><span class="line">ax.plot_surface(X, Y, Z, cmap=plt.cm.winter)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_25_1_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>cmap=plt.cm.winter</code> 表示采用了 <code>winter</code> 配色方案。除了通过 <code>Axes3D()</code> 声明三维图形，我们也可以通过 <code>projection='3d'</code> 参数声明 3D 图形。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 projection=&#x27;3d&#x27; 声明绘制 3D 图形</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X, Y, Z, cmap=plt.cm.winter)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_28_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="三维混合图">三维混合图</h3>
<p>混合图就是将两种不同类型的图绘制在一张图里。绘制混合图一般有前提条件，那就是两种不同类型图的范围大致相同，否则将会出现严重的比例不协调，而使得混合图失去意义。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建 3D 图形对象</span><br><span class="line">fig &#x3D; plt.figure()</span><br><span class="line">ax &#x3D; Axes3D(fig)</span><br><span class="line"></span><br><span class="line"># 生成数据并绘制图 1</span><br><span class="line">x1 &#x3D; np.linspace(-3 * np.pi, 3 * np.pi, 500)</span><br><span class="line">y1 &#x3D; np.sin(x1)</span><br><span class="line">ax.plot(x1, y1, zs&#x3D;0, c&#x3D;&#39;red&#39;)</span><br><span class="line"></span><br><span class="line"># 生成数据并绘制图 2</span><br><span class="line">x2 &#x3D; np.random.normal(0, 1, 100)</span><br><span class="line">y2 &#x3D; np.random.normal(0, 1, 100)</span><br><span class="line">z2 &#x3D; np.random.normal(0, 1, 100)</span><br><span class="line">ax.scatter(x2, y2, z2)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_32_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="三维子图">三维子图</h3>
<p>我们已经学习过二维子图的绘制，其实三维情况下也是一样的。我们可以将二维图像和三维图像绘制在一起，又或者将几个三维图像绘制在一起。这里我们就拿上面绘制过的线形图和曲面图为例，看一看需要增删哪些代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建 1 张画布</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向画布添加子图 1</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"><span class="comment"># 生成子图 1 数据</span></span><br><span class="line">x = np.linspace(<span class="number">-6</span> * np.pi, <span class="number">6</span> * np.pi, <span class="number">1000</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">z = np.cos(x)</span><br><span class="line"><span class="comment"># 绘制第 1 张图</span></span><br><span class="line">ax1.plot(x, y, z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向画布添加子图 2</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"><span class="comment"># 生成子图 2 数据</span></span><br><span class="line">X = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">Y = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">X, Y = np.meshgrid(X, Y)</span><br><span class="line">Z = np.sqrt(X ** <span class="number">2</span> + Y ** <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 绘制第 2 张图</span></span><br><span class="line">ax2.plot_surface(X, Y, Z, cmap=plt.cm.winter)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_36_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>三维图形的绘制，实际上是二维图形的衍生。在绘制方法上并无较大差别，你需要组织合适的数据，并声明三维绘图对象即可。</p>
<p>以上出自https://huhuhang.com/post/machine-learning/matplotlib-basic</p>
<h1 id="seaborn">seaborn</h1>
<p>Seaborn 基于 Matplotlib 核心库进行了更高阶的 API 封装，可以让你轻松地画出更漂亮的图形。Seaborn 的漂亮主要体现在配色更加舒服、以及图形元素的样式更加细腻，下面是 Seaborn 官方给出的参考图。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/document-uid214893labid3264timestamp1501118752821.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="快速优化图形">快速优化图形</h2>
<p>当我们使用 Matplotlib 绘图时，默认的图像样式算不上美观。此时，就可以使用 Seaborn 完成快速优化。下面，我们先使用 Matplotlib 绘制一张简单的图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">13</span>, <span class="number">15</span>, <span class="number">17</span>, <span class="number">19</span>]</span><br><span class="line">y_bar = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">y_line = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line">plt.bar(x, y_bar)</span><br><span class="line">plt.plot(x, y_line, <span class="string">&#x27;-o&#x27;</span>, color=<span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_11_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>使用 Seaborn 完成图像快速优化的方法非常简单。只需要将 Seaborn 提供的样式声明代码 <code>sns.set()</code> 放置在绘图前即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">sns.set()  <span class="comment"># 声明使用 Seaborn 样式</span></span><br><span class="line"></span><br><span class="line">plt.bar(x, y_bar)</span><br><span class="line">plt.plot(x, y_line, <span class="string">&#x27;-o&#x27;</span>, color=<span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_15_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们可以发现，相比于 Matplotlib 默认的纯白色背景，Seaborn 默认的浅灰色网格背景看起来的确要细腻舒适一些。而柱状图的色调、坐标轴的字体大小也都有一些变化。</p>
<p><code>sns.set()</code> 的默认参数为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set(context=<span class="string">&#x27;notebook&#x27;</span>, style=<span class="string">&#x27;darkgrid&#x27;</span>, palette=<span class="string">&#x27;deep&#x27;</span>, font=<span class="string">&#x27;sans-serif&#x27;</span>, font_scale=<span class="number">1</span>, color_codes=<span class="literal">False</span>, rc=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>context=''</code> 参数控制着默认的画幅大小，分别有 <code>&#123;paper, notebook, talk, poster&#125;</code> 四个值。其中，<code>poster &gt; talk &gt; notebook &gt; paper</code>。</li>
<li><code>style=''</code> 参数控制默认样式，分别有 <code>&#123;darkgrid, whitegrid, dark, white, ticks&#125;</code>，你可以自行更改查看它们之间的不同。</li>
<li><code>palette=''</code> 参数为预设的调色板。分别有 <code>&#123;deep, muted, bright, pastel, dark, colorblind&#125;</code> 等，你可以自行更改查看它们之间的不同。</li>
<li>剩下的 <code>font=''</code> 用于设置字体，<code>font_scale=</code> 设置字体大小，<code>color_codes=</code> 不使用调色板而采用先前的 <code>'r'</code> 等色彩缩写。</li>
</ul>
<h2 id="seaborn-绘图-api">Seaborn 绘图 API</h2>
<p>Seaborn 一共拥有 50 多个 API 类，相比于 Matplotlib 数千个的规模，可以算作是短小精悍了。其中，根据图形的适应场景，Seaborn 的绘图方法大致分类 6 类，分别是：关联图、类别图、分布图、回归图、矩阵图和组合图。而这 6 大类下面又包含不同数量的绘图函数。</p>
<p>接下来，我们就通过实际数据进行演示，使用 Seaborn 绘制不同适应场景的图形。</p>
<h2 id="关联图">关联图</h2>
<p>当我们需要对数据进行关联性分析时，可能会用到 Seaborn 提供的以下几个 API。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">关联性分析</th>
<th style="text-align: center;">介绍</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">relplot</td>
<td style="text-align: center;">绘制关系图</td>
</tr>
<tr class="even">
<td style="text-align: center;">scatterplot</td>
<td style="text-align: center;">多维度分析散点图</td>
</tr>
<tr class="odd">
<td style="text-align: center;">lineplot</td>
<td style="text-align: center;">多维度分析线形图</td>
</tr>
</tbody>
</table>
<p><a href="https://seaborn.pydata.org/generated/seaborn.relplot.html"><code>relplot</code></a> 是 relational plots 的缩写，其可以用于呈现数据之后的关系，主要有散点图和条形图 2 种样式。我们载入鸢尾花示例数据集。</p>
<p>在绘图之前，先熟悉一下 iris 鸢尾花数据集。数据集总共 150 行，由 5 列组成。分别代表：萼片长度、萼片宽度、花瓣长度、花瓣宽度、花的类别。其中，前四列均为数值型数据，最后一列花的分类为三种，分别是：Iris Setosa、Iris Versicolour、Iris Virginica。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris = sns.load_dataset(<span class="string">&quot;iris&quot;</span>)</span><br><span class="line">iris.head()</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr class="header">
<th>sepal_length</th>
<th>sepal_width</th>
<th>petal_length</th>
<th>petal_width</th>
<th>species</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td>1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td>2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td>3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td>4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
</tbody>
</table>
<p>此时，我们指定 x<em>x</em> 和 y<em>y</em> 的特征，默认可以绘制出散点图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_33_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>但是，上图并不能看出数据类别之间的联系，如果我们加入类别特征对数据进行着色，就更加直观了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, hue=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_36_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>Seaborn 的函数都有大量实用的参数，例如我们指定 <code>style</code> 参数可以赋予不同类别的散点不同的形状。更多的参数，希望大家通过阅读官方文档了解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>,</span><br><span class="line">            hue=<span class="string">&quot;species&quot;</span>, style=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_42_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>你会发现，上面我们一个提到了 3 个 API，分别是：<code>relplot</code>，<a href="https://seaborn.pydata.org/generated/seaborn.scatterplot.html"><code>scatterplot</code></a> 和 <a href="https://seaborn.pydata.org/generated/seaborn.lineplot.html"><code>lineplot</code></a>。实际上，你可以把我们已经练习过的 <code>relplot</code> 看作是 <code>scatterplot</code> 和 <code>lineplot</code> 的结合版本。</p>
<p>这里就要提到 Seaborn 中的 API 层级概念，Seaborn 中的 API 分为 Figure-level 和 Axes-level 两种。<code>relplot</code> 就是一个 Figure-level 接口，而 <code>scatterplot</code> 和 <code>lineplot</code> 则是 Axes-level 接口。</p>
<p>Figure-level 和 Axes-level API 的区别在于，Axes-level 的函数可以实现与 Matplotlib 更灵活和紧密的结合，而 Figure-level 则更像是「懒人函数」，适合于快速应用。</p>
<p>例如上方的图，我们也可以使用 <code>lineplot</code> 函数绘制，你只需要取消掉 <code>relplot</code> 中的 <code>kind</code> 参数即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lineplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;petal_length&quot;</span>,</span><br><span class="line">             hue=<span class="string">&quot;species&quot;</span>, style=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_48_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="类别图">类别图</h2>
<p>与关联图相似，类别图的 Figure-level 接口是 <code>catplot</code>，其为 categorical plots 的缩写。而 <code>catplot</code> 实际上是如下 Axes-level 绘图 API 的集合：</p>
<ul>
<li>分类散点图：<a href="https://seaborn.pydata.org/generated/seaborn.stripplot.html"><code>stripplot()</code></a> (<code>kind="strip"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.swarmplot.html"><code>swarmplot()</code></a> (<code>kind="swarm"</code>)</li>
<li>分类分布图：<a href="https://seaborn.pydata.org/generated/seaborn.boxplot.html"><code>boxplot()</code></a> (<code>kind="box"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.violinplot.html"><code>violinplot()</code></a> (<code>kind="violin"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.boxenplot.html"><code>boxenplot()</code></a> (<code>kind="boxen"</code>)</li>
<li>分类估计图：<a href="https://seaborn.pydata.org/generated/seaborn.pointplot.html"><code>pointplot()</code></a> (<code>kind="point"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.barplot.html"><code>barplot()</code></a> (<code>kind="bar"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.countplot.html"><code>countplot()</code></a> (<code>kind="count"</code>)</li>
</ul>
<p>下面，我们看一下 <code>catplot</code> 绘图效果。该方法默认是绘制 <code>kind="strip"</code> 散点图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_54_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>kind="swarm"</code> 可以让散点按照 beeswarm 的方式防止重叠，可以更好地观测数据分布。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;swarm&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_56_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>同理，<code>hue=</code> 参数可以给图像引入另一个维度，由于 iris 数据集只有一个类别列，我们这里就不再添加 <code>hue=</code> 参数了。如果一个数据集有多个类别，<code>hue=</code> 参数就可以让数据点有更好的区分。</p>
<p>接下来，我们依次尝试其他几种图形的绘制效果。绘制箱线图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;box&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_59_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制小提琴图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;violin&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_62_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制增强箱线图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;species&quot;</span>, y=<span class="string">&quot;sepal_length&quot;</span>, kind=<span class="string">&quot;boxen&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_65_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制点线图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;point&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_68_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制条形图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;bar&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_71_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="分布图">分布图</h2>
<p>分布图主要是用于可视化变量的分布情况，一般分为单变量分布和多变量分布。当然这里的多变量多指二元变量，更多的变量无法绘制出直观的可视化图形。</p>
<p>Seaborn 提供的分布图绘制方法一般有这几个：<a href="https://seaborn.pydata.org/generated/seaborn.jointplot.html"><code>jointplot</code></a>，<a href="https://seaborn.pydata.org/generated/seaborn.pairplot.html"><code>pairplot</code></a>，<a href="https://seaborn.pydata.org/generated/seaborn.distplot.html"><code>distplot</code></a>，<a href="https://seaborn.pydata.org/generated/seaborn.kdeplot.html"><code>kdeplot</code></a>。接下来，我们依次来看一下这些绘图方法的使用。</p>
<p>Seaborn 快速查看单变量分布的方法是 <code>distplot</code>。默认情况下，该方法将会绘制直方图并拟合核密度估计图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.distplot(iris[<span class="string">&quot;sepal_length&quot;</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_80_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>istplot</code> 提供了参数来调整直方图和核密度估计图，例如设置 <code>kde=False</code> 则可以只绘制直方图，或者 <code>hist=False</code> 只绘制核密度估计图。当然，<code>kdeplot</code> 可以专门用于绘制核密度估计图，其效果和 <code>distplot(hist=False)</code> 一致，但 <code>kdeplot</code> 拥有更多的自定义设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.kdeplot(iris[<span class="string">&quot;sepal_length&quot;</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_83_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>jointplot</code> 主要是用于绘制二元变量分布图。例如，我们探寻 <code>sepal_length</code> 和 <code>sepal_width</code>二元特征变量之间的关系。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_86_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>jointplot</code> 并不是一个 Figure-level 接口，但其支持 <code>kind=</code> 参数指定绘制出不同样式的分布图。例如，绘制出核密度估计对比图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris, kind=<span class="string">&quot;kde&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_89_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>六边形计数图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris, kind=<span class="string">&quot;hex&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_92_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>回归拟合图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris, kind=<span class="string">&quot;reg&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_95_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>最后要介绍的 <code>pairplot</code> 更加强大，其支持一次性将数据集中的特征变量两两对比绘图。默认情况下，对角线上是单变量分布图，而其他则是二元变量分布图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.pairplot(iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_98_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>此时，我们引入第三维度 <code>hue="species"</code> 会更加直观。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.pairplot(iris, hue=<span class="string">&quot;species&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_101_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="回归图">回归图</h2>
<p>接下来，我们继续介绍回归图，回归图的绘制函数主要有：<a href="https://seaborn.pydata.org/generated/seaborn.lmplot.html"><code>lmplot</code></a> 和 <a href="https://seaborn.pydata.org/generated/seaborn.regplot.html"><code>regplot</code></a>。</p>
<p><code>regplot</code> 绘制回归图时，只需要指定自变量和因变量即可，<code>regplot</code> 会自动完成线性回归拟合。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.regplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_106_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>lmplot</code> 同样是用于绘制回归图，但 <code>lmplot</code> 支持引入第三维度进行对比，例如我们设置 <code>hue="species"</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, hue=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_109_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="矩阵图">矩阵图</h2>
<p>矩阵图中最常用的就只有 2 个，分别是：<a href="https://seaborn.pydata.org/generated/seaborn.heatmap.html"><code>heatmap</code></a> 和 <a href="https://seaborn.pydata.org/generated/seaborn.clustermap.html"><code>clustermap</code></a>。</p>
<p>意如其名，<code>heatmap</code> 主要用于绘制热力图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">sns.heatmap(np.random.rand(<span class="number">10</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_114_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>热力图在某些场景下非常实用，例如绘制出变量相关性系数热力图。</p>
<p>除此之外，<code>clustermap</code> 支持绘制层次聚类结构图。如下所示，我们先去掉原数据集中最后一个目标列，传入特征数据即可。当然，你需要对层次聚类有所了解，否则很难看明白图像多表述的含义。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris.pop(<span class="string">&quot;species&quot;</span>)</span><br><span class="line">sns.clustermap(iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_118_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>如果你浏览官方文档，你会发现 Seaborn 中还存在大量已大些字母开始的类，例如 <code>JointGrid</code>，<code>PairGrid</code> 等。实际上这些类只是其对应小写字母的函数 <code>jointplot</code>，<code>pairplot</code> 的进一步封装。当然，二者可能稍有不同，但并没有本质的区别。</p>
<p>除此之外，<span class="exturl" data-url="aHR0cHM6Ly9zZWFib3JuLnB5ZGF0YS5vcmcvYXBpLmh0bWw=">Seaborn 官方文档<i class="fa fa-external-link-alt"></i></span> 中还有关于 <span class="exturl" data-url="aHR0cHM6Ly9zZWFib3JuLnB5ZGF0YS5vcmcvYXBpLmh0bWwjc3R5bGUtY29udHJvbA==">样式控制<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9zZWFib3JuLnB5ZGF0YS5vcmcvYXBpLmh0bWwjY29sb3ItcGFsZXR0ZXM=">色彩自定义<i class="fa fa-external-link-alt"></i></span> 等一些辅助组件的介绍。对于这些 API 的应用没有太大的难点，重点需要勤于练习。</p>
<p>来自https://huhuhang.com/post/machine-learning/seaborn-basic</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>Water Classification for Inversion/Retrieval</title>
    <url>/posts/696b3f33.html</url>
    <content><![CDATA[<p>A hybrid algorithm for estimating the chlorophyll-<em>a</em> concentration across different trophic states in Asian inland waters</p>
<p>Optical water type discrimination and tuning remote sensing band-ratio algorithms: application to retrieval of chlorophyll and kd (490) in the Irish and Celtic seas</p>
<p>Influence of a red band-based water classification approach on chlorophyll algorithms for optically complex estuaries</p>
<p>A soft-classification-based chlorophyll-a estimation method using MERIS data in the highly turbid and eutrophic Taihu Lake</p>
<p>A system to measure the data quality of spectral remote-sensing reflectance of aquatic environments</p>
<p>An improved optical classification scheme for the Ocean Colour Essential Climate Variable and its applications</p>
<a id="more"></a>
<h1 id="a-system-to-measure-the-data-quality-of-spectral-remote-sensing-reflectance-of-aquatic-environments">A system to measure the data quality of spectral remote-sensing reflectance of aquatic environments</h1>
<h2 id="water-classification">Water Classification</h2>
<p>The reference Rrs spectra were first normalized by their respective root of sum of squares (RSS), <span class="math display">\[
nR_{rs}(\lambda)=\frac{R_{rs}}{[\sum^N_{i=1}R_{rs}(\lambda_i)^2]^{1/2}}
\]</span> where the index N represents the total number of wavelengths, varying from 1 to 9 and <span class="math inline">\(\lambda_i\)</span> corresponds to the wavelengths of 412, 443, 488, 510, 531, 547, 555, 667, and 678 nm. The nRrs spectra vary over the range between 0 and 1, while it retains the ‘‘shapes’’ pertaining to the original Rrs spectra, i.e., the band ratios of nRrs(<span class="math inline">\(\lambda_i\)</span>) remain the same as Rrs(<span class="math inline">\(\lambda_i\)</span>).</p>
<p>The number of data clusters k was evaluated using the gap method [Tibshirani et al., 2001]. The gap value is defined as: <span class="math display">\[
GAP_n(k)=E_n^*[log(W_k)]-log(W_k)
\]</span> where n is the sample size, k is the number of clusters being evaluated, and Wk is the pooled within-cluster dispersion measurement, with <span class="math display">\[
W_k=\sum_{r=1}^k\frac{1}{2n_r}D_r
\]</span> where nr is the number of data points in cluster r, and <span class="math inline">\(D_r\)</span> is the sum of the pair-wise distances for all points in cluster r.</p>
<p>The expected value <span class="math inline">\(E_n^*[log(W_k)]\)</span> is determined by Monte Carlo sampling from a reference distri- bution, and $log(Wk) is computed from the sample data. According to the gap method, the optimum cluster number of the nRrs data is determined as 23. Interestingly, this number is nearly the same as that of Forel- Ule water type classes developed 100 years ago [Arnone et al., 2004].</p>
<p>The unsupervised method, K-means clustering technique, was further used to group the nRrs spectra.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115135501466.png" alt="image-00030115135501466"><figcaption aria-hidden="true">image-00030115135501466</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115140950759.png" alt="image-00030115140950759"><figcaption aria-hidden="true">image-00030115140950759</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115141023265.png" alt="image-00030115141023265"><figcaption aria-hidden="true">image-00030115141023265</figcaption>
</figure>
<p>This is a very detailed classification.</p>
<p>But what i want to do is just"Case1, Case2, and Case2 into slightly turbid, moderet turbid and highly turbid"</p>
<p>Anyway, I'm gonna to read it over as I also need it to do the verification/validation.</p>
<h2 id="quantitatively-measurement">Quantitatively measurement</h2>
<ol type="1">
<li><p>match up <span class="math inline">\(R_{rs}^*(\lambda^{&#39;})\)</span> with <span class="math inline">\(nR_{rs}(\lambda)\)</span> with regard to the wavelengths. If <span class="math inline">\(R^*_{rs}\)</span> has more spectral bands than that of <span class="math inline">\(nR_{rs}(\lambda)\)</span>, we will only choose the same wavelengths with <span class="math inline">\(nR_{rs}(\lambda)\)</span> for further analysis. If <span class="math inline">\(R^*_{rs}\)</span> has fewer wavelengths than the <span class="math inline">\(nR_{rs}(\lambda)\)</span> spectra (i.e., <span class="math inline">\(N(\lambda^{&#39;})&lt;9\)</span>), a subset of <span class="math inline">\(nR_{rs}(\lambda^{&#39;})\)</span> and associated upper boundary spectra <span class="math inline">\(nR_{rs}^U(\lambda^{&#39;})\)</span> and lower boundary spectra <span class="math inline">\(nR_{rs}^L(\lambda^{&#39;})\)</span> will be extrated first for <span class="math inline">\(\lambda^{&#39;}\)</span>.</p></li>
<li><p>the normalization of <span class="math inline">\(R_{rs}^*\)</span> spectra following equation (1). For the case of <span class="math inline">\(N(\lambda^{&#39;})&lt;9\)</span>, the new <span class="math inline">\(nR_{rs}(\lambda^{&#39;})\)</span> specta will be rescaled through the normalization procedure of eq(1) so that the RSS of <span class="math inline">\(nR_{rs}(\lambda^{&#39;})\)</span> is equal to 1 (<strong>?</strong>). Further, the new upper and lower boundary spectra <span class="math inline">\(nR_{rs}^{U}(\lambda^{&#39;})\)</span> and <span class="math inline">\(nR_{rs}^{L}(\lambda^{&#39;})\)</span> will also be rescaled by the newly rescaled <span class="math inline">\(nR_{rs}(\lambda^{&#39;})\)</span> spectra as below <span class="math display">\[
nR_{rs}^{U}(\lambda)=\frac{nR_{rs}^{U}(\lambda)}{[\sum_{i=1}^NnR_{rs}(\lambda_i)^2]^{1/2}}
\]</span></p>
<p><span class="math display">\[
nR_{rs}^{L}(\lambda)=\frac{nR_{rs}^{L}(\lambda)}{[\sum_{i=1}^NnR_{rs}(\lambda_i)^2]^{1/2}}
\]</span></p></li>
<li><p>assign a water type to the target spectrum by comparing it with the reference nRrs spectra. The spectra similarity between the target spectrum <span class="math inline">\(nR_{rs}^*\)</span> and refference spectra nRrs are estimated using a spectral angle mapper(SAM)[Kruse et al., 1993], <span class="math display">\[
cos\ \alpha=\frac{\sum_{i=1}^{N}[nR_{rs}^**nR_{rs}]}{\sqrt{\sum_{i=1}^{N}[nR_{rs}^{*}(\lambda_i)]^2\sum_{i=1}^{N}[nR_{rs}(\lambda_i)]^2}}
\]</span> Where <span class="math inline">\(\alpha\)</span> is the angle formed between the refference spectrum nRrs and the normalized target spectrum <span class="math inline">\(nR_{rs}^*\)</span>. As a spectral classifier, SAM is able to determine the spectral similarity by treating them as vertors in a space with dimensionality equal to the number of bands, N. The water type of the target spectrum <span class="math inline">\(nR_{rs}^*\)</span> is identified as one with the largest cosine values (equivalent to the smllest angles).</p></li>
<li><p>the computation of QA scores by comparing the target spectrum <span class="math inline">\(nRrs\)</span> with the upper and lower boundaries (<span class="math inline">\(nRrs^U\)</span> and <span class="math inline">\(nRrs^L\)</span>) of the corresponding water type. The number of wavelengths where <span class="math inline">\(nR_{rs}^*\)</span> falling within the boundaries is counted, and used to derive the total score (<span class="math inline">\(C_{tot}\)</span>) for the <span class="math inline">\(nR_{rs}\)</span> spectrum, <span class="math display">\[
C_{tot}=\frac{C(\lambda_1)+C(\lambda_2)+\ldots+C(\lambda_N)}{N}
\]</span></p></li>
</ol>
<p>Where <span class="math inline">\(C_{i}\)</span> is the wavelength-specific score with N the total number of wavelengths for both <span class="math inline">\(R_{rs}^*\)</span> and <span class="math inline">\(R_{rs}^{ref}\)</span>. At wavelength <span class="math inline">\(\lambda_i\)</span> , for example, if <span class="math inline">\(R_{rs}^*(\lambda_i)\)</span> is found beyond either the upper or lower boundary of nRrs, a score of 0 will be assigned to this wavelength; otherwise score=1. As suggested by equation (7), the total score <span class="math inline">\(C_{tot}\)</span> will vary within the range of [0, 1]. A higher score indicates higher data quality.</p>
<p>To account for the measurement uncertainty and possible data-processing errors and likely insufficient data coverage, the original upper boundary and lower boundary are slightly modified by <span class="math inline">\(\pm0.5%\)</span>,<span class="math inline">\(nRrs^U=nRrs^U\times(1+0.005)\ and\ nRrs^L=nRrs^L\times(1-0.005)\)</span>, respectively. Note that this added range of 0.5% is one order of magnitude smaller than the projected accuracy for radiance measurement [Hooker et al., 1992].</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115182324282.png" alt="image-00030115182324282"><figcaption aria-hidden="true">image-00030115182324282</figcaption>
</figure>
<h2 id="result">Result</h2>
<p>Because all field measurements are discrete, it is likely that the database used here does not cover every water types and/or there are situations where the range of Rrs variability goes beyond the domains defined here. Such a limitation can be updated or revised when more high-quality in situ measurements are avail- able. A MATLABVR script is made available (http://oceanoptics.umb.edu/score_metric/) to facilitate the evaluation and refinement of the score metrics. Nevertheless, this QA scheme provides an easily applicable system to quantitatively evaluate the quality of individual Rrs spectra.</p>
<h2 id="code">Code</h2>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[maxCos, cos, clusterID, totScore]</span> = <span class="title">QAscores_matrix</span><span class="params">(test_Rrs, test_lambda)</span></span></span><br><span class="line"><span class="comment">% Quality assurance system for Rrs spectra (version 1)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Author: Jianwei Wei, University of Massachusetts Boston</span></span><br><span class="line"><span class="comment">% Email: Jianwei.Wei@umb.edu</span></span><br><span class="line"><span class="comment">% Nov-01-2016</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">% KNOWN VARIABLES :   ref_nRrs   -- Normalized Rrs spectra per-determined from water clustering (23x9 matrix)  </span></span><br><span class="line"><span class="comment">%                     ref_lambda -- Wavelengths for ref_nRrs (1x9 matrix)</span></span><br><span class="line"><span class="comment">%                     upB        -- Upper boundary (23x9 matrix)</span></span><br><span class="line"><span class="comment">%                     lowB       -- Lower boundary (23x9 matrix)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% INPUTS:            test_Rrs   -- Rrs spectra for testing (units: sr^-1);</span></span><br><span class="line"><span class="comment">%                                  a row vector</span></span><br><span class="line"><span class="comment">%                    test_lambda-- Wavelengths for test_Rrs</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% OUTPUTS:  maxCos     -- maximum cosine values</span></span><br><span class="line"><span class="comment">%           cos        -- cosine values for every ref_nRrs spectra</span></span><br><span class="line"><span class="comment">%           clusterID  -- idenfification of water types (from 1-23)</span></span><br><span class="line"><span class="comment">%           totScore   -- total score assigned to test_Rrs</span></span><br><span class="line"><span class="comment">% ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line"><span class="comment">% <span class="doctag">NOTE:</span></span></span><br><span class="line"><span class="comment">%         1) Nine wavelengths (412, 443, 488, 510, 531, 547, 555, 667, 678nm) are assumed in the model</span></span><br><span class="line"><span class="comment">%         2) If your Rrs data were measured at other wavelength, e.g. 440nm, you may want to change 440 to 443 before the model run;</span></span><br><span class="line"><span class="comment">%             or modify the code below to find a cloest wavelength from the nine bands.</span></span><br><span class="line"><span class="comment">%         3) The latest version may be found online at HTTP://oceanoptics.umb.edu/score_metric</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Reference:</span></span><br><span class="line"><span class="comment">%         Wei, Jianwei; Lee, Zhongping; Shang, Shaoling (2016). A system</span></span><br><span class="line"><span class="comment">%         to measure the data quality of spectral remote sensing</span></span><br><span class="line"><span class="comment">%         reflectance of aquatic environments. Journal of Geophysical Research, </span></span><br><span class="line"><span class="comment">%         121, doi:10.1002/2016JC012126</span></span><br><span class="line"><span class="comment">%         </span></span><br><span class="line"><span class="comment">% ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">% Apr. 5 2017, Keping Du</span></span><br><span class="line"><span class="comment">%     1) Vectorize code</span></span><br><span class="line"><span class="comment">%     2) totScore takes account of NaN bands</span></span><br><span class="line"><span class="comment">%     3) add input data check</span></span><br><span class="line"><span class="comment">% Apr. 11, 2017</span></span><br><span class="line"><span class="comment">%     4) compatible with previous matlab version (tested on v2014a)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% INPUTS:            </span></span><br><span class="line"><span class="comment">%           test_Rrs -- matrix (inRow*inCol), each row represents one Rrs spectrum</span></span><br><span class="line"><span class="comment">% OUTPUTS:  </span></span><br><span class="line"><span class="comment">%           maxCos,clusterID,totScore -- row vector (1*inRow)</span></span><br><span class="line"><span class="comment">%           cos -- matrix (refRow[23]*inRow) </span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Note:</span></span><br><span class="line"><span class="comment">%     1) nanmean, nansum need statistics toolbox</span></span><br><span class="line"><span class="comment">%     2) on less memory and multi-core system, it may further speedup using</span></span><br><span class="line"><span class="comment">%        parfor</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">%% check input data</span></span><br><span class="line">[row_lam, len] = <span class="built_in">size</span>(test_lambda);</span><br><span class="line"><span class="keyword">if</span>( row_lam ~= <span class="number">1</span> )</span><br><span class="line">    test_lambda = test_lambda&#x27;;</span><br><span class="line">    [row_lam, len] = <span class="built_in">size</span>(test_lambda);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">[row, col] = <span class="built_in">size</span>(test_Rrs);</span><br><span class="line"><span class="keyword">if</span>( len~=col &amp;&amp; len~=row)</span><br><span class="line">    error(<span class="string">&#x27;Rrs and lambda size mismatch, please check the input data!&#x27;</span>);</span><br><span class="line"><span class="keyword">elseif</span>( len == row )</span><br><span class="line">    test_Rrs = test_Rrs&#x27;;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% </span></span><br><span class="line">ref_lambda = [... </span><br><span class="line"><span class="number">4.1200000e+02</span>   <span class="number">4.4300000e+02</span>   <span class="number">4.8800000e+02</span>   <span class="number">5.1000000e+02</span>   <span class="number">5.3100000e+02</span>   <span class="number">5.4700000e+02</span>   <span class="number">5.5500000e+02</span>   <span class="number">6.6700000e+02</span>   <span class="number">6.7800000e+02</span>];</span><br><span class="line"></span><br><span class="line">ref_nRrs = [...</span><br><span class="line"><span class="number">7.3796683e-01</span>   <span class="number">5.3537883e-01</span>   <span class="number">3.3492125e-01</span>   <span class="number">1.6941114e-01</span>   <span class="number">1.1182662e-01</span>   <span class="number">8.4361643e-02</span>   <span class="number">7.2175090e-02</span>   <span class="number">7.2722859e-03</span>   <span class="number">7.0353728e-03</span></span><br><span class="line"><span class="number">6.7701882e-01</span>   <span class="number">5.3387929e-01</span>   <span class="number">3.9394438e-01</span>   <span class="number">2.2455653e-01</span>   <span class="number">1.5599408e-01</span>   <span class="number">1.2008708e-01</span>   <span class="number">1.0354070e-01</span>   <span class="number">1.0933735e-02</span>   <span class="number">1.0455480e-02</span></span><br><span class="line"><span class="number">6.0833086e-01</span>   <span class="number">5.2121439e-01</span>   <span class="number">4.3584243e-01</span>   <span class="number">2.7962783e-01</span>   <span class="number">2.0377847e-01</span>   <span class="number">1.6110758e-01</span>   <span class="number">1.4032775e-01</span>   <span class="number">1.6391579e-02</span>   <span class="number">1.6652716e-02</span></span><br><span class="line"><span class="number">5.0963646e-01</span>   <span class="number">4.7791625e-01</span>   <span class="number">4.6164394e-01</span>   <span class="number">3.4802439e-01</span>   <span class="number">2.7862610e-01</span>   <span class="number">2.3009577e-01</span>   <span class="number">2.0608914e-01</span>   <span class="number">2.8730802e-02</span>   <span class="number">3.1444642e-02</span></span><br><span class="line"><span class="number">4.2964691e-01</span>   <span class="number">4.3556598e-01</span>   <span class="number">4.7152369e-01</span>   <span class="number">3.8584748e-01</span>   <span class="number">3.2599050e-01</span>   <span class="number">2.7815421e-01</span>   <span class="number">2.5272485e-01</span>   <span class="number">3.7857754e-02</span>   <span class="number">4.0848963e-02</span></span><br><span class="line"><span class="number">3.6333623e-01</span>   <span class="number">3.8706313e-01</span>   <span class="number">4.5815748e-01</span>   <span class="number">4.0800274e-01</span>   <span class="number">3.6779296e-01</span>   <span class="number">3.2800639e-01</span>   <span class="number">3.0440341e-01</span>   <span class="number">4.2053379e-02</span>   <span class="number">4.6881488e-02</span></span><br><span class="line"><span class="number">3.0946099e-01</span>   <span class="number">3.5491575e-01</span>   <span class="number">4.5120901e-01</span>   <span class="number">4.1874143e-01</span>   <span class="number">3.9159654e-01</span>   <span class="number">3.5624518e-01</span>   <span class="number">3.3479154e-01</span>   <span class="number">4.7772121e-02</span>   <span class="number">5.2270007e-02</span></span><br><span class="line"><span class="number">2.7592997e-01</span>   <span class="number">3.1479809e-01</span>   <span class="number">4.1544764e-01</span>   <span class="number">4.1498609e-01</span>   <span class="number">4.1372468e-01</span>   <span class="number">3.9362850e-01</span>   <span class="number">3.7826076e-01</span>   <span class="number">6.1949978e-02</span>   <span class="number">6.7485875e-02</span></span><br><span class="line"><span class="number">3.4894221e-01</span>   <span class="number">3.3506487e-01</span>   <span class="number">3.9141989e-01</span>   <span class="number">3.8562158e-01</span>   <span class="number">3.8741043e-01</span>   <span class="number">3.8162021e-01</span>   <span class="number">3.7750529e-01</span>   <span class="number">9.0297871e-02</span>   <span class="number">1.1765683e-01</span></span><br><span class="line"><span class="number">2.2772731e-01</span>   <span class="number">2.7529725e-01</span>   <span class="number">3.8286839e-01</span>   <span class="number">4.0702216e-01</span>   <span class="number">4.2986184e-01</span>   <span class="number">4.2741518e-01</span>   <span class="number">4.2034636e-01</span>   <span class="number">7.8973961e-02</span>   <span class="number">8.2281945e-02</span></span><br><span class="line"><span class="number">2.9144133e-01</span>   <span class="number">2.7609677e-01</span>   <span class="number">3.4217459e-01</span>   <span class="number">3.6720207e-01</span>   <span class="number">4.0137560e-01</span>   <span class="number">4.2429030e-01</span>   <span class="number">4.3706779e-01</span>   <span class="number">1.2861174e-01</span>   <span class="number">1.8141021e-01</span></span><br><span class="line"><span class="number">1.8746813e-01</span>   <span class="number">2.4076435e-01</span>   <span class="number">3.4198541e-01</span>   <span class="number">3.8187091e-01</span>   <span class="number">4.2690383e-01</span>   <span class="number">4.5020436e-01</span>   <span class="number">4.6108232e-01</span>   <span class="number">1.4677497e-01</span>   <span class="number">1.5051459e-01</span></span><br><span class="line"><span class="number">1.7255536e-01</span>   <span class="number">2.2029128e-01</span>   <span class="number">3.4230960e-01</span>   <span class="number">3.9321173e-01</span>   <span class="number">4.4659383e-01</span>   <span class="number">4.6240583e-01</span>   <span class="number">4.6390040e-01</span>   <span class="number">9.2807580e-02</span>   <span class="number">9.5738816e-02</span></span><br><span class="line"><span class="number">1.8841854e-01</span>   <span class="number">2.3450346e-01</span>   <span class="number">3.1896860e-01</span>   <span class="number">3.6310347e-01</span>   <span class="number">4.1160987e-01</span>   <span class="number">4.4466363e-01</span>   <span class="number">4.6280653e-01</span>   <span class="number">2.1459148e-01</span>   <span class="number">2.1401522e-01</span></span><br><span class="line"><span class="number">1.4302269e-01</span>   <span class="number">1.9142029e-01</span>   <span class="number">3.0575515e-01</span>   <span class="number">3.6501150e-01</span>   <span class="number">4.3375853e-01</span>   <span class="number">4.7213469e-01</span>   <span class="number">4.9178025e-01</span>   <span class="number">1.6955637e-01</span>   <span class="number">1.7983785e-01</span></span><br><span class="line"><span class="number">1.8122161e-01</span>   <span class="number">2.0034662e-01</span>   <span class="number">2.6123587e-01</span>   <span class="number">3.0652476e-01</span>   <span class="number">3.6505277e-01</span>   <span class="number">4.1049611e-01</span>   <span class="number">4.3692672e-01</span>   <span class="number">3.5885777e-01</span>   <span class="number">3.7375096e-01</span></span><br><span class="line"><span class="number">1.7376760e-01</span>   <span class="number">2.0335076e-01</span>   <span class="number">2.8260384e-01</span>   <span class="number">3.3433902e-01</span>   <span class="number">3.9927549e-01</span>   <span class="number">4.4616335e-01</span>   <span class="number">4.7240007e-01</span>   <span class="number">2.7161480e-01</span>   <span class="number">2.8030883e-01</span></span><br><span class="line"><span class="number">1.4172683e-01</span>   <span class="number">1.6884314e-01</span>   <span class="number">2.7937007e-01</span>   <span class="number">3.4856431e-01</span>   <span class="number">4.3857605e-01</span>   <span class="number">4.9800156e-01</span>   <span class="number">5.2526881e-01</span>   <span class="number">1.2057525e-01</span>   <span class="number">1.3119104e-01</span></span><br><span class="line"><span class="number">4.9762118e-02</span>   <span class="number">1.2646476e-01</span>   <span class="number">2.1885211e-01</span>   <span class="number">2.7695980e-01</span>   <span class="number">3.3962502e-01</span>   <span class="number">3.9232585e-01</span>   <span class="number">4.2293225e-01</span>   <span class="number">4.5168610e-01</span>   <span class="number">4.4940869e-01</span></span><br><span class="line"><span class="number">1.1664824e-01</span>   <span class="number">1.5255979e-01</span>   <span class="number">2.5801235e-01</span>   <span class="number">3.2411839e-01</span>   <span class="number">4.1170366e-01</span>   <span class="number">4.7713532e-01</span>   <span class="number">5.1451309e-01</span>   <span class="number">2.4308012e-01</span>   <span class="number">2.5948949e-01</span></span><br><span class="line"><span class="number">1.6300080e-01</span>   <span class="number">1.7545808e-01</span>   <span class="number">2.4907066e-01</span>   <span class="number">3.0835049e-01</span>   <span class="number">4.0042169e-01</span>   <span class="number">4.9006514e-01</span>   <span class="number">5.4422570e-01</span>   <span class="number">1.8971850e-01</span>   <span class="number">2.1691957e-01</span></span><br><span class="line"><span class="number">1.1144977e-01</span>   <span class="number">1.3489716e-01</span>   <span class="number">2.2644205e-01</span>   <span class="number">2.9215646e-01</span>   <span class="number">3.8536483e-01</span>   <span class="number">4.6326561e-01</span>   <span class="number">5.1087974e-01</span>   <span class="number">3.0960602e-01</span>   <span class="number">3.2932847e-01</span></span><br><span class="line"><span class="number">1.4502528e-01</span>   <span class="number">1.3256756e-01</span>   <span class="number">1.7550282e-01</span>   <span class="number">2.1469996e-01</span>   <span class="number">2.8639896e-01</span>   <span class="number">4.2323996e-01</span>   <span class="number">5.4785581e-01</span>   <span class="number">3.4123619e-01</span>   <span class="number">4.4889669e-01</span>];</span><br><span class="line"></span><br><span class="line">upB = [...</span><br><span class="line"><span class="number">7.7969936e-01</span>   <span class="number">5.5909264e-01</span>   <span class="number">3.6692096e-01</span>   <span class="number">2.0292753e-01</span>   <span class="number">1.3779175e-01</span>   <span class="number">1.0873357e-01</span>   <span class="number">9.5895728e-02</span>   <span class="number">4.5695335e-02</span>   <span class="number">4.6623543e-02</span></span><br><span class="line"><span class="number">7.1135851e-01</span>   <span class="number">5.5483793e-01</span>   <span class="number">4.2431975e-01</span>   <span class="number">2.5442939e-01</span>   <span class="number">1.8182569e-01</span>   <span class="number">1.4088103e-01</span>   <span class="number">1.2594384e-01</span>   <span class="number">2.7945457e-02</span>   <span class="number">2.7482701e-02</span></span><br><span class="line"><span class="number">6.4636996e-01</span>   <span class="number">5.4024177e-01</span>   <span class="number">4.7082785e-01</span>   <span class="number">3.2199848e-01</span>   <span class="number">2.4284402e-01</span>   <span class="number">1.9718059e-01</span>   <span class="number">1.7318334e-01</span>   <span class="number">6.7007986e-02</span>   <span class="number">6.1761903e-02</span></span><br><span class="line"><span class="number">5.6956355e-01</span>   <span class="number">5.1481217e-01</span>   <span class="number">5.2762943e-01</span>   <span class="number">3.7374247e-01</span>   <span class="number">3.1163845e-01</span>   <span class="number">2.6467090e-01</span>   <span class="number">2.3993224e-01</span>   <span class="number">6.1840977e-02</span>   <span class="number">6.1595171e-02</span></span><br><span class="line"><span class="number">4.7766327e-01</span>   <span class="number">4.8771143e-01</span>   <span class="number">5.4753295e-01</span>   <span class="number">4.1775156e-01</span>   <span class="number">3.5180203e-01</span>   <span class="number">3.1410390e-01</span>   <span class="number">3.0074757e-01</span>   <span class="number">9.8916601e-02</span>   <span class="number">9.8223557e-02</span></span><br><span class="line"><span class="number">4.2349058e-01</span>   <span class="number">4.1629204e-01</span>   <span class="number">5.0574462e-01</span>   <span class="number">4.2702700e-01</span>   <span class="number">3.8954221e-01</span>   <span class="number">3.5793655e-01</span>   <span class="number">3.4536165e-01</span>   <span class="number">6.5299946e-02</span>   <span class="number">7.0929396e-02</span></span><br><span class="line"><span class="number">3.6203259e-01</span>   <span class="number">3.8603916e-01</span>   <span class="number">4.8546366e-01</span>   <span class="number">4.3877038e-01</span>   <span class="number">4.1263302e-01</span>   <span class="number">3.7826776e-01</span>   <span class="number">3.6026748e-01</span>   <span class="number">8.9755079e-02</span>   <span class="number">9.6484956e-02</span></span><br><span class="line"><span class="number">3.2810264e-01</span>   <span class="number">3.4343461e-01</span>   <span class="number">4.6353434e-01</span>   <span class="number">4.4890674e-01</span>   <span class="number">4.4108569e-01</span>   <span class="number">4.1758379e-01</span>   <span class="number">4.1232286e-01</span>   <span class="number">9.4401188e-02</span>   <span class="number">1.4021177e-01</span></span><br><span class="line"><span class="number">4.2855883e-01</span>   <span class="number">3.6912183e-01</span>   <span class="number">4.3403075e-01</span>   <span class="number">4.1270429e-01</span>   <span class="number">4.1160816e-01</span>   <span class="number">4.0289362e-01</span>   <span class="number">4.1035327e-01</span>   <span class="number">1.6615177e-01</span>   <span class="number">1.7528681e-01</span></span><br><span class="line"><span class="number">2.8324712e-01</span>   <span class="number">3.1754972e-01</span>   <span class="number">4.7084893e-01</span>   <span class="number">4.5098695e-01</span>   <span class="number">4.5149446e-01</span>   <span class="number">4.5357177e-01</span>   <span class="number">4.5236036e-01</span>   <span class="number">1.2816675e-01</span>   <span class="number">1.2540729e-01</span></span><br><span class="line"><span class="number">3.5991344e-01</span>   <span class="number">3.1914376e-01</span>   <span class="number">3.7307732e-01</span>   <span class="number">3.9984107e-01</span>   <span class="number">4.2745720e-01</span>   <span class="number">4.5149720e-01</span>   <span class="number">4.7720363e-01</span>   <span class="number">1.6995977e-01</span>   <span class="number">2.8445448e-01</span></span><br><span class="line"><span class="number">2.5323148e-01</span>   <span class="number">2.8678090e-01</span>   <span class="number">3.7399254e-01</span>   <span class="number">4.0526187e-01</span>   <span class="number">4.3921995e-01</span>   <span class="number">4.7516031e-01</span>   <span class="number">5.0687105e-01</span>   <span class="number">1.8317200e-01</span>   <span class="number">1.8818901e-01</span></span><br><span class="line"><span class="number">2.3499754e-01</span>   <span class="number">2.5303395e-01</span>   <span class="number">3.9213672e-01</span>   <span class="number">4.2364082e-01</span>   <span class="number">4.7335481e-01</span>   <span class="number">4.8597037e-01</span>   <span class="number">4.8826847e-01</span>   <span class="number">1.2800547e-01</span>   <span class="number">1.3376144e-01</span></span><br><span class="line"><span class="number">2.6334872e-01</span>   <span class="number">2.6326210e-01</span>   <span class="number">3.4983739e-01</span>   <span class="number">3.8201315e-01</span>   <span class="number">4.2907348e-01</span>   <span class="number">4.6056025e-01</span>   <span class="number">5.0704621e-01</span>   <span class="number">2.6195191e-01</span>   <span class="number">2.7603537e-01</span></span><br><span class="line"><span class="number">2.0165686e-01</span>   <span class="number">2.1944496e-01</span>   <span class="number">3.3293904e-01</span>   <span class="number">3.8081387e-01</span>   <span class="number">4.4757827e-01</span>   <span class="number">4.9268537e-01</span>   <span class="number">5.2092931e-01</span>   <span class="number">2.0348242e-01</span>   <span class="number">2.2378780e-01</span></span><br><span class="line"><span class="number">2.2950692e-01</span>   <span class="number">2.2362822e-01</span>   <span class="number">2.9607108e-01</span>   <span class="number">3.3929798e-01</span>   <span class="number">3.8191277e-01</span>   <span class="number">4.3237136e-01</span>   <span class="number">4.6462834e-01</span>   <span class="number">3.9304042e-01</span>   <span class="number">4.1905293e-01</span></span><br><span class="line"><span class="number">2.3208516e-01</span>   <span class="number">2.4386127e-01</span>   <span class="number">3.1588427e-01</span>   <span class="number">3.5480624e-01</span>   <span class="number">4.1530756e-01</span>   <span class="number">4.6339021e-01</span>   <span class="number">5.0286163e-01</span>   <span class="number">3.0237661e-01</span>   <span class="number">3.1290136e-01</span></span><br><span class="line"><span class="number">2.0171262e-01</span>   <span class="number">2.0441871e-01</span>   <span class="number">3.0892189e-01</span>   <span class="number">3.7634368e-01</span>   <span class="number">4.5467828e-01</span>   <span class="number">5.2197132e-01</span>   <span class="number">5.6041815e-01</span>   <span class="number">1.6311236e-01</span>   <span class="number">1.6976942e-01</span></span><br><span class="line"><span class="number">6.5661340e-02</span>   <span class="number">1.4690487e-01</span>   <span class="number">2.3551261e-01</span>   <span class="number">2.9595427e-01</span>   <span class="number">3.6727210e-01</span>   <span class="number">4.1473807e-01</span>   <span class="number">4.3942630e-01</span>   <span class="number">4.7896558e-01</span>   <span class="number">4.9313138e-01</span></span><br><span class="line"><span class="number">1.5923700e-01</span>   <span class="number">1.8447802e-01</span>   <span class="number">2.9637570e-01</span>   <span class="number">3.5554446e-01</span>   <span class="number">4.2928965e-01</span>   <span class="number">5.0010046e-01</span>   <span class="number">5.7076206e-01</span>   <span class="number">2.9044526e-01</span>   <span class="number">2.9315569e-01</span></span><br><span class="line"><span class="number">2.3467705e-01</span>   <span class="number">2.3694940e-01</span>   <span class="number">2.9291331e-01</span>   <span class="number">3.3603937e-01</span>   <span class="number">4.4272385e-01</span>   <span class="number">5.1506755e-01</span>   <span class="number">6.0505783e-01</span>   <span class="number">2.4064496e-01</span>   <span class="number">2.8576387e-01</span></span><br><span class="line"><span class="number">1.5917155e-01</span>   <span class="number">1.6716117e-01</span>   <span class="number">2.5081075e-01</span>   <span class="number">3.1848061e-01</span>   <span class="number">4.0755621e-01</span>   <span class="number">4.8220009e-01</span>   <span class="number">5.7294813e-01</span>   <span class="number">3.5104257e-01</span>   <span class="number">3.8328993e-01</span></span><br><span class="line"><span class="number">1.8025311e-01</span>   <span class="number">1.6668715e-01</span>   <span class="number">1.9757519e-01</span>   <span class="number">2.3256976e-01</span>   <span class="number">3.0993604e-01</span>   <span class="number">4.5188827e-01</span>   <span class="number">5.7836256e-01</span>   <span class="number">3.7903370e-01</span>   <span class="number">5.0856220e-01</span>];</span><br><span class="line"></span><br><span class="line">lowB = [...</span><br><span class="line"><span class="number">7.0944028e-01</span>   <span class="number">5.1166101e-01</span>   <span class="number">2.7132138e-01</span>   <span class="number">1.1925057e-01</span>   <span class="number">7.3117696e-02</span>   <span class="number">5.2517151e-02</span>   <span class="number">4.4424250e-02</span>   <span class="number">2.3244358e-03</span>   <span class="number">1.7280789e-03</span></span><br><span class="line"><span class="number">6.3840139e-01</span>   <span class="number">5.0883522e-01</span>   <span class="number">3.6351047e-01</span>   <span class="number">1.9833316e-01</span>   <span class="number">1.3181697e-01</span>   <span class="number">1.0045892e-01</span>   <span class="number">8.4327293e-02</span>   <span class="number">2.7526552e-03</span>   <span class="number">3.0136510e-03</span></span><br><span class="line"><span class="number">5.5332832e-01</span>   <span class="number">4.9738169e-01</span>   <span class="number">4.1160489e-01</span>   <span class="number">2.4634336e-01</span>   <span class="number">1.7860486e-01</span>   <span class="number">1.3952599e-01</span>   <span class="number">1.1925864e-01</span>   <span class="number">7.1624892e-03</span>   <span class="number">6.7813256e-03</span></span><br><span class="line"><span class="number">4.3575142e-01</span>   <span class="number">4.3822012e-01</span>   <span class="number">4.1917290e-01</span>   <span class="number">3.1017788e-01</span>   <span class="number">2.4134878e-01</span>   <span class="number">1.9276253e-01</span>   <span class="number">1.6873340e-01</span>   <span class="number">1.0336969e-02</span>   <span class="number">1.0575256e-02</span></span><br><span class="line"><span class="number">3.6482973e-01</span>   <span class="number">3.9039153e-01</span>   <span class="number">4.1720917e-01</span>   <span class="number">3.6595976e-01</span>   <span class="number">2.8660924e-01</span>   <span class="number">2.3234012e-01</span>   <span class="number">2.0247522e-01</span>   <span class="number">1.5868207e-02</span>   <span class="number">1.5286574e-02</span></span><br><span class="line"><span class="number">3.0704995e-01</span>   <span class="number">3.6020020e-01</span>   <span class="number">4.0499850e-01</span>   <span class="number">3.8743491e-01</span>   <span class="number">3.4744031e-01</span>   <span class="number">2.9691113e-01</span>   <span class="number">2.7164222e-01</span>   <span class="number">2.8723854e-02</span>   <span class="number">2.8095758e-02</span></span><br><span class="line"><span class="number">2.5106498e-01</span>   <span class="number">3.1479600e-01</span>   <span class="number">4.1503769e-01</span>   <span class="number">4.0334518e-01</span>   <span class="number">3.7325697e-01</span>   <span class="number">3.3395352e-01</span>   <span class="number">3.0649812e-01</span>   <span class="number">1.6409266e-02</span>   <span class="number">2.1277292e-02</span></span><br><span class="line"><span class="number">1.9524320e-01</span>   <span class="number">2.6645927e-01</span>   <span class="number">3.7459566e-01</span>   <span class="number">3.8648689e-01</span>   <span class="number">3.8966056e-01</span>   <span class="number">3.7107656e-01</span>   <span class="number">3.4536957e-01</span>   <span class="number">2.3468373e-02</span>   <span class="number">2.5248160e-02</span></span><br><span class="line"><span class="number">2.9510963e-01</span>   <span class="number">3.1603431e-01</span>   <span class="number">3.6697675e-01</span>   <span class="number">3.6241475e-01</span>   <span class="number">3.5891532e-01</span>   <span class="number">3.5210964e-01</span>   <span class="number">3.4139078e-01</span>   <span class="number">5.8341191e-02</span>   <span class="number">6.6080536e-02</span></span><br><span class="line"><span class="number">1.3127870e-01</span>   <span class="number">2.3383370e-01</span>   <span class="number">3.3563122e-01</span>   <span class="number">3.8054666e-01</span>   <span class="number">4.0677434e-01</span>   <span class="number">3.8957954e-01</span>   <span class="number">3.7636462e-01</span>   <span class="number">2.1549732e-02</span>   <span class="number">3.2454227e-02</span></span><br><span class="line"><span class="number">2.4706327e-01</span>   <span class="number">2.4040986e-01</span>   <span class="number">3.1094797e-01</span>   <span class="number">3.4504382e-01</span>   <span class="number">3.6604542e-01</span>   <span class="number">3.6960554e-01</span>   <span class="number">3.7735013e-01</span>   <span class="number">8.4929835e-02</span>   <span class="number">1.1753899e-01</span></span><br><span class="line"><span class="number">1.4757789e-01</span>   <span class="number">2.0726071e-01</span>   <span class="number">3.0160822e-01</span>   <span class="number">3.3610868e-01</span>   <span class="number">4.0871602e-01</span>   <span class="number">4.2488320e-01</span>   <span class="number">4.2659628e-01</span>   <span class="number">1.0951814e-01</span>   <span class="number">1.1484183e-01</span></span><br><span class="line"><span class="number">9.1742158e-02</span>   <span class="number">1.6100841e-01</span>   <span class="number">3.1322179e-01</span>   <span class="number">3.7490499e-01</span>   <span class="number">4.2297563e-01</span>   <span class="number">4.3757985e-01</span>   <span class="number">4.3639722e-01</span>   <span class="number">2.4259065e-02</span>   <span class="number">2.3478356e-02</span></span><br><span class="line"><span class="number">1.5838339e-01</span>   <span class="number">1.9960855e-01</span>   <span class="number">2.6513370e-01</span>   <span class="number">3.1086089e-01</span>   <span class="number">3.8179041e-01</span>   <span class="number">4.2671191e-01</span>   <span class="number">4.3813226e-01</span>   <span class="number">1.5437250e-01</span>   <span class="number">1.7919256e-01</span></span><br><span class="line"><span class="number">6.5751115e-02</span>   <span class="number">1.4872663e-01</span>   <span class="number">2.7329740e-01</span>   <span class="number">3.3440351e-01</span>   <span class="number">4.1829544e-01</span>   <span class="number">4.5463364e-01</span>   <span class="number">4.6632118e-01</span>   <span class="number">1.3489346e-01</span>   <span class="number">1.4272407e-01</span></span><br><span class="line"><span class="number">1.5596873e-01</span>   <span class="number">1.6063788e-01</span>   <span class="number">2.2583023e-01</span>   <span class="number">2.8187737e-01</span>   <span class="number">3.5551812e-01</span>   <span class="number">3.9392236e-01</span>   <span class="number">4.1661845e-01</span>   <span class="number">3.2762330e-01</span>   <span class="number">3.3207209e-01</span></span><br><span class="line"><span class="number">1.3658524e-01</span>   <span class="number">1.7620400e-01</span>   <span class="number">2.5184514e-01</span>   <span class="number">3.0981985e-01</span>   <span class="number">3.8772491e-01</span>   <span class="number">4.1841560e-01</span>   <span class="number">4.3663895e-01</span>   <span class="number">2.4409767e-01</span>   <span class="number">2.4335830e-01</span></span><br><span class="line"><span class="number">5.7943169e-02</span>   <span class="number">1.1577971e-01</span>   <span class="number">2.4910978e-01</span>   <span class="number">3.2064774e-01</span>   <span class="number">4.1928998e-01</span>   <span class="number">4.8032887e-01</span>   <span class="number">4.9879067e-01</span>   <span class="number">4.9669377e-02</span>   <span class="number">5.4213979e-02</span></span><br><span class="line"><span class="number">3.2114597e-02</span>   <span class="number">7.9563157e-02</span>   <span class="number">1.8250239e-01</span>   <span class="number">2.4567895e-01</span>   <span class="number">3.2360944e-01</span>   <span class="number">3.7846671e-01</span>   <span class="number">4.1099745e-01</span>   <span class="number">4.1683471e-01</span>   <span class="number">4.0913583e-01</span></span><br><span class="line"><span class="number">3.5790266e-02</span>   <span class="number">9.6338446e-02</span>   <span class="number">2.1754001e-01</span>   <span class="number">2.9267040e-01</span>   <span class="number">3.9487537e-01</span>   <span class="number">4.6406111e-01</span>   <span class="number">4.9047457e-01</span>   <span class="number">2.0439610e-01</span>   <span class="number">2.1684389e-01</span></span><br><span class="line"><span class="number">1.0724044e-01</span>   <span class="number">1.4052739e-01</span>   <span class="number">1.9880290e-01</span>   <span class="number">2.4646929e-01</span>   <span class="number">3.4713330e-01</span>   <span class="number">4.6406216e-01</span>   <span class="number">5.0762214e-01</span>   <span class="number">1.4872355e-01</span>   <span class="number">1.7132289e-01</span></span><br><span class="line"><span class="number">7.3193803e-02</span>   <span class="number">9.8029772e-02</span>   <span class="number">2.0015322e-01</span>   <span class="number">2.4913266e-01</span>   <span class="number">3.3016201e-01</span>   <span class="number">4.5041635e-01</span>   <span class="number">4.8460783e-01</span>   <span class="number">2.6383395e-01</span>   <span class="number">2.9161859e-01</span></span><br><span class="line"><span class="number">9.3197327e-02</span>   <span class="number">9.4502428e-02</span>   <span class="number">1.4641494e-01</span>   <span class="number">1.9385761e-01</span>   <span class="number">2.6497912e-01</span>   <span class="number">3.8223376e-01</span>   <span class="number">4.8516910e-01</span>   <span class="number">3.0135913e-01</span>   <span class="number">3.8303801e-01</span>];</span><br><span class="line">    </span><br><span class="line">[refRow,refCol]=<span class="built_in">size</span>(ref_nRrs);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% match the ref_lambda and test_lambda</span></span><br><span class="line">idx0 = []; <span class="comment">% for ref_lambda </span></span><br><span class="line">idx1 = []; <span class="comment">% for test_lambda</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">length</span>(test_lambda)</span><br><span class="line">    pos = <span class="built_in">find</span>(ref_lambda==test_lambda(<span class="built_in">i</span>));</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isempty</span>(pos)</span><br><span class="line">        idx1(<span class="built_in">i</span>) = NaN;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        idx0(<span class="built_in">i</span>) = pos;</span><br><span class="line">        idx1(<span class="built_in">i</span>) = <span class="built_in">i</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">pos = <span class="built_in">isnan</span>(idx1);  idx1(pos) = [];</span><br><span class="line"></span><br><span class="line">test_lambda = test_lambda(idx1); test_Rrs = test_Rrs(:,idx1);</span><br><span class="line">ref_lambda = ref_lambda(idx0); ref_nRrs = ref_nRrs(:,idx0); </span><br><span class="line">upB = upB(:,idx0); lowB = lowB(:,idx0); </span><br><span class="line"></span><br><span class="line"><span class="comment">%% match the ref_nRrs and test_Rrs</span></span><br><span class="line"><span class="comment">% keep the original value</span></span><br><span class="line">test_Rrs_orig = test_Rrs;</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"><span class="comment">%% nromalization</span></span><br><span class="line">[inRow, inCol] = <span class="built_in">size</span>(test_Rrs);</span><br><span class="line"></span><br><span class="line"><span class="comment">% transform spectrum to column, inCol*inRow</span></span><br><span class="line">test_Rrs = test_Rrs&#x27;;</span><br><span class="line">test_Rrs_orig = test_Rrs_orig&#x27;;</span><br><span class="line"></span><br><span class="line"><span class="comment">% inCol*inRow</span></span><br><span class="line">nRrs_denom=<span class="built_in">sqrt</span>(nansum(test_Rrs.^<span class="number">2</span>));</span><br><span class="line">nRrs_denom = <span class="built_in">repmat</span>(nRrs_denom,[inCol,<span class="number">1</span>]);</span><br><span class="line">nRrs = test_Rrs./nRrs_denom;  </span><br><span class="line"></span><br><span class="line"><span class="comment">% SAM input, inCol*inRow*refRow </span></span><br><span class="line">test_Rrs2 = <span class="built_in">repmat</span>(test_Rrs_orig,[<span class="number">1</span>,<span class="number">1</span>,refRow]);</span><br><span class="line"></span><br><span class="line"><span class="comment">%for ref Rrs, inCol*refRow*inRow </span></span><br><span class="line">test_Rrs2p = <span class="built_in">permute</span>(test_Rrs2,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% inCol*inRow*refRow  </span></span><br><span class="line">nRrs2_denom=<span class="built_in">sqrt</span>(nansum(test_Rrs2.^<span class="number">2</span>));</span><br><span class="line">nRrs2_denom = <span class="built_in">repmat</span>(nRrs2_denom,[inCol,<span class="number">1</span>]);</span><br><span class="line">nRrs2 = test_Rrs2./nRrs2_denom;  </span><br><span class="line"><span class="comment">% inCol*refRow*inRow  </span></span><br><span class="line">nRrs2 = <span class="built_in">permute</span>(nRrs2,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% adjust the ref_nRrs, according to the matched wavebands</span></span><br><span class="line"><span class="comment">%[row, ~] = size(ref_nRrs);</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%%%% re-normalize the ref_adjusted</span></span><br><span class="line">ref_nRrs = ref_nRrs&#x27;;</span><br><span class="line"></span><br><span class="line"><span class="comment">% inCol*refRow*inRow </span></span><br><span class="line">ref_nRrs2 = <span class="built_in">repmat</span>(ref_nRrs,[<span class="number">1</span>,<span class="number">1</span>,inRow]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% inCol*refRow*inRow </span></span><br><span class="line">ref_nRrs2_denom=<span class="built_in">sqrt</span>(nansum(ref_nRrs2.^<span class="number">2</span>));</span><br><span class="line">ref_nRrs2_denom = <span class="built_in">repmat</span>(ref_nRrs2_denom,[inCol,<span class="number">1</span>]);</span><br><span class="line">ref_nRrs_corr2 = ref_nRrs2./ref_nRrs2_denom;</span><br><span class="line"></span><br><span class="line"><span class="comment">%% Classification </span></span><br><span class="line"><span class="comment">%%%% calculate the Spectral angle mapper</span></span><br><span class="line"><span class="comment">% inCol*refRow*inRow </span></span><br><span class="line">cos_denom=<span class="built_in">sqrt</span>(nansum(ref_nRrs_corr2.^<span class="number">2</span>).*nansum(nRrs2.^<span class="number">2</span>));</span><br><span class="line">cos_denom = <span class="built_in">repmat</span>(cos_denom,[inCol,<span class="number">1</span>]);</span><br><span class="line"><span class="built_in">cos</span> = (ref_nRrs_corr2.*nRrs2)./cos_denom; </span><br><span class="line"><span class="comment">% 1*refRow*inRow </span></span><br><span class="line"><span class="built_in">cos</span> = sum(<span class="built_in">cos</span>);</span><br><span class="line"><span class="comment">% refRow*inRow</span></span><br><span class="line"><span class="built_in">cos</span> = <span class="built_in">permute</span>(<span class="built_in">cos</span>,[<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 1*inRow</span></span><br><span class="line">[maxCos,clusterID] = <span class="built_in">max</span>(<span class="built_in">cos</span>);</span><br><span class="line">posClusterID = <span class="built_in">isnan</span>(maxCos);</span><br><span class="line"><span class="comment">%potential bug for vectorized code</span></span><br><span class="line"><span class="comment">%clusterID(pos) = NaN;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% if isnan(cos)</span></span><br><span class="line"><span class="comment">%     clusterID = NaN;</span></span><br><span class="line"><span class="comment">% else</span></span><br><span class="line"><span class="comment">%     clusterID = find(cos==maxCos);</span></span><br><span class="line"><span class="comment">% end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% scoring</span></span><br><span class="line"> </span><br><span class="line">upB_corr = upB&#x27;; </span><br><span class="line">lowB_corr = lowB&#x27;; </span><br><span class="line"></span><br><span class="line"><span class="comment">%% comparison</span></span><br><span class="line"><span class="comment">% inCol*inRow</span></span><br><span class="line">upB_corr2 = upB_corr(:,clusterID).*(<span class="number">1</span>+<span class="number">0.005</span>);</span><br><span class="line">lowB_corr2 = lowB_corr(:,clusterID).*(<span class="number">1</span><span class="number">-0.005</span>);</span><br><span class="line">ref_nRrs2 = ref_nRrs(:,clusterID);</span><br><span class="line"></span><br><span class="line"><span class="comment">%normalization</span></span><br><span class="line">ref_nRrs2_denom=<span class="built_in">sqrt</span>(nansum(ref_nRrs2.^<span class="number">2</span>));</span><br><span class="line">ref_nRrs2_denom = <span class="built_in">repmat</span>(ref_nRrs2_denom,[inCol,<span class="number">1</span>]);</span><br><span class="line">upB_corr2 = upB_corr2 ./ ref_nRrs2_denom;</span><br><span class="line">lowB_corr2 = lowB_corr2 ./ ref_nRrs2_denom;</span><br><span class="line"></span><br><span class="line">upB_diff = upB_corr2 - nRrs;</span><br><span class="line">lowB_diff = nRrs - lowB_corr2;</span><br><span class="line"></span><br><span class="line">C = <span class="built_in">zeros</span>(inCol,inRow);</span><br><span class="line">pos = <span class="built_in">find</span>( upB_diff&gt;=<span class="number">0</span> &amp; lowB_diff&gt;=<span class="number">0</span> );</span><br><span class="line">C(pos) = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">%process all NaN spectral </span></span><br><span class="line">C(:,posClusterID)=NaN;                                               </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">totScore = <span class="built_in">nanmean</span>(C) ;  </span><br></pre></td></tr></table></figure>
<h2 id="annotation">Annotation</h2>
<p>I believe this is actually not the true evaluation that do not need any 'in-situ' data.</p>
<p>It should met a lot of problem when applied it to other regions and sensors.</p>
<p>I need to modify the former code if I want to use it in the evaluation of fusion result.</p>
<h1 id="a-hybrid-algorithm-for-estimating-the-chlorophyll-a-concentration-across-different-trophic-states-in-asian-inland-waters">A hybrid algorithm for estimating the chlorophyll-<em>a</em> concentration across different trophic states in Asian inland waters</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115201801830.png" alt="image-00030115201801830"><figcaption aria-hidden="true">image-00030115201801830</figcaption>
</figure>
<p><span class="math inline">\(MCI\le0.001\)</span> Slightly turbid</p>
<p><span class="math inline">\(0.001&lt;MCI\le0.0016\)</span> Moderate turbid</p>
<p><span class="math inline">\(MCI&gt;0.0016\)</span> Highly turbid</p>
<h1 id="optical-water-type-discrimination-and-tuning-remote-sensing-band-ratio-algorithms-application-to-retrieval-of-chlorophyll-and-kd490-in-the-irish-and-celtic-seas">Optical water type discrimination and tuning remote sensing band-ratio algorithms: Application to retrieval of chlorophyll and <em>K</em>d(490) in the Irish and Celtic Seas</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115202628690.png" alt="image-00030115202628690"><figcaption aria-hidden="true">image-00030115202628690</figcaption>
</figure>
<p>This is a very very emprical classification.</p>
<h1 id="influence-of-a-red-band-based-water-classification-approach-on-chlorophyll-algorithms-for-optically-complex-estuarie">Influence of a red band-based water classification approach on chlorophyll algorithms for optically complex estuarie</h1>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115202825460.png" alt="image-00030115202825460"><figcaption aria-hidden="true">image-00030115202825460</figcaption>
</figure>
<p>I can try this. Along with the Chia/TSM ratio</p>
<h1 id="a-soft-classification-based-chlorophyll-a-estimation-method-using-meris-data-in-the-highly-turbid-and-eutrophic-taihu-lake">A soft-classification-based chlorophyll-<em>a</em> estimation method using MERIS data in the highly turbid and eutrophic Taihu Lake</h1>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0303243417303148-gr2_lrg.jpg"></p>
<p>SGLI didn't have red edge wavelength, which introduced a lot of problem in this work.</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuc2NpZW5jZWRpcmVjdC5jb20vdG9waWNzL2VhcnRoLWFuZC1wbGFuZXRhcnktc2NpZW5jZXMvcGh5dG9wbGFua3Rvbg==">Phytoplankton<i class="fa fa-external-link-alt"></i></span> pigments cause high reflectance in red edge wavelengths (<em>e.g.</em> 709 nm), and low reflectance in red wavelengths (<em>e.g.</em> 681 nm) because of the phytoplankton pigment absorption peak around 681 nm.</p>
<h1 id="an-improved-optical-classification-scheme-for-the-ocean-colour-essential-climate-variable-and-its-applications">An improved optical classification scheme for the Ocean Colour Essential Climate Variable and its applications</h1>
<p>其实这个并不能算是OWT-&gt;inversion/estimation</p>
<p>只是先用FCM划分了分类，然后假定模型在每类的error是一样的，最后通过每一类的error来给一个error estimation</p>
<h1 id="optical-types-of-inland-and-coastal-waters">Optical types of inland and coastal waters</h1>
<p>这篇文章真的是我感觉非常理想的文章了，因为他们非常理想的讲了OWT里面都是由什么构成的</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402161611706.png" alt="image-00030402161611706"><figcaption aria-hidden="true">image-00030402161611706</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402162450657.png" alt="image-00030402162450657"><figcaption aria-hidden="true">image-00030402162450657</figcaption>
</figure>
<p>这个13是按照给Inland water分类的，所以会有很严重的蓝藻的东西，</p>
<p>然后Coastal他们分了9类，但是没有给出解释之类的。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402162603375.png" alt="image-00030402162603375"><figcaption aria-hidden="true">image-00030402162603375</figcaption>
</figure>
<p>讲了给提供数据，但是链接打不开。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402164934583.png" alt="image-00030402164934583"><figcaption aria-hidden="true">image-00030402164934583</figcaption>
</figure>
<p>这个地方是讲怎么Match的</p>
<p>L2 norm distance 是基于Vector 的Euclidean distance</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402172203229.png" alt="image-00030402172203229"><figcaption aria-hidden="true">image-00030402172203229</figcaption>
</figure>
<p>至于这个Norm?我查了查似乎并不是规范化的意思。</p>
<p>然后这个是全Dataset的Cluster结果。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402172450000.png" alt="image-00030402172450000"><figcaption aria-hidden="true">image-00030402172450000</figcaption>
</figure>
<p>这个其实也害不错，但是就是没有讲这个大类里面每一种到底是什么样的。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402172636127.png" alt="image-00030402172636127"><figcaption aria-hidden="true">image-00030402172636127</figcaption>
</figure>
<h2 id="a-global-approach-for-chlorophyll-a-retrieval-across-optically-complex-inland-waters-based-on-optical-water-type">A global approach for chlorophyll-a retrieval across optically complex inland waters based on optical water type</h2>
<p>这个是根据上一篇的结果做出来的。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402172912120.png" alt="image-00030402172912120"><figcaption aria-hidden="true">image-00030402172912120</figcaption>
</figure>
<p>然后在ACIX-Aqua李只选用了其中几个。</p>
<h1 id="remote-estimation-of-chlorophyll-a-concentrations-over-a-wide-range-of-optical-conditions-based-on-water-classification-from-viirs-observations">Remote estimation of chlorophyll a concentrations over a wide range of optical conditions based on water classification from VIIRS observations</h1>
<p>这个是算Chla的，但是好的地方在于这个文章给了一个非常清晰的怎么分类的过程。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402173332530.png" alt="image-00030402173332530"><figcaption aria-hidden="true">image-00030402173332530</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402173357960.png" alt="image-00030402173357960"><figcaption aria-hidden="true">image-00030402173357960</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402173419427.png" alt="image-00030402173419427"><figcaption aria-hidden="true">image-00030402173419427</figcaption>
</figure>
<p>An absorption-related optical classification approach was developed by considering the contributions of different particle sources, aph(443)/ ad(443) (Table 3), to divide the study sites into three water classes, i.e., detritus-dominated waters (aph(443)/ad(443) &lt; 0.2, Wd), pigment- dominated waters (aph(443)/ad(443) ≥ 1.0, Wp) and intermediate waters (0.2 ≤ aph(443)/ad(443) &lt; 1.0, Wm),</p>
<p>自己可以尝试一下。</p>
<h1 id="remotely-estimating-total-suspended-solids-concentration-in-clear-to-extremely-turbid-waters-using-a-novel-semi-analytical-method">Remotely estimating total suspended solids concentration in clear to extremely turbid waters using a novel semi-analytical method</h1>
<p>这个是我最近特别喜欢的一篇文章。</p>
<p>果然还是中国人理解中国人。</p>
<p>而且这个用的是QAA</p>
<p>他的做Simulation和Rrs correction的过程也特别值得一看。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402173740967.png" alt="image-00030402173740967"><figcaption aria-hidden="true">image-00030402173740967</figcaption>
</figure>
<p>I 560</p>
<p>II 665</p>
<p>III 754</p>
<p>IV 865</p>
<p>这个可以保证算出来的bbp是准确的</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030402173903360.png" alt="image-00030402173903360"><figcaption aria-hidden="true">image-00030402173903360</figcaption>
</figure>
<p>虽然没有提到bbp shape的事情。</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Inherent Optical Properties</tag>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>《乡土中国》摘录与笔记</title>
    <url>/posts/f71631a2.html</url>
    <content><![CDATA[<p>最近终于断断续续地看完了《乡土中国》这本书。这本书是我大一的时候思修（毛概？）老师推荐的，当时图书馆借了之后就没有看，最近想给每天都是公式代码论文的日子找个调剂，于是就想起了这本书。慢慢地读了好几个月终于读完了，印证着2020/2021年的一些事情，就忽然有些恍然大悟的感觉。</p>
<p>有些东西当时不情愿去学不情愿去做，等到后面人生阅历起来了才会发现当时学的东西是多么有用。</p>
<p>这里把一些觉得很精髓的描述了乡土社会的句子和对我有启发的句子摘录出来，部分附加我的笔记。常读常新。</p>
<a id="more"></a>
<h1 id="乡土本色">乡土本色</h1>
<blockquote>
<p>这种办法在一个陌生人面前是无法应用的。在我们社会的急速变迁中，从乡土社会进入现代社会的过程中，我们在乡土社会中所养成的生活方式处处产生了流弊。陌生人所组成的现代社会是无法用乡土社会的习俗来应付的。于是，“土气”成了骂人的词汇，“乡”也不再是衣锦荣归的去处了</p>
</blockquote>
<h1 id="文字下乡">文字下乡</h1>
<blockquote>
<p>文字所能传的情、达的意是不完全的。这不完全是出于“间接接触”的原因。我们所要传达的情意是和当时当地的外局相配合的。你用文字把当时当地的情意记了下来，如果在异时异地的圜局中去看，所会引起的反应很难尽合于当时当地的圜局中可能引起的反应。文字之成为传情达意的工具常有这个无可补救的缺陷。于是在利用文字时，我们要讲究文法，讲究艺术。文法和艺术就在减少文字的“走样”。 语言只能在一个社群所有的相同经验的一层上发生。群体愈大，包括的人所有的经验愈繁杂，发生语言的一层共同基础也必然愈有限，于是语言也愈趋于简单化。这在语言史上是看得很清楚的。 于是在熟人中，我们话也少了，我们“眉目传情”，我们“指石相证”，我们抛开了比较间接的象征原料，而求更直接的会意了。所以在乡土社会中，不但文字是多余的，连语言都并不是传达情意的唯一象征体系。</p>
</blockquote>
<h1 id="再论文字下乡">再论文字下乡</h1>
<blockquote>
<p>所谓时间上的阻隔有两方面：一方面是个人的今昔之隔；一方面是社会的世代之隔。让我先从前一方面说起。</p>
</blockquote>
<h1 id="差序格局">差序格局</h1>
<blockquote>
<p>为什么我们这个最基本的社会单位的名词会这样不清不楚呢？在我看来却表示了我们的社会结构本身和西洋的格局是不相同的，我们的格局不是一捆一捆扎清楚的柴，而是好像把一块石头丢在水面上所发生的一圈圈推出去的波纹。每个人都是他社会影响所推出去的圈子的中心。被圈子的波纹所推及的就发生联系。每个人在某一时间某一地点所动用的圈子是不一定相同的。 伦重在分别，在《礼记》祭统里所讲的十伦：鬼神、君臣、父子、贵贱、亲疏、爵赏、夫妇、政事、长幼、上下，都是指差等。“不失其伦”是在别父子、远近、亲疏。伦是有差等的次序。在我们现在读来，鬼神、君臣、父子、夫妇等具体的社会关系，怎能和贵贱、亲疏、远近、上下等抽象的相对地位相提并论？其实在我们传统的社会结构里最基本的概念，这个人和人往来所构成的网络中的纲纪，就是一个差序，也就是伦。《礼记》大传里说：“亲亲也、尊尊也、长长也、男女有别，此其不可得与民变革者也。”意思是这个社会结构的架格是不能变的，变的只是利用这架格所做的事。 我们一旦明白这个能放能收、能伸能缩的社会范围就可以明白中国传统社会中的私的问题了。我常常觉得：“中国传统社会里一个人为了自己可以牺牲家，为了家可以牺牲党，为了党可以牺牲国，为了国可以牺牲天下。</p>
<h1 id="维系着私人的道德">维系着私人的道德</h1>
<p>在“团体格局”中，道德的基本观念建筑在团体和个人的关系上。团体是个超于个人的“实在”，不是有形的东西。我们不能具体地拿出一个有形体的东西来说这是团体。它是一束人和人的关系，是一个控制各个人行为的力量，是一种组成分子生活所依赖的对象，是先于任何个人而又不能脱离个人的共同意志……这种“实在”只能用有形的东西去象征它、表示它。在“团体格局”的社会中才发生笼罩万有的神的观念。团体对个人的关系就象征在神对于信徒的关系中，是个有赏罚的裁判者，是个公正的维持者，是个全能的保护者。 神对每个个人是公道的，是一视同仁的，是爱的；如果代理者违反了这些“不证自明的真理”，代理者就失去了代理的资格。团体格局的道德体系中于是发生了权利的观念。人对人得互相尊重权利，团体对个人也必须保障这些个人的权利，防止团体代理人滥用权力，于是发生了宪法。宪法观念是和西洋公务观念相配合的。国家可以要求人民的服务，但是国家也得保证不侵害人民的权利，在公道和爱护的范围内行使权力。 不但在我们传统道德系统中没有一个像基督教里那种“爱”的观念——不分差序的兼爱；而且我们也很不容易找到个人对于团体的道德要素。在西洋团体格局的社会中，公务，履行义务，是一个清楚明白的行为规范。而这在中国传统中是没有的。现在我们有时把“忠”字抬出来放在这位置上，但是忠字的意义，在《论语》中并不如此。我在上面所引“为人谋而不忠乎”一句中的忠，是“忠恕”的注解，是“对人之诚”。“主忠信”的忠，可以和衷字相通，是由衷之意。 中国的道德和法律，都因之得看所施的对象和“自己”的关系而加以程度上的伸缩。我见过不少痛骂贪污的朋友，遇到他的父亲贪污时，不但不骂，而且代他讳隐。更甚的，他还可以向父亲要贪污得来的钱，同时骂别人贪污。等到自己贪污时，还可以“能干”两字来自解。这在差序社会里可以不觉得是矛盾；因为在这种社会中，一切普遍的标准并不发生作用，一定要问清了，对象是谁，和自己是什么关系之后，才能决定拿出什么标准来。</p>
</blockquote>
<h1 id="家族">家族</h1>
<blockquote>
<p>家庭这概念在人类学上有明确的界说：这是个亲子所构成的生育社群。亲子指它的结构，生育指它的功能。亲子是双系的，兼指父母双方；子女限于配偶所生出的孩子。这社群的结合是为了子女的生和育。在由个人来担负孩子生育任务的社会里，这种社群是不会少的。但是生育的功能，就每个个别的家庭说，是短期的，孩子们长成了也就脱离他们的父母的抚育，去经营他们自己的生育儿女的事务，一代又一代。家庭这社群因之是暂时性的。从这方面说，家庭这社群和普通的社群不完全一样。学校、国家这些社群并不是暂时，虽则事实上也不是永久的，但是都不是临时性的，因为它们所具的功能是长期性的。家庭既以生育为它的功能，在开始时就得准备结束。抚育孩子的目的就在结束抚育。关于这一层意思我在《生育制度》一书中有详细的讨论。 中国的家是一个事业组织，家的大小是依着事业的大小而决定的。如果事业小，夫妇两人的合作已够应付，这个家也可以小得等于家庭；如果事业大，超过了夫妇两人所能担负时，兄弟伯叔全可以集合在一个大家里。这说明了我们乡土社会中家的大小变异可以很甚。但不论大小上差别到什么程度，结构原则上却是一贯的、单系的差序格局。</p>
</blockquote>
<h1 id="男女有别">男女有别</h1>
<blockquote>
<p>感情从心理方面说是一种体内的行为，导发外表的行为。 社会秩序范围着个性，为了秩序的维持，一切足以引起破坏秩序的要素都被遏制着。男女之间的鸿沟从此筑下。乡土社会是个男女有别的社会，也是个安稳的社会。</p>
</blockquote>
<h1 id="礼治秩序">礼治秩序</h1>
<blockquote>
<p>所谓人治和法治之别，不在人和法这两个字上，而是在维持秩序时所用的力量，和所根据的规范的性质。 礼是社会公认合式的行为规范。合于礼的就是说这些行为是做得对的，对是合式的意思。如果单从行为规范一点说，本和法律无异，法律也是一种行为规范。礼和法不相同的地方是维持规范的力量。法律是靠国家的权力来推行的。“国家”是指政治的权力，在现代国家没有形成前，部落也是政治权力。而礼却不需要这有形的权力机构来维持。维持礼这种规范的是传统。 文化本来就是传统，不论哪一个社会，绝不会没有传统的。衣食住行种种最基本的事务，我们并不要事事费心思，那是因为我们托祖宗之福，一一有着可以遵守的成法。但是在乡土社会中，传统的重要性比现代社会更甚。那是因为在乡土社会里传统的效力更大。 礼并不是靠一个外在的权力来推行的，而是从教化中养成了个人的敬畏之感，使人服膺；人服礼是主动的。礼是可以为人所好的，所谓“富于好礼”。孔子很重视服礼的主动性，在下面一段话里说得很清楚： 礼治的可能必须以传统可以有效地应付生活问题为前提。乡土社会满足了这前提，因之它的秩序可以用礼来维持。在一个变迁很快的社会，传统的效力是无法保证的。不管一种生活的方法在过去是怎样有效，如果环境一改变，谁也不能再依着法子去应付新的问题了。所应付的问题如果要由团体合作的时候，就得大家接受个同意的办法，要保证大家在规定的办法下合作应付共同问题，就得有个力量来控制各个人了。这其实就是法律。也就是所谓“法治”。</p>
</blockquote>
<h1 id="无讼">无讼</h1>
<blockquote>
<p>但是在乡土社会的礼治秩序中做人，如果不知道“礼”，就成了撒野，没有规矩，简直是个道德问题，不是个好人。一个负责地方秩序的父母官，维持礼治秩序的理想手段是教化，而不是折狱。如果有非打官司不可，那必然是因为有人破坏了传统的规矩。在旧小说上，我们常见的听讼，亦称折狱的程序是：把“犯人”拖上堂，先各打屁股若干板，然后一方面大呼冤枉。父母官用了他“看相”式的眼光，分出那个“獐头鼠目”，必非好人，重加呵责，逼出供状，结果好恶分辨，冤也伸了，大呼青天。——这种程序在现代眼光中，会感觉到没有道理；但是在乡土社会中，这却是公认正当的。否则为什么这类记载，《包公案》、《施公案》等等能成了传统的畅销书呢？</p>
</blockquote>
<h1 id="无为政治">无为政治</h1>
<blockquote>
<p>甲团体想用权力来统治乙团体以谋得经济利益，必须有一前提：就是乙团体的存在可以供给这项利益；说得更明白一些，乙团体的生产量必须能超过他的消费量，然后有一些剩余去引诱甲团体来征服他。这是极重要的。一个只有生产他生存必需的消费品的人是并没有资格做奴隶的。我说这话意思是想指出农业社会中横暴权力的限制。在广西瑶山里调查时，我常见到汉人侵占瑶人的土地，而并不征服瑶人来作奴隶。原因当然很多，但主要的一个，依我看来，是土地太贫乏，而种水田的瑶人，并不肯降低生活程度，做汉人的佃户。如果瑶人打不过汉人，他们就放弃土地搬到别处去。在农业民族的争斗中，最主要的方式是把土著赶走而占据他们的土地自己来耕种。尤其是在人口已经很多、劳力可以自足、土地利用已到了边际的时候更是如此。我们读历史，常常可以找到“坑卒几万人”之类的记录，至于见人便杀的流寇，一直到不久之前还是可能遭遇的经验。这种情形大概不是工业性的侵略权力所能了解的。</p>
</blockquote>
<h1 id="长老统治">长老统治</h1>
<blockquote>
<p>社会继替，就是社会分工的世代交替。“在人寿有限、生死无常的变动中，一个人的生活却依赖于一个完整的社会分工结构，所以社会不能不不断地预备下新人物等着去接替旧人物死亡和退伍所发生的缺位。 教化性的权力虽则在亲子关系里表现得最明显，但并不限于亲子关系。凡是文化性的，不是政治性的强制都包含这种权力。文化和政治的区别就在这里：凡是被社会不成问题地加以接受的规范，是文化性的；当一个社会还没有共同接受一套规范，各种意见纷呈，求取临时解决办法的活动是政治。文化的基础必须是同意的，但文化对于社会的新分子是强制的，是一种教化过程。</p>
</blockquote>
<h1 id="血缘和地缘">血缘和地缘</h1>
<blockquote>
<p>缺乏变动的文化里，长幼之间发生了社会的差次，年长的对年幼的具有强制的权力。这是血缘社会的基础。血缘的意思是人和人的权利和义务根据亲属关系来决定。亲属是由生育和婚姻所构成的关系。血缘，严格说来，只指由生育所发生的亲子关系。事实上，在单系的家庭组织中所注重的亲属确多由于生育而少由于婚姻，所以说是血缘也无妨。 在亲密的血缘社会中商业是不能存在的。这并不是说这种社会不发生交易，而是说他们的交易是以人情来维持的，是相互馈赠的方式。实质上馈赠和贸易都是有无相通，只在清算方式上有差别。以馈赠来经营大规模的易货在太平洋岛屿间还可以看得到。Malinowski所描写和分析的kula制度就是一个例证。但是这种制度不但复杂，而且很受限制。普通的情形是在血缘关系之外去建立商业基础。在我们乡土社会中，有专门作贸易活动的街集。街集时常不在村子里，而在一片空场上，各地的人到这特定的地方，各以“无情”的身份出现。在这里大家把原来的关系暂时搁开，一切交易都得当场算清。我常看见隔壁邻舍大家老远的走上十多里在街集上交换清楚之后，又老远地背回来。他们何必到街集上去跑这一趟呢，在门前不是就可以交换的么？这一趟是有作用的，因为在门前是邻舍，到了街集上才是“陌生”人。当场算清是陌生人间的行为，不能牵涉其他社会关系的。</p>
</blockquote>
<h1 id="名实的分离">名实的分离</h1>
<h1 id="从欲望到需要">从欲望到需要</h1>
<blockquote>
<p>同样的，你在远处看，每天人都在吃淀粉、脂肪，吃维他命A、维他命C，一篇很长的单子，你又回去在实验室研究了一下，发现一点不错，淀粉供给热料，维他命A给人这个那个——合于营养，用以维持生命。但是你去找一个不住在现代都市的乡下佬问他，为什么吃辣子、大蒜，他会回答你：“这才好吃，下饭的呀。” 在现代社会里知识即是权力，因为在这种社会里生活的人要依他们的需要去做计划。从知识里得来的权力是我在上文中所称的时势权力；乡土社会是靠经验的，他们不必计划，因为时间过程中，自然替他们选择出一个足以依赖的传统的生活方案。各人依着欲望去活动就得了。</p>
</blockquote>
<h1 id="后记">后记</h1>
<blockquote>
<p>社会学能不能成为一门特殊的社会科学其实还是一个没有解决的问题。这里牵涉到了社会科学领域的划分。如果我们承认政治学、经济学有它们特殊的领域，我们也就承认了社会科学可以依社会制度加以划分：政治学研究政治制度，经济学研究经济制度等。社会现象能分多少制度也就可以成立多少门社会科学。现在的社会学，从这种立场上说来，只是个没有长成的社会科学的老家。一旦长成了，羽毛丰满，就可以闹分家，独立门户去了。这个譬喻确实是说明了现代社会学中的一个趋势。</p>
</blockquote>
<h1 id="附录">附录</h1>
<blockquote>
<p>社会在自然的演化中是继生物世界而出现的一个新的但同样是实在的世界。这个世界是以生物体为基础的，正如生物体是以无生的有机体为基础一样。生命的开始，出现了生物界，生物群体的发展，出现了社会界。人还是动物，但已不是一般的动物，人的群体已不是一般的群体，上升成为社会。从这个角度来看，社会本身是个实体，生物人不能认为是社会的实体，而只是社会的载体。没有生物人，社会实体无法存在，等于说没有有机物质，生物实体无法存在一样。有机物质是生命的载体，生物人是社会的载体。实体和载体不同，实体有自己发展的规律，它可以在载体的新陈代谢中继续存在和发展。正如一个生物人是由无数细胞组成，个别细胞的生死，不决定整个人的寿命。个人的生命正是靠其机体细胞的不断更新而得以延续。同样的社会里的个别成员，因其尚属生物体，还是受生物规律的支配，有生有死，但并不决定社会群体兴衰存亡。因之，生物实体和社会实体是属于自然演化过程中的两个层次。人有两个属性：生物人和社会人。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>社会学</tag>
      </tags>
  </entry>
  <entry>
    <title>在我成为井井有条的大人之前</title>
    <url>/posts/d040ebe8.html</url>
    <content><![CDATA[<p>马上就要到我的24岁生日了，最近特别喜欢这首歌，就拿它当了标题。</p>
<p>也许是真的长大了吧，开始怀念小时候，开始怀念大学，怀念那个时候的自己。</p>
<p>越长大就越怀念当时那个富有激情，无所畏惧，充满希望，有头发脑子好用还有人喜欢的自己。</p>
<blockquote>
<p>以前念着要快长大</p>
<p>现在好想返老还童</p>
<p>未曾珍惜过的天真</p>
<p>成为有遗憾的回不去</p>
<p>以前仗着时间还多</p>
<p>不知不觉中我挥霍</p>
<p>还没来得及好好爱过一个人</p>
<p>就老去了</p>
</blockquote>
<a id="more"></a>
<h1 id="再也没有吃到像那夜的好豆再也没有看到像那夜的好戏了"><a class="markdownIt-Anchor" href="#再也没有吃到像那夜的好豆再也没有看到像那夜的好戏了"></a> 再也没有吃到像那夜的好豆，再也没有看到像那夜的好戏了</h1>
<p>长大一个最突出的特征就是对于高中和大学学过的无用之学的理解。</p>
<p>去年这个时候疫情刚刚开始，各种治病的假消息，例如板蓝根，双黄连，假中医，甚嚣尘上。我试图用最简单的语言跟父母家人和文科朋友们解释什么是病毒🦠，怎么治病，双黄连板蓝根为什么不管用，疫苗什么时候才能出来，才发现这些知识大部分都涵盖在初中和高中的课本里。就突然开始感觉到九年义务教育的另一重含义——教会我们在现在这个社会所需要的最基本的科学常识和文化常识。只是从结果来看，国家的九年义务教育实施的还不完善罢了。当然了美国也没好到哪去，注射💉84消毒液比板蓝根更尼玛离谱。</p>
<p>无用之学最突出的就是政治。学个数学物理我好歹会算数以及知道开车的时候为什么要保持安全距离，学个化学我至少买药买吃的会看配料表，学个生物好歹不用花冤枉钱买板蓝根，语文英语不至于是文盲，历史地理好歹出去旅游的时候能讲出来点东西。但是政治呢？政治有什么用处呢？除了高中的时候我读了一点点哲学入门稍微引起了我的兴趣，更多的时候我都觉得他很无聊，讲的都是空话套话。</p>
<p>直到2020年。</p>
<p>因为疫情原因，我开始思考各个国家为什么会做出截然相反的应对措施，直到思考到各个国家的政治经济体制，资本主义与社会主义，再到马克思主义。</p>
<p>中间我开始尝试理财，也关注了原油的事件，于是开始关注经济学，开始关注贸易，开始了解布雷顿森林体系，经济危机，消费主义，贸易自由，巴塞尔协议这一个个对我来说似曾相识，但是当时只是背了下来的东西。</p>
<p>后面则是慢慢整合了起来，开始思考政府的存在，政府的管理，言论自由和行动自由，偶像经济，剩余价值，资本主义体系存在的问题，赛博朋克，也经常去听罗翔老师的课程，开始思考法律，思考一些诸如劳资关系，教育等等的社会问题，思考人生的意义。</p>
<blockquote>
<p>“Man Thinks; God Laughs.”</p>
</blockquote>
<p>同时还有历史和地理。最近几年一直在看国家宝藏和国宝会说话等等一些考古文博节目，于是发现高中不喜欢历史的我居然本质上是因为我支持了历史虚无主义。现在我觉得相比于哪那年发生了什么事，历史虚无主义才是历史教育中最需要讲好的东西。而我的研究范畴也从过去的生物生态转换到了更大的也更喜欢的海洋学领域，于是开始慢慢理解过去学过的地理知识，比如季风洋流，三横五纵；同时也开始将地理与政治经济联合起来，思考和查阅过经济类型和国家应对疫情的原因。</p>
<p>之前大学的时候常常听别人说，理工科最好再学一些人文社会的东西。当时我只是觉得很有道理，却没有体会到为什么，因此只是借了书，注册了网课，却一点都没学。现在才开始了解为什么，并且有了学习的motivation。</p>
<p>最大的理解，还是对于语文的理解。除了因为破除历史虚无主义带来的对与文脉传承的使命感，更多的是，终于读懂了语文课本的课文和诗词。</p>
<p>少小离家老大回，</p>
<p>乡音无改鬓毛衰。</p>
<p>儿童相见不相识，</p>
<p>笑问客从何处来。</p>
<blockquote>
<p>但愿人长久，千里共婵娟。</p>
</blockquote>
<p>大学还是在同一个省份，想家的感情并不强烈，出来之后，才深切的体会到这一句句诗里，到底在写什么。</p>
<blockquote>
<p>高邮咸蛋的特点是质细而油多。蛋白柔嫩，不似别处的发干、发粉，入口如嚼石灰。油多尤为别处所不及。鸭蛋的吃法，如袁子才所说，带壳切开，是一种，那是席间待客的办法。平常食用，一般都是敲破“空头”用筷子挖着吃。筷子头一扎下去，吱——红油就冒出来了。高邮咸蛋的黄是通红的。苏北有一道名菜，叫做“朱砂豆腐”，就是用高邮鸭蛋黄炒的豆腐。我在北京吃的咸鸭蛋，蛋黄是浅黄色的，这叫什么咸鸭蛋呢！端午节，我们那里的孩子兴挂“鸭蛋络子”。头一天，就由姑姑或姐姐用彩色丝线打好了络子。端午一早，鸭蛋煮熟了，由孩子自己去挑一个，鸭蛋有什么可挑的呢！有！一要挑淡青壳的。鸭蛋壳有白的和淡青的两种。二要挑形状好看的。别说鸭蛋都是一样的，细看却不同。有的样子蠢，有的秀气。挑好了，装在络子里，挂在大襟的纽扣上。这有什么好看呢？然而它是孩子心爱的饰物。鸭蛋络子挂了多半天，什么时候孩子一高兴，就把络子里的鸭蛋掏出来，吃了。端午的鸭蛋，新腌不久，只有一点淡淡的咸味，白嘴吃也可以。</p>
</blockquote>
<p>在我从淘宝买了十斤煎饼之后，终于开始理解什么是家乡的味道。</p>
<blockquote>
<p>“阿！闰土哥，——你来了？……”</p>
<p>我接着便有许多话，想要连珠一般涌出：角鸡，跳鱼儿，贝壳，猹，……但又总觉得被什么挡着似的，单在脑里面回旋，吐不出口外去。</p>
<p>他站住了，脸上现出欢喜和凄凉的神情；动着嘴唇，却没有作声。他的态度终于恭敬起来了，分明的叫道：</p>
<p>“老爷！……”</p>
<p>我似乎打了一个寒噤；我就知道，我们之间已经隔了一层可悲的厚障壁了。我也说不出话。</p>
</blockquote>
<p>小时候的同学，现在看来似乎已经是不同世界的人了。也许鲁迅这里的厚障壁指的是阶级，但是在我体会来却是人生的分叉。</p>
<blockquote>
<p>少年不识愁滋味，为赋新词强说愁。</p>
</blockquote>
<p>小时候矫揉造作的QQ空间和朋友圈，而现在终于明白了这些情感却说不出话来。</p>
<blockquote>
<p>影子在前，影子在后</p>
</blockquote>
<blockquote>
<p>影子常常跟着我，</p>
<p>就像一条小黑狗。</p>
<p>影子在左，影子在右，</p>
<p>影子常常陪着我，</p>
<p>它是我的好朋友</p>
</blockquote>
<p>开始享受独处，理解孤独。</p>
<blockquote>
<p>祥子的生活多半仗着这种残存的仪式与规矩。有结婚的，他替人家打着旗伞；有出殡的，他替人家举着花圈挽联；他不喜，也不哭，他只为那十几个铜子，陪着人家游街。穿上杠房或喜轿铺所预备的绿衣或蓝袍，戴上那不合适的黑帽，他暂时能把一身的破布遮住，稍微体面一些。遇上那大户人家办事，教一干人等都剃头穿靴子，他便有了机会使头上脚下都干净利落一回。脏病使他迈不开步，正好举着面旗，或两条挽联，在马路边上缓缓的蹭。</p>
<p>可是，连作这点事，他也不算个好手。他的黄金时代已经过去了，既没从洋车上成家立业，什么事都随着他的希望变成了“那么回事”。他那么大的个子，偏争着去打一面飞虎旗，或一对短窄的挽联；那较重的红伞与肃静牌等等，他都不肯去动。和个老人，小孩，甚于至妇女，他也会去争竞。他不肯吃一点亏。</p>
<p>打着那么个小东西，他低着头，弯着背，口中叼着个由路上拾来的烟卷头儿，有气无力的慢慢的蹭。大家立定，他也许还走；大家已走，他也许多站一会儿；他似乎听不见那施号发令的锣声。他更永远不看前后的距离停匀不停匀，左右的队列整齐不整齐，他走他的，低着头象作着个梦，又象思索着点高深的道理。那穿红衣的锣夫，与拿着绸旗的催押执事，几乎把所有的村话都向他骂去：“孙子！我说你呢，骆驼！你他妈的看齐！”他似乎还没有听见。打锣的过去给了他一锣锤，他翻了翻眼，朦胧的向四外看一下。没管打锣的说了什么，他留神的在地上找，看有没有值得拾起来的烟头儿。</p>
<p>体面的，要强的，好梦想的，利己的，个人的，健壮的，伟大的，祥子，不知陪着人家送了多少回殡；不知道何时何地会埋起他自己来，埋起这堕落的，自私的，不幸的，社会病胎里的产儿，个人主义的末路鬼！</p>
</blockquote>
<p>开始切身体会到祥子的三起三落，个人的力量在时代的浪潮面前是有多渺小。</p>
<blockquote>
<p>再也没有吃到像那夜的好豆，再也没有看到像那夜的好戏了</p>
</blockquote>
<p>再也，回不去了。</p>
<p>你好，24岁，我也要成为大人了。</p>
<p>我会不会成为我最讨厌的那种大人呢？</p>
<h1 id="你在教室灯光厚厚作业本下把我装成书签每刻都相逢"><a class="markdownIt-Anchor" href="#你在教室灯光厚厚作业本下把我装成书签每刻都相逢"></a> 你在教室灯光厚厚作业本下,把我装成书签每刻都相逢</h1>
<p>这句话出自《致每个你》的歌词，这首歌当时把我听哭了。因为它真实地描述了我和偶像的关系。</p>
<p>今天我想谈一谈偶像。</p>
<p>其实我是打算剪个视频出来的，看我有没有时间了。</p>
<p>第一次知道AKB是在<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMThzNDExbzc0Mw==">这个视频<i class="fa fa-external-link-alt"></i></span>里，当时还是在优酷，大概是在2013年，当时真的只是觉得，这个小姐姐真的好可爱，后续又看了一系列的她的舞蹈，开始知道了AKB的这个团体，但是当时连里面都有谁都不知道。</p>
<p>在兔子琳发布自己在日本的恋情之后，我也给他评论了好长一段。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115150238855.png" alt="在兔子琳视频下面的评论"></p>
<p>然后就通过优酷的视频推荐知道了SNH48，和其他人一样，我也是从汤敏和偶像预备生之半熟少女开始追起的。</p>
<p>无尽旋转，化作樱花树，黑白格子裙，马尾与发圈，石头剪刀布，爱的幸运曲奇，飞翔入手，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMTRzNDExQzd6Wj9wPTI=">十六人姐妹歌<i class="fa fa-external-link-alt"></i></span>。以及让我彻底入坑的，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXZhNHkxczdUYS8/c3BtX2lkX2Zyb209MzMzLjc4OC52aWRlb2NhcmQuMQ==">525星花为你绽放，支柱<i class="fa fa-external-link-alt"></i></span>。</p>
<p>从这首歌我开始知道赵嘉敏这个人，当时她对我来说就是那个坐在我前面班里的勤奋小女孩，学习好，还兼顾偶像的梦想。毫不客气的说她就是那个在当时支持着我走下去的人。</p>
<p>2014年5月6日，SNH48第一届总选举“一心向前”演唱会。</p>
<p>其实初中的我也没有那么多时间来追星，所以当时在这个演唱会上没有看到汤敏还是让我很震惊的，后来一番了解才知道汤敏退团了。本来其实我是想不再追的，但是看完了整个演唱会的我看到了这两个女孩子，也是支持我喜欢SNH48到现在的两个人。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXM0NDExZTdiNz9mcm9tPXNlYXJjaCZhbXA7c2VpZD0xMDQ2Mjk2NzE4OTQ2NjIyMzkxMA==">《第一只兔子》<i class="fa fa-external-link-alt"></i></span></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115151914979.png" alt="对不起娜娜我又截你崩图了"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030115152122569.png" alt="笑死了小四的我截的更崩"></p>
<p>当然更喜欢娜娜，元气，可爱，一心向前那一嗓子我到现在还留在脑子里。小四当时知道她是北影（后来才知道是独立学院）毕业之后，也很戳这个有一点智性恋的我。</p>
<p>当然了，高中的我是没有那么多时间追星的，更多的时候我还是被塞纳河的歌陪伴。毫不夸张地说，就是塞纳河和周杰伦支撑着我走过高中的每一个夜晚。</p>
<p>大学开始有空去看公演直播，当时只会看一下S和N队的。</p>
<p>其实后面我不知道该怎么写了。因为中间的快乐真的太多了，比如十八个挂科瞬间，曾艳芬。也有各种各样的感动，比如明珠48，还有各种周飞上公演。</p>
<p>正如我老板所说，我是个逻辑很差的人（摔）。</p>
<p>直到。</p>
<p>2018年2月3日。</p>
<p>Team XII解散，N队重组。</p>
<p>从那天开始，我对塞纳河的热情开始消失了。最主要的原因就是，我喜欢塞纳河真的是因为“梦想，汗水，坚持”，但是这次重组却让我感到，梦想汗水坚持，似乎是没有用了。每年都是那几个永远都不会被兑现的饼，投总选不如投小分队，再怎么努力该解散的还是解散，犯了错的小偶像却可以一句道歉就得到众人的原谅。</p>
<p>从那个时候开始，我好像不能从小偶像身上得到力量了。</p>
<p>我还记得我第一次也是最后一次去参加学院某个自称是最高奖项实际早已经内定完毕的奖项评选的时候，我们班班主任问我，到底是什么支持我每天早晨五点半起来赶校车去崂山上课。</p>
<p>我当时脑子里就全部都是《第一只兔子》，真的就是因为偶像的力量才让我那么努力。</p>
<p>但是当时脸皮薄的我并不能讲出来“SNH48 万丽娜” 这八个字。</p>
<p>2018年2月3日开始，万丽娜和林思意都开启了养老模式，我也是。</p>
<p>2018年3月2日，我和ex分手。ex也是一个元气满满的人，尽管我看得到她元气下面到底有什么。距离今天(1.15)刚好过去1050天。</p>
<p>2018年是我一个非常明显的人生转折点，大概是少年意气结束的阶段吧。</p>
<blockquote>
<p>当时我21岁，在我一生的黄金时代，我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过21岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。</p>
<p>–《黄金时代》</p>
</blockquote>
<p>长大的另一个特征，或许就是不能在别人身上得到力量了吧。或许说是，我开始依靠自己的力量支持自己前进。</p>
<p>就像欧布和泽塔最后在TV里用的都是最初的形态，他们不再借用前辈的力量，而我也不再借用她们的力量。</p>
<p>本来我觉得，虽然今年万丽娜和林思意都退团了，但是可爱的小偶像一茬接一茬，我总会喜欢新的。</p>
<p>但是谢蕾蕾谈恋爱这件事确实彻底摧毁了我的想法。</p>
<p>在18年之后这件事之前，我只是觉得梦想汗水坚持在塞纳河里没有用，但是我依然很敬佩她们的努力。</p>
<p>在这件事之后，我觉得这些，她们表现给我们这些，梦想汗水坚持，也可能只是她们出售给我们的商品而已。</p>
<p>所以2021年，就是我喜欢偶像的结束。微博上取关了四大，取关了大部分塞纳河的营销号，只留下了少数几个还在真心实意喜欢的小偶像，她们也即将毕业了。</p>
<p>2013-2021，整整八年时间。我真情实感地喜欢过小偶像，在她们的鼓励下一点点的努力成长。我看着整个团队越来越好，我也越来越好。</p>
<p>她们不再需要我，因为新来的粉丝各种应援技能和钱都比我厉害得多。</p>
<p>我也不再需要她们，因为我可以开始依靠我自己的力量，让我前进。</p>
<p>2020年1月1日去初詣的时候，我曾经许愿2020年的愿望就是找到那个像那天的太阳一样让我在半夜三四点就能起来的东西。</p>
<p>从初高中开始到2018年，它曾经是周杰伦，塞纳河；是那个化学竞赛失败转文科的男生，那些《我们都不是神的孩子》《花开不败》《你凭什么上北大》的主人公；是高绩点，是竞赛，是小镇做题家的好胜心。</p>
<p>2018年之后，它就消失了。</p>
<p>其实我现在也没有找到它。</p>
<p>但是我已经能慢慢的依靠自己的力量坚持下去。虽然我不知道这是因为我的热爱，还只是单单被迫学会的生存技能。</p>
<p>但是我不再需要偶像给予我力量了。</p>
<blockquote>
<p>听好了</p>
<p>你们</p>
<p>不要总是为了来看我而翘班</p>
<p>拼个优秀员工 和老板谈加薪 顺便旅游不更好吗</p>
<p>还有读书的小朋友就更是了</p>
<p>逃课挂科</p>
<p>不如考个好成绩</p>
<p>爸妈开心了才能快乐追星呀</p>
<p>每天窝在家里好不容易出门来看我了</p>
<p>排队的时候不要闷头总是换个地玩手机</p>
<p>多和周边的人聊一聊嘛</p>
<p>万一 就遇到自己的缘分了呢</p>
<p>还有哦</p>
<p>你们又没有上镜需求就不能好好吃饭啊</p>
<p>没有强大的化妆技术就给我好好睡觉</p>
<p>这方面饭随偶像干嘛呢啊</p>
<p>抽烟、喝酒的更是悠着点</p>
<p>我对气味很敏感的</p>
<p>小心你们来握手会的时候我盐你们</p>
<p>还有拍图、拍视频的时候退着走很危险的</p>
<p>下雨天更是</p>
<p>湿滑摔倒你人不怕</p>
<p>设备也是怕的好吗？</p>
<p>要先把自己的事情处理完才来看我嘛</p>
<p>我又不会跑</p>
<p>但是你的机会得自己好好把握啊</p>
<p>你要成为圈子里的巨聚 才能更好安利我不是？</p>
<p>更多的时候</p>
<p>也看看周边的人</p>
<p>偶像总是会有距离的</p>
<p>但他们才是无时无刻不陪在你身边的</p>
<p>还有那些我希望呵护到的人们</p>
<p>我只是你们的精神需求</p>
<p>但是好好生活、好好照顾自己才是你对自己最棒的拯救</p>
<p>我相信你，你可以做到的</p>
<p>最最最不佳，再看看这河里的瓜</p>
<p>每天吃瓜还不够开心的吗？</p>
<p>丧什么呢笨蛋嗯！</p>
<p>我没有办法顾及到所有的人，</p>
<p>但我真诚的希望你们每一个人都能幸福。</p>
<p>你们一定得清楚</p>
<p>你变得更好</p>
<p>全是你自己拼命努力的结果</p>
<p>你看我身上有光</p>
<p>是因为 你们的眼中 本身就充满了光芒</p>
<p>你们才是 自己的光</p>
<p>等到 你们的光芒足够亮</p>
<p>再看我</p>
<p>我应该 只是一个普通人</p>
<p>而你们真的很棒</p>
<p>– <span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMU02NHkxWjdkcA==">SNH48 一期生 莫寒 最后一次总选拉票会发言<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<h1 id="有些事现在不做-一辈子都不会做了"><a class="markdownIt-Anchor" href="#有些事现在不做-一辈子都不会做了"></a> 有些事现在不做 一辈子都不会做了</h1>
<p>这最后一部分我想谈谈选择。</p>
<p>出处很明显了吧哈哈哈，五月天的歌。</p>
<blockquote>
<p>每次冲动留下的 都有所不同</p>
<p>然而有天你会懂 就是那些 让你不同</p>
<p>每滴眼泪挣脱后 都带走懦弱</p>
<p>感动总在冲动后 苦涩回忆 都会温柔</p>
<p>每个平凡的自我 都曾幻想过</p>
<p>然而大多的自我 都紧抓着某个理由</p>
<p>每个渺小的理由 都困住自由</p>
<p>有些事情还不做 你的理由 会是什么？</p>
</blockquote>
<p>曾经喜欢小偶像的我非常看不起自己，因为相比于小偶像们一签八年的合同，我连五年的读博这件事都犹疑不决，拖延了很久不敢下决定。所以我一直认为我自己很懦弱，就像三年之前我在<a href="https://lifeodyssey.github.io/posts/726664aa.html">这里</a>写的一样。</p>
<p>我也<a href="https://lifeodyssey.github.io/posts/94a46e7b.html">犹疑了很久</a>。</p>
<p>回想起来，自己之前的多数决定都是出于情绪而做的决定</p>
<p>其实也就是这一章的内容让我不想把这个写了很久的东西转发到朋友圈（当然还有一些zzzq的内容），因为哪怕到了现在，我也不是很确定要不要读博，而且也因为不想为自己负责，选择把读博这个决定交给funding-能拿到funding就读，拿不到就不读，我压根对这个专业没有那么多热爱。</p>
<p>但是对自己的选择负责才是长大最重要的指标。</p>
<blockquote>
<p>“你得对着这新来的日子抱着虔敬的心。别想什么一年十年以后的事。你得想到今天。把你的理论统统丢开。所有的理论，哪怕是关于道德的，都是不好的，愚蠢的，对人有害的。别用暴力去挤逼人生。先过了今天再说。对每一天都得抱着虔诚的态度。得爱它，尊敬它，尤其不能污辱它，妨害它的发荣滋长。便是像今天这样灰暗愁闷的日子，你也得爱。你不用焦心。你先看着。现在是冬天，一切都睡着。将来大地会醒过来的。你只要跟大地一样，像它那样的有耐性就是了。你得虔诚，你得等待。如果你是好的，一切都会顺当的。如果你不行，如果你是弱者，如果你不成功，你还是应当快乐。因为那表示你不能再进一步。干吗你要抱更多的希望呢？干吗为了你做不到的事悲伤呢？一个人应当做他能做的事。 竭尽所能。”</p>
<p>真正的英雄是明白世界的残酷，也遭受了社会带给他的苦难，他依然能用心的说“我热爱这个世界，我愿竭尽所能去为我的世界而好好战斗”。</p>
</blockquote>
<p>认真的讲，我选择读博，只是因为我没有更好的选择了；但是不去多试一下，怎么知道自己有没有更好的选择呢。</p>
<p>还有就是，我的学生思维，我太怕落在别人后面，太过着重于和同龄人比较，同时也太过于看重稳定性和确定性。但是实质上，任何东西都是有代价的，就像做投资一样，你要稳定，你的收益就不可能高；你要高收益，你就要承受高风险。</p>
<p>我就是那个想要稳定，同时又羡慕着别人的高收益的人。</p>
<p>但是自己的选择，其实并不是那么具有稳定性和确定性。招聘要求一年年的水涨船高，现在自己看来没那么难的要求，后面可能就是遥不可及。现在要做一轮博后才能留校，后面可能就是两轮三轮，乃至千老，就像我们实验室的博后一样。</p>
<p>自己这一行还是一个重观测重实验的方向，算法再整出花来，没有什么办法实地验证，还是0，全国上下出得起海的的数来数去就海大厦大浙海大一所二所三所南海所。</p>
<p>稳定吗？一点都不。而且从今年（2021）开始公益类事业单位开始改革，编制取消。讲真的编制取消之后，还不如留在国外。</p>
<p>而且今年申请考核带来的水涨船高，4-5年后大概率是国内毕业的博士的爆发期。如果自己不能在4-5年内顺利毕业的话，大概率会面临另一轮高强度竞争，不论是post还是faculty。</p>
<p>自己喜欢这样的生活吗？基金，项目，论文，学生，评审。每天看着我老板奔波劳碌，但是感觉他很幸福。</p>
<p>自己喜欢目前的生活状态吗？</p>
<p>自己目前的生活状态，可是一点都不开心啊。</p>
<p>果然是想的越多，就会越不开心。</p>
<p>所以，读吗？</p>
<p>大概率还是会读的吧。希望这次我能做到对自己负责，成为一个大人。</p>
<p>接受这个选择所带来的后果。</p>
<h1 id="庚子鼠年腊月十九"><a class="markdownIt-Anchor" href="#庚子鼠年腊月十九"></a> 庚子鼠年腊月十九</h1>
<p>我的生日是一个很尴尬的时候，腊月十九。小学，初中，高中，大学，都一直是考试放假的时候。而且我喜欢过农历的生日（曾经被人吐槽像个古代人），别人更难记住我生日的日子。</p>
<p>所以一直没有（前几年开始，有了两三个）朋友同学记得我的生日。</p>
<p>之前其实因为这件事情自卑自闭，每年过生日的BGM都是<span class="exturl" data-url="aHR0cHM6Ly9jLnkucXEuY29tL2Jhc2UvZmNnaS1iaW4vdT9fXz12eFZyUDZ3">《祝我生日快乐》<i class="fa fa-external-link-alt"></i></span>。</p>
<blockquote>
<p>一个人坐在空荡包厢里面</p>
<p>手机 让它休息一夜</p>
<p>难 想切歌切掉回忆的画面</p>
<p>眼泪不能流过十二点</p>
<p>生日快乐 我对自己说</p>
<p>蜡烛点了 寂寞亮了</p>
<p>生日快乐 泪也融了</p>
<p>我要谢谢 你给的 你拿走的一切</p>
</blockquote>
<p>但是其实就是太矫情了，平均每天有三四十万人出生，你又不是含着金钥匙出生，别人没有必要非得记得你。</p>
<p>这只是一个普普通通的日子，你也只是一个普普通通的人。</p>
<p>今天也没有什么特殊的活动，一个普普通通的研究生在实验室的普普通通的一天，还在为了发表和毕业头秃。</p>
<p>新的一岁，希望自己能对自己的选择负责，成为一个井井有条的大人。</p>
<p>每年过生日的时候都会把头像换成周杰伦和我一样大的时候发表的专辑封面，今年还是特意换的台版的专辑封面。</p>
<p>周杰伦24岁的时候发了《七里香》</p>
<p>我能发个论文嘛？</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>广义加性模型</title>
    <url>/posts/17683e80.html</url>
    <content><![CDATA[<h1 id="广义加性模型">广义加性模型</h1>
<p>去年这个时候准备SRDP立项就看到了一堆用广义加性模型的例子，国内关于这个的资源实在太少了，大半年之后我才开始学习用这玩意。把自己找到的各种参考文献整理一下作为学习笔记发出来，给别人一个方便。</p>
<a id="more"></a>
<p>（吐槽一句关于机器学习，感觉就是一个生造的概念，我在这里就把所有的这些东西称为统计学习——应用统计学的方法，让机器自行学习规律，然后给出结果。)</p>
<p>线性模型简单、只管、便于理解，但是很多时候在实际情况中并不能满足线性的假设。这时有两种方法，一个是通过降低模型的复杂度和估计量的方差来改善模型，另一种方法就是改变线性假设。由第二种方法引出的就是广义加性模型。</p>
<h2 id="gam-广义相加模型generalized-additive-model">GAM 广义相加模型Generalized additive model</h2>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 83%">
</colgroup>
<thead>
<tr class="header">
<th>项目</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>概念</td>
<td>回归模型中部分或全部的自变量采用平滑函数，降低线性设定带来的模型风险，对模型的假定不严，如不需要假定自变量线性相关于因变量（线性或非线性都可以）。</td>
</tr>
<tr class="even">
<td>方程</td>
<td>，<em>g</em>是一个链接函数，y是独立变量,为未知的光滑函数,代替经典线性回归中的，对样本要求少，适用性广</td>
</tr>
<tr class="odd">
<td>参数估计方法</td>
<td>最小二乘法，极大似然法</td>
</tr>
<tr class="even">
<td>检验</td>
<td>残差Pseduo系数(PCf)估计，PCf = 1 - RD / ND (RD残差偏差，ND 无效偏差)</td>
</tr>
<tr class="odd">
<td>分类</td>
<td>可加/非参数（Aditive/Nonparametric): 参数（Parametric): 半参数/部分线性（Semiparametric/Partial Linear）: 薄板样条（Thin-plate spline）：允许两个自变量里有交互作用</td>
</tr>
<tr class="even">
<td>前提</td>
<td>如x1和x2并非独立而存在交互作用，则应设为Thin-plate spline: f(x1, x2)（之所以有这一项是因为广义加性模型假定各项之间是相互独立的，这样计算最后的期望的时候就可以把他们加起来，如果不是相互独立的，需要手动设置交叉相互作用项） 模型中不必每一项都是非线性的，如都非线性会出现计算量大、过拟合等问题，通过查看xi与y的是否存在线性关系来判断是否使用平滑函数。 要遵循统计学和操作中的注意事项</td>
</tr>
<tr class="odd">
<td>光滑函数</td>
<td>见”样条函数”</td>
</tr>
<tr class="even">
<td>缺点</td>
<td>样条函数参数的不确定性使之不能直接用于预估新的数据</td>
</tr>
<tr class="odd">
<td>Q&amp;A</td>
<td>如何确定光滑项？ 这是个比较哲学的问题（掐死吧！） 1.计算每一种可能性，然后使用拟合效果最好的那个（利用一些标准来衡量，例如AIC） 2.使用最能够反应数据产生过程的那一个模型</td>
</tr>
</tbody>
</table>
<p>（参考<span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdGV4dGJveS9hcnRpY2xlL2RldGFpbHMvNDcyNzcxMzE=">http://blog.csdn.net/textboy/article/details/47277131<i class="fa fa-external-link-alt"></i></span>）</p>
<p>样条函数函数</p>
<p>我理解的这个模型就是说，和之间是线性关系，这样就可以使用线性回归的计算方法和检验方法来得到结果了，然后是一个平滑函数。这里样条函数是啥…对我就是不明白这一点，网上查到的资料说是和三次样条插值的那个函数差不多，但是这样不就变成插值了吗摔。</p>
<p>先给自己一个存疑，留待日后解决，然后更详细的参考资料如下</p>
<p><span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG9uZ3dlaWdhbmdscC9hcnRpY2xlL2RldGFpbHMvNTM0MjIzMjQ=">http://blog.csdn.net/tongweiganglp/article/details/53422324<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cDovL3d3dy5sb3lob21lLmNvbS8lZTIlODklYWElZTclYmIlOWYlZTglYWUlYTElZTUlYWQlYTYlZTQlYjklYTAlZTclYjIlYmUlZTglYTYlODF0aGUtZWxlbWVudHMtb2Ytc3RhdGlzdGljYWwtbGVhcm5pbmclZTIlODklYWIlZTglYWYlYmUlZTUlYTAlODIlZTclYWMlOTQlZTglYWUlYjAlZWYlYmMlODglZTUlOGQlODElZTQlYmElOGMlZWYlYmMlODkv">http://www.loyhome.com/%e2%89%aa%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%b2%be%e8%a6%81the-elements-of-statistical-learning%e2%89%ab%e8%af%be%e5%a0%82%e7%ac%94%e8%ae%b0%ef%bc%88%e5%8d%81%e4%ba%8c%ef%bc%89/<i class="fa fa-external-link-alt"></i></span></p>
<p>mgcv manual</p>
<p>Generalized Additive Models:An inroduction with R</p>
<h1 id="aic-bic-roc与auc">AIC BIC ROC与AUC</h1>
<p>任何一个统计学方法都会有过拟合欠拟合的问题，在吴恩达的课程里给出来了一种比较直观的感性的判断方式（以后会整理的抱头鼠窜）在这里介绍另一类方法，通过一个评价的函数来p安短，这里给出其中三种：AIC、BIC和ROC与AUC</p>
<p>（其实还有交叉验证方法，在后一个吴老师课程里讲的非常详细我也会整理的抱头鼠窜）</p>
<h2 id="aic">AIC</h2>
<p>AIC是衡量统计模型拟合优良性的一种标准，由日本统计学家赤池弘次在1974年提出，它建立在熵的概念上，提供了权衡估计模型复杂度和拟合数据优良性的标准。</p>
<p>通常情况下，AIC定义为：</p>
<p>其中k是模型参数个数，L是似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。假设条件是模型的误差服从独立正态分布。 让n为观察数，RSS为剩余平方和,则AIC变为：</p>
<p>当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上式第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。</p>
<p>一般而言，当模型复杂度提高（k增大）时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。目标是选取AIC最小的模型，AIC不仅要提高模型拟合度（极大似然），而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。</p>
<h2 id="bic">BIC</h2>
<p>BIC（Bayesian InformationCriterion）贝叶斯信息准则与AIC相似，用于模型选择，1978年由Schwarz提出。训练模型时，增加参数数量，也就是增加模型复杂度，会增大似然函数，但是也会导致过拟合现象，针对该问题，AIC和BIC均引入了与模型参数个数相关的惩罚项，BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。</p>
<p>其中，k为模型参数个数，n为样本数量，L为似然函数，kln(n)惩罚项在维数过大且训练样本数据相对较少的情况下，可以有限避免出现维度灾难现象。</p>
<h2 id="roc与auc-衡量分类器的好坏">ROC与AUC-衡量分类器的好坏</h2>
<h3 id="二元分类器">二元分类器</h3>
<p>二元分类器是指要输出(预测)的结果只有两种类别的模型。例如预测阳性/阴性，有病/没病，在银行信用评分模型中，也用来预测用户是否会违约，等等。</p>
<p>  既然是一种预测模型，则实际情况一定是有些结果猜对了，有些结果猜错了。因为二元分类器的预测结果有两种类别(以下以阴/阳为例)，对应其真实值，则会有以下四种情形:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Actual</th>
<th>class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>predict</td>
<td>true positive</td>
<td>false positive</td>
</tr>
<tr class="even">
<td>class</td>
<td>false negative</td>
<td>true negative</td>
</tr>
</tbody>
</table>
<p><a href="http://beader.me/imgs/auc-roc/9686a1f19149fe16eb4b6b383904d086.png"><img src="http://beader.me/imgs/auc-roc/9686a1f19149fe16eb4b6b383904d086.png" alt="img"></a></p>
<p>图1.confusion matrix (混乱矩阵)</p>
<p>精确率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是对的。召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。</p>
<p>当且仅当两者都高的时候，我们才可以说这种算法很NICE。在某些情况下我们可能要设定threshold来进行trade-off</p>
<ul>
<li>如果我们希望在很确信的情况下才告诉病人有cancer，也就是说不要给病人太多惊吓，我告诉你有cancer，你肯定有cancer；我告诉你没cancer，你也有可能有cancer，那么该情况下有：higher threshold，higher precision，lower recall</li>
<li>如果我们不希望让病人错过提前治疗，与上例相反，就有：lower threshold，lower precision，higher recall</li>
</ul>
<p>除此之外，还有另外一个评价标准来进行trade-off</p>
<p>越大越好</p>
<h3 id="roc空间与roc曲线">ROC空间与ROC曲线</h3>
<p>在信号检测理论中，接收者操作特征曲线（receiver operating characteristic curve，或者叫<span class="exturl" data-url="aHR0cDovL3poLndpa2lwZWRpYS5vcmcvd2lraS9ST0MlRTYlOUIlQjIlRTclQkElQkY=">ROC曲线<i class="fa fa-external-link-alt"></i></span>）是一种座标图式的分析工具。  要了解ROC曲线，先要了解一下ROC空间，ROC空间是一个以伪阳性率(FPR, false positive rate)为X轴，真阳性率(TPR, true positive rate)为Y轴的二维坐标系所代表平面。</p>
<ul>
<li>TPR: 真阳性率，所有阳性样本中(TP+FN)，被分类器正确判断为阳的比例。TPR = TP / (TP + FN) = TP / 所有真实值为阳性的样本个数</li>
<li>FPR: 伪阳性率，所有阴性样本中(FP+TN)，被分类器错误判断为阳的比例。FPR = FP / (FP + TN) = FP / 所有真实值为阴性的样本个数</li>
</ul>
<p>  我们想象这样一种场景，接触阳性样本可以给我们带来“收益”，接触阴性样本则会给我们造成”成本”。并且如果我们接触样本中所有的阳性样本，我们的收益是1，接触样本中的所有阴性样本，我们的成本也是1。如果不接触样本，则既不产生收益也不产生成本。  自然的，如果不使用分类器，接触所有样本，则总的效益为1-1=0。现在让我们利用分类器来决定是否接触样本，分类器预测为阳，我们就去接触样本，分类器预测为阴，我们就不去接触。因为不接触样本不会产生收益或是成本，因此我们只需要看分类器预测为阳的样本。预测为阳的样本中，TP将产生 TPR 的收益， FP将产生FPR的成本。  那么一个分类器的分类效果就对应ROC空间里的一个点:</p>
<p><a href="http://beader.me/imgs/auc-roc/1a02adedd70816dcd49461354390aaed.png"><img src="http://beader.me/imgs/auc-roc/1a02adedd70816dcd49461354390aaed.png" alt="img"></a></p>
<p>图2.ROC空间</p>
<p>A,B,C三个点可以分别代表三个不同的分类器对同样的样本做预测的结果。最好的方法是A，因为他的收益大于成本(TPR &gt; FPR)，最差的是C(TPR &lt; FPR)。中等的是B，相当于随机分类器。这里有趣的一点是若把C以(0.5, 0.5)为中点作一个镜像，得到C’， C’的效果比A要来的好。C’相当于一个做与C预测结果完全相反的分类器。  实际的应用当中，分类器还会给出它预测某个样本为阳的概率，并且有一个事先给定的门槛值(threshold)，概率高于threshold的就预测为阳性，低于threshold的就预测为阴性。假设以下是某个分类器对id为1-10的客户的分类结果:</p>
<p>表1.分类器预测结果</p>
<p><a href="http://beader.me/imgs/auc-roc/95ccbafd95b1ef894b2711d3698d5187.png"><img src="http://beader.me/imgs/auc-roc/95ccbafd95b1ef894b2711d3698d5187.png" alt="img"></a></p>
<p>其中probability of 1为分类器判断该样本为阳性的概率，true class为该样本的真实情况。  如果我们把threshold定位0.5，即去接触id为1~8的客户。此时</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TPR &#x3D; TP &#x2F; 所有真实值为阳性的样本个数 &#x3D; 6 &#x2F; 6 &#x3D; 1</span><br><span class="line">FPR &#x3D; FP &#x2F; 所有真实值为阴性的样本个数 &#x3D; 2 &#x2F; 4 &#x3D; 0.6</span><br></pre></td></tr></table></figure>
<p>同理，如果我们把threshold定位0.8，即去接触id为1~5的客户。此时</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TPR &#x3D; TP &#x2F; 所有真实值为阳性的样本个数 &#x3D; 4 &#x2F; 6 &#x3D; 0.67</span><br><span class="line">FPR &#x3D; FP &#x2F; 所有真实值为阴性的样本个数 &#x3D; 1 &#x2F; 4 &#x3D; 0.25</span><br></pre></td></tr></table></figure>
<p>  这两个threshold分别对应ROC空间中的两个点A、B</p>
<p><a href="http://beader.me/imgs/auc-roc/f3aac8b8603adb924363e766992df3cd.png"><img src="http://beader.me/imgs/auc-roc/f3aac8b8603adb924363e766992df3cd.png" alt="img"></a></p>
<p>图3.不同的threshold对应ROC空间中不同的点</p>
<p>上面的例子当中，共有10笔预测数据，则一共有11种threshold的设定方法，每一个threshold对应ROC空间中的一个点，把这些点连接起来，就成了ROC曲线。</p>
<p><a href="http://beader.me/imgs/auc-roc/92175e2de4a480e52938a836994e823c.png"><img src="http://beader.me/imgs/auc-roc/92175e2de4a480e52938a836994e823c.png" alt="img"></a></p>
<p>图4.ROC曲线</p>
<p>  这里因为数据量太少，所以曲线是一折一折的，数据量大的时候，看上去才像”曲线”。</p>
<h3 id="auc">AUC</h3>
<p>(Area under the Curve of ROC) 曲线下面积</p>
<p>以下直接搬维基百科:</p>
<ul>
<li>因为是在1x1的方格里求面积，AUC必在0~1之间。</li>
<li>假设threshold以上是阳性，以下是阴性；</li>
<li>若随机抽取一个阳性样本和一个阴性样本，分类器正确判断阳性样本的值高于阴性样本之机率。(即前文当中把C做一个镜像变为C’)</li>
<li>简单说：AUC值越大的分类器，正确率越高。</li>
</ul>
<p>  从AUC判断分类器（预测模型）优劣的标准：</p>
<ul>
<li><p>AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。</p></li>
<li><p>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</p></li>
<li><p>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</p></li>
<li><p>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测，因此不存在AUC &lt; 0.5的情况。</p>
<p><a href="http://beader.me/imgs/auc-roc/f03add592a75ef5b5e7346a5209b0cb8.png"><img src="http://beader.me/imgs/auc-roc/f03add592a75ef5b5e7346a5209b0cb8.png" alt="img"></a></p>
<p>图5.用AUC来衡量不同分类器的分类能力(更准确的说是排序能力)</p>
<h3 id="总结">总结</h3>
<p>一个分类模型的分类结果的好坏取决于以下两个部分：</p>
<ol type="1">
<li>分类模型的排序能力(能否把概率高的排前面，概率低的排后面)</li>
<li>threshold的选择</li>
</ol>
<p>  使用AUC来衡量分类模型的好坏，可以忽略由于threshold的选择所带来的影响，因为实际应用中，这个threshold常常由先验概率或是人为决定的。</p>
<h3 id="补充gini-coefficient">补充：Gini coefficient</h3>
<p>在用SAS或者其他一些统计分析软件，用来评测分类器分类效果时，常常会看到一个叫做gini coefficient的东西，那么这个gini coefficient又是什么呢？gini系数通常被用来判断收入分配公平程度，具体请参阅<span class="exturl" data-url="aHR0cDovL3poLndpa2lwZWRpYS5vcmcvd2lraS8lRTUlOUYlQkElRTUlQjAlQkMlRTclQjMlQkIlRTYlOTUlQjA=">wikipedia-基尼系数<i class="fa fa-external-link-alt"></i></span>。<a href="http://beader.me/imgs/auc-roc/1a9a293ac6c97475ebb337fb32081a4d.png"><img src="http://beader.me/imgs/auc-roc/1a9a293ac6c97475ebb337fb32081a4d.png" alt="img"></a>  图6.洛伦茨曲线与基尼系数</p>
<p>  Gini coefficient 是指绝对公平线(line of equality)和洛伦茨曲线(Lorenz Curve)围成的面积与绝对公平线以下面积的比例，即gini coefficient = A面积 / (A面积+B面积) 。</p>
<p>  用在评判分类模型的预测效力时，是指ROC曲线曲线和中线围成的面积与中线之上面积的比例。</p>
<p><a href="http://beader.me/imgs/auc-roc/074c46dccea3031e5ce8fcbb67453cd4.png"><img src="http://beader.me/imgs/auc-roc/074c46dccea3031e5ce8fcbb67453cd4.png" alt="img"></a>  图7.Gini coefficient与AUC</p>
<p>因此Gini coefficient与AUC可以互相转换：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  </span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gini &#x3D; A &#x2F; (A + B) &#x3D; (AUC - C) &#x2F; (A + B) &#x3D; (AUC -0.5) &#x2F; 0.5 &#x3D; 2*AUC - 1</span><br></pre></td></tr></table></figure></li>
</ul>
<p>参考 ：</p>
<p><span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGZkYW5kaW5nL2FydGljbGUvZGV0YWlscy81MDczMjc2Mj9sb2NhdGlvbk51bT04JmFtcDtmcHM9MQ==">http://blog.csdn.net/lfdanding/article/details/50732762?locationNum=8&amp;fps=1<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cDovL2JlYWRlci5tZS8yMDEzLzEyLzE1L2F1Yy1yb2Mv">http://beader.me/2013/12/15/auc-roc/<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="r语言实现">R语言实现</h2>
<h3 id="r语言实现广义加性模型及相关函数">R语言实现广义加性模型及相关函数</h3>
<p>仅仅列出我最常用的几个 gam gam.check plot.gam predict.gam choose.k gam.selection</p>
<p>(给自己开了一个大坑啊，不知道能不能在生态学下课之前写完)</p>
<p>（看来是写不完了，要下课了…)</p>
<p>这一部分参考了manual和 R语言实现广义加性模型 Generalized Additive Models(GAM) 入门</p>
<h5 id="实现和画图">1.实现和画图</h5>
<p>R语言官网：<span class="exturl" data-url="aHR0cDovL3d3dy5yLXByb2plY3Qub3JnLw==">http://www.r-project.org/<i class="fa fa-external-link-alt"></i></span></p>
<p>R语言软件下载：<span class="exturl" data-url="aHR0cDovL2Z0cC5jdGV4Lm9yZy9taXJyb3JzL0NSQU4v">http://ftp.ctex.org/mirrors/CRAN/<i class="fa fa-external-link-alt"></i></span> 注：下载时点击 install R for the first time</p>
<p>下面进行一个简单的入门程序学习。</p>
<p>先新建一个txt，叫做 Rice_insect.txt，内容为：</p>
<p><a href="https://lifeodyssey.github.io/home/zhenjiazhou/%E5%9B%BE%E7%89%87/%E9%80%89%E5%8C%BA_002.bmp"><img src="https://lifeodyssey.github.io/home/zhenjiazhou/%E5%9B%BE%E7%89%87/%E9%80%89%E5%8C%BA_002.bmp" alt="选区_002"></a></p>
<p>　　Adult为累计蛾量，Day为降雨持续天数，Precipitation为降雨量。</p>
<p>输入代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(mgcv)      #加载mgcv软件包，因为gam函数在这个包里</span><br><span class="line">Data &lt;- read.delim(&quot;Rice_insect.txt&quot;)     #读取txt数据，存到Data变量中</span><br><span class="line">Data &lt;- as.matrix(Data)     #转为矩阵形式</span><br><span class="line">#查看Data数据：Data，查看第2列：Data[,2]，第2行：Data[2,]</span><br><span class="line"></span><br><span class="line">result1 &lt;- gam(log(Adult) ~ s(Day))     #此时，Adult为相应变量，Day为解释变量</span><br><span class="line">summary(result1)      #输出计算结果</span><br></pre></td></tr></table></figure>
<p>　　此时可以看到：</p>
<p>Family: gaussian Link function: identity</p>
<p>Formula:log(Adult) ~ s(Day)</p>
<p>Parametric coefficients:Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.9013 0.3562 22.18 4.83e-13 <strong>—Signif. codes: 0 ‘</strong>’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>Approximate significance of smooth terms:edf Ref.df F p-values(Day) 1.713 2.139 0.797 0.473</p>
<p>R-sq.(adj) = 0.0471 Deviance explained = 14.3%GCV score = 2.6898 Scale est. = 2.2844 n = 18</p>
<p>Day的影响水平p-value=0.473，解释能力为14.3%，说明影响不明显。</p>
<p>其中，edf为自由度，理论上，当自由度接近1时，表示是线性关系；当自由度比1大，则表示为曲线关系。</p>
<p>接下来使用另一个解释变量Precipitation。输入代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">result2 &lt;- gam(log(Adult) ~ s(Precipitation))</span><br><span class="line">summary(result2)</span><br></pre></td></tr></table></figure>
<p>　　发现：</p>
<p>Family: gaussian Link function: identity</p>
<p>Formula:log(Adult) ~ s(Precipitation)</p>
<p>Parametric coefficients:Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.9013 0.2731 28.94 1.87e-12 <strong>—Signif. codes: 0 ‘</strong>’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>Approximate significance of smooth terms:edf Ref.df F p-value s(Precipitation) 5.022 6.032 2.561 0.0774 .—Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>R-sq.(adj) = 0.44 Deviance explained = 60.6%GCV score = 2.0168 Scale est. = 1.342 n = 18</p>
<p>此时p-value为0.0774，说明该因子在P&lt;0.1水平下影响显著。（一般情况下p&lt;0.05为显著。）</p>
<p>接下来画图：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plot(result2,se&#x3D;T,resid&#x3D;T,pch&#x3D;16)</span><br></pre></td></tr></table></figure>
<p>　　<a href="file://tmp/wps-zhenjiazhou/ksohtml/wpsoAF24S.jpg"><img src="file://tmp/wps-zhenjiazhou/ksohtml/wpsoAF24S.jpg" alt="img"></a></p>
<p>pch=16这个是图标的序号，比如改成17就是三角形了。</p>
<p>log(Adult)中的log是什么意思呢?</p>
<p>log是数据变换，取对数可以把大范围的数变成小范围的数，这在将几组相差太大的数据画在同一个坐标轴时特别有用，比如一组数据范围是1～10，第二组数据范围是10～100000000，要是不对第二组取常用对数，第一组在坐标轴上只是一点点，都看不到，对第二组取常用对数后，第二组范围变成1～8了，这样两组数据都能看到了。</p>
<p>下面尝试将两个变量同时作为解释变量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">result3&lt;-gam(log(Adult)~s(Precipitation)+s(Day))</span><br></pre></td></tr></table></figure>
<p>　　出错：Model has more coefficients than data</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">result3&lt;-gam(log(Adult)~s(Precipitation,k&#x3D;9)+s(Day,k&#x3D;9)</span><br></pre></td></tr></table></figure>
<p>　　k是什么？</p>
<p>　　k is the dimension of the basis used to represent the smooth term. If k is not specified then basis specific defaults are used.</p>
<p>K的最小值是3，最大值是17，为3、4的时候都是直线，说明太小了体现不出来，在不断增大的过程中发现，K越大，曲线原来越平滑，再大时，曲线就出现了一些弯曲，说明更精准了，再大时，图形就基本不变了，说明也没必要设那么大了。</p>
<p>再</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">summary(result3)</span><br></pre></td></tr></table></figure>
<p>　　结果：</p>
<p>Family: gaussian Link function: identity</p>
<p>Formula:log(Adult) ~ s(Precipitation, k = 9) + s(Day, k = 9)</p>
<p>Parametric coefficients:Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.9013 0.2831 27.91 8.16e-12 <strong>—Signif. codes: 0 ‘</strong>’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>Approximate significance of smooth terms:edf Ref.df F p-value s(Precipitation) 4.653 5.572 2.546 0.0848 .s(Day) 1.000 1.000 0.500 0.4939 —Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>R-sq.(adj) = 0.398 Deviance explained = 59.8%GCV score = 2.288 Scale est. = 1.4423 n = 18</p>
<h5 id="其它函数">2.其它函数</h5>
<p>具体内容请查看manual</p>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 45%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>函数</th>
<th>描述</th>
<th>用法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>gam.check</td>
<td>采用由gam（）生成的拟合的gam对象来产生关于拟合程序和结果的一些诊断信息。 缺省情况是产生4个残差图，关于光滑性选择优化的收敛的一些信息，以及运行基本维度选择是否足够的诊断测试。 应用于由gamm返回的gam对象时应注意解释结果。</td>
<td>gam.check(b,old.style=FALSE, type=c(“deviance”, “pearson”, “response”), k.sample=5000,k.rep=200, rep=0, level=.9, rl.col=2, rep.col=”gray80”, …)参数说明见后</td>
</tr>
<tr class="even">
<td>predict.gam</td>
<td>采用由gam（）生成的拟合gam对象来给出一组新的用于模型协变量或用于模型拟合的原始值的预测值。 基于模型系数的后验分布，预测可以伴随着标准误差。 常规程序可以选择性地返回模型系数的矩阵，这个矩阵必须必须预先倍增（？？？），以便在所提供的协变量值处产生线性预测值的值：这对于从模型中获得的预测值获得置信区间是有用的（例如， 从平滑函数中衍生）以及R之外的查找表预测。</td>
<td>predict(object, newdata, type=”link”, se.fit=FALSE, terms=NULL, exclude=NULL, block.size=NULL, newdata.guaranteed=FALSE, na.action=na.pass,unconditional=FALSE,…)参数说明：object是预测出的模型，newdata是预测基于的自变量的值，注意一个是名字要和之前构建模型的名字一样，另一个是如果缺省，给出的结果是基于之前模型构建样本的因变量值，其余缺省即可</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>gam.check参数说明</p>
<table>
<thead>
<tr class="header">
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>b</td>
<td>由GAM模型产生的结果</td>
</tr>
<tr class="even">
<td>old.style</td>
<td>如果改成true得到word2006版本的图像（黑人问号脸）</td>
</tr>
<tr class="odd">
<td>type</td>
<td>餐叉的类型，具体参见residuals.gam</td>
</tr>
<tr class="even">
<td>k.sample</td>
<td>在这个k值水平上使用一个来自于样本的随机子集来测试</td>
</tr>
<tr class="odd">
<td>k.rep</td>
<td>多少次重新洗牌才能得到k测试的p值（黑人）</td>
</tr>
<tr class="even">
<td>rep, level, rl.col, rep.col</td>
<td>在old.style为false时传递给qq.gam（）的参数，请参阅qq.gam().</td>
</tr>
</tbody>
</table>
<p>剩余的图形参数请参见画图函数的参数</p>
<h4 id="r实现aic-bic-roc-auc">R实现AIC BIC ROC AUC</h4>
<p>非常简单！</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">AIC(object, ..., k &#x3D; 2)</span><br><span class="line"></span><br><span class="line">BIC(object, ...)</span><br></pre></td></tr></table></figure>
<p>ROC<span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc29sbzc3NzMvYXJ0aWNsZS9kZXRhaWxzLzg2OTk2OTM=">http://blog.csdn.net/solo7773/article/details/8699693<i class="fa fa-external-link-alt"></i></span></p>
<p>AUC <span class="exturl" data-url="aHR0cDovL3d3dy5haWNoZW5neHUuY29tL3B5dGhvbi84OTAwMzQyLmh0bWU=">http://www.aichengxu.com/python/8900342.htme<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>广义加性模型</tag>
        <tag>统计分析</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas基础</title>
    <url>/posts/50bcdc38.html</url>
    <content><![CDATA[<p>其实我一点儿都不想用pandas的dataframe，总感觉这个东西很难用，也许是我的水平还没达到。但是好多时候读写实验室的excel和输出成excel又必须用这个，之前用的seaborn也是基于pandas的，那就再把基础操作复习一下。</p>
<a id="more"></a>
<h1 id="读写与创建">读写与创建</h1>
<h2 id="数据读写">数据读写</h2>
<h3 id="sql">sql</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line">db = create_engine(<span class="string">&quot;mysql+pymysql://用户名:用户密码@localhost:端口号（3306）/使用的数据库名?charset=utf8&quot;</span>)</span><br><span class="line">sql = <span class="string">&quot;select * from text&quot;</span></span><br><span class="line">df = pd.read_sql(sql, db, index_col=<span class="string">&quot;index&quot;</span>) <span class="comment"># index_col设置索引列，默认自动生成索引</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sql.to_sql(df, name=<span class="string">&#x27;test&#x27;</span>, con=db,</span><br><span class="line">                 if_exists=<span class="string">&quot;append&quot;</span>,<span class="comment"># 如果表存在：append追加 replace删除原表新建并插入 fail不插入</span></span><br><span class="line">                 index=<span class="literal">False</span> <span class="comment"># 设置df的索引不插入数据库</span></span><br><span class="line">                 )</span><br></pre></td></tr></table></figure>
<h3 id="excel">excel</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_excel(<span class="string">r&#x27;file_path&#x27;</span>,</span><br><span class="line">                   sheet_name=<span class="string">&#x27;指定sheet,默认第一个&#x27;</span>,</span><br><span class="line">                   index=<span class="literal">False</span>, <span class="comment"># 不读取excel中的索引，自动生成新索引</span></span><br><span class="line">                   index_col=<span class="number">0</span>, <span class="comment"># 将第0列设置为索引</span></span><br><span class="line">                   header=<span class="number">0</span>, <span class="comment"># 将第n行设置为columns, 默认是0，可以设置为None（自动生成0-n的columns）</span></span><br><span class="line">                   usecols=[<span class="number">0</span>, <span class="number">2</span>] <span class="comment"># 只导入0, 2列</span></span><br><span class="line">                   )</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">按照不同sheet写入</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 创建表格</span></span><br><span class="line">excelWriter = pd.ExcelFile(<span class="string">&#x27;file_path/test.xlsx&#x27;</span>)</span><br><span class="line"><span class="comment"># 写入表格</span></span><br><span class="line">df.to_excel(</span><br><span class="line">    excelWriter,</span><br><span class="line">    sheet_name=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    insex=<span class="literal">False</span>, <span class="comment"># 设置df的索引不传入excel</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], <span class="comment"># 指定某列写入excel</span></span><br><span class="line">    na_rep=<span class="number">0</span>, <span class="comment"># 缺失值处理（填充为0）</span></span><br><span class="line">    inf_rep=<span class="number">0</span>, <span class="comment"># 无穷值处理（填充为0）</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 保存（不保存不生效）</span></span><br><span class="line">excelWriter.save()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">直接写入</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df.to_excel(<span class="string">&#x27;file_path/test.xlsx&#x27;</span>) <span class="comment"># 参数：insex、encoding、columns、na_rep、inf_rep</span></span><br></pre></td></tr></table></figure>
<h3 id="csv">csv</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read(</span><br><span class="line">    <span class="string">r&#x27;file_path/test.csv&#x27;</span>,</span><br><span class="line">    sep=<span class="string">&quot;&quot;</span>, <span class="comment"># 指定分隔符，默认是逗号</span></span><br><span class="line">    nrows=<span class="number">2</span>, <span class="comment"># 指定读取行数</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    engine=<span class="string">&#x27;python&#x27;</span>, <span class="comment"># 当路径存在中文会报错，加上这个即解决</span></span><br><span class="line">    usecols=[<span class="number">0</span>, <span class="number">2</span>], <span class="comment"># 仅导入0, 2列</span></span><br><span class="line">    index_col=<span class="number">0</span>, <span class="comment"># 将第0列设置为索引</span></span><br><span class="line">    header=<span class="number">0</span> <span class="comment"># 将第n行设置为columns, 默认是0，可以设置为None（自动生成0-n的columns）</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.to_csv(</span><br><span class="line">    <span class="string">r&#x27;file_path/test.csv&#x27;</span>,</span><br><span class="line">    index=<span class="literal">False</span>, <span class="comment"># 索引列不写入</span></span><br><span class="line">    columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], <span class="comment"># 指定写入的列</span></span><br><span class="line">    sep=<span class="string">&#x27;,&#x27;</span>, <span class="comment"># 设置分隔符（默认是逗号）</span></span><br><span class="line">    na_rep=<span class="number">0</span>, <span class="comment"># 缺失值填充为0</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    <span class="comment">#inf_rep=0 没有这个参数</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="txt">txt</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.read_table(<span class="string">r&#x27;file_path/test.txt&#x27;</span>, sep=<span class="string">&#x27;&#x27;</span>) <span class="comment">#也可以用来读取csv文件</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.to_csv(</span><br><span class="line">    <span class="string">r&#x27;file_path/test.csv&#x27;</span>,</span><br><span class="line">    index=<span class="literal">False</span>, <span class="comment"># 索引列不写入</span></span><br><span class="line">    columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], <span class="comment"># 指定写入的列</span></span><br><span class="line">    sep=<span class="string">&#x27;,&#x27;</span>, <span class="comment"># 设置分隔符（默认是逗号）</span></span><br><span class="line">    na_rep=<span class="number">0</span>, <span class="comment"># 缺失值填充为0</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    <span class="comment">#inf_rep=0 没有这个参数</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>来源https://www.modb.pro/db/26894</p>
<h2 id="创建">创建</h2>
<p>最让我不爽的就是dataframe没有像np.zeros,np.ones这种根据已有的dataframe来初始化一个空dataframe.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_empty=pd.Dataframe(columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>,<span class="string">&#x27;D&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>所以有一种办法就是把已有的datafram列名提取出来，然后再去创建。</p>
<h1 id="索引">索引</h1>
<p>Pandas 数据的索引就像一本书的目录，让我们很快地找到想要看的章节，作为大量数据，创建合理的具有业务意义的索引对我们分析数据至关重要。</p>
<h2 id="认识索引">认识索引</h2>
<p>下图是一个简单的 DataFrame 中索引的示例：</p>
<figure>
<img src="https://www.gairuo.com/file/pic/2020/04/pandas_index_01.jpg" alt="pandas index"><figcaption aria-hidden="true">pandas index</figcaption>
</figure>
<p>其中：</p>
<ul>
<li>行索引是数据的索引，列索引指向的是一个 Series</li>
<li>DataFrame 的索引也是系列形成的 Series 的索引</li>
<li>建立索引让数据更加直观明确，如每行数据是针对一个国家的</li>
<li>建立索引方便数据处理</li>
<li>索引允许重复，但业务上一般不会让它重复</li>
</ul>
<p>有时一个行和列层级较多的数据会出现<span class="exturl" data-url="aHR0cHM6Ly93d3cuZ2FpcnVvLmNvbS9wL3BhbmRhcy1tdWx0aUluZGV4">多层索引<i class="fa fa-external-link-alt"></i></span> 的情况。</p>
<h2 id="建立索引">建立索引</h2>
<p>之前我们学习了加载数据生成 DataFrame 时可以指定索引</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = <span class="string">&#x27;https://www.gairuo.com/file/data/dataset/team.xlsx&#x27;</span></span><br><span class="line">df = pd.read_excel(data, index_col=<span class="string">&#x27;name&#x27;</span>) <span class="comment"># 设置索引为 name</span></span><br><span class="line">df</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">      team  Q1  Q2  Q3  Q4</span></span><br><span class="line"><span class="string">name</span></span><br><span class="line"><span class="string">Liver    E  89  21  24  64</span></span><br><span class="line"><span class="string">Arry     C  36  37  37  57</span></span><br><span class="line"><span class="string">Ack      A  57  60  18  84</span></span><br><span class="line"><span class="string">Eorge    C  93  96  71  78</span></span><br><span class="line"><span class="string">Oah      D  65  49  61  86</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>如果加载时没有指定索引，我们可以使用 <code>df.set_index()</code> 指定：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>) <span class="comment"># 设置月份为索引</span></span><br><span class="line">df.set_index([<span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;year&#x27;</span>]) <span class="comment"># 设置月份和年为多层索引</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            sale</span></span><br><span class="line"><span class="string">month year</span></span><br><span class="line"><span class="string">1     2012    55</span></span><br><span class="line"><span class="string">4     2014    40</span></span><br><span class="line"><span class="string">      2013    84</span></span><br><span class="line"><span class="string">10    2014    31</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">s = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">df.set_index(s) <span class="comment"># 指定一个索引</span></span><br><span class="line">df.set_index([s, <span class="string">&#x27;year&#x27;</span>]) <span class="comment"># 指定的索引和现有字段同时指定</span></span><br><span class="line">df.set_index([s, s**<span class="number">2</span>]) <span class="comment"># 计算索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他的参数</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>, drop=<span class="literal">False</span>) <span class="comment"># 保留原列</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>, append=<span class="literal">True</span>) <span class="comment"># 保留原来的索引</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>, inplace=<span class="literal">True</span>) <span class="comment"># 建立索引并重写覆盖 df</span></span><br></pre></td></tr></table></figure>
<h2 id="重置索引">重置索引</h2>
<p>有时我们想取消已有的索引，以重新来过，可以使用 <code>df.reset_index()</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.reset_index() <span class="comment"># 清除索引</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>).reset_index() <span class="comment"># 相当于啥也没干</span></span><br><span class="line"><span class="comment"># 删除原索引，month 列没了</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df2.reset_index(inplace=<span class="literal">True</span>) <span class="comment"># 覆盖使生效</span></span><br><span class="line"><span class="comment"># year 一级索引取消</span></span><br><span class="line">df.set_index([<span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;year&#x27;</span>]).reset_index(level=<span class="number">1</span>)</span><br><span class="line">df2.reset_index(level=<span class="string">&#x27;class&#x27;</span>) <span class="comment"># 同上使用层级索引名</span></span><br><span class="line">df.reset_index(level=<span class="string">&#x27;class&#x27;</span>, col_level=<span class="number">1</span>) <span class="comment"># 列索引</span></span><br><span class="line"><span class="comment"># 不存在层级名称的填入指定名称</span></span><br><span class="line">df.reset_index(level=<span class="string">&#x27;class&#x27;</span>, col_level=<span class="number">1</span>, col_fill=<span class="string">&#x27;species&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="索引类型">索引类型</h2>
<p>为了适应各种业务数据的处理，索引又针对各种类型数据定义了不同的索引类型：</p>
<h3 id="数字索引-numeric-index">数字索引 Numeric Index</h3>
<p>共有以下几种：</p>
<ul>
<li>RangeIndex: 单调整数范围的不可变索引。</li>
<li>Int64Index: int64类型，有序可切片集合的不可变ndarray。</li>
<li>UInt64Index: 无符号整数标签的</li>
<li>Float64Index: Float64 类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.RangeIndex(<span class="number">1</span>,<span class="number">100</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># RangeIndex(start=1, stop=100, step=2)</span></span><br><span class="line">pd.Int64Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">-4</span>], name=<span class="string">&#x27;num&#x27;</span>)</span><br><span class="line"><span class="comment"># Int64Index([1, 2, 3, -4], dtype=&#x27;int64&#x27;, name=&#x27;num&#x27;)</span></span><br><span class="line">pd.UInt64Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># UInt64Index([1, 2, 3, 4], dtype=&#x27;uint64&#x27;)</span></span><br><span class="line">pd.Float64Index([<span class="number">1.2</span>,<span class="number">2.3</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># Float64Index([1.2, 2.3, 3.0, 4.0], dtype=&#x27;float64&#x27;)</span></span><br></pre></td></tr></table></figure>
<h3 id="类别索引-categoricalindex">类别索引 CategoricalIndex</h3>
<p>类别只能包含有限数量的（通常是固定的）可能值（类别）。 可以理解成枚举，比如性别只有男女，但在数据中每行都有，如果按文本处理会效率不高。类别的底层是 pandas.Categorical。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.CategoricalIndex([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"><span class="comment"># CategoricalIndex([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;a&#x27;, &#x27;b&#x27;], categories=[&#x27;a&#x27;, &#x27;b&#x27;], ordered=False, dtype=&#x27;category&#x27;)</span></span><br></pre></td></tr></table></figure>
<p>类别后边后有专门的讲解，只有在体量非常大的数据面前才能显示其优势。</p>
<h3 id="间隔索引-intervalindex">间隔索引 IntervalIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.interval_range(start=<span class="number">0</span>, end=<span class="number">5</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],</span></span><br><span class="line"><span class="string">              closed=&#x27;right&#x27;,</span></span><br><span class="line"><span class="string">              dtype=&#x27;interval[int64]&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="多层索引-multiindex">多层索引 MultiIndex</h3>
<p>教程后边会有专门的讲解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arrays = [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>]]</span><br><span class="line">pd.MultiIndex.from_arrays(arrays, names=(<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;color&#x27;</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">MultiIndex([(1,  &#x27;red&#x27;),</span></span><br><span class="line"><span class="string">            (1, &#x27;blue&#x27;),</span></span><br><span class="line"><span class="string">            (2,  &#x27;red&#x27;),</span></span><br><span class="line"><span class="string">            (2, &#x27;blue&#x27;)],</span></span><br><span class="line"><span class="string">           names=[&#x27;number&#x27;, &#x27;color&#x27;])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="时间索引-datetimeindex">时间索引 DatetimeIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从一个日期连续到另一个日期</span></span><br><span class="line">pd.date_range(start=<span class="string">&#x27;1/1/2018&#x27;</span>, end=<span class="string">&#x27;1/08/2018&#x27;</span>)</span><br><span class="line"><span class="comment"># 指定开始时间和周期</span></span><br><span class="line">pd.date_range(start=<span class="string">&#x27;1/1/2018&#x27;</span>, periods=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 以月为周期</span></span><br><span class="line">pd.period_range(start=<span class="string">&#x27;2017-01-01&#x27;</span>, end=<span class="string">&#x27;2018-01-01&#x27;</span>, freq=<span class="string">&#x27;M&#x27;</span>)</span><br><span class="line"><span class="comment"># 周期嵌套</span></span><br><span class="line">pd.period_range(start=pd.Period(<span class="string">&#x27;2017Q1&#x27;</span>, freq=<span class="string">&#x27;Q&#x27;</span>),</span><br><span class="line">                end=pd.Period(<span class="string">&#x27;2017Q2&#x27;</span>, freq=<span class="string">&#x27;Q&#x27;</span>), freq=<span class="string">&#x27;M&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="时间差-timedeltaindex">时间差 TimedeltaIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.TimedeltaIndex(data =[<span class="string">&#x27;06:05:01.000030&#x27;</span>, <span class="string">&#x27;+23:59:59.999999&#x27;</span>,</span><br><span class="line">                         <span class="string">&#x27;22 day 2 min 3us 10ns&#x27;</span>, <span class="string">&#x27;+23:29:59.999999&#x27;</span>,</span><br><span class="line">                         <span class="string">&#x27;+12:19:59.999999&#x27;</span>])</span><br><span class="line"><span class="comment"># 使用 datetime</span></span><br><span class="line">pd.TimedeltaIndex([<span class="string">&#x27;1 days&#x27;</span>, <span class="string">&#x27;1 days, 00:00:05&#x27;</span>,</span><br><span class="line">                   np.timedelta64(<span class="number">2</span>, <span class="string">&#x27;D&#x27;</span>),</span><br><span class="line">                   datetime.timedelta(days=<span class="number">2</span>, seconds=<span class="number">2</span>)])</span><br></pre></td></tr></table></figure>
<h3 id="周期索引-periodindex">周期索引 PeriodIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = pd.period_range(<span class="string">&#x27;2020-5-1 10:00:05&#x27;</span>, periods=<span class="number">8</span>, freq=<span class="string">&#x27;S&#x27;</span>)</span><br><span class="line">pd.PeriodIndex(t,freq=<span class="string">&#x27;S&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="索引对象">索引对象</h2>
<p>行和列的索引在 Pandas 里其实是一个 <code>Index</code> 对象，以下是创建一个 <code>index</code> 对象的方法：</p>
<h3 id="创建对象">创建对象</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.Index([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># Int64Index([1, 2, 3], dtype=&#x27;int64&#x27;)</span></span><br><span class="line">pd.Index(list(<span class="string">&#x27;abc&#x27;</span>))</span><br><span class="line"><span class="comment"># Index([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], dtype=&#x27;object&#x27;)</span></span><br><span class="line"><span class="comment"># 可以定义一相 name</span></span><br><span class="line">pd.Index([<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], name=<span class="string">&#x27;something&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查看">查看</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.index</span><br><span class="line"><span class="comment"># RangeIndex(start=0, stop=4, step=1)</span></span><br><span class="line">df.columns</span><br><span class="line"><span class="comment"># Index([&#x27;month&#x27;, &#x27;year&#x27;, &#x27;sale&#x27;], dtype=&#x27;object&#x27;)</span></span><br></pre></td></tr></table></figure>
<h3 id="属性">属性</h3>
<p>以下方法也适用于 <code>df.columns</code>, 因为都是 index 对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 属性</span></span><br><span class="line">df.index.name <span class="comment"># 名称</span></span><br><span class="line">df.index.array <span class="comment"># array 数组</span></span><br><span class="line">df.index.dtype <span class="comment"># 数据类型</span></span><br><span class="line">df.index.shape <span class="comment"># 形状</span></span><br><span class="line">df.index.size <span class="comment"># 元素数量</span></span><br><span class="line">df.index.values <span class="comment"># array 数组</span></span><br><span class="line"><span class="comment"># 其他，不常用</span></span><br><span class="line">df.index.empty <span class="comment"># 是否为空</span></span><br><span class="line">df.index.is_unique <span class="comment"># 是否不重复</span></span><br><span class="line">df.index.names <span class="comment"># 名称列表</span></span><br><span class="line">df.index.is_all_dates <span class="comment"># 是否全是日期时间</span></span><br><span class="line">df.index.has_duplicates <span class="comment"># 是否有重复值</span></span><br><span class="line">df.index.values <span class="comment"># 索引的值 array</span></span><br></pre></td></tr></table></figure>
<h3 id="操作">操作</h3>
<p>以下方法也适用于 <code>df.columns</code>, 因为都是 index 对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方法</span></span><br><span class="line">df.index.astype(<span class="string">&#x27;int64&#x27;</span>) <span class="comment"># 转换类型</span></span><br><span class="line">df.index.isin() <span class="comment"># 是否存在，见下方示例</span></span><br><span class="line">df.index.rename(<span class="string">&#x27;number&#x27;</span>) <span class="comment"># 修改索引名称</span></span><br><span class="line">df.index.nunique() <span class="comment"># 不重复值的数量</span></span><br><span class="line">df.index.sort_values(ascending=<span class="literal">False</span>,) <span class="comment"># 排序,倒序</span></span><br><span class="line">df.index.map(<span class="keyword">lambda</span> x:x+<span class="string">&#x27;_&#x27;</span>) <span class="comment"># map 函数处理</span></span><br><span class="line">df.index.str.replace(<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="comment"># str 替换</span></span><br><span class="line">df.index.str.split(<span class="string">&#x27;_&#x27;</span>) <span class="comment"># 分隔</span></span><br><span class="line">df.index.to_list() <span class="comment"># 转为列表</span></span><br><span class="line">df.index.to_frame(index=<span class="literal">False</span>, name=<span class="string">&#x27;a&#x27;</span>) <span class="comment"># 转成 DataFrame</span></span><br><span class="line">df.index.to_series() <span class="comment"># 转 series</span></span><br><span class="line">df.index.to_numpy() <span class="comment"># 转为 numpy</span></span><br><span class="line">df.index.unique() <span class="comment"># 去重</span></span><br><span class="line">df.index.value_counts() <span class="comment"># 去重及数量</span></span><br><span class="line">df.index.where(df.index==<span class="string">&#x27;a&#x27;</span>) <span class="comment"># 筛选</span></span><br><span class="line">df.index.rename(<span class="string">&#x27;grade&#x27;</span>, inplace=<span class="literal">False</span>) <span class="comment"># 重命名索引名称</span></span><br><span class="line">df.index.rename([<span class="string">&#x27;species&#x27;</span>, <span class="string">&#x27;year&#x27;</span>]) <span class="comment"># 多层，重命名索引名称</span></span><br><span class="line">df.index.max() <span class="comment"># 最大值</span></span><br><span class="line">df.index.argmax() <span class="comment"># 最大索引值</span></span><br><span class="line">df.index.any()</span><br><span class="line">df.index.all()</span><br><span class="line">df.index.T <span class="comment"># 转置，多层索引里很有用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他，不常用</span></span><br><span class="line">df.index.append(pd.Index([<span class="number">4</span>,<span class="number">5</span>])) <span class="comment"># 追加</span></span><br><span class="line">df.index.repeat(<span class="number">2</span>) <span class="comment"># 重复几次</span></span><br><span class="line">df.index.inferred_type <span class="comment"># 推测数据类型</span></span><br><span class="line">df.index.hasnans <span class="comment"># 有没有空值</span></span><br><span class="line">df.index.is_monotonic_decreasing <span class="comment"># 是否单调递减</span></span><br><span class="line">df.index.is_monotonic <span class="comment"># 是否单调递增</span></span><br><span class="line">df.index.is_monotonic_increasing <span class="comment"># 是否单调递增</span></span><br><span class="line">df.index.nbytes <span class="comment"># 基础数据中的字节数</span></span><br><span class="line">df.index.ndim <span class="comment"># 维度数，维数</span></span><br><span class="line">df.index.nlevels <span class="comment"># 索引层级数，通常为 1</span></span><br><span class="line">df.index.min() <span class="comment"># 最小值</span></span><br><span class="line">df.index.argmin() <span class="comment"># 最小索引值</span></span><br><span class="line">df.index.argsort() <span class="comment"># 顺序值组成的数组</span></span><br><span class="line">df.index.asof(<span class="number">2</span>) <span class="comment"># 返回最近的索引</span></span><br><span class="line"><span class="comment"># numpy dtype or pandas type</span></span><br><span class="line">df.index.astype(<span class="string">&#x27;int64&#x27;</span>, copy=<span class="literal">True</span>) <span class="comment"># 深拷贝</span></span><br><span class="line"><span class="comment"># 拷贝</span></span><br><span class="line">df.index.copy(name=<span class="string">&#x27;new&#x27;</span>, deep=<span class="literal">True</span>, dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line">df.index.delete(<span class="number">1</span>) <span class="comment"># 删除指定位置</span></span><br><span class="line"><span class="comment"># 对比不同</span></span><br><span class="line">df.index.difference(pd.Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>]), sort=<span class="literal">False</span>)</span><br><span class="line">df.index.drop(<span class="string">&#x27;a&#x27;</span>, errors=<span class="string">&#x27;ignore&#x27;</span>) <span class="comment"># 删除</span></span><br><span class="line">df.index.drop_duplicates(keep=<span class="string">&#x27;first&#x27;</span>) <span class="comment"># 去重值</span></span><br><span class="line">df.index.droplevel(<span class="number">0</span>) <span class="comment"># 删除层级</span></span><br><span class="line">df.index.dropna(how=<span class="string">&#x27;all&#x27;</span>) <span class="comment"># 删除空值</span></span><br><span class="line">df.index.duplicated(keep=<span class="string">&#x27;first&#x27;</span>) <span class="comment"># 重复值在结果数组中为True</span></span><br><span class="line">df.index.equals(df.index) <span class="comment"># 与另外一个索引对象是否相同</span></span><br><span class="line">df.index.factorize() <span class="comment"># 分解成（array:0-n, Index）</span></span><br><span class="line">df.index.fillna(<span class="number">0</span>, &#123;<span class="number">0</span>:<span class="string">&#x27;nan&#x27;</span>&#125;) <span class="comment"># 填充空值</span></span><br><span class="line"><span class="comment"># 字符列表, 把 name 值加在第一位, 每个值加10</span></span><br><span class="line">df.index.format(name=<span class="literal">True</span>, formatter=<span class="keyword">lambda</span> x:x+<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回一个 array, 指定值的索引位数组，不在的为 -1</span></span><br><span class="line">df.index.get_indexer([<span class="number">2</span>,<span class="number">9</span>])</span><br><span class="line"><span class="comment"># 获取 指定层级 Index 对象</span></span><br><span class="line">df.index.get_level_values(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 指定索引的位置，见示例</span></span><br><span class="line">df.index.get_loc(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">df.index.insert(<span class="number">2</span>, <span class="string">&#x27;f&#x27;</span>) <span class="comment"># 在索引位 2 插入 f</span></span><br><span class="line">df.index.intersection(df.index) <span class="comment"># 交集</span></span><br><span class="line">df.index.is_(df.index) <span class="comment"># 类似 is 检查</span></span><br><span class="line">df.index.is_categorical() <span class="comment"># 是否分类数据</span></span><br><span class="line">df.index.is_type_compatible(df.index) <span class="comment"># 类型是否兼容</span></span><br><span class="line">df.index.is_type_compatible(<span class="number">1</span>) <span class="comment"># 类型是否兼容</span></span><br><span class="line"></span><br><span class="line">df.index.isna() <span class="comment"># array 是否为空</span></span><br><span class="line">df.index.isnull() <span class="comment"># array 是否缺失值</span></span><br><span class="line">df.index.join(df.index, how=<span class="string">&#x27;left&#x27;</span>) <span class="comment"># 连接</span></span><br><span class="line">df.index.notna() <span class="comment"># 是否不存在的值</span></span><br><span class="line">df.index.notnull() <span class="comment"># 是否不存在的值</span></span><br><span class="line">df.index.ravel() <span class="comment"># 展平值的ndarray</span></span><br><span class="line">df.index.reindex([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>]) <span class="comment"># 新索引 (Index,array:0-n)</span></span><br><span class="line">df.index.searchsorted(<span class="string">&#x27;f&#x27;</span>) <span class="comment"># 如果插入这个值排序后在哪个索引位</span></span><br><span class="line">df.index.searchsorted([<span class="number">0</span>, <span class="number">4</span>]) <span class="comment"># array([0, 3]) 多个</span></span><br><span class="line">df.index.set_names(<span class="string">&#x27;quarter&#x27;</span>) <span class="comment"># 设置索引名称</span></span><br><span class="line">df.index.set_names(<span class="string">&#x27;species&#x27;</span>, level=<span class="number">0</span>)</span><br><span class="line">df.index.set_names([<span class="string">&#x27;kind&#x27;</span>, <span class="string">&#x27;year&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">df.index.shift(<span class="number">10</span>, freq=<span class="string">&#x27;D&#x27;</span>) <span class="comment"># 日期索引向前移动 10 天</span></span><br><span class="line">idx1.symmetric_difference(idx2) <span class="comment"># 两个索引不同的内容</span></span><br><span class="line">idx1.union(idx2) <span class="comment"># 拼接</span></span><br><span class="line"></span><br><span class="line">df.add_prefix(<span class="string">&#x27;t_&#x27;</span>) <span class="comment"># 表头加前缀</span></span><br><span class="line">df.add_suffix(<span class="string">&#x27;_d&#x27;</span>) <span class="comment"># 表头加后缀</span></span><br><span class="line">df.first_valid_index() <span class="comment"># 第一个有值的索引</span></span><br><span class="line">df.last_valid_index() <span class="comment"># 最后一个有值的索引</span></span><br></pre></td></tr></table></figure>
<h2 id="索引重命名">索引重命名</h2>
<p>对行和列的索引名进行修改。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一一对应修改列索引</span></span><br><span class="line">df.rename(columns=&#123;<span class="string">&quot;A&quot;</span>: <span class="string">&quot;a&quot;</span>, <span class="string">&quot;B&quot;</span>: <span class="string">&quot;c&quot;</span>&#125;)</span><br><span class="line">df.rename(str.lower, axis=<span class="string">&#x27;columns&#x27;</span>)</span><br><span class="line"><span class="comment"># 修改行索引</span></span><br><span class="line">df.rename(index=&#123;<span class="number">0</span>: <span class="string">&quot;x&quot;</span>, <span class="number">1</span>: <span class="string">&quot;y&quot;</span>, <span class="number">2</span>: <span class="string">&quot;z&quot;</span>&#125;)</span><br><span class="line">df.rename(&#123;<span class="number">1</span>: <span class="number">2</span>, <span class="number">2</span>: <span class="number">4</span>&#125;, axis=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line"><span class="comment"># 修改数据类型</span></span><br><span class="line">df.rename(index=str)</span><br><span class="line"><span class="comment"># 重新修改索引</span></span><br><span class="line">replacements = &#123;l1:l2 <span class="keyword">for</span> l1, l2 <span class="keyword">in</span> zip(list1, list2)&#125;</span><br><span class="line">df.rename(replacements)</span><br></pre></td></tr></table></figure>
<h2 id="索引名重命名">索引名重命名</h2>
<p>注意，这是修改索引的名称，不是索引或者列名本身：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.rename_axis(<span class="string">&quot;animal&quot;</span>) <span class="comment"># 索引重命名</span></span><br><span class="line">df.rename_axis([<span class="string">&quot;dow&quot;</span>, <span class="string">&quot;hr&quot;</span>]) <span class="comment"># 多层索引索引名修改</span></span><br><span class="line">df.rename_axis(<span class="string">&#x27;info&#x27;</span>, axis=<span class="string">&quot;columns&quot;</span>) <span class="comment"># 修改行索引名</span></span><br><span class="line"><span class="comment"># 修改多层列索引名</span></span><br><span class="line">df.rename_axis(index=&#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: <span class="string">&#x27;B&#x27;</span>&#125;)</span><br><span class="line"><span class="comment"># 修改多层列行索引名</span></span><br><span class="line">df.rename_axis(columns=&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;s_name&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: <span class="string">&#x27;B&#x27;</span>&#125;)</span><br><span class="line">df.rename_axis(columns=str.upper) <span class="comment"># 行索引名变大写</span></span><br></pre></td></tr></table></figure>
<h2 id="部分示例">部分示例</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># idx.isin() 是否存在</span></span><br><span class="line">idx = pd.Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">df.index.isin(idx)</span><br><span class="line"><span class="comment"># array([False, False, False, False])</span></span><br><span class="line">df.index.isin([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"><span class="comment"># array([ True,  True, False, False])</span></span><br><span class="line">midx = pd.MultiIndex.from_arrays([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">                                 [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>]],</span><br><span class="line">                                 names=(<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;color&#x27;</span>))</span><br><span class="line">midx.isin([(<span class="number">1</span>, <span class="string">&#x27;red&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;red&#x27;</span>)])</span><br><span class="line"><span class="comment"># array([ True, False, False])</span></span><br><span class="line">dates = [<span class="string">&#x27;2000-03-11&#x27;</span>, <span class="string">&#x27;2000-03-12&#x27;</span>, <span class="string">&#x27;2000-03-13&#x27;</span>]</span><br><span class="line">dti = pd.to_datetime(dates)</span><br><span class="line">dti.isin([<span class="string">&#x27;2000-03-11&#x27;</span>])</span><br><span class="line"><span class="comment"># array([ True, False, False])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i.argsort() 排序</span></span><br><span class="line"><span class="comment"># 将对索引进行排序的整数索引，见下文示例</span></span><br><span class="line">idx = pd.Index([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">order = idx.argsort() <span class="comment"># array([1, 0, 3, 2])</span></span><br><span class="line">idx[order] <span class="comment"># Index([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;], dtype=&#x27;object&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i.asof(2) 返回最近的索引, 支持日期，可实现找最近日期</span></span><br><span class="line"><span class="comment"># 从索引中返回标签；如果不存在，则返回前一个标签</span></span><br><span class="line">idx2 = pd.Index([<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>])</span><br><span class="line">idx2.asof(<span class="number">5</span>) <span class="comment"># 3</span></span><br><span class="line">idx2.asof(<span class="number">6</span>) <span class="comment"># 5</span></span><br><span class="line">idx2.asof(<span class="number">-1</span>) <span class="comment"># nan</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># index.get_loc 指定索引的位置，见示例</span></span><br><span class="line">unique_index = pd.Index(list(<span class="string">&#x27;abc&#x27;</span>))</span><br><span class="line">unique_index.get_loc(<span class="string">&#x27;b&#x27;</span>) <span class="comment"># 1</span></span><br><span class="line">monotonic_index = pd.Index(list(<span class="string">&#x27;abbc&#x27;</span>))</span><br><span class="line">monotonic_index.get_loc(<span class="string">&#x27;b&#x27;</span>) <span class="comment"># slice(1, 3, None)</span></span><br><span class="line">non_monotonic_index = pd.Index(list(<span class="string">&#x27;abcb&#x27;</span>))</span><br><span class="line">non_monotonic_index.get_loc(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="comment"># array([False,  True, False,  True], dtype=bool)</span></span><br></pre></td></tr></table></figure>
<h1 id="查询与修改">查询与修改</h1>
<h2 id="数据检查">数据检查</h2>
<p>我们一拿到数据需要对数据有一个抽查，一方面是了解数据结构，另一方面随机检查一下数据的质量问题。常用的：</p>
<table>
<thead>
<tr class="header">
<th>语法</th>
<th>操作</th>
<th>返回结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>df.head(n)</code></td>
<td>查看 DataFrame 对象的前n行</td>
<td>DataFrame</td>
</tr>
<tr class="even">
<td><code>df.tail(n)</code></td>
<td>查看 DataFrame 对象的最后n行</td>
<td>DataFrame</td>
</tr>
<tr class="odd">
<td><code>df.sample(n)</code></td>
<td>查看 n 个样本，随机</td>
<td>DataFrame</td>
</tr>
</tbody>
</table>
<p>以上都是选择整行。</p>
<h3 id="查看头部-df.head">查看头部 df.head()</h3>
<p>每次加载数据后一般需要看一下头部数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line">out:</span><br><span class="line">    name team  Q1  Q2  Q3  Q4</span><br><span class="line"><span class="number">0</span>  Liver    E  <span class="number">89</span>  <span class="number">21</span>  <span class="number">24</span>  <span class="number">64</span></span><br><span class="line"><span class="number">1</span>   Arry    C  <span class="number">36</span>  <span class="number">37</span>  <span class="number">37</span>  <span class="number">57</span></span><br><span class="line"><span class="number">2</span>    Ack    A  <span class="number">57</span>  <span class="number">60</span>  <span class="number">18</span>  <span class="number">84</span></span><br><span class="line"><span class="number">3</span>  Eorge    C  <span class="number">93</span>  <span class="number">96</span>  <span class="number">71</span>  <span class="number">78</span></span><br><span class="line"><span class="number">4</span>    Oah    D  <span class="number">65</span>  <span class="number">49</span>  <span class="number">61</span>  <span class="number">86</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可指定数量</span></span><br><span class="line">df.head(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查看尾部-df.tail">查看尾部 df.tail()</h3>
<p>查看最后的尾部数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line">out:</span><br><span class="line">        name team  Q1  Q2  Q3  Q4</span><br><span class="line"><span class="number">95</span>   Gabriel    C  <span class="number">48</span>  <span class="number">59</span>  <span class="number">87</span>  <span class="number">74</span></span><br><span class="line"><span class="number">96</span>   Austin7    C  <span class="number">21</span>  <span class="number">31</span>  <span class="number">30</span>  <span class="number">43</span></span><br><span class="line"><span class="number">97</span>  Lincoln4    C  <span class="number">98</span>  <span class="number">93</span>   <span class="number">1</span>  <span class="number">20</span></span><br><span class="line"><span class="number">98</span>       Eli    E  <span class="number">11</span>  <span class="number">74</span>  <span class="number">58</span>  <span class="number">91</span></span><br><span class="line"><span class="number">99</span>       Ben    E  <span class="number">21</span>  <span class="number">43</span>  <span class="number">41</span>  <span class="number">74</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可指定数量</span></span><br><span class="line">df.tail(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查看样本-df.sample">查看样本 df.sample()</h3>
<p><code>df.sample()</code> 会随机返回一条样本数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sample()</span><br><span class="line">out:</span><br><span class="line">     name team  Q1  Q2  Q3  Q4</span><br><span class="line"><span class="number">79</span>  Tyler    A  <span class="number">75</span>  <span class="number">16</span>  <span class="number">44</span>  <span class="number">63</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可指定数量</span></span><br><span class="line">df.sample(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<p>数据截取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 去掉索引之前和之后的数据</span></span><br><span class="line">df.truncate(before=<span class="number">2</span>, after=<span class="number">4</span>) <span class="comment"># 只要索引 2-4</span></span><br><span class="line">s.truncate(before=<span class="string">&quot;60&quot;</span>, after=<span class="string">&quot;66&quot;</span>)</span><br><span class="line">df.truncate(before=<span class="string">&quot;A&quot;</span>, after=<span class="string">&quot;B&quot;</span>, axis=<span class="string">&quot;columns&quot;</span>) <span class="comment"># 选取列</span></span><br></pre></td></tr></table></figure>
<h2 id="操作列">操作列</h2>
<p>以下两种方法都可以代表一列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;name&#x27;</span>] <span class="comment"># 会返回本列的 Series</span></span><br><span class="line">df.name</span><br><span class="line">df.Q1</span><br><span class="line"><span class="comment"># df.1Q 即使列名叫 1Q 也无法使用</span></span><br><span class="line"><span class="comment"># df.my name 有空格也无法调用，可以处理加上下划线</span></span><br></pre></td></tr></table></figure>
<p>注意，当列名为一个合法的 python 变量时可以直接作为属性去使用。</p>
<h2 id="选择行列部分">选择行列部分</h2>
<p>有时我们需要按条件选择部分列、部分行，一般常用的有：</p>
<table>
<thead>
<tr class="header">
<th>操作</th>
<th>语法</th>
<th>返回结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>选择列</td>
<td><code>df[col]</code></td>
<td>Series</td>
</tr>
<tr class="even">
<td>按索引选择行</td>
<td><code>df.loc[label]</code></td>
<td>Series</td>
</tr>
<tr class="odd">
<td>按数字索引选择行</td>
<td><code>df.iloc[loc]</code></td>
<td>Series</td>
</tr>
<tr class="even">
<td>使用切片选择行</td>
<td><code>df[5:10]</code></td>
<td>DataFrame</td>
</tr>
<tr class="odd">
<td>用表达式筛选行</td>
<td><code>df[bool_vec]</code></td>
<td>DataFrame</td>
</tr>
</tbody>
</table>
<p>接下来我们将重点介绍一下这些查询的方法。</p>
<h2 id="切片">切片 []</h2>
<p>我们可以像列表那样利用切片功能选择部分行的数据，但是不支持索引一条：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[:<span class="number">2</span>] <span class="comment"># 前两行数据</span></span><br><span class="line">df[<span class="number">4</span>:<span class="number">10</span>]</span><br><span class="line">df[:] <span class="comment"># 所有数据，一般没这么用的</span></span><br><span class="line">df[:<span class="number">10</span>:<span class="number">2</span>] <span class="comment"># 按步长取</span></span><br><span class="line">s[::<span class="number">-1</span>] <span class="comment"># 反转顺序</span></span><br></pre></td></tr></table></figure>
<p>也可以选择列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;name&#x27;</span>] <span class="comment"># 只要一列，Series</span></span><br><span class="line">df[[<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]] <span class="comment"># 选择两列</span></span><br><span class="line">df[[<span class="string">&#x27;name&#x27;</span>]] <span class="comment"># 选择一列，返回 DataFrame，注意和上例区别</span></span><br></pre></td></tr></table></figure>
<h2 id="按标签-.loc">按标签 .loc</h2>
<p><code>df.loc()</code> 的格式为 df.loc[<索引表达式>, <列表达式>]，表达式支持以下形式：</列表达式></索引表达式></p>
<p>单个标签:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 代表索引，如果是字符需要加引号</span></span><br><span class="line">df.loc[<span class="number">0</span>] <span class="comment"># 选择索引为 0 的行</span></span><br><span class="line">df.loc[<span class="number">8</span>]</span><br></pre></td></tr></table></figure>
<p>单个列表标签：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>]] <span class="comment"># 指定索引 0，5，10 的行</span></span><br><span class="line">df.loc[[<span class="string">&#x27;Eli&#x27;</span>, <span class="string">&#x27;Ben&#x27;</span>]] <span class="comment"># 如果索引是 name</span></span><br><span class="line"><span class="comment"># 真假选择，长度要和索引一样</span></span><br><span class="line">df.loc[[<span class="literal">False</span>, <span class="literal">True</span>]*<span class="number">50</span>] <span class="comment"># 为真的列显示，隔一个显示一个</span></span><br></pre></td></tr></table></figure>
<p>带标签的切片（包括起始和停止）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[<span class="number">0</span>:<span class="number">5</span>] <span class="comment"># 索引切片, 代表0-5行，包括5</span></span><br><span class="line">df.loc[<span class="string">&#x27;2010&#x27;</span>:<span class="string">&#x27;2014&#x27;</span>] <span class="comment"># 如果索引是时间可以用字符查询</span></span><br><span class="line">df.loc[:] <span class="comment"># 所有</span></span><br><span class="line"><span class="comment"># 本方法支持 Series</span></span><br></pre></td></tr></table></figure>
<p>列筛选，必须有行筛选：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dft.loc[:, [<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]] <span class="comment"># 所有行，Q1 和 Q2两列</span></span><br><span class="line">dft.loc[:, [<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]] <span class="comment"># 所有行，Q1 和 Q2两列</span></span><br><span class="line">dft.loc[:<span class="number">10</span>, <span class="string">&#x27;Q1&#x27;</span>:] <span class="comment"># 0-10 行，Q1后边的所有列</span></span><br></pre></td></tr></table></figure>
<h2 id="按位置-.iloc">按位置 .iloc</h2>
<p><code>df.iloc</code> 与 <code>df.loc</code> 相似，但只能用自然索引（行和列的 0 - n 索引），不能用标签。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.iloc[:<span class="number">3</span>]</span><br><span class="line">df.iloc[:]</span><br><span class="line">df.iloc[<span class="number">2</span>:<span class="number">20</span>:<span class="number">3</span>]</span><br><span class="line">s.iloc[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<h2 id="取具体值-.at">取具体值 .at</h2>
<p>类似于 loc, 但仅取一个具体的值，结构为 at[<索引>,<列名>]：</列名></索引></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 注：索引是字符需要加引号</span></span><br><span class="line">df.at[<span class="number">4</span>, <span class="string">&#x27;Q1&#x27;</span>] <span class="comment"># 65</span></span><br><span class="line">df.at[<span class="string">&#x27;lily&#x27;</span>, <span class="string">&#x27;Q1&#x27;</span>] <span class="comment"># 65 假定索引是 name</span></span><br><span class="line">df.at[<span class="number">0</span>, <span class="string">&#x27;name&#x27;</span>] <span class="comment"># &#x27;Liver&#x27;</span></span><br><span class="line">df.loc[<span class="number">0</span>].at[<span class="string">&#x27;name&#x27;</span>] <span class="comment"># &#x27;Liver&#x27;</span></span><br><span class="line"><span class="comment"># 指定列的值对应其他列的值</span></span><br><span class="line">df.set_index(<span class="string">&#x27;name&#x27;</span>).at[<span class="string">&#x27;Eorge&#x27;</span>, <span class="string">&#x27;team&#x27;</span>] <span class="comment"># &#x27;C&#x27;</span></span><br><span class="line">df.set_index(<span class="string">&#x27;name&#x27;</span>).team.at[<span class="string">&#x27;Eorge&#x27;</span>] <span class="comment"># &#x27;C&#x27;</span></span><br><span class="line"><span class="comment"># 指定列的对应索引的值</span></span><br><span class="line">df.team.at[<span class="number">3</span>] <span class="comment"># &#x27;C&#x27;</span></span><br></pre></td></tr></table></figure>
<p>同样 iat 和 iloc 一样，仅支持数字索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.iat[<span class="number">4</span>, <span class="number">2</span>] <span class="comment"># 65</span></span><br><span class="line">df.loc[<span class="number">0</span>].iat[<span class="number">1</span>] <span class="comment"># &#x27;E&#x27;</span></span><br></pre></td></tr></table></figure>
<p>.get 可以做类似字典的操作，如果无值给返回默认值（例中是0）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.get(<span class="string">&#x27;name&#x27;</span>, <span class="number">0</span>) <span class="comment"># 是 name 列</span></span><br><span class="line">df.get(<span class="string">&#x27;nameXXX&#x27;</span>, <span class="number">0</span>) <span class="comment"># 0, 返回默认值</span></span><br><span class="line">s.get(<span class="number">3</span>, <span class="number">0</span>) <span class="comment"># 93, Series 传索引返回具体值</span></span><br><span class="line">df.name.get(<span class="number">99</span>, <span class="number">0</span>) <span class="comment"># &#x27;Ben&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="表达式筛选">表达式筛选</h2>
<p><code>[]</code> 切片里可以使用表达式进行筛选：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>] <span class="comment"># Q1 等于8</span></span><br><span class="line">df[~(df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>)] <span class="comment"># 不等于8</span></span><br><span class="line">df[df.name == <span class="string">&#x27;Ben&#x27;</span>] <span class="comment"># 姓名为Ben</span></span><br><span class="line">df.loc[df[<span class="string">&#x27;Q1&#x27;</span>] &gt; <span class="number">90</span>, <span class="string">&#x27;Q1&#x27;</span>:]  <span class="comment"># Q1 大于90，只显示 Q1</span></span><br><span class="line">df.loc[(df.Q1 &gt; <span class="number">80</span>) &amp; (df.Q2 &lt; <span class="number">15</span>)] <span class="comment"># and 关系</span></span><br><span class="line">df.loc[(df.Q1 &gt; <span class="number">90</span>) | (df.Q2 &lt; <span class="number">90</span>)] <span class="comment"># or 关系</span></span><br><span class="line">df[df.Q1 &gt; df.Q2]</span><br></pre></td></tr></table></figure>
<p><code>df.loc</code> 里的索引部分可以使用表达式进行数据筛选。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>] <span class="comment"># 等于8</span></span><br><span class="line">df.loc[df.Q1 == <span class="number">8</span>] <span class="comment"># 等于8</span></span><br><span class="line">df.loc[df[<span class="string">&#x27;Q1&#x27;</span>] &gt; <span class="number">90</span>, <span class="string">&#x27;Q1&#x27;</span>:] <span class="comment"># Q1 大于90，只显示 Q1</span></span><br><span class="line"><span class="comment"># 其他表达式与切片一致</span></span><br><span class="line"></span><br><span class="line">df.loc[:, <span class="keyword">lambda</span> df: df.columns.str.len()==<span class="number">4</span>] <span class="comment"># 真假组成的序列</span></span><br><span class="line">df.loc[:, <span class="keyword">lambda</span> df: [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> <span class="string">&#x27;Q&#x27;</span> <span class="keyword">in</span> i]] <span class="comment"># 列名列表</span></span><br><span class="line">df.iloc[:<span class="number">3</span>, <span class="keyword">lambda</span> df: df.columns.str.len()==<span class="number">2</span>] <span class="comment"># 真假组成的序列</span></span><br></pre></td></tr></table></figure>
<p>逻辑判断和函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.eq() <span class="comment"># 等于相等 ==</span></span><br><span class="line">df.ne() <span class="comment"># 不等于 !=</span></span><br><span class="line">df.le() <span class="comment"># 小于等于 &gt;=</span></span><br><span class="line">df.lt() <span class="comment"># 小于 &lt;</span></span><br><span class="line">df.ge() <span class="comment"># 大于等于 &gt;=</span></span><br><span class="line">df.gt() <span class="comment"># 大于 &gt;</span></span><br><span class="line"><span class="comment"># 都支持  axis&#123;0 or ‘index’, 1 or ‘columns’&#125;, default ‘columns’</span></span><br><span class="line">df[df.Q1.ne(<span class="number">89</span>)] <span class="comment"># Q1 不等于8</span></span><br><span class="line">df.loc[df.Q1.gt(<span class="number">90</span>) &amp; df.Q2.lt(<span class="number">90</span>)] <span class="comment"># and 关系 Q1&gt;90 Q2&lt;90</span></span><br></pre></td></tr></table></figure>
<p>其他函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># isin</span></span><br><span class="line">df[df.team.isin([<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>])] <span class="comment"># 包含 AB 两组的</span></span><br><span class="line">df[df.isin(&#123;<span class="string">&#x27;team&#x27;</span>: [<span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>], <span class="string">&#x27;Q1&#x27;</span>:[<span class="number">36</span>,<span class="number">93</span>]&#125;)] <span class="comment"># 复杂查询，其他值为 NaN</span></span><br></pre></td></tr></table></figure>
<h2 id="函数筛选">函数筛选</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="keyword">lambda</span> df: df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>] <span class="comment"># Q1为8的</span></span><br><span class="line">df.loc[<span class="keyword">lambda</span> df: df.Q1 == <span class="number">8</span>, <span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q2&#x27;</span>] <span class="comment"># Q1为8的, 显示 Q1 Q2</span></span><br></pre></td></tr></table></figure>
<h2 id="where-和-mask">where 和 mask</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.where(s &gt; <span class="number">90</span>) <span class="comment"># 不符合条件的为 NaN</span></span><br><span class="line">s.where(s &gt; <span class="number">90</span>, <span class="number">0</span>) <span class="comment"># 不符合条件的为 0</span></span><br><span class="line"><span class="comment"># np.where, 大于80是真否则是假</span></span><br><span class="line">np.where(s&gt;<span class="number">80</span>, <span class="literal">True</span>, <span class="literal">False</span>)</span><br><span class="line">np.where(df.num&gt;=<span class="number">60</span>, <span class="string">&#x27;合格&#x27;</span>, <span class="string">&#x27;不合格&#x27;</span>)</span><br><span class="line"></span><br><span class="line">s.mask(s &gt; <span class="number">90</span>) <span class="comment"># 符合条件的为 NaN</span></span><br><span class="line">s.mask(s &gt; <span class="number">90</span>, <span class="number">0</span>) <span class="comment"># 符合条件的为 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 例：能被整除的显示，不能的显示相反数</span></span><br><span class="line">m = df.loc[:,<span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q4&#x27;</span>] % <span class="number">3</span> == <span class="number">0</span></span><br><span class="line">df.loc[:,<span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q4&#x27;</span>].where(m, -df.loc[:,<span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q4&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 行列相同数量，返回一个 array</span></span><br><span class="line">df.lookup([<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="string">&#x27;Q1&#x27;</span>,<span class="string">&#x27;Q2&#x27;</span>,<span class="string">&#x27;Q3&#x27;</span>]) <span class="comment"># array([36, 96, 61])</span></span><br><span class="line">df.lookup([<span class="number">1</span>], [<span class="string">&#x27;Q1&#x27;</span>]) <span class="comment"># array([36])</span></span><br></pre></td></tr></table></figure>
<h2 id="query">query</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.query(<span class="string">&#x27;Q1 &gt; Q2 &gt; 90&#x27;</span>) <span class="comment"># 直接写类型 sql where 语句</span></span><br><span class="line">df.query(<span class="string">&#x27;Q1 + Q2 &gt; 180&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;Q1 == Q2&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;(Q1&lt;50) &amp; (Q2&gt;40) and (Q3&gt;90)&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;Q1 &gt; Q2 &gt; Q3 &gt; Q4&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;team != &quot;C&quot;&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;team not in (&quot;E&quot;,&quot;A&quot;,&quot;B&quot;)&#x27;</span>)</span><br><span class="line"><span class="comment"># 对于名称中带有空格的列，可以使用反引号引起来</span></span><br><span class="line">df.query(<span class="string">&#x27;B == `team name`&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持传入变量，如：大于平均分40分的</span></span><br><span class="line">a = df.Q1.mean()</span><br><span class="line">df.query(<span class="string">&#x27;Q1 &gt; @a+40&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;Q1 &gt; `Q2`+@a&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># df.eval() 用法与 df.query 类似</span></span><br><span class="line">df[df.eval(<span class="string">&quot;Q1 &gt; 90 &gt; Q3 &gt; 10&quot;</span>)]</span><br><span class="line">df[df.eval(<span class="string">&quot;Q1 &gt; `Q2`+@a&quot;</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="filter">filter</h2>
<p>使用 filter 可以对行名和列名进行筛选。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.filter(items=[<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]) <span class="comment"># 选择两列</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;Q&#x27;</span>, axis=<span class="number">1</span>) <span class="comment"># 列名包含Q的</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;e$&#x27;</span>, axis=<span class="number">1</span>) <span class="comment"># 以 e 结尾的</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;1$&#x27;</span>, axis=<span class="number">0</span>) <span class="comment"># 正则, 索引名包含1的</span></span><br><span class="line">df.filter(like=<span class="string">&#x27;2&#x27;</span>, axis=<span class="number">0</span>) <span class="comment"># 索引中有2的</span></span><br><span class="line"><span class="comment"># 索引中2开头列名有Q的</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;^2&#x27;</span>, axis=<span class="number">0</span>).filter(like=<span class="string">&#x27;Q&#x27;</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>上面两个来自于https://www.gairuo.com/</p>
<h1 id="合并与新增行列">合并与新增行列</h1>
<h2 id="新增列">新增列</h2>
<p>假设原始数据如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;num_legs&#x27;</span>: [<span class="number">4</span>, <span class="number">2</span>], <span class="string">&#x27;num_wings&#x27;</span>: [<span class="number">0</span>, <span class="number">2</span>]&#125;,</span><br><span class="line">                  index=[<span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;hawk&#x27;</span>])</span><br><span class="line">slen = len(df[<span class="string">&#x27;num_legs&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>1）直接赋值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;a&#x27;</span>] = pd.Series(np.random.randn(slen), index=df.index) <span class="comment"># index要记得添加</span></span><br><span class="line">df[<span class="string">&#x27;b&#x27;</span>] = <span class="literal">None</span> <span class="comment"># 添加一列值为None</span></span><br><span class="line">df[<span class="string">&#x27;c&#x27;</span>] = [<span class="number">2</span>, <span class="number">4</span>] <span class="comment"># 添加列表数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># c1和c3列的顺序是一样的， c2则与之相反，具体看下文</span></span><br><span class="line">df[<span class="string">&#x27;c1&#x27;</span>] = [<span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>]</span><br><span class="line">df.index = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">df[<span class="string">&#x27;c2&#x27;</span>] = pd.Series([<span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>])</span><br><span class="line">df[<span class="string">&#x27;c3&#x27;</span>] = pd.Series([<span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>], index=df.index)</span><br></pre></td></tr></table></figure>
<p>2）loc方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[:,<span class="string">&#x27;d&#x27;</span>] = pd.Series(np.random.randn(slen), index=df.index)</span><br><span class="line">df.loc[:, <span class="string">&#x27;d&#x27;</span>] = [<span class="number">2</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>3）insert方法</p>
<p><em>insert方法使用的列名不能有重复值，连更新都不能</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.insert(len(df.columns), <span class="string">&#x27;e&#x27;</span>, pd.Series(np.random.randn(slen)), index=df.index)</span><br><span class="line">df.insert(len(df.columns), <span class="string">&#x27;ee&#x27;</span>, [<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>4）assign方法</p>
<p>assign方法参数可以是Series、标量、列表，还可以同时添加多列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = df.assign(f=df.num_wings.mean())  <span class="comment"># 将num_wings这列的平均值作为新增列f的结果</span></span><br><span class="line">df = df.assign(A=df.num_wings.sum(), B=[<span class="number">1</span>,<span class="number">2</span>])  <span class="comment"># 新增列A和B</span></span><br></pre></td></tr></table></figure>
<p>5）concat方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.concat([df, pd.Series([<span class="string">&#x27;yes&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>]).rename(<span class="string">&#x27;t&#x27;</span>)], axis=<span class="number">1</span>) <span class="comment"># 增加列t</span></span><br></pre></td></tr></table></figure>
<p>注意点：</p>
<ul>
<li>每个方法的参数都可以是Series、标量、列表</li>
<li>insert方法中新增的列名不能跟已有的一样，即使更新刚刚新增的列也会出错</li>
<li><code>df['a']=pd.Series(['no', 'yes']</code>的index顺序如果被修改，默认是以Series的index为准，可以通过<code>index=df.index</code>来指定按照原始DataFrame的index顺序</li>
</ul>
<h2 id="新增行">新增行</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建空白DataFrame</span></span><br><span class="line">df = pd.DataFrame(columns=[<span class="string">&#x27;lib&#x27;</span>, <span class="string">&#x27;qty1&#x27;</span>, <span class="string">&#x27;qty2&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>1）使用loc</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    df.loc[i] = [np.random.randint(<span class="number">-1</span>, <span class="number">1</span>) <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">3</span>)]</span><br><span class="line">    <span class="comment"># df.loc[i] = 5 添加一条数据都为5的记录</span></span><br></pre></td></tr></table></figure>
<p>2）使用append</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.append(&#123;<span class="string">&#x27;lib&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;qty1&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;qty2&#x27;</span>: <span class="number">4</span>&#125;, ignore_index=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># append也可以直接添加DataFrame</span></span><br><span class="line">df2 = pd.DataFrame([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]], columns=[<span class="string">&#x27;lib&#x27;</span>, <span class="string">&#x27;qty1&#x27;</span>, <span class="string">&#x27;qty2&#x27;</span>])</span><br><span class="line">df.append(df2, ignore_index=<span class="literal">True</span>)  <span class="comment"># ignore_index设置为True，index将会忽略df2的index</span></span><br></pre></td></tr></table></figure>
<p>3）重新生成DataFrame</p>
<p>循环将要添加的数据以字典的形式保存到一个列表中，在用列表创建出DataFrame</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">row_list = [] </span><br><span class="line">input_rows = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]] <span class="comment"># 待插入数据</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> input_rows:</span><br><span class="line">    dict1 = dict(lib=row[<span class="number">0</span>], qty1=row[<span class="number">1</span>], qty2=row[<span class="number">2</span>]) <span class="comment"># 将数据转为字典</span></span><br><span class="line">    row_list.append(dict1) <span class="comment"># 保存到列表中</span></span><br><span class="line">df = pd.DataFrame(row_list)</span><br></pre></td></tr></table></figure>
<p>以上两个来源于https://amberwest.github.io/</p>
<h2 id="合并">合并</h2>
<h3 id="append-vs.-concat">append() Vs. concat()</h3>
<p>连接或者合并DataFrame的时候一般有两种方式：纵向和横向。听起来总是觉得有点迷迷糊糊的。通俗的解释就是，纵向就是把两个或多个DataFrame纵向（从上到下）连接到一个DataFrame当中，index和column有重复情况也不进行任何操作，就是粗暴的纵向拼接DataFrame。横向就是会考虑如果有相同的index的话就会把相同index上所有列的数据合并在一起了，简单点理解就是相当于使用Excel中的V-lookup在两张有相同id但不同数据的表中进行了数据的融合。连接与合并DataFrame的常用函数有两个<code>append()</code>,<code>concat()</code>还有<code>merge()</code>。其中append()只能进行纵向连接，而<code>concat()</code>和<code>merge()</code>可以进行both。<code>concat()</code>默认是进行纵向连接，也就是跟<code>append()</code>效果一样，如果想要使用<code>concat()</code>进行横向合并则需要在<code>concat()</code>中声明变量axis。默认值：<code>concat(axis=0)</code>纵向连接，<code>concat(axis=1)</code>横向合并。下面举几个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: population = pd.read_csv(<span class="string">&#x27;population_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: unemployment = pd.read_csv(<span class="string">&#x27;unemployment_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: print(population)</span><br><span class="line">|               | <span class="number">2010</span> Census Population |</span><br><span class="line">|---------------|------------------------|</span><br><span class="line">| Zip Code ZCTA |                        |</span><br><span class="line">| <span class="number">57538</span>         | <span class="number">322</span>                    |</span><br><span class="line">| <span class="number">59916</span>         | <span class="number">130</span>                    |</span><br><span class="line">| <span class="number">37660</span>         | <span class="number">40038</span>                  |</span><br><span class="line">| <span class="number">2860</span>          | <span class="number">45199</span>                  |</span><br><span class="line">In [<span class="number">4</span>]: print(unemployment)</span><br><span class="line">|       | unemployment | participants |</span><br><span class="line">|-------|--------------|--------------|</span><br><span class="line">| Zip   |              |              |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line">| <span class="number">46167</span> | <span class="number">0.02</span>         | <span class="number">4800</span>         |</span><br><span class="line">| <span class="number">1097</span>  | <span class="number">0.33</span>         | <span class="number">42</span>           |</span><br><span class="line">| <span class="number">80808</span> | <span class="number">0.07</span>         | <span class="number">4310</span>         |</span><br></pre></td></tr></table></figure>
<p>以上为两个数据文件中数据的情况，下面讲举例说明append()和concat(axis=0)默认值对DataFrame纵向连接的结果，两种方式得到的结果是完全相同的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: population.append(unemployment)</span><br><span class="line">Out[<span class="number">5</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | NaN                                              | <span class="number">34447.0</span>      | <span class="number">0.11</span>         |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">4800.0</span>       | <span class="number">0.02</span>         |</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">42.0</span>         | <span class="number">0.33</span>         |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">4310.0</span>       | <span class="number">0.07</span>         |</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: pd.concat([population, unemployment], axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">6</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | NaN                                              | <span class="number">34447.0</span>      | <span class="number">0.11</span>         |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">4800.0</span>       | <span class="number">0.02</span>         |</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">42.0</span>         | <span class="number">0.33</span>         |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">4310.0</span>       | <span class="number">0.07</span>         |</span><br></pre></td></tr></table></figure>
<p>这里我们可以看到zip邮编下的”2860”出现了两次。如果我们想把相同zip下两个DataFrame的数据信息合并，我们就得用到横向合并，concat()提供了一个非常方便的办法就是concat(axis=1)或者concat(axis=’columns’)就可以实现横向合并了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">7</span>]: pd.concat([population, unemployment], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">17</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">0.33</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">0.02</span>         | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">0.07</span>         | <span class="number">4310.0</span>       |</span><br></pre></td></tr></table></figure>
<h3 id="concat-vs.-merge">concat() Vs. merge()</h3>
<p>在上面说完了<code>concat()</code>和<code>append()</code>横向纵向的连接与合并之后，下面要说一下<code>concat()</code>和<code>merge()</code>的区别和关系。上面我们说了<code>concat()</code>和<code>merge()</code>都可以进行横纵向的合并，在用法上和输出结果上两者有一些区别。这里要引入join的概念。<code>concat()</code>的默认join方式是outer join，而<code>merge()</code>的默认join方式是inner join。另外<code>concat()</code>和<code>merge()</code>在合并DataFrame的时候还有一个重要的区别就是，<code>concat()</code>是通过index来合并的，而<code>merge()</code>是通过列明（column label ）来合并的，如果列名设置成为了index的话需要把用来合并列名的index去掉之后再进行合并，否则会出现KeyError错误提示找不到列名。下面继续使用population和unemployment两个DataFrame来进行相关展示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: population = pd.read_csv(<span class="string">&#x27;population_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: unemployment = pd.read_csv(<span class="string">&#x27;unemployment_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: print(population)</span><br><span class="line">|               | <span class="number">2010</span> Census Population |</span><br><span class="line">|---------------|------------------------|</span><br><span class="line">| Zip Code ZCTA |                        |</span><br><span class="line">| <span class="number">57538</span>         | <span class="number">322</span>                    |</span><br><span class="line">| <span class="number">59916</span>         | <span class="number">130</span>                    |</span><br><span class="line">| <span class="number">37660</span>         | <span class="number">40038</span>                  |</span><br><span class="line">| <span class="number">2860</span>          | <span class="number">45199</span>                  |</span><br><span class="line">In [<span class="number">2</span>]: print(unemployment)</span><br><span class="line">|       | unemployment | participants |</span><br><span class="line">|-------|--------------|--------------|</span><br><span class="line">| Zip   |              |              |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line">| <span class="number">46167</span> | <span class="number">0.02</span>         | <span class="number">4800</span>         |</span><br><span class="line">| <span class="number">1097</span>  | <span class="number">0.33</span>         | <span class="number">42</span>           |</span><br><span class="line">| <span class="number">80808</span> | <span class="number">0.07</span>         | <span class="number">4310</span>         |</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: pd.concat([population, unemployment], axis=<span class="number">1</span>) <span class="comment">#pd.concat(join=&#x27;outer&#x27;)默认值为outer</span></span><br><span class="line">Out[<span class="number">3</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">0.33</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">0.02</span>         | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">0.07</span>         | <span class="number">4310.0</span>       |</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: pd.concat([population, unemployment], axis=<span class="number">1</span>, join=<span class="string">&#x27;inner&#x27;</span>) <span class="comment">#pd.concat(join=&#x27;outer&#x27;)默认值为outer，这里把join设置成了inner</span></span><br><span class="line">Out[<span class="number">4</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br></pre></td></tr></table></figure>
<p>接下来是对相同df进行merge操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: population = pd.read_csv(<span class="string">&#x27;population_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">5</span>]: unemployment = pd.read_csv(<span class="string">&#x27;unemployment_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#这里的导入我们还是设置了第一列ZipCode和Zip为各df的index，然后看一下使用merge()的时候会出现什么情况</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: pd.merge(population, unemployment, left_on=<span class="string">&#x27;ZipCode&#x27;</span>, right_on=<span class="string">&#x27;Zip&#x27;</span>)</span><br><span class="line">Out[<span class="number">5</span>]: KeyError: <span class="string">&quot;None of [&#x27;ZipCode&#x27;] are in the columns&quot;</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">#因为ZipCode被设置成了index所以merge找不到该列名，无法进行merge，我们可以.reset_index()，或者在导入数据的时候不设置index就可以解决该问题。</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: population = population.reset_index()</span><br><span class="line">In [<span class="number">6</span>]: unemployment = unemployment.reset_index()</span><br><span class="line">In [<span class="number">6</span>]: pd.merge(population, unemployment, left_on=<span class="string">&#x27;ZipCode&#x27;</span>, right_on=<span class="string">&#x27;Zip&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#pd.merge(how=&#x27;inner&#x27;)默认值为inner，merge()的合并方式参数是how不是join</span></span><br><span class="line"></span><br><span class="line">Out[<span class="number">6</span>]:</span><br><span class="line">|   | ZipCode | <span class="number">2010</span> Census Population | Zip  | Unemployment | Participants |</span><br><span class="line">|---|---------|------------------------|------|--------------|--------------|</span><br><span class="line">| <span class="number">0</span> | <span class="number">2860</span>    | <span class="number">45199</span>                  | <span class="number">2860</span> | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line"></span><br><span class="line"><span class="comment">#merge的join和concat的join出来的结果会有一些不同，concat出来的df没有index，merge出来的df会有默认index和两个df合并的的列ZipCode和Zip</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: pd.merge(population, unemployment, left_on=<span class="string">&#x27;ZipCode&#x27;</span>, right_on=<span class="string">&#x27;Zip&#x27;</span>,</span><br><span class="line">               how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">7</span>]: </span><br><span class="line">|   | ZipCode | <span class="number">2010</span> Census Population | Zip     | Unemployment | Participants |</span><br><span class="line">|---|---------|------------------------|---------|--------------|--------------|</span><br><span class="line">| <span class="number">0</span> | <span class="number">57538.0</span> | <span class="number">322.0</span>                  | NaN     | NaN          | NaN          |</span><br><span class="line">| <span class="number">1</span> | <span class="number">59916.0</span> | <span class="number">130.0</span>                  | NaN     | NaN          | NaN          |</span><br><span class="line">| <span class="number">2</span> | <span class="number">37660.0</span> | <span class="number">40038.0</span>                | NaN     | NaN          | NaN          |</span><br><span class="line">| <span class="number">3</span> | <span class="number">2860.0</span>  | <span class="number">45199.0</span>                | <span class="number">2860.0</span>  | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">4</span> | NaN     | NaN                    | <span class="number">46167.0</span> | <span class="number">0.02</span>         | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">5</span> | NaN     | NaN                    | <span class="number">1097.0</span>  | <span class="number">0.33</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">6</span> | NaN     | NaN                    | <span class="number">80808.0</span> | <span class="number">0.07</span>         | <span class="number">4310.0</span>       |</span><br><span class="line"><span class="comment">#这里有点奇怪，ZipCode和Zip经过outer join之后变成了float类型。</span></span><br></pre></td></tr></table></figure>
<p>我暂且认为更改ZipCode和Zip的这个行为是个bug，并且已经提交给git了。可以看下之后的反馈：https://github.com/pandas-dev/pandas/issues/34017</p>
<p>当然还是有一些办法去解决这个问题，可是使用会concat()方法来进行合并，或者我们可以通过统一两个DataFrame邮编的label来使用on= [‘Zip’]来进行合并，实验表明通过on= [‘Zip’]进行合并不会出现上述问题：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: population.rename(columns=&#123;<span class="string">&#x27;ZipCode&#x27;</span>:<span class="string">&#x27;Zip&#x27;</span>&#125;, inplace=<span class="literal">True</span>) <span class="comment">#更改population中的column label</span></span><br><span class="line">In [<span class="number">8</span>]: merge_2 = pd.merge(population, unemployment, on=[<span class="string">&#x27;Zip&#x27;</span>], how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">print(merge_2)</span><br><span class="line">Out[<span class="number">8</span>]:</span><br><span class="line">|   | Zip   | <span class="number">2010</span> Census Population | Unemployment | Participants | Participants |</span><br><span class="line">|---|-------|------------------------|--------------|--------------|--------------|</span><br><span class="line">| <span class="number">0</span> | <span class="number">57538</span> | <span class="number">322.0</span>                  | NaN          | NaN          | NaN          |</span><br><span class="line">| <span class="number">1</span> | <span class="number">59916</span> | <span class="number">130.0</span>                  | NaN          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2</span> | <span class="number">37660</span> | <span class="number">40038.0</span>                | NaN          | NaN          | NaN          |</span><br><span class="line">| <span class="number">3</span> | <span class="number">2860</span>  | <span class="number">45199.0</span>                | <span class="number">0.11</span>         | <span class="number">34447.0</span>      | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">4</span> | <span class="number">46167</span> | NaN                    | <span class="number">0.02</span>         | <span class="number">4800.0</span>       | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">5</span> | <span class="number">1097</span>  | NaN                    | <span class="number">0.33</span>         | <span class="number">42.0</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">6</span> | <span class="number">80808</span> | NaN                    | <span class="number">0.07</span>         | <span class="number">4310.0</span>       | <span class="number">4310.0</span>       |</span><br></pre></td></tr></table></figure>
<h3 id="join-vs.-concat">join() Vs. concat()</h3>
<p>join有四种合并方法，分别是<code>how='left</code>‘, <code>how='right'</code>, <code>how='inner'</code>和<code>how='outer'</code>。当然这些合并方法<code>merge()</code>也是全部都有的。所以看到这里也应该对<code>append()</code>, <code>concat()</code>, <code>join()</code>和<code>merge()</code>有很充分的理解了。<code>merge()</code>是四个函数里面最强大的，但是在使用原则上来讲并不是每次对数据操作都要用<code>merge()</code>，有时候<code>append()</code>和<code>concat()</code>使用起来可能会更加方便，在最后会总结一下这四个函数的分类和原则。这里先看一下<code>join()</code>的实际操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: population.join(unemployment) <span class="comment">#join的默认合并方式是how=&#x27;left&#x27;</span></span><br><span class="line">Out[<span class="number">1</span>]:</span><br><span class="line">|         | <span class="number">2010</span> Census Population | unemployment | participants |</span><br><span class="line">|---------|------------------------|--------------|--------------|</span><br><span class="line">| ZipCode |                        |              |              |</span><br><span class="line">| <span class="number">57538</span>   | <span class="number">322</span>                    | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span>   | <span class="number">130</span>                    | NaN          | NaN          |</span><br><span class="line">| <span class="number">37660</span>   | <span class="number">40038</span>                  | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>    | <span class="number">45199</span>                  | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br></pre></td></tr></table></figure>
<p>df1.join(df2, how=’left’)的意思是指以左边的DataFrame为准进行合并，population在unemployment左边，所以这个合并就会以population的index也就是ZipCode为准进行合并。所以df1.join(df2, how=’right’)就会以unemployment的index进行合并：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">2</span>]: population.join(unemployment, how= <span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">Out[<span class="number">2</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population | unemployment | participants |</span><br><span class="line">|-------|------------------------|--------------|--------------|</span><br><span class="line">| Zip   |                        |              |              |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line">| <span class="number">46167</span> | NaN                    | <span class="number">0.02</span>         | <span class="number">4800</span>         |</span><br><span class="line">| <span class="number">1097</span>  | NaN                    | <span class="number">0.33</span>         | <span class="number">42</span>           |</span><br><span class="line">| <span class="number">80808</span> | NaN                    | <span class="number">0.07</span>         | <span class="number">4310</span>         |</span><br></pre></td></tr></table></figure>
<p>join和concat都是要以index来进行合并，所以在合并时，必须要有对应的index。concat相比join缺少了left和right两种合并方式，但是在outer和inner合并方式来讲得到的结果是一模一样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">population.join(unemployment, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">pd.concat([population, unemployment], join=<span class="string">&#x27;outer&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#以上两者结果相同</span></span><br><span class="line">population.join(unemployment, how=<span class="string">&#x27;inner&#x27;</span>)</span><br><span class="line">pd.concat([population, unemployment], join=<span class="string">&#x27;inner&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#以上两者结果相同</span></span><br></pre></td></tr></table></figure>
<h3 id="append-concat-join和merge总结">append(), concat(), join()和merge()总结</h3>
<h4 id="append">append()</h4>
<p>语法：<code>df1.append(df2)</code></p>
<p>说明：<code>append()</code>就是简单的把两个DataFrame纵向罗列起来，<strong>不需要index</strong>。</p>
<h4 id="concat">concat()</h4>
<p>语法：<code>pd.concat([df1, df2])</code></p>
<p>说明：<code>concat()</code>可以横纵向合并多行或者多列，可以使用inner或者outer方式来合并，<strong>需要index</strong>。</p>
<h4 id="join">join()</h4>
<p>语法：<code>df1.join(df2)</code></p>
<p>说明：<code>join()</code>可以使用多种合并方式，除了inner和outer之外还可以用left和right，这些操作同样<strong>需要index</strong>。</p>
<h4 id="merge">merge()</h4>
<p>语法：<code>pd.merge([df1, df2])</code></p>
<p>说明：方式最多的合并函数。<strong>不需要index。</strong></p>
<h3 id="merge_order函数">merge_order()函数</h3>
<p><code>merge_order()</code>函数可以用一个函数进行两个操作，即<code>merge()</code>和<code>sort_value()</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.merge_ordered(hardware, software, on=[<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>], suffixes=[<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>]，fill_method=<span class="string">&#x27;ffill&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>来自于https://mingju.net/2020/05/merging-dataframes-with-pandas/</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>Robust fit</title>
    <url>/posts/7ff46c3b.html</url>
    <content><![CDATA[<p>这一篇差不多是作为<a href="https://lifeodyssey.github.io/posts/7decea87.html">这个</a>的后续</p>
<a id="more"></a>
<h1 id="scipy.optimize.least_squares">scipy.optimize.least_squares</h1>
<p>用来搞Robust fit的有好几个，这里先从scipy的这个函数讲起</p>
<p>先看一下scipy cookbook里面的<span class="exturl" data-url="aHR0cHM6Ly9zY2lweS1jb29rYm9vay5yZWFkdGhlZG9jcy5pby9pdGVtcy9yb2J1c3RfcmVncmVzc2lvbi5odG1s">这个例子<i class="fa fa-external-link-alt"></i></span></p>
<p>这个例子里拟合了一个正弦函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data</span>(<span class="params">t, A, sigma, omega, noise=<span class="number">0</span>, n_outliers=<span class="number">0</span>, random_state=<span class="number">0</span></span>):</span></span><br><span class="line">    y = A * np.exp(-sigma * t) * np.sin(omega * t)</span><br><span class="line">    rnd = np.random.RandomState(random_state)</span><br><span class="line">    error = noise * rnd.randn(t.size)</span><br><span class="line">    outliers = rnd.randint(<span class="number">0</span>, t.size, n_outliers)</span><br><span class="line">    error[outliers] *= <span class="number">35</span></span><br><span class="line">    <span class="keyword">return</span> y + error</span><br></pre></td></tr></table></figure>
<p>确定模型参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = <span class="number">2</span></span><br><span class="line">sigma = <span class="number">0.1</span></span><br><span class="line">omega = <span class="number">0.1</span> * <span class="number">2</span> * np.pi</span><br><span class="line">x_true = np.array([A, sigma, omega])</span><br><span class="line"></span><br><span class="line">noise = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">t_min = <span class="number">0</span></span><br><span class="line">t_max = <span class="number">30</span></span><br></pre></td></tr></table></figure>
<p>将三个离群值放在fitting dataset里</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t_train = np.linspace(t_min, t_max, <span class="number">30</span>)</span><br><span class="line">y_train = generate_data(t_train, A, sigma, omega, noise=noise, n_outliers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>定义损失函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">x, t, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x[<span class="number">0</span>] * np.exp(-x[<span class="number">1</span>] * t) * np.sin(x[<span class="number">2</span>] * t) - y</span><br></pre></td></tr></table></figure>
<p>剩下就是一些常规的过程</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x0 = np.ones(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> least_squares</span><br><span class="line">res_lsq = least_squares(fun, x0, args=(t_train, y_train))</span><br><span class="line">res_robust = least_squares(fun, x0, loss=<span class="string">&#x27;soft_l1&#x27;</span>, f_scale=<span class="number">0.1</span>, args=(t_train, y_train))</span><br><span class="line">t_test = np.linspace(t_min, t_max, <span class="number">300</span>)</span><br><span class="line">y_test = generate_data(t_test, A, sigma, omega)</span><br><span class="line">y_lsq = generate_data(t_test, *res_lsq.x)</span><br><span class="line">y_robust = generate_data(t_test, *res_robust.x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(t_train, y_train, <span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">plt.plot(t_test, y_test, label=<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line">plt.plot(t_test, y_lsq, label=<span class="string">&#x27;lsq&#x27;</span>)</span><br><span class="line">plt.plot(t_test, y_robust, label=<span class="string">&#x27;robust lsq&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$t$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;$y$&#x27;</span>)</span><br><span class="line">plt.legend();</span><br></pre></td></tr></table></figure>
<figure>
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmkAAAGECAYAAABtQ7cTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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%0AERERF/p/BgabFaz9QPEAAAAASUVORK5CYII=%0A" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>很清楚的可以看出来，这里robust lsq结果明显更接近那个true的线</p>
<p>这里只用了soft l1,在least_squares里还有另外几个</p>
<blockquote>
<p><strong>loss</strong> str or callable, optional</p>
<p>Determines the loss function. The following keyword values are allowed:</p>
<blockquote>
<ul>
<li>‘linear’ (default) : <code>rho(z) = z</code>. Gives a standard least-squares problem.</li>
<li>‘soft_l1’ : <code>rho(z) = 2 * ((1 + z)**0.5 - 1)</code>. The smooth approximation of l1 (absolute value) loss. Usually a good choice for robust least squares.</li>
<li>‘huber’ : <code>rho(z) = z if z &lt;= 1 else 2*z**0.5 - 1</code>. Works similarly to ‘soft_l1’.</li>
<li>‘cauchy’ : <code>rho(z) = ln(1 + z)</code>. Severely weakens outliers influence, but may cause difficulties in optimization process.</li>
<li>‘arctan’ : <code>rho(z) = arctan(z)</code>. Limits a maximum loss on a single residual, has properties similar to ‘cauchy’.</li>
</ul>
</blockquote>
</blockquote>
<p>比较难受的就是这次没法像curve_fit那个函数一样那么好用了</p>
<p>就 我还要自己手动写个cost func</p>
<h2 id="另一个例子">另一个例子</h2>
<p>这个例子来自于<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnNjaXB5Lm9yZy9kb2Mvc2NpcHkvcmVmZXJlbmNlL2dlbmVyYXRlZC9zY2lweS5vcHRpbWl6ZS5sZWFzdF9zcXVhcmVzLmh0bWw=">这儿<i class="fa fa-external-link-alt"></i></span>。</p>
<p>感谢这个例子教会我写cost func</p>
<p>Define the model function as <code>y = a + b * exp(c * t)</code>, where t is a predictor variable, y is an observation and a, b, c are parameters to estimate</p>
<p>First, define the function which generates the data with noise and outliers, define the model parameters, and generate data:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">gen_data</span>(<span class="params">t, a, b, c, noise=<span class="number">0</span>, n_outliers=<span class="number">0</span>, random_state=<span class="number">0</span></span>):</span></span><br><span class="line"><span class="meta">... </span>    y = a + b * np.exp(t * c)</span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    rnd = np.random.RandomState(random_state)</span><br><span class="line"><span class="meta">... </span>    error = noise * rnd.randn(t.size)</span><br><span class="line"><span class="meta">... </span>    outliers = rnd.randint(<span class="number">0</span>, t.size, n_outliers)</span><br><span class="line"><span class="meta">... </span>    error[outliers] *= <span class="number">10</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> y + error</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = <span class="number">0.5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = <span class="number">2.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = <span class="number">-1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t_min = <span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t_max = <span class="number">10</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>n_points = <span class="number">15</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t_train = np.linspace(t_min, t_max, n_points)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train = gen_data(t_train, a, b, c, noise=<span class="number">0.1</span>, n_outliers=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>Define function for computing residuals and initial estimate of parameters.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">x, t, y</span>):</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> x[<span class="number">0</span>] + x[<span class="number">1</span>] * np.exp(x[<span class="number">2</span>] * t) - y</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x0 = np.array([<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>])</span><br></pre></td></tr></table></figure>
<p><strong>NOTE</strong>: x0,x1,x2 corresponding to a,b,c; and t is what we always treat as x</p>
<p>Compute a standard least-squares solution:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>res_lsq = least_squares(fun, x0, args=(t_train, y_train))</span><br></pre></td></tr></table></figure>
<p>Now compute two solutions with two different robust loss functions. The parameter <em>f_scale</em> is set to 0.1, meaning that inlier residuals should not significantly exceed 0.1 (the noise level used).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>res_soft_l1 = least_squares(fun, x0, loss=<span class="string">&#x27;soft_l1&#x27;</span>, f_scale=<span class="number">0.1</span>,</span><br><span class="line"><span class="meta">... </span>                            args=(t_train, y_train))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res_log = least_squares(fun, x0, loss=<span class="string">&#x27;cauchy&#x27;</span>, f_scale=<span class="number">0.1</span>,</span><br><span class="line"><span class="meta">... </span>                        args=(t_train, y_train))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t_test = np.linspace(t_min, t_max, n_points * <span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_true = gen_data(t_test, a, b, c)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_lsq = gen_data(t_test, *res_lsq.x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_soft_l1 = gen_data(t_test, *res_soft_l1.x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_log = gen_data(t_test, *res_log.x)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.plot(t_train, y_train, <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.plot(t_test, y_true, <span class="string">&#x27;k&#x27;</span>, linewidth=<span class="number">2</span>, label=<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.plot(t_test, y_lsq, label=<span class="string">&#x27;linear loss&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.plot(t_test, y_soft_l1, label=<span class="string">&#x27;soft_l1 loss&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.plot(t_test, y_log, label=<span class="string">&#x27;cauchy loss&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.xlabel(<span class="string">&quot;t&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.ylabel(<span class="string">&quot;y&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.legend()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/scipy-optimize-least_squares-1_00_00.png" alt="scipy-optimize-least_squares-1_00_00"><figcaption aria-hidden="true">scipy-optimize-least_squares-1_00_00</figcaption>
</figure>
<p>这个例子后面还有一个解决复数优化的问题，可真是牛逼</p>
<h1 id="scikit-learn">scikit learn</h1>
<p>这个大体上相同，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> (</span><br><span class="line">    LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">X = np.random.normal(size=<span class="number">400</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"><span class="comment"># Make sure that it X is 2D</span></span><br><span class="line">X = X[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">X_test = np.random.normal(size=<span class="number">200</span>)</span><br><span class="line">y_test = np.sin(X_test)</span><br><span class="line">X_test = X_test[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">y_errors = y.copy()</span><br><span class="line">y_errors[::<span class="number">3</span>] = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X_errors = X.copy()</span><br><span class="line">X_errors[::<span class="number">3</span>] = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">y_errors_large = y.copy()</span><br><span class="line">y_errors_large[::<span class="number">3</span>] = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X_errors_large = X.copy()</span><br><span class="line">X_errors_large[::<span class="number">3</span>] = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">estimators = [(<span class="string">&#x27;OLS&#x27;</span>, LinearRegression()),</span><br><span class="line">              (<span class="string">&#x27;Theil-Sen&#x27;</span>, TheilSenRegressor(random_state=<span class="number">42</span>)),</span><br><span class="line">              (<span class="string">&#x27;RANSAC&#x27;</span>, RANSACRegressor(random_state=<span class="number">42</span>)),</span><br><span class="line">              (<span class="string">&#x27;HuberRegressor&#x27;</span>, HuberRegressor())]</span><br><span class="line">colors = &#123;<span class="string">&#x27;OLS&#x27;</span>: <span class="string">&#x27;turquoise&#x27;</span>, <span class="string">&#x27;Theil-Sen&#x27;</span>: <span class="string">&#x27;gold&#x27;</span>, <span class="string">&#x27;RANSAC&#x27;</span>: <span class="string">&#x27;lightgreen&#x27;</span>, <span class="string">&#x27;HuberRegressor&#x27;</span>: <span class="string">&#x27;black&#x27;</span>&#125;</span><br><span class="line">linestyle = &#123;<span class="string">&#x27;OLS&#x27;</span>: <span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;Theil-Sen&#x27;</span>: <span class="string">&#x27;-.&#x27;</span>, <span class="string">&#x27;RANSAC&#x27;</span>: <span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;HuberRegressor&#x27;</span>: <span class="string">&#x27;--&#x27;</span>&#125;</span><br><span class="line">lw = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">x_plot = np.linspace(X.min(), X.max())</span><br><span class="line"><span class="keyword">for</span> title, this_X, this_y <span class="keyword">in</span> [</span><br><span class="line">        (<span class="string">&#x27;Modeling Errors Only&#x27;</span>, X, y),</span><br><span class="line">        (<span class="string">&#x27;Corrupt X, Small Deviants&#x27;</span>, X_errors, y),</span><br><span class="line">        (<span class="string">&#x27;Corrupt y, Small Deviants&#x27;</span>, X, y_errors),</span><br><span class="line">        (<span class="string">&#x27;Corrupt X, Large Deviants&#x27;</span>, X_errors_large, y),</span><br><span class="line">        (<span class="string">&#x27;Corrupt y, Large Deviants&#x27;</span>, X, y_errors_large)]:</span><br><span class="line">    plt.figure(figsize=(<span class="number">5</span>, <span class="number">4</span>))</span><br><span class="line">    plt.plot(this_X[:, <span class="number">0</span>], this_y, <span class="string">&#x27;b+&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> name, estimator <span class="keyword">in</span> estimators:</span><br><span class="line">        model = make_pipeline(PolynomialFeatures(<span class="number">3</span>), estimator)</span><br><span class="line">        model.fit(this_X, this_y)</span><br><span class="line">        mse = mean_squared_error(model.predict(X_test), y_test)</span><br><span class="line">        y_plot = model.predict(x_plot[:, np.newaxis])</span><br><span class="line">        plt.plot(x_plot, y_plot, color=colors[name], linestyle=linestyle[name],</span><br><span class="line">                 linewidth=lw, label=<span class="string">&#x27;%s: error = %.3f&#x27;</span> % (name, mse))</span><br><span class="line"></span><br><span class="line">    legend_title = <span class="string">&#x27;Error of Mean\nAbsolute Deviation\nto Non-corrupt Data&#x27;</span></span><br><span class="line">    legend = plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, frameon=<span class="literal">False</span>, title=legend_title,</span><br><span class="line">                        prop=dict(size=<span class="string">&#x27;x-small&#x27;</span>))</span><br><span class="line">    plt.xlim(<span class="number">-4</span>, <span class="number">10.2</span>)</span><br><span class="line">    plt.ylim(<span class="number">-2</span>, <span class="number">10.2</span>)</span><br><span class="line">    plt.title(title)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>有个PolynomialFeatures(3)的意思是，可以从0阶多项式拟合到3阶多项式</p>
<blockquote>
<p>Robust fitting is demoed in different situations:</p>
<ul>
<li>No measurement errors, only modelling errors (fitting a sine with a polynomial)</li>
<li>Measurement errors in X</li>
<li>Measurement errors in y</li>
</ul>
<p>The median absolute deviation to non corrupt new data is used to judge the quality of the prediction.</p>
<p>What we can see that:</p>
<ul>
<li>RANSAC is good for strong outliers in the y direction</li>
<li>TheilSen is good for small outliers, both in direction X and y, but has a break point above which it performs worse than OLS.</li>
<li>The scores of HuberRegressor may not be compared directly to both TheilSen and RANSAC because it does not attempt to completely filter the outliers but lessen their effect.</li>
</ul>
</blockquote>
<h1 id="iterative-bi-square-method">iterative bi-square method</h1>
<p>其实我最想找的是这个，这个来源于<span class="exturl" data-url="ZG9pOjEwLjMzOTAvcnMxMjAxMDA3Nw==">这篇文献<i class="fa fa-external-link-alt"></i></span></p>
<p>但是找来找去都没找到python的包</p>
<p>啊 又逼着我改用R了</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>游戏人生</title>
    <url>/posts/6fe52848.html</url>
    <content><![CDATA[<p>其实本来是不打算在这个博客里写这么多内容的，但是没想到自己的表达欲和身边没有能表达的人双重境况下又让我慢慢把这些东西发了出来。</p>
<p>没关系啦，我曾经跟好几个同学朋友发过我链接的网址，跟他们说我会在这里写点东西，但是迄今为止没有一个人因为关注到了我的更新来关心我。</p>
<p>既然没有人看到，那就当自己的一个私密又公开的日记本就好了。</p>
<p>如果你有缘看到，我很开心能和你分享这些心事，也希望这些东西对你有用。</p>
<p>可能自己之后会开第二个博客来写这些东西吧。</p>
<a id="more"></a>
<h1 id="人生的意义是什么呢">人生的意义是什么呢？</h1>
<p>每个人大概都有过那种非常自信的时间段，就是觉得那种，100个人里面有一个人活了下来，就觉得自己是那个活着的人，而不是死的那些。我也有过。</p>
<p>我一直以为自己是个天选之子，曾经。比如，在班里我是最早去找实验室的，我也很快就触及到了很多目前没解决的科学问题，并且觉得自己似乎有能力来解决它。</p>
<p>但是，慢慢的发现其实自己只是一个普通人。</p>
<p>自己的想法别人也可以想到，自己的工作也没有什么不可替代性，没有我还会有张XX李CC来解决它，毕竟问题就在那里，迟早是要被解决的。</p>
<p>自己不是什么天选，自己只是一个普通人。所以自己想不出来一个很好的课题很正常，自己做不出来东西也很正常。</p>
<p>因为自己只是普通人，一个可能稍微运气好一点的普通人。自己在迷路的时候稍微看到了点特殊的东西，就觉得那是因为自己坚持走了好久的路才看到它的，其实它的出现根本和自己的努力没关系。</p>
<p>就像那个经典的问题。</p>
<blockquote>
<p>三个人一起坐着电梯上楼，上楼之后，有人问他，你是怎么上来的呀？</p>
<p>一个人讲：“我一直在看书，是知识的力量。”</p>
<p>另一个人讲：“我一直在电梯里仰卧起坐，是运动的力量。”</p>
<p>最后一个人讲：“我在电梯里呆了很长很长时间，是坚持的力量。”</p>
</blockquote>
<p>那我活着的意义到底是什么？</p>
<p>大概是不久之前，我就和朋友讨论过这个问题。</p>
<p>我目前给我自己的答案就是</p>
<p>人出生就是为了受苦的。</p>
<p>人类诞生下来，唯一一个从诞生开始就客观存在的使命就是繁衍，每一个物种都是。很多时候说生物都是基因的奴隶也不为过。</p>
<p>但是人类居然有了自己的想法， 居然不想执行自己的使命，上天自然要给人类各种各样的痛苦。</p>
<p>其实这么讲，最快的结束痛苦，对抗这个使命的方法就是自杀。我也想过自杀。</p>
<p>但是其实可能，每个人都有必须活下去的理由，或者说支撑着自己活下去的理由。</p>
<p>对我来讲，我是还有好多想看的东西没有看，我觉得这样太对不起自己来人间这一趟了，也太便宜基因这个小恶魔了。</p>
<blockquote>
<p>且夫天地之间，物各有主，苟非吾之所有，虽一毫而莫取。惟江上之清风，与山间之明月，耳得之而为声，目遇之而成色，取之无禁，用之不竭。是造物者之无尽藏也，而吾与子之所共适。</p>
</blockquote>
<p>自己还有好多风景没有看过，好多地方没有去过，好多事情没有做过。</p>
<blockquote>
<p>人生若梦，为欢几何？古人秉烛夜游，良有以也。况阳春召我以烟景，大块假我以文章。会桃花之芳园，序天伦之乐事。群季俊秀，皆为惠连；吾人咏歌，独惭康乐。幽赏未已，高谈转清。</p>
</blockquote>
<p>大自然真的好像在PUA我，一方面拿天地间的奇伟瑰丽召唤我，让我坚持下去；另一方面又给我施加无穷无尽的苦难。</p>
<p>我的人生，也就是来受苦的吧。但是能在这种种苦难中能让我目酣神醉，这人间烟火能让我潸然泪下，这些东西就像画龙点睛一样，照亮了整个的黑暗。</p>
<p>所以我目前的一个个选择，也都是想让自己越来越自由。如果我没有了感受这些东西的机会，那我还不如去死好了。</p>
<h1 id="人生是什么">人生是什么？</h1>
<p>但是人类真的能掌握自己人生的走向吗？就像我一直想做的一个个事情，我真的能做吗？很有可能最终也会死不瞑目。因为我只是个普通人。普通的不能再普通。</p>
<p>我越来越感受到，相比于个人的努力，运气 和 时代 两个东西，真的是几乎决定了90%的人生走向。</p>
<p>这么讲吧，如果固定运气和时代这两个因素，那么努力和结果的关系大概是这样的。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030321182943797.png" alt="y=arctan(x)"><figcaption aria-hidden="true">y=arctan(x)</figcaption>
</figure>
<p>努力会让你越来越好，但是这会有一个极限，会有一个渐近线。</p>
<p>熟悉我的人都知道我是一个RPG玩家，最近我越来越有人生其实就像一场游戏的感觉了，也就是本文的标题。</p>
<p>最出名的RPG《博德之门》，每次事件，每次战斗，都是一场扔骰子。哪怕好感达到了100%，你也有可能表白失败；哪怕你的等级属性比BOSS厉害好多，你也有可能被他打死。</p>
<p>因为一切都是随机的，都要看概率。</p>
<p>人生真的好像呀，很多事情，就像我之前一样，只是因为你运气好，和你自己的努力并不一定有什么关系。</p>
<p>这里牵扯到另一个问题，人类社会是可以被预测的吗？</p>
<p>因为我们现在已经在慢慢研究到了每个原子每个分子每个蛋白质每个RNA的行为和功能了，如果我们把他们的规律研究出来，人类不就是一大坨蛋白质加溶液吗？那我们也可以预测每个人类的行为咯？这样我们也可以预测人类社会的发展咯？就像马克思搞的那一套“人类社会的发展规律”。</p>
<p>这么说，人类的未来是确定的，可以被预测的咯？</p>
<p>我最近越来觉得不会了，因为我开始感觉上帝是掷骰子的。</p>
<p>就像面前有两只快死的小老鼠，上帝只能救活一只。上帝要决定救哪一只。</p>
<p>上帝计算了所有的参数，这个时候他需要一个东西：目标函数。或者讲，为了什么才来救小老鼠。</p>
<p>上帝如果按照自己的想法来救，那么我们人类社会的命运其实就被确定了。但是真的存在“上帝”这个东西吗？</p>
<p>如果上帝只是来履行职责，它本身对于救哪个小老鼠并没有什么偏好。那他就是在掷骰子。</p>
<p>人生是游戏的另一重含义，就是，你的命运大概率是被时代-也就是剧本决定的。</p>
<p>毕竟单个的人在时代的浪潮里，连一朵小水花都算不上。哪怕你练成了十里坡剑神，你可能还是救不了月如和灵儿。</p>
<p>哪怕你是天下第一高手，你也会有救不了守护不了的人。</p>
<p>人生就是一场游戏，一场由时代编剧，由上帝掷骰子的RPG游戏。</p>
<p>游戏打的爽不爽，很多时候是由上帝的骰子决定。</p>
<p>游戏的结局好不好，则是由时代决定。</p>
<h1 id="updata-of-the-blog">Updata of the blog</h1>
<p>I decide to add google analytics back to get closer with my friends. The way of collect persenal information is based on google. Thank you for your understanding.</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>怎么写研究计划书</title>
    <url>/posts/f43786f7.html</url>
    <content><![CDATA[<p>第四弹在我修士快毕业的时候终于出来了。</p>
<p>有咨询日本理工科硕士博士留学或者研究计划书写作的可以联系我哦，邮箱zhouthepassion@outlook.com。</p>
<p>为了证明这个方法的可行性，我随机选了一个我完全不熟悉的工科。我接触过海洋/环境/计算机/信息/生物等方向，这个老师做金属材料的。</p>
<a id="more"></a>
<h1 id="寻找合适的老师"><a class="markdownIt-Anchor" href="#寻找合适的老师"></a> 寻找合适的老师</h1>
<p>相比于之前介绍过的在学校主页或者论文里找老师，这里提供其他另外几个更好的地方。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9rYWtlbi5uaWkuYWMuanAvZW4vaW5kZXgv">https://kaken.nii.ac.jp/en/index/<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9yZXNlYXJjaC1lci5qcC8=">https://research-er.jp/<i class="fa fa-external-link-alt"></i></span></p>
<p>这两个可以直接搜到老师的项目，并且一口气是全日本的，直接用关键词就行，但是要注意的是第二个只能用日语搜索。</p>
<p>因为我已经随机找完了这个老师，接下来进行到下一步。</p>
<h1 id="看懂老师当前的项目"><a class="markdownIt-Anchor" href="#看懂老师当前的项目"></a> 看懂老师当前的项目</h1>
<p>这里是用第二个网站查出来的结果，这个老师项目还挺多。</p>
<p>项目多的老师一般比较推荐申请hhh，如果他不push的话。在这个网站上查不出来有正在进行的项目的老师一般不建议申请。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030523172730033.png" alt="image-00030523172730033"></p>
<p>在这里面找出来他负责的项目，这里这四个都是。就是在项目的前面有代表两个字的。</p>
<p>我这里选了第一个项目，因为那些东西我都不知道是啥。</p>
<p>点开之后有个这个</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030523173022754.png" alt="image-00030523173022754"></p>
<p>那里有个关连link，点开可以进入到这个项目的详细情况。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030523173124945.png" alt="image-00030523173124945"></p>
<p>看到那个Outline了没，我们这一步最终目的就是把这个Outline搞明白。有的进行很多年的项目会在这里有一个Progress Report，那个也要读懂。</p>
<blockquote>
<p>COVID-19の世界的な流行は、個人防護具(PPE)の増産と性能改善を早急に行う必要性を浮き彫りにした。現状の最大の課題は、エアロゾル化されたウイルスはほとんどの種類のマスクを簡単に通過できることである。したがって、マスクを着用する場合、他人への拡散を防ぐことには一定の効果があるが、自分への拡散を防ぐことには効果が薄い。迅速な対応を必要とされ ている現在、既存のPPEの改善に焦点を当てた研究が必要である。<strong>そこで本研究では申請者がこれまでに開発してきたポリフェノール性コーティングをサージカルマスクやその他の市販マスクへと適用し、ウイルスや粒子状物質の透過性に対する影響について研究する</strong> 。</p>
</blockquote>
<p>（吐槽一句，那几个Katakana还真就是关键字）</p>
<p>读懂了之后找出关键字，基本都在Objective那句话里。</p>
<p>这里这个基本就是要改善口罩涂层，研究病毒和颗粒渗透性的影响。</p>
<h1 id="读懂-至少一篇相关论文"><a class="markdownIt-Anchor" href="#读懂-至少一篇相关论文"></a> 读懂 至少一篇相关论文</h1>
<p>这里要先提一下，如果你在上一个页面里有找到Progress Report的话，大概率会有论文发表和会议发表，这时候直接读那一篇就好了，如果没有的话，打开谷歌学术。输入关键词。像我这里的关键词就是polyphenolic coating, surgical masks,  permeability of viruses and particulate matter</p>
<p>把时间线调到最近三四年以内的文章</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030523173817074.png" alt="image-00030523173817074"></p>
<p>如果你清楚这个领域什么期刊比较好的话，就选那个顶刊。像我，不知道的话，就是Review优先。所以我就选了第一个。</p>
<p>注意，这里要看的重点，是Intro和Discussion，Material&amp;Methods部分只要看懂每一步的目的是什么就可以了，具体的细节可以先不去了解。</p>
<h1 id="完成命题作文"><a class="markdownIt-Anchor" href="#完成命题作文"></a> 完成命题作文</h1>
<p>这时候回到最开始的那个</p>
<blockquote>
<p><strong>そこで本研究では申請者がこれまでに開発してきたポリフェノール性コーティングをサージカルマスクやその他の市販マスクへと適用し、ウイルスや粒子状物質の透過性に対する影響について研究する</strong> 。</p>
</blockquote>
<p>这个时候就是你的命题作文了，需要你自己提出方案设计实验（或者复制粘贴别人的）来给出一个解答。</p>
<p>不要担心写的不好，只要你将Intro部分写的好一点，说明以下几点</p>
<ol>
<li>题干里的这几个关键词都是什么意思</li>
<li>你要研究的目的（就是这个题干）和为什么做这个研究</li>
<li>这个研究的历史是什么，你提出的（复制的）实验方案和别人有什么不同</li>
</ol>
<p>基本就是一个老师会回复你的研究计划书了。</p>
<p>然后老板如果想要你的话，大概率会帮助你改实验方案的部分，因为这是他自己的项目，他永远比你懂这个该怎么做。</p>
<p>以上部分对于申请Research student基本够用了。至于考修士博士用的，还得自身努力，或者欢迎私信细聊哈哈哈。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>python step wise MLR</title>
    <url>/posts/f4626862.html</url>
    <content><![CDATA[<p>这两天在搞CDOM的东西，参照Mannino et al., 2014总是需要搞MLR。之前都是搞到R上，这次打算弄完它直接用python写了得了。</p>
<a id="more"></a>
<p>好麻烦，最后还是用R了。</p>
<p>直接对着这个来就行了</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZ3VydTk5LmNvbS9yLXNpbXBsZS1tdWx0aXBsZS1saW5lYXItcmVncmVzc2lvbi5odG1s">https://www.guru99.com/r-simple-multiple-linear-regression.html<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>Detection and tracking of Chattonella spp. and Skeletonema spp. blooms using Geostationary Ocean Color Imager (GOCI) in Ariake Sea, Japan</title>
    <url>/posts/5ea02cae.html</url>
    <content><![CDATA[<p>I participated in the statistics and plot part of this paper.</p>
<p>https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020JC016924</p>
<a id="more"></a>
<h1 id="abstract">Abstract</h1>
<p>Algal blooms dominated by the raphidophyte <em>Chattonella</em> spp. and diatom <em>Skeletonema</em> spp. are a regular summer-time phenomenon in the Ariake Sea (Japan). Given its high-temporal frequency, the Geostationary Ocean Color Imager (GOCI) affords us the extraordinary ability to investigate short-temporal scale dynamic of these blooms. Here we present a bloom detection method and classification criteria named Normalized Difference Red peak Index (NDRI), which relies on a combination of data from the red wavebands of GOCI, with the spectral shape of remote sensing reflectance (<span class="math inline">\(R_{rs}(\lambda)\)</span>) around 490 nm [SS(490)] to distinguish bloom pixels from non-bloom pixels. Diurnal changes in the bloom distribution and intensity were successfully captured by the new method with GOCI data. In the next step, an optical discrimination method was developed to differentiate <em>Chattonella</em> spp. from <em>Skeletonema</em> spp. blooms. Specifically, the backscattering at 555 nm of bloom waters was retrieved from a bio-optical algorithm,<span class="math inline">\(b_{bp,index}(555)\)</span>, based on the satellite <span class="math inline">\(R_{rs}\)</span>of green and red bands. Combined with the NDRI, bloom species were successfully differentiated in the featured distribution of ,<span class="math inline">\(b_{bp,index}(555)\)</span>. Further validations using GOCI images series and local observations indicate that the newly developed algorithm yields robust classification results. Moreover, transitions in diatom and <em>Chattonella</em> spp. blooms were captured in a 20-day time series of daily composite GOCI for July 2018. The successful application of the classification approach to GOCI opens up the possibility of understanding the factors influencing daily changes of harmful blooms in Ariake Sea, which at present is limited by the paucity of field observations.</p>
]]></content>
      <categories>
        <category>Papers And Thesis</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Harmful Algae</tag>
        <tag>Research Article</tag>
      </tags>
  </entry>
  <entry>
    <title>Bayes Theorem 1</title>
    <url>/posts/65240ce.html</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>未选择的路</title>
    <url>/posts/8abcc3ae.html</url>
    <content><![CDATA[<blockquote>
<p>Two roads diverged in a wood, and I--</p>
<p>I took the one less traveled by,</p>
<p>And that has made all the difference.</p>
</blockquote>
<a id="more"></a>
<p>其实我选择的路反而不是什么选择的人比较少的路，我自身感觉最近读研读博的人真的越来越多了，虽然说最后坚持在科研道路上的人没有多少。</p>
<blockquote>
<p>大事上的选择一定要深思熟虑 做到当下的自己最好的选择。既然选择了就要把当下的选择做到最好。</p>
<p>思考你想要什么样的人生，想过什么样的生活。</p>
<p>博士是一份给你学位的工作，而且还是一份工资不高且时间有限的工作。博士只是人生的一个阶段，而且是很短暂的一个阶段，不可能一直在学校读博士，即使继续做科研，也不一定能有机会继续做博士的研究内容。做好人生规划，尽快做好自己的工作按时完成论文按时走人，继续人生的下一阶段才是正事。</p>
</blockquote>
<p>这三句话基本是我做出这个选择的原因了吧。</p>
<p>其实自己已经不止一次的想过要转行了。</p>
<p>本科时候在想要不要转CS，然后学了一点python机器学习统计的玩意，但是就没能下定决心去转。</p>
<p>本科毕业的时候在想要不要转CS的master，也没有去</p>
<p>研究生期间在想要不要不读博了在日本找工作，没去</p>
<p>现在又在想要不要转行CS，还是没去</p>
<p>前几天查了查我这行几个经典的学校的招聘要求（直接给事业编制的那种）</p>
<ul>
<li>海大：4篇以上论文+其中有一篇TOP，按照我现在的速度不太可能拿到</li>
<li>南京师范大学：没有写明，讲师直接事业编，但是过去有过黑历史</li>
<li>南信工：二区 4（一区TOP1）</li>
<li>浙海大：二区3（一区TOP1）</li>
<li>广东海洋大学：没查到，讲师直接事业编</li>
<li>汕头大学：没查到</li>
<li>南海所：没查到</li>
</ul>
<p>这些都是要求35岁以下。那我就假设个文章膨胀，在我毕业的时候二区*4是讲师的要求，怎么算我都发不到。</p>
<p>所以我真的也不是啥学术大神。</p>
<blockquote>
<p>你能看到这个领域亟待的问题嘛？</p>
</blockquote>
<p>能。大气校正，时空分辨率，光谱分辨率，反演算法，次表层反演，算是几个光学上（或者遥感上）亟待解决的问题。</p>
<p>生物海洋学上，pCO2 relation with phytoplankton，data assimilation with biology data，算是我觉得比较亟待解决的问题，但是确实不如上一个领域了解的多。</p>
<p>还有一个问题就是这个领域缺少出口，如果只把生物地化当一个出口的话，那人员明显过剩了，所以才会有那么多人转去做水质遥感。</p>
<p>我可以做渔业的出口。</p>
<blockquote>
<p>你能解决这些问题吗？</p>
</blockquote>
<p>说实话，我并不能。</p>
<p>这就是我和小狼的差别吧。小狼不仅能发现问题，还能第一个formulate这些问题，提出确切的数学规则，最后解决这些问题。</p>
<p>但是我可以是在小范围里，那个把精度从0.4提升到0.41的人，不知道这样算不算解决问题。</p>
<p>当自己在一个领域做不到前5%的时候，那最好的选择就是让自己在多个领域都处于前20%或者前50%也行。</p>
<p>一个很简单的道理，如果你只是在单一领域的前5%，那你的稀缺度只有5%。</p>
<p>你是两个领域的前20%，那你的稀缺度就有了4%。</p>
<p>对我来讲 可能就是 渔业，ML，水色这几个领域一起了吧</p>
<p>这只是学术上的。</p>
<p>前段时间我有不懂的东西的时候，就去油管上搜，但是好多就也不带中文字幕，我自己听起来也有点犯困，就想去B站查一下。</p>
<p>结果B站完全搜不到相关的资料。</p>
<p>而那些信息并不是特别specialized 的。</p>
<p>我不是很清楚国内那些课题组的学生在遇到和我类似的问题的时候是怎么解决这些问题的，但是我想把这些我能分享的知识也用中文分享一下。</p>
<p>我生于毫末，家徒四壁，父母未上过高中，一路走到这里，分不清是运气还是努力的成分偏多。</p>
<p>一路上犹豫失落迷惑闪躲，于是，终于到了我现在的这个地方，走上了一条我从未作为最优选择的道路。</p>
<blockquote>
<p>做好人生规划，尽快做好自己的工作按时完成论文按时走人，继续人生的下一阶段才是正事。</p>
</blockquote>
<p>对我来讲，我能成为一个一本二本的老师，就已经是阶级跨越了。</p>
<p>不行毕业去当个高中老师也可以。</p>
<p>从现在开始，你的目标很明确了，就两个。</p>
<p>一个是基金，一个是文章。</p>
<blockquote>
<p>大事上的选择一定要深思熟虑 做到当下的自己最好的选择。既然选择了就要把当下的选择做到最好。</p>
</blockquote>
<p>其实我还有一个选择，就是gap一年或者半年，转到大气或者陆地等方向，五年后毕业，但是这个是当下自己最好的选择吗？</p>
<p>现在国内进老师的政策一年一变，并且目前来看，是一年变得比一年差，所以对我来说就是越早毕业越好了。</p>
<p>我没有那个本事预测五年后的风向会是什么情况，只要在自己能够掌控的部分里面，一天比一天好，那未来肯定也不会差。</p>
<p>无论什么选择都会有烦恼，就像我之前博客里写的。</p>
<blockquote>
<p>希望这次我能做到对自己负责，成为一个大人。</p>
<p>接受这个选择所带来的后果。</p>
</blockquote>
<p>既然这些选择都那么让自己难以抉择，就说明这些选择都差不多。</p>
<p>那就坚定继续做下去好了。</p>
<blockquote>
<p>世界上只有一种英雄主义</p>
</blockquote>
<p>也许我做不到热爱，但是我可以诚实。</p>
<p>之前一直想做一点生物-物理模型的东西，现在看起来也不太容易，而且和现在的方向有点远。</p>
<p>未来三年的目标</p>
<ol type="1">
<li>三篇文章</li>
<li>日语学好</li>
<li>补足Data science 的课程</li>
</ol>
<p>能进江苏海洋大学就算成功。</p>
<p>不行就去当高中地理老师！</p>
]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>清华苏州环境创新研究院面试经历</title>
    <url>/posts/bcb6c0dc.html</url>
    <content><![CDATA[<p>因为前段时间总是拿不定读不读，就索性跑去投了一些简历，好歹给自己多一些选择，也知道一下自己的价钱。</p>
<p>这篇是记录一下我拉胯的人生中的第一次企业面试，网上关于这家公司的信息也比较少，我只搜到了<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL2NvbHVtbi9jXzEzODQ5OTc4OTc1NDk4MTE3MTM=">这个<i class="fa fa-external-link-alt"></i></span>的面试经历，因此也把我的写出来做个样本。</p>
<a id="more"></a>
<p>我面试的是这个岗位。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030618220411988.png" alt="image-00030618220411988"><figcaption aria-hidden="true">image-00030618220411988</figcaption>
</figure>
<p>就，也不知道我一个应届生为什么投了社招的岗位还被邀请面试了。</p>
<p>面试一共有三个人，HR，两个技术相关的人员，其中一个是我未来的同事的感觉（暂称A），另一个是上司的感觉（暂称B）。</p>
<p>首先HR让我开了摄像头，但是对面全程都没开，让我感觉不太好。HR问了两个基础问题，一个是自我介绍，另一个是为什么要来苏州（看来离职率还挺高，也有可能是清华人都喜欢留在北京）。</p>
<p>接着是A的提问，从这里我就开始拉胯了，A问了一些我之前做过的遥感融合项目的事情，但是我自认没有讲清楚。然后A讲了一下他们做遥感融合的项目，回头我去查了查他们果然有一个遥感融合的专利。接着A又问了我其他的有关遥感分类的项目经历，u1s1我这个是确确实实的拉胯了，本身我自己也没有太多经历。然后A后面翻到我有一个机器学习相关的项目，问了下我是做的分类还是回归，我回答是做的回归（看来他们做分类的项目比较多，可能类似于国土自然资源监测一样的项目）。还有一个问题忘记了顺序了，问了我对于机器学习这么大规模的在遥感领域应用的看法，感觉这个问题是我唯一回答的还可以的。然后让我介绍了一下SGLI，感觉这部分我也拉胯了。</p>
<p>然后是B的提问，B问了我平时处理数据用什么软件，我说是需要上网查的那种。他说他们这里会有很重的workload，可能需要自己查文献写代码去github找代码那种，如果代码能力不强的话可能会有些痛苦，并且会有很多比较新的深度学习的东西例如知识图谱之类的，顺带问了下我机器学习的经历和我对知识图谱的了解，我说只做过机器学习，神经网络还没做过，知识图谱我知道刘知远老师（原来你也网上冲浪啊.jpg）。</p>
<p>面试大概就到这里，然后他问我有什么问题，我问说之前在你们官网没有看到遥感的老师，所以好奇你们做的是遥感的什么项目。B回答主要分三块，一个是语义表达深度学习，一个是内陆河流水库湖泊的水环境监测，一个是高光谱无人机的水质监测。</p>
<p>然后就尴尬的结束等通知了，没有问我期望薪资之类的，就感觉我已经凉了。</p>
<p>回去具体查了查，这个公司是自收自支的事业单位，18年刚成立的样子，问了下同学，这种单位的情况就是接多少项目发多少工资，没有编制，有末位淘汰。并且从他们的语气中他们团队离职比较多的样子。</p>
<p>在领英上搜了搜，里面大部分都是有清华读书经历的人。团队负责人是在清华读过博然后出来搞科技成果转化的样子。智联上的评价也大多数偏向正面，例如不加班工资福利好团队氛围好。一个让我比较警醒的评论就是这个公司大部分都是年轻人，上升路径不明确，因此我觉得我过去的话需要做好捞一笔钱跑路或者重新读博的觉悟。</p>
<p>等通知吧，苏州房价也挺贵的。据说两周内出结果，希望不要耽误了我博士报名。</p>
<p><strong>6.22 后续更新 没有通过面试 我好菜.jpg </strong></p>
]]></content>
      <categories>
        <category>成为社畜的路上</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian</title>
    <url>/posts/b58cbef5.html</url>
    <content><![CDATA[<p>在听了榛子的分享会之后决定把我日常梳理论文的东西从公开发布的Annotated Bibliography改成Obsidian，但是这个网站上有的时候还会发一些我写的类似于综述的东西吧。</p>
<a id="more"></a>
<h1 id="git同步"><a class="markdownIt-Anchor" href="#git同步"></a> Git同步</h1>
<p>需要安装<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Rlbm9sZWhvdi9vYnNpZGlhbi1naXQ=">obsidian-git<i class="fa fa-external-link-alt"></i></span>这个插件，然后就和其他的创建repo同步的方法差不多了，我参照的是<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj1INmlwanphTjJXWQ==">这个<i class="fa fa-external-link-alt"></i></span>视频。</p>
<p>在Obsidian-git插件里可以设置同步时间之类的</p>
<h1 id="day-planner-and-calendar"><a class="markdownIt-Anchor" href="#day-planner-and-calendar"></a> Day planner and Calendar</h1>
<p>基本弄完之后就很好看</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030619235856373.png" alt="image-00030619235856373"></p>
<h1 id="work-with-zotero"><a class="markdownIt-Anchor" href="#work-with-zotero"></a> Work with zotero</h1>
<h1 id="榛子-写作工作流分享会"><a class="markdownIt-Anchor" href="#榛子-写作工作流分享会"></a> 榛子 写作工作流分享会</h1>
<p>讲的很细，自己还是得先把双向链接用起来再听这个</p>
<p>前期可以依靠很多输入，但是不能依靠脑图这种方式，脑图是别人的想法。</p>
<p>除非写下自己为什么在乎这个，自己对这个的想法是什么，一边输入一边输出</p>
<h2 id="双向链接"><a class="markdownIt-Anchor" href="#双向链接"></a> 双向链接</h2>
<p>Backlinks: 在写的时候就想链接在一起的</p>
<h2 id="其他东西"><a class="markdownIt-Anchor" href="#其他东西"></a> 其他东西</h2>
<p>工作的时候专注产出，自己写的产出，而不是时间之类的</p>
<p>虚假繁荣</p>
<ol>
<li>Mind-map</li>
<li>复盘方式</li>
<li>copy past</li>
<li>note taking：除非paraphrase成自己的话</li>
<li>好看的排版</li>
</ol>
<h2 id="plugin"><a class="markdownIt-Anchor" href="#plugin"></a> Plugin</h2>
<h3 id="citations"><a class="markdownIt-Anchor" href="#citations"></a> Citations</h3>
<p>修改content template</p>
<h3 id="dataview"><a class="markdownIt-Anchor" href="#dataview"></a> dataview</h3>
<p>可以用来学习SQL</p>
<h3 id="calenda"><a class="markdownIt-Anchor" href="#calenda"></a> Calenda</h3>
<p>添加模版，和day planner 联动</p>
<h3 id="templater"><a class="markdownIt-Anchor" href="#templater"></a> Templater</h3>
<p>用来生成模版</p>
<h3 id="advancede-tablels"><a class="markdownIt-Anchor" href="#advancede-tablels"></a> Advancede tablels</h3>
<p>用来写表格</p>
<h3 id="better-word-countsdaily-stat"><a class="markdownIt-Anchor" href="#better-word-countsdaily-stat"></a> Better word counts&amp;Daily stat</h3>
<p>前者用来统计整个仓库多少字，每天多少字，后面那个类似github</p>
<h3 id="outliner"><a class="markdownIt-Anchor" href="#outliner"></a> Outliner</h3>
<h3 id="iframesmediam-extent"><a class="markdownIt-Anchor" href="#iframesmediam-extent"></a> Iframes&amp;Mediam extent</h3>
<p>方便视频笔记</p>
<p>后者只能用油管和B站</p>
<h3 id="hotkey-settings"><a class="markdownIt-Anchor" href="#hotkey-settings"></a> Hotkey settings</h3>
<p>设置快捷键</p>
<h3 id="check-list"><a class="markdownIt-Anchor" href="#check-list"></a> Check list</h3>
<p>GTD</p>
<h3 id="reviewperiodic-notes"><a class="markdownIt-Anchor" href="#reviewperiodic-notes"></a> Review&amp;Periodic Notes</h3>
<p>像Anki</p>
<p>可以自动创建提醒</p>
]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>苏州某小公司实习生</title>
    <url>/posts/85253d2a.html</url>
    <content><![CDATA[<p>这个是自己在Boss直聘上随便乱投的，居然被邀请去面试了。</p>
<a id="more"></a>
<p>居然面试时间是在星期天下午，有点让我反感（？）。</p>
<p>但是他们开了摄像头。</p>
<p>过程如下</p>
<p>在国内还是国外？什么时候毕业？是不是拿了奖学金？是不是毕业之后再过来？</p>
<p>之前的项目经历是什么情况？</p>
<p>最后说让我看看农作物分类的应用，等快毕业的时候再联系他们看看是什么情况，就结束了。</p>
<p>最后多问了句是不是苏州人，为什么过来。</p>
<p>我？？</p>
<p>就这？？</p>
<p>全程不到五分钟。</p>
<p>感觉大部分小企业都没有那种提前签合同的实习/全职之类的，但是除了北上广深就没啥大公司了-，-</p>
<p>果然比起来还是读博当老师好一点？</p>
]]></content>
      <categories>
        <category>成为社畜的路上</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>CMDS Summer Course</title>
    <url>/posts/a451b089.html</url>
    <content><![CDATA[<p>The OCLI application course hosted by EUMETSAT in June 2021 Day1 notes.</p>
<p>I met Lauren Biermann there who publish the first (?) paper of plastic detection using optical satellite.</p>
<a id="more"></a>
<p>This course is quite too looooong.</p>
<p>Maybe I only record some useful things</p>
<h1 id="snap"><a class="markdownIt-Anchor" href="#snap"></a> SNAP</h1>
<p>Data download from <span class="exturl" data-url="aHR0cHM6Ly9jb2RhLmV1bWV0c2F0LmludC8jL2hvbWU=">https://coda.eumetsat.int/#/home<i class="fa fa-external-link-alt"></i></span></p>
<p>Unpack the data, then you can use world view to know the location of your data</p>
<p>You can use spectra view to get the spectra of specific area.</p>
<p>And use the flag to show land or cloud.</p>
<p>It is a baby.</p>
<h1 id="python"><a class="markdownIt-Anchor" href="#python"></a> Python</h1>
<p>The jupyter file can be found in <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RvY2xlbWVudHM=">here<i class="fa fa-external-link-alt"></i></span>.</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>OLCI</tag>
      </tags>
  </entry>
  <entry>
    <title>My Grind With Depression</title>
    <url>/posts/b5654816.html</url>
    <content><![CDATA[<p>一些日记或者类似于闲言碎语的日常发牢骚。</p>
<p><strong>6.23</strong>: 在删去了一些个人隐私之后，终于把它放了出来，</p>
<a id="more"></a>
<h1 id="section">2021.3.9</h1>
<p>最近一直在处理实验室过去的吸收数据，处理得我脑袋疼。不得不主动停下来，去想一些别的事情。</p>
<p>最开始想的就是自己博士的课题。</p>
<p>老板快要退休了，很直白的告诉我他没有funding了，所以其实在这里继续读下去不是一个很好的选择。但是自己在这里想继续读，其实很多时候就是像心理咨询老师讲的一样，我只是在逃避自己不喜欢的东西而已。</p>
<p>自己并没有什么特别喜欢的东西。</p>
<p>自己真的没有什么特别喜欢的东西，但是自己有很多想做的事情，和很多不想做的事情。</p>
<p>自己对学术其实也没有什么特别的热情，其实真相是，自己大概率不会成为老板这个实验室里面的Outlier，而最好的两个Outlier才分别去了JAMSTEC和南信工而已。</p>
<p>所以其实自己很大概率在博士毕业之后，也只能去个普通一本二本-自己实验室里绝大多数人的工作都是一个普通的一本二本，或者公司。</p>
<p>而这意味着，自己很大概率和科研无缘。</p>
<p>所以，其实还不如读完博去上班。</p>
<p>做科研几乎和WLB无缘了。</p>
<p>自己就是在逃避。</p>
<p>想了半天，看了好多https://dingzeyu.li/blog/的博客，看到他写的PhD. Grind读后感很有同感，于是</p>
<p>其实我就忽然觉得。</p>
<p>自己不需要对自己要求太高，毕竟慢慢走才走得慢。</p>
<p><strong>自己很大概率和科研无缘</strong></p>
<p><strong>自己很大概率和科研无缘</strong></p>
<p><strong>所以不要强迫自己去解决太难的问题，也不要强迫自己去提出来太好的课题，自己现在连一个PhD student都不是</strong></p>
<p><strong>所以不要强迫自己去解决太难的问题，也不要强迫自己去提出来太好的课题，自己现在连一个PhD student都不是</strong></p>
<p><strong>只要自己足够努力，对自己的每一篇Paper都负责就可以了</strong></p>
<p><strong>只要自己足够努力，对自己的每一篇Paper都负责就可以了</strong></p>
<p>自己最好选择一个那种 对自己要求不是太高，自己稍稍伸下手就能够得到，同时又能充分利用自己的想法，让自己活得很舒服的状态。</p>
<p>不要总是去挑战自己。</p>
<p>那。</p>
<p>我似乎知道了。</p>
<p>自己似乎最好学好日语，读完博在日本找工作。</p>
<p>虽然在日本博士就职也挺困难的，但是对自己来讲这是比较容易达到理想生活的方式了。</p>
<p>或者去其他国家做博后，然后留在那里。</p>
<p>如果自己不读的话，就回去做个公务员吧。</p>
<p>自己要尽快学好日语，越快越好。</p>
<p>然后顺利毕业。</p>
<p>这样在老板不能给我提供RA的情况下，自己也可以尽快在日本找到工作。</p>
<p>无论如何，对自己来讲，在日本工作比在国内工作舒服很多呀。</p>
<p>但是日本这里也会有自己不喜欢的内容，自己千万别太过分美化这里了。</p>
<p>日本没有移民文化，自己在这里就是一个外人。</p>
<p><strong>自己要时刻做好，老板没有Funding，去工作的公司会倒闭的准备。</strong></p>
<p>给自己一个Plan B</p>
<p>摘录一下上面提到的博客里面的内容来提示自己：</p>
<blockquote>
<p>1.人生不可控</p>
<p>PhD期间意识到最大的一点，我觉得就是意识到了人生无常。很多时候命运的安排远远超出我们自己的能力的范围。很多东西都不是我们自己可以控制的。作为一个computer scientist, 我下意识的就觉得很多东西都应该是deterministic的，就像是写了个程序，它的输出就是应该是十分确定的，可是人生的确是不可控的。</p>
<p>举几个例子吧。第一个，研究的方向。入学前两年，多数学生都是clueless，基本都是靠导师提供一些想法和方向，而这个方向由于各种各样的原因，有可能做了几年是个dead end，有可能做了几年变成deep learning一般的热门方向。这种大方向的控制，基本都是学生自己没法预测和控制的。</p>
<p>再举一个，各种闲事琐事的作用也是无法量化和预测的。在郭生的经历里，他怎么可能预测到自己和好基友闲聊从而听说了某个workshop，从而认识哈佛的教授，从而帮他把idea D完善，从而在他博士最后一年能去哈佛访问，从而发表博士论文的最后一篇文章，从而凑齐自己的答辩委员会。</p>
<p>当初，他怎么可能预测到，和好基友喝的一杯咖啡和闲聊，能在几年后帮助到他自己毕业呢。这就是无法预测，无法计划的。</p>
<p>只能顺其自然，做最好的自己，增大成功的概率。关键在于意识到身边发生的很多事情是在自己控制以外的，成功了不必过于沾沾自喜，失败了也无需太责备自己。</p>
<ol start="2" type="1">
<li>不坚持就不会成功</li>
</ol>
<p>虽然人生无法预测，但是个人努力还是十分重要的。基本没有谁可以不努力就获得很大的成功，就算不努力可以一时顺利，也无法一直顺利。</p>
<p>郭生虽然前面几年都一直在撞墙，既没找到自己研究的方向，也没投出一作的文章，但是他一直在努力，没有放弃。正是这些年的积累，能让他在第四年第五年，厚积薄发，一股气做完了四个项目，这种写code能力写paper的能力，都是郭生前几年坚持的成果。</p>
<p>我的博士起步也是比较艰难，第一篇论文很快就做完投出去了，但是投会议被拒了两次，每次被拒就是要接着花时间改进，这样一年就过去了。之后转投一个journal，经过再两次major revision和一连串的minor revision，最终过了三年才present。不得不说这样子的体验是挺可怕的，我挺幸运的，各种机缘巧合能够从谷底走出。</p>
<p>最近在读一本书，<span class="exturl" data-url="aHR0cHM6Ly9hbXpuLnRvLzJuYW1STHU=">Grit: The Power of Passion and Perseverance<i class="fa fa-external-link-alt"></i></span>。书名里的Grit原意是小沙粒，后来延伸出“courage and resolve”的意思，勇气和决心。不得不说Grit和郭生的Grind这本书有异曲同工之意。都是要慢慢研磨，坚持不懈。这本Grit的书里举了很多名人成功的例子，发现他们成功的共同点并不是他们很先天聪明或者很有天赋， 而是后天不断的努力，遇到困难也不放弃。读Grit的时候总感觉自己在读鸡汤，可是那些例子貌似又的确挺convincing。之后有时间再写写那个的读后感吧。</p>
<ol start="3" type="1">
<li>导师太重要</li>
</ol>
<p>这些年来，断断续续的也很多同学都问过我说怎么选PhD offer。虽说这个是个幸福的烦恼（毕竟拿了好几个offer），但如果选择不当的话，的确可以造成多年困扰。</p>
<p>我觉得学校排名重要，地理位置重要，实验室的同学重要，可最终最重要的还是导师。其实导师重要的原因太多太多，我也没法一一列举，就说两个本科同学可能没意识到的吧。当然，如果你的目标是天天划水，几年后混个学位的话，就不用考虑以下的因素了。</p>
<ul>
<li>导师决定你的毕业时间。有的导师就是习惯五六年毕业学生，有的导师就是出名的拖着学生不毕业的，很多这些在理科生物化学里面尤其为甚，工科的稍微少一点点。当然作为学生，自己的努力也会影响自己的研究进度，可是看回上面的第一点：人生不可控，毕业时间就是一个不可控的事情。</li>
<li>导师能推动你的研究起步。你在不在导师的<span class="exturl" data-url="aHR0cDovL3d3dy5wZ2JvdmluZS5uZXQvY3JpdGljYWwtcGF0aC5odG0=">critical path<i class="fa fa-external-link-alt"></i></span>上？要了解接下来导师五年的计划，是不是要休sabbatical，是不是要忙自己的startup，是不是要休产假，是不是要partime去大公司。这些情况我都从自己的朋友同学那里听说过，都对新入学的学生的研究起步有很大的影响。如果你的导师能在接下来五年安心做研究，对你的发展会很有帮助。</li>
<li>导师要付你全部的学费和工资。所以理论上导师可以直接fire你。作为学生，我觉得很重要的一点，就要认识到：要是你连着很长一段时间都没法meet导师的expectation的话，赶紧好好沟通，如何让双方能on the same page.</li>
</ul>
<p>说回到郭生的案例，他导师真是太不错了。这些年郭生都没有做导师的critical path上的project，导师也没很大的意见。其中部分原因是郭生自带funding，部分原因就是导师自己本身比较nice。在这种情况下，让郭生做了DEFGH五个项目顺利毕业，也是挺难得的。</p>
</blockquote>
<h1 id="section-1">3.10</h1>
<p>上午碎碎念。</p>
<p>自己既然大概率与科研无缘，那么自己后面其实很多时候，所要处理的事情也并不是自己想象中具有很高创造性的工作。而且自己研究的性质决定了不可能会有太多人感兴趣。 其实拿国外的教职环境，研究环境和国内相比非常合适。 其实如果自己成不了什么特别厉害的人，何不赶紧放弃，让自己成为一个普通人。 自己读研两年，一篇论文都没发呢。 自己能接受目前国内的工作环境吗？ 能接受就可以回去。 其实。 没什么大不了的。 https://www.zhihu.com/question/24308741 自己适合做公务员吗？ 自己现在的问题就变成了，如果明确知道自己毕业以后不会做科研，读博还有意义吗？</p>
<p>不管怎么样，自己比海大的学生好多了？是吗？</p>
<p>至少比同期的学生好多了。</p>
<p>同班。</p>
<p>虽然自己未来的竞争者也不是这些人。</p>
<blockquote>
<p>博士是一份给你学位的工作，而且还是一份工资不高且时间有限的工作。博士只是人生的一个阶段，而且是很短暂的一个阶段，不可能一直在学校读博士，即使继续做科研，也不一定能有机会继续做博士的研究内容。做好人生规划，尽快做好自己的工作按时完成论文按时走人，继续人生的下一阶段才是正事。</p>
</blockquote>
<p>自己对科研有兴趣吗？</p>
<p>有 确实是有</p>
<p>但是自己的兴趣都更来源于算法，光学，偏物理的那一部分。</p>
<p>而不是生物。</p>
<p>自己对生物，没有任何兴趣。</p>
<p>被数据的不规范编号逼疯的下午碎碎念。</p>
<p>自己有能力去做自己感兴趣的那一部分吗？</p>
<p>没有。</p>
<p>真的没有。</p>
<p>而且还有焦虑的问题。</p>
<p>自己这种人怎么可能不焦虑。</p>
<p>而且搞学术真的很容易被更大的peer所包围。</p>
<p>这个peer包括所有干你这行的人</p>
<p>太难了</p>
<p>如果我能找到自己的niche就好了</p>
<p>就是那种，很适合我做的事情。</p>
<p>太累了。</p>
<p>自己最好能找到自己的niche，即：</p>
<ol type="1">
<li>没有太多应付性，无意义，重复性的工作</li>
<li>没有太多应酬</li>
<li>不加班，能有很多空闲时间来完成自己的想法</li>
<li>月薪5000起即可，但是要有足够的可预见的上升空间</li>
<li>能让自己不要那么焦虑</li>
<li>不要有太傻逼的领导，或者说随机性不要那么强，因为自己不知道入职之后的领导会是什么样子的。</li>
</ol>
<p>太难了。</p>
<h2 id="跟yk姐姐的讨论">跟yk姐姐的讨论</h2>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030310173439199.png" alt="image-00030310173439199"><figcaption aria-hidden="true">image-00030310173439199</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030310173507624.png" alt="image-00030310173507624"><figcaption aria-hidden="true">image-00030310173507624</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030310173532532.png" alt="image-00030310173532532"><figcaption aria-hidden="true">image-00030310173532532</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030310173600811.png" alt="image-00030310173600811"><figcaption aria-hidden="true">image-00030310173600811</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030310173625087.png" alt="image-00030310173625087"><figcaption aria-hidden="true">image-00030310173625087</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030310173646631.png" alt="image-00030310173646631"><figcaption aria-hidden="true">image-00030310173646631</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030310173703981.png" alt="image-00030310173703981"><figcaption aria-hidden="true">image-00030310173703981</figcaption>
</figure>
<p>接下来的问题</p>
<ol type="1">
<li><p>问老板支不支持我做一些偏向光学的项目</p></li>
<li><p>问请家里人的经济情况</p></li>
</ol>
<p>自己还是想做大学老师这份职业的。</p>
<p>自己在上学的时候就想过如果自己当了大学老师会怎么讲课。</p>
<h2 id="再次劝退">再次劝退</h2>
<p>https://note.com/chol_gyu/n/na93b711b844f 做研究就是世界上最差的工作。 工作的收入和满意度基本是最差的那档了。 9107一个月七八千，外加无尽的考核。 你像企业里，有了支付宝还有微信支付，有了淘宝还有京东拼多多 做研究你不是第一个你就是0 要跟全世界所有你的同行竞争，跟全世界最聪明最有执行力的人一起竞争 你是第二个发现的，第二个做出来的，你什么也不是 &gt;所以说只有热爱、聪明、坚毅的人，才是真正做研究的人。目前很多读博做研究的人都很没必要。</p>
<p>所以我觉得我也没必要[破涕为笑]。</p>
<p>经济上，没有必要。 心理上想读。 害怕抑郁。 想留在国外/进技术单位/公务员啥的。</p>
<h1 id="section-2">3.11</h1>
<p>如果有一件事，你做了会不开心，但是不做会有遗憾，你还愿意去做吗？</p>
<p>这就是我目前犹豫的点了。</p>
<p>人生总会有遗憾。</p>
<p>我要不要选择这个遗憾呢。</p>
<h2 id="跟gtc打完电话">跟GTC打完电话</h2>
<p>最近在减肥，晚上不怎么吃东西。</p>
<p>我发现过了七点/七点半之后就不会饿了。</p>
<p>跟GTC打完电话。</p>
<p>回国还是可以找工作的。</p>
<p>如果想搞钱，还是最好去工作呀。</p>
<p>如果自己之后的目标是进事业单位，</p>
<p>又想起来狸教授（还是谁）说的那句话</p>
<blockquote>
<p>当你面临选择比较迷茫时，那么请选择最艰难的那条路。</p>
<p>在不能既要又要还要的时候，先选择一个自觉有味的方向做起来再说！</p>
</blockquote>
<p>搜转行又搜到了一个<span class="exturl" data-url="aHR0cDovL3d3dy5qdXlhbmcuY28vcGhk6L2s6KGM5LmL6LevLw==">这个<i class="fa fa-external-link-alt"></i></span>。</p>
<p>自己想搞钱吗？</p>
<p>不想，自己搞钱感觉只是完全为了买车子房子这些东西。</p>
<p>不想要孩子真的好省钱。</p>
<p>https://www.zhihu.com/question/372930972</p>
<p>好难决定。</p>
<p>自己</p>
<h1 id="section-3">3.12</h1>
<p>忽然想起来我这次的学费减免钱是不是写的有点太少了点。</p>
<p>窗外一阵惊雷，这就是撒谎会被雷劈吗hhhhh。</p>
<p>如果我想进企业工作，那不管怎么样，在日本工作不比在国内舒服多了吗？</p>
<p>那就看老板喽.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030312121514625.png" alt="image-00030312121514625"><figcaption aria-hidden="true">image-00030312121514625</figcaption>
</figure>
<p>老板觉得我能完成-&gt;在日本读博/转行进业界</p>
<p>老板觉得我不能完成-&gt;回国考公/事业单位/国企</p>
<p>就酱。</p>
<h1 id="section-4">3.16</h1>
<p>居然罕见地被老板push。</p>
<p>我感觉我现在的前路一片灰暗。</p>
<p>我不知道该往哪里走。</p>
<p>没有一个人，或者没有一个事情可以让我作为我的锚点。</p>
<p>我不知道 我是要留在国外还是回国内。</p>
<p>我不知道 要去哪个城市。</p>
<p>我每天都在这一片迷雾里，走两步，看看周围，再走两步。</p>
<p>感觉就就像绕圈子。</p>
<p>就像在磨坊里拉磨的驴一样。</p>
<p>自己做了很多事情，走了很多路。</p>
<p>但自己只看过磨坊里面的风景。</p>
<p>为什么不出磨坊呢？</p>
<p>因为出了磨坊对我来说是一片迷雾。</p>
<p>我好像已经没有勇气，像之前那样。</p>
<p>不管往哪儿走，不管前面有什么，都先进去看看。</p>
<p>因为现在我想做的事情，都不是我一个人就能决定的事情了。</p>
<p>我的努力，我的力量，在这些事情面前都显得无比渺小。</p>
<p>就像随波逐流的浮萍。</p>
<p>老实讲，这种感觉真的非常不好。</p>
<p>你永远不知道，你是会被带到一个秀美的湖泊惬意生长，还是在下水道里腐烂至死。</p>
<p>作为一个浮萍，你只能奋力吸收光和营养，然后等待水流的最终审判。</p>
<p>很多时候，你没法像之前一样，从头再来。</p>
<p>很多时候，我更想不再漂流，赶紧结束这段旅途。</p>
<p>人总是要死的。</p>
<h2 id="摸了会鱼之后">摸了会鱼之后</h2>
<p>既然自己毕业之后大概率不做科研，那读博还有意义吗？</p>
<blockquote>
<p>Devote it</p>
<p>Like it</p>
<p>Good at it</p>
</blockquote>
<p>自己擅长研究吗？</p>
<p>自己擅长写代码吗？</p>
<p>自己擅长什么呢？</p>
<p>自己擅长提idea，但是这屁用没有。</p>
<p>我只想找一个差不多很舒服的工作。</p>
<p>那自己现在做研究，舒服吗？</p>
<p>我感觉自己很多时候，都是不舒服的吧？</p>
<p>看着他就不想做的那种。</p>
<p>那自己还要读吗？</p>
<p>自己就把博士当工作，来跟自己回去考公务员相比呢？</p>
<p>回去当公务员的最大好处能很快地成家立业。</p>
<p>好累。</p>
<p>好不想读呀。</p>
<p>但是自己还是有一点点点兴趣的。</p>
<p>自己的的兴趣来源于什么？</p>
<p>自己是从什么时候开始对量化 算法 模型这一块开始感兴趣的？</p>
<p>是从数学。</p>
<p>自己喜欢条理清晰，遵从计算，并且不是统计的东西。</p>
<p>而自己学的专业并不能做到。</p>
<p>所以自己想改变这一点。</p>
<p>本科班上自己的成绩让自己觉得自己有改变这一点的可能。</p>
<p>自己有改变这一点的可能吗？</p>
<p>这是自己的 兴趣？ 想法？ 还是只是想做的事情。</p>
<p>只是自己想做的事情。</p>
<p>自己想做的事情，不做会不会有遗憾。</p>
<p>会！</p>
<p>自己要不要搞定这个遗憾？</p>
<p>我不知道。</p>
<p>总而言之，选择一个自己喜欢的生活方式吧。</p>
<p>不行，就回国，考公务员，尝试自己没试过的另一种生活方式。</p>
<h1 id="section-5">3.17</h1>
<p>某老师居然成了副教授</p>
<p>我去，到底是怎么评的都。</p>
<p>一篇一区都不发就能副教授啥的吗？</p>
<p>一篇一区都不发就能当硕导？</p>
<p>还是说都是共一和通讯？</p>
<p>到底是渔业比较难发论文，还是评选有问题。</p>
<p>我懵了。</p>
<h1 id="section-6">3.18</h1>
<p>我真的应该好好感谢一下我老板。</p>
<p>昨天他问我能不能帮忙填一个表，我填了一部分之后问他剩下的咋填。</p>
<p>他跑过来跟我讲，你要专心Science，数据的事搞不了就先算了，就忽略呗，然后跑过来跟我讨论了好久研究的事情。</p>
<p>然后他今天就让Mizuno去搞数据的事情了。</p>
<p>老板真好啊真好</p>
<h1 id="section-7">3.22</h1>
<p>感觉自打自己确定自己没有JSPS的机会了之后，完全放飞了自我。</p>
<p>很明显的就是，之前都是我跟老板讲I'm worried, 现在是我老板跟我讲I'm worried。</p>
<p>自己这几天忽然看到了北卡的招生通知，想了想自己要不要去读。</p>
<p>最后决定还是别去。</p>
<p>自己并不是那种特别厉害的人，去北卡也不能提升多少，而且自己几乎可以说是与科研无缘了。</p>
<p>对自己来讲最重要的，就是先毕业。</p>
<p>拿到工作之后可以申请CSC再到处出去。</p>
<p>我的抗挫折能力真的太差了。</p>
<p>最近半年开始高频地出现自杀的想法，从一开始的数月一次，到现在的一个月数次，伴有莫名其妙的流泪，我现在就是一边在流泪一边在写这些东西。</p>
<p>回想起来自己之前看一些自杀的人发布的消息，往往宣布自杀的那条消息和他之前的消息相比，简直一个天上一个地下-即使信号已经很明显了，也几乎没有人会注意到。</p>
<p>我感觉我好像也不适合这个世界。</p>
<p>我似乎也不怎么适合活着。</p>
<p>这个世界会变好吗？努力会变好吗？</p>
<p>我不觉得。因为我这一辈子的结局，虽然现在看还有很多可能性，但是最后复盘的话，很大概率是基本决定的。</p>
<p>我 基本改变不了我的人生。</p>
<p>会不会变好，和我基本没有什么太大的关系。</p>
<p>我选择把我的信息发布在这上面，基本不会有人关注吧。不像微博，有的时候还会有江宁婆婆之类的人转发救助抢过来。</p>
<p>我即使把我自杀的计划发在这上面，具体到哪天拿什么手法也不会有人注意到的吧。</p>
<p>但是我还是想活下去的，如果你看到这里，请你帮帮我，求你了。</p>
<p>我现在的状态很差很差，也许就只需要你的一条关心的信息来拯救我。</p>
<p>我把我博客的链接挂到了FB, twitter, GitHub, Researchgate.</p>
<p>我多希望有人能关心我，现在的我。</p>
<h1 id="section-8">3.23</h1>
<p>可能自己都不会有把这个页面改成My PhD Grind的机会。</p>
<p>要是去横滨国立大，那就别读了。</p>
<p>太累了。</p>
<p>不想干活，只想哭。</p>
<p>我只想找个人陪我吃顿饭，喝点酒也行，我从来都不喝酒的，我发了誓不喝酒的，让我好好的哭一顿。</p>
<p>可是大家都忙，找了一圈，没有人。</p>
<p>我可真是个废物。</p>
<p>来这里一年半了，什么都没做出来，一个能抽空陪我哭的人都不知道，我现在都不知道该找谁讲。</p>
<p>我可能也不适合活着吧。</p>
<p>我真的好像不适合活着。</p>
<p>不会社交，不会表达，什么都做不好，什么都不行。</p>
<p>只是个废物，</p>
<h1 id="section-9">3.24</h1>
<p>早晨挣扎了好久要不要去实验室，但是想起来要给师姐量毕业证的尺寸，最后还是去了。</p>
<p>路上停了好几次，想哭，不想去，感觉自己实验室的门就像停尸间的门一样，自己进去只会变成一具尸体。</p>
<p>路上看到花开的好美，脑子里想的居然不是拍照，感叹了一下这里好美，心里想的是，如果我要死的话，也一定是要死在这么美丽的时候。</p>
<p>我脑子怎么这么容易联想到自杀呢。</p>
<p>我真没用呢。</p>
<p>我真的是脑子里会有各种各样的想法的人。</p>
<p>各种各样奇怪的想法。</p>
<p>比如我现在脑子里就在想我该怎么跟日本告别，跟 我本来的博士生活提前说再见。</p>
<blockquote>
<p>时运不齐，命途多舛。冯唐易老，李广难封。屈贾谊于长沙，非无圣主；窜梁鸿于海曲，岂乏明时。</p>
<p>时也，命也，运也！天有不测风云，人有旦夕祸福。 蜈蚣百足，行不及蛇。 灵鸡有翼，飞不如鸭。 马有千里之程，无人不能自往。 人有凌云之志，非运不能腾达。 文章盖世，孔子尚困于陈邦；武略超群，太公垂钓于渭水。 盗跖年长，不是善良之辈；颜回命短，实非凶恶之徒。 尧、舜至圣，却生不肖之子；瞽叟顽呆，反生大圣之儿。 张良原是布衣，萧何称谓县吏。 晏子身无五尺，封为齐国首相；孔明卧居草卢，能作蜀汉军师。 韩信无缚鸡之力，封为汉朝大将；冯唐有安邦之志，到老半官无封。 李广有射虎之威，终身不第。 楚王虽雄，难免乌江自刎；汉王虽弱，却有江山万里。 满腹经纶，白发不第。 才疏学浅，少年登科。 有先富而后贫，有先贫而后富。 蛟龙未遇，潜身于鱼虾之间。 君子失时，拱手于小人之下。 天不得时，日月无光。 地不得时，草木不长。 水不得时，风浪不平。 人不得时，利运不通。 昔时也，余在洛阳，日投僧院，夜宿寒窑；布衣不能遮其体，淡粥不能充其飢；上人憎，下人厌，皆言：“余之贱也！”余曰：“非吾贱也！乃时也，运也，命也！” 余及第登科，官至极品，位列三公；有挞百僚之杖，有斩鄙吝之剑；出则壮士执鞭，入则佳人捧袂；思衣则有绫罗锦缎，思食则有山珍海味；上人宠，下人拥，人皆仰慕，言：“余之贵也！”余曰：“非吾贵也！乃时也，运也，命也！” 盖，人生在世，富贵不能移，贫贱不可欺；此乃天地循环，终而复始者也！</p>
</blockquote>
<p>我会说，再见了 我闪闪发光的梦，对不起，我的梦想。</p>
<p>在日本两年就像一场梦，梦里有飞舞的樱花，有飘落的枫叶，有火红的鸟居，有蔚蓝的大海，还有我一个人孤孤单单的在海边捡贝壳。</p>
<p>好不容易看到了一个美丽贝壳的一半，挖坑来看，里面却是</p>
<p>无穷无尽的噩梦。</p>
<p>梦该醒了，既然是噩梦，那就不要做下去了。</p>
<p>我之前微信的签名是“青衫磊落险峰行”。这句话是天龙八部的第一回目，我换上他的时候大概是19年年初，我确定我能来日本的时候。</p>
<blockquote>
<p>青衫磊落险峰行，玉壁月华明。 马疾香幽，崖高人远，微步縠纹生。 谁家子弟谁家院，无计悔多情。 虎啸龙吟，换巢鸾凤，剑气碧烟横。</p>
</blockquote>
<p>我好羡慕当时的我，多有精气神啊，多么充沛的活力。</p>
<p>多好的过去。</p>
<p>现在是“梦里真真”，同样出自天龙八部。</p>
<blockquote>
<p>输赢成败，又争由人算,且自逍遥没谁管,奈天昏地暗，斗转星移,风骤紧，缥缈峰头云乱,红颜弹指老，刹那芳华,梦里真真语真幻,同一笑，到头万事俱空,胡涂醉，情长计短,解不了，名缰系嗔贪,却试问，几时把痴心断</p>
</blockquote>
<p>梦里真真语真幻 这一章，虚竹和被天山童姥掳来的梦姑春风三度，这里用了一个典故。</p>
<p>画里真真：用来比喻不切实际的空想，或是根本实现不了的幻想。</p>
<p>记载于唐朝人杜荀鹤编撰的《松窗杂记》中。</p>
<blockquote>
<p>唐进士赵颜，于画工处得一软障，图一妇人，甚丽。颜谓画工曰：“世无其人也，如可令生，余愿纳为妻。”画工曰：“余神画也，此亦有名，曰<strong>真真</strong>。呼其名百日，昼夜不歇，即必应之，应则以百家彩灰酒灌之，必活。” 颜如其言，遂呼之百日，昼夜不止。乃应曰”诺”。急以百家彩灰酒灌之，遂活。下步言笑，饮食如常。曰：“谢君召妾，妾愿事箕帚。”终岁，生一儿。儿年两岁，友人曰：“此妖也，必与君为患！余有神剑，可斩之。”其夕，乃遗颜剑，剑才及颜室，真真乃泣曰：“妾，南岳地仙也。无何为人画妾之形，君又呼妾名，既不夺君愿。君今疑妾，妾不可住。”言讫，携其子，却上软障，呕出先所饮百家彩灰酒。睹其障，为添一孩子，皆是画焉。</p>
</blockquote>
<p>纳兰性德也用过</p>
<blockquote>
<p>春情只到梨花薄，片片催零落。夕阳何事近黄昏，不道人间犹有未招魂。 银笺别梦当时句，密绾同心苣。为伊判作梦中人，长向画图清夜唤<strong>真真</strong>。</p>
</blockquote>
<p>在那三天后，虚竹苦熬相思，天山童姥再也没有把梦姑带来。对虚竹来说，梦姑就是画里真真，就是根本实现不了的幻想。</p>
<p>至于语真幻</p>
<blockquote>
<p>虚竹道：“嗯，你是我的梦中仙姑，我叫你 ‘梦姑’ 好么？” 那少女拍手笑道：“好啊，你是我的梦郎，我是你的梦姑。这样的甜梦，咱俩要做一辈子，真盼永远也不会醒。” 说到情浓之处，两人又沉浸于美梦之中，真不知<strong>是真是幻</strong>？是天上人间？</p>
</blockquote>
<p>梦里说的话，到底是真是幻。</p>
<p>在日本这两年就像一场梦，和研究走这么近也像一场梦，梦里我和它相识相爱（或许也没有相爱，只是觉得他很有意思），说了不知道多少话。</p>
<p>现在它对我而言，就是画里真真，说过的话，到底是真是幻。</p>
<p>也许真的到了离开的时候。</p>
<p>毕竟自己都给它做了这么多的铺垫。</p>
<p>从第一次自己觉得不开心开始。</p>
<h1 id="section-10">3.25</h1>
<p>今天是学校的毕业式，好多穿着和服好看的日本小姑娘。</p>
<p>在路上我就在想，也许简单的把那两句拼在一块，就足够描述我在日本的这两年生活了。</p>
<blockquote>
<p>青衫磊落险峰行，玉壁月华明。 马疾香幽，崖高人远，微步縠纹生。</p>
<p>梦里真真语真幻，同一笑，到头万事俱空,胡涂醉，情长计短,解不了，名缰系嗔贪，却试问，几时把痴心断</p>
</blockquote>
<p>给Kase和Air准备了毕业礼物。</p>
<p>我今天居然来的比老板还早。</p>
<p>早晨打开github看到Salem发现了我之前发现的那篇Paper，但是我的想法却被老板给否了。</p>
<p>也许是我没有能力说服我老板吧。</p>
<p>现在又要重新开始做课题了。</p>
<p>我真没用。</p>
<p>我真废物。</p>
<p>早晨来到打开PPT打开Pycharm心里就忍不住的犯恶心。</p>
<p>做不下去。</p>
<p>不想做了。</p>
<p>我还是放弃吧哈哈哈，毕竟连走的时候写什么都想好了。</p>
<p>脑子里忽然又想起来。</p>
<p>我跟老板提要用bbp*+hydrolight的时候老板拒绝了。</p>
<p>说这个超出一个硕士毕业论文的内容。</p>
<p>老板说或许让我试试能不能把硕士毕业论文做的非常好的时候的讽刺的笑。</p>
<p>我现在就有把这个电脑砸了的冲动。</p>
<p>老板人好是好，但是这种嘲讽真的太令人难受了。</p>
<p>脑子里忍不住地犯恶心。</p>
<p>不知道是因为我老板呢，还是因为学术呢？</p>
<p>换一个老板会好一些么？我好像一点都不觉得。</p>
<p>我就只是觉得，我不适合做学术。读完博出来大概率不会做科研，所以越早读完越好。</p>
<p>所以我 如果不在这里读，那早点结束这个痛苦生活比较好。</p>
<p>师姐说不要把这些东西当成你自己的错误，这都是老板的错。</p>
<p>好吧。</p>
<p>我很好，我没错。</p>
<p>都是老板的错误。</p>
<p>么？ # 3.27 躺在床上才开始想老板给我回复的邮件。</p>
<p>我跟老板说“我觉得我做不出好的研究了，因为我在这里的一年半都没有做出来什么成果。”</p>
<p>老板一句安慰的话都没有说。</p>
<p>老板就是老板，我们就是老板和员工。</p>
<p>他只关心你的成果，至于你这个人怎么样，他一点也不关心。</p>
<p>他给我们的仔仔细细的批语，也只是在旅行一个老板的责任罢了。</p>
<p>我很崇拜和向往他，但是我并不喜欢他。</p>
<p>连一句 辛苦 鼓励 都没有。</p>
<p>我不喜欢他。</p>
<h1 id="section-11">4.4</h1>
<p>最近状态好了很多，可能是终于完成了自己在日本一直以来的心愿吧</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/DSCF0944.JPG" alt="在京都二年坂拍摄的日本标志性地标"><figcaption aria-hidden="true">在京都二年坂拍摄的日本标志性地标</figcaption>
</figure>
<p>最近又有中期答辩又有Fellowship申请书，搞的本来应该自己忙的不可开交，但是自己最近似乎陷入了那种对什么都不感兴趣的状态，PPT为了毕业勉勉强强的改了改，Fellowship申请书本来打算这周末搞定交给老板第一稿，但是到现在我连1/4都没写完。</p>
<p>就这样吧，我感觉我是不太可能能继续在这里读了。</p>
<p>下午支撑起精神写了一页多一点的申请书，但是感觉真的有点写不下去，脑子里一片混沌，自己就没有一个对于这个课题的完整的想法。</p>
<p>和之前的Sasagawa不一样，sasagawa自己有很明确的想法，有几乎就等着打磨和实现的一套流程，现在这个，自己脑袋里只有一团浆糊。</p>
<p>而且自己似乎真的对这个课题，一点自己的想法和激情都没有。</p>
<p>脑子里只想着毕业。</p>
<p>又想起来小狼的访谈，这可是自己这个博客的第一篇内容。</p>
<blockquote>
<p>你能看到这个领域需要解决的重要问题吗？能。</p>
<p>你有能力解决这个问题吗？</p>
<p>我目前在尝试，我不知道我能不能解决。</p>
<p>我觉得我不能解决。</p>
<p>因为这个问题是我这个学科一个亘古存在的老问题了，跟皇冠上的明珠那种有的一拼。</p>
</blockquote>
<p>我感觉我选择它，完全只是为了毕业。</p>
<p>很多时候人就是没得选。</p>
<p>并不能去做你心心念念的事情。</p>
<h1 id="section-12">4.5</h1>
<p>老板的邮件</p>
<blockquote>
<p>As I wrote before, there is a big problem for this mid-term presentation.</p>
<p>Mid-term presentation is not the place to present only what you did, but it is the place to present your plan.</p>
<p>It is same as proposal, you need detail plan for the research.</p>
<p>If you do not have plan, you can not have mid-term presentation or proposal.</p>
<p>​</p>
<p>I feel you should have more confidence for your thinking.</p>
<p>First you should follow someone’s method, then you can always think about next step.</p>
</blockquote>
<p>查论文的时候查到了老板力推给我的Higa的修士论文和博士论文。</p>
<p>修士论文就写了100页，虽然大部分都是在那个时候还不是很成熟的东西，类似Proctol。</p>
<p>而他这样的人只能在横滨国立大做个助教。</p>
<p>放平心态，自己可能真的不适合读博。</p>
<p>做不到的事情就放弃好了，没什么大不了的。</p>
<p>反正自己读了博也很有可能像Fukutomi一样四十多还是博后然后还单身。</p>
<p>自己应该接受的一个事实是，尽管自己的能力比起来身边的一些同学来说好很多，但是在海大，在名大，都不是处于综合最顶尖的那波。</p>
<p>自己要先接受，自己即使在这里，也只是一个普普通通的人。</p>
<p>不要因为身边很多同学都不怎么样，就觉得自己一定是top20%，各种奖学金funding的都能拿得到。</p>
<p>而且这些东西都得看运气不是么？</p>
<p>能证明你能力的最直接的永远都是你做的事情，而不是在这上面的一系列其他东西。</p>
<p>而且单单一个普普通通的博士提前半年毕业 就已经超过很多人了不是吗？</p>
<h1 id="section-13">4.7</h1>
<p>昨天晚上跟老板讲不申请了，发现了自己之前图里的一个错误。</p>
<p>早上给老板发了勘误。</p>
<p>老板很快就会了。</p>
<p>自己今天本来就只想写写脚本，然后跟老板讲一下那个图的事情和我的那个问题。</p>
<p>但是就在收到老板的回信之后心情突然爆炸。</p>
<p>一直磨磨唧唧搞到了现在。</p>
<p>什么事都没干，甚至去相亲网站注册了个账号。</p>
<p>我的确得学学情绪控制了。</p>
<p>看会脱口秀大会给老板回邮件。</p>
<h1 id="section-14">4.9</h1>
<p>按照心理咨询师的要求</p>
<ol type="1">
<li><p>每天做一件让自己开心的事情</p></li>
<li><p>记录每天都做了什么，做什么事情的时候心情会比较好，给自己打分，-10～10分</p></li>
</ol>
<p>早晨来到，重新看老板给我的邮件。</p>
<p>还是好不想改，看一半就看不下去，心里发痛想哭的感觉，不想去思考这些乱七八糟的，心里就想着随便弄弄毕业了得了，回去随便找个工作。</p>
<p>当时是你（老板告诉我）说，我选择继续做Chla什么之类的课题再过几年就不会有人对他感兴趣了。然后我开始主动了解学术前沿，想做最顶尖的研究，一开始是没有数据做不了，后来我好不容易想了一个我觉得我可以做，现在没有人做，好歹也能发RSE的课题，你说指导不了让我换。我只能瞅着看着跟那个差不多的有些关系的课题选了一个，我想努力把它变得有意思，想做到前沿。</p>
<p>你最后告诉我，哪怕是Chla（评估，还不是改进）也是很重要很难很有意义的课题。</p>
<p>我读研干嘛来了。</p>
<p>我费那么多事干嘛呢。</p>
<p>你早说不行？</p>
<p>就这样吧，我真不想搞了，你早说弄这个我赶紧研一就做完了，研二要么出去玩要么写论文要么找工作。</p>
<p>我真的不想做这个。</p>
<p>是你鼓励我让我去做难的有意义的课题的，我努力了。</p>
<p>不想搞。</p>
<p>-9。</p>
<p>Om(泰国同学)也太好了，看我心情不好跑去星巴克给我买了杯冰沙。</p>
<p>心情变为+1</p>
<p>开始有心情搞PPT了</p>
<p>给老板回了他到现在也没回复，看得出来他也觉得我破罐子破摔心情不好了。</p>
<p>下午三点 老板好声好气的回复了。</p>
<p>心情变为+5</p>
<p>摸鱼的时候看到了矮子王的Panorama一键换装，想念拿锅，不知道拿锅什么时候能回来，希望我走之前能看场拿锅公演或者演唱会。</p>
<p>心情变为+6</p>
<p>感觉我好像在推gal?</p>
<p>攻略我自己可太草了。</p>
<p>五点 下班回家 打打游戏</p>
<p>明天再改PPT发给老板</p>
<p>最近博客访问人数异常增多，就把这个日记给移出来了。</p>
<h1 id="section-15">4.10</h1>
<p>今天总体心情在+5</p>
<p>磨磨叽叽的改PPT，拿到了京吹的票，晚上看到了精彩的比赛。</p>
<h1 id="section-16">4.12</h1>
<p>昨天晚上看了比赛，心情+1</p>
<p>这两天都在改PPT，就是提不起兴趣，很消极的态度，一看到他我就很烦躁。</p>
<p>真的是烦得很，都不想毕业了。</p>
<p>心情贼差。</p>
<p>这几天似乎连每天看看星星都提不起兴趣，不想出门。</p>
<p>连窗帘都不想拉开。</p>
<p>这几天做的让我开心的事情就是睡觉睡到自然醒和躺着打游戏。</p>
<p>跟老板交流是一个让自己开心的好办法</p>
<p>+3</p>
<h1 id="section-17">4.13</h1>
<p>昨天跟Air的练习被夸了，开心。</p>
<p>今天总体心情是0吧，就是那种正儿八经的上班的心情。</p>
<p>刷知乎看到一句话感觉简直说的太对了。</p>
<blockquote>
<p>读博的大体有三类人</p>
<p>第一类是非常热爱学术有天赋的，这一类往往能取得很好的学术成就。</p>
<p>第二类是本科出身不错，但是不清楚自己喜欢什么，一路路径依赖读下来的，这类通常会有在博士毕业后思考到底是读博还是去业界，摇摆不定，同时对自己读博和人生的意义开始反思。</p>
<p>第三类是本科出身不好，但是一步步读过来之后过的比本科的peer过的也好很多，所以最后也留在了学术界。</p>
</blockquote>
<p>我就是很明显的第二类人。</p>
<p>刚刚跟Matsui测试网络自己太过紧张忘记喊老师好之类的[Hurt]</p>
<p>算了，不会有人在意。</p>
<p>而且自己也不一定读了是不。。</p>
<blockquote>
<p>（1）精力极其旺盛，晚睡早起，脑子里只有做实验写代码；</p>
<p>（2）聪明，领悟问题非常快，举一反三非常快；</p>
<p>（3）认真，写论文尤其认真，一眼能够看出你写的东西问题在哪里。</p>
</blockquote>
<p>自己压根跟这三条没有任何关系。。。</p>
<p>老板问 谁本科学过海洋学。我：我学过。。。老板：废话，你海洋大学的</p>
<p>笑死，心情变为+5</p>
<h1 id="section-18">4.14</h1>
<p>搞定了中期答辩，老板笑嘻嘻的过来跟我聊了一会。</p>
<p>老板不生气的时候还是个好人。</p>
<p>心情+3</p>
<h1 id="section-19">4.19</h1>
<p>最终决定还是把这篇文章发出来，毕竟虽然这只是我个人的碎碎念，甚至类似于日记一样的隐私，但是如果我最终战胜了他，看到这篇文章的人也会受到鼓舞吧。</p>
<p>如果真的也有在关心我的朋友，也许他也能帮到我。</p>
<p>开始理解为什么偶像和搞笑艺人那么容易抑郁，我在跟xa聊天的时候也非常希望我能感染到他，表现的非常乐观向上积极正能量，但是内心也快枯竭了。</p>
<p>按照咨询师的要求继续记录我的心情。</p>
<p>16号，看了柯南，心情+3。</p>
<p>17号，看了京吹演奏会（心情+5），但是在op还没演奏完的时候就收到了老板的邮件，非常紧张，心情最后为+3。</p>
<p>18号，和老板最终决定每周五都开会讨论，晚上出去吃了火锅，晚上看了星星，心情最终为+3。</p>
<p>晚上看了师弟的PPT，感觉这也太烂了。。。同时心里多了一份自信，因为自己当时做的比这个好很多。</p>
<p>晚上和ky聊天踩了雷，同时也知道了为什么她对我一直这么冷淡。</p>
<p>能有自己喜欢的人真好呀，我也想有自己喜欢的人，我什么时候才能喜欢上一个人呢？</p>
<p>感觉对现在的我而言，我好像已经丧失喜欢一个人的能力了。</p>
<p>19号开始就又要开始面对研究了，之前我都是在以逃避研究的方式来使自己开心，这次要尝试加量了。</p>
<p>希望我可以永远让自己开心下去。</p>
<p>希望我 尽早 有喜欢的人。</p>
<p>回头想到隐私，还是不要把这么私密的东西发出来了。</p>
<p>也许后面有机会，希望有机会，把我这些东西整理成册子，给后来的人看。</p>
<p>以上是19号凌晨写的内容。</p>
<p>下面是19号晚上的内容。</p>
<p>今天收到了中期答辩的具体评论，总体而言，负面评价多过正面评价。</p>
<p>今天定了跟老板周五的讨论，每周五都有。。。</p>
<p>然后终于稍微收拾了一下家里。</p>
<p>接着收到了毕业答辩和毕业论文的通知，不到100天了。</p>
<p>今天总体心情是0吧。</p>
<p>明天 二三四 三天 要准备好多东西</p>
<h1 id="section-20">4.20</h1>
<p>最近每天都能查到博客有一个来自北京的访问</p>
<p>感觉应该是咨询师每天都在看</p>
<p>我真的特别感谢这位心理咨询师，让我感觉到了被人关心的感觉</p>
<p>怪不得总有人会喜欢上自己的心理咨询师。</p>
<p>今天又试了好几种方法，那个结果始终出不来，总感觉还是数据的问题，但是ap测量的那一步就开始出问题就你妈离谱。</p>
<p>这种时候心情就贼烦躁。</p>
<p>总体心情在-2吧</p>
<h1 id="section-21">4.21</h1>
<p>研究稍微理出来了一点头绪</p>
<p>心情为+1</p>
<h1 id="section-22">4.22</h1>
<p>摸了一上午</p>
<p>下午一点才开始工作</p>
<p>明天上午开始跟老板讨论，PPT还没做，图还没画</p>
<p>中午又来了一发</p>
<p>半夜一点半才睡觉</p>
<p>祝我明天活的好好的</p>
<h1 id="section-23">4.23</h1>
<p>今天跟老板讨论了，老板也是很心平气和，而且明显更认真了起来。</p>
<p>并且还一反常态，给了我清晰的建议让我干什么。</p>
<p>然后我下午晚上一直摸鱼，心情0</p>
<h1 id="section-24">4.24</h1>
<p>今天在家里瘫了一天打游戏，晚上灵魂拷问自己。心情0</p>
<h2 id="灵魂拷问">灵魂拷问</h2>
<p>半夜睡不着觉开始想，如果我去读博能做什么呢？更进一步的讲，我做的东西能对社会有什么贡献呢？</p>
<p>最直接的办法，虽然过去不能预测未来，但是也是可以看一下的嘛，那就看看美国。</p>
<p>查了查美国，最直接的就业就只有两个，一个是NASA/NOAA，另一个就是学校，前者对应海洋信息中心海洋技术中心，后者就是对应现在的大学了。</p>
<p>前者进去的还是挺多的其实，就是，如果我想进去的话，为什么不现在就去呢？</p>
<p>后者就是纯粹的搞科研了。但是翻来覆去的查了查，美国有在做海洋遥感，或者说水色遥感的，也就那么几个学校，对应到国内顶多就是211的水平，再往上基本都是做全球性的，生物地球化学的那种东西才能在非常好的学校。</p>
<p>而且就之前学校某个学姐的经历来看（学了六年海洋最后被迫去了陆地遥感的组），美国现在海洋遥感做的是真的不多。从全球来看，遥感发论文最厉害的就是国内，但是给我的感觉就是换汤不换药-观测这一块感觉已经到了天花板了，一个很明显的证据就是，30m制图这种基本是行业极限的东西都做出来了。很多算法的文章也只是在1%的精确度上搞来搞去，或者就是针对一个特定的问题，而且很多都是在乘计算机的东风。</p>
<p>整个卫星遥感的历史基本才不到一百年，但是已经让我感觉到有了瓶颈了，我们只是在不断重复走着老祖宗探索出来的路，不断清扫着路上的石子，至于最前面的路继续该怎么走，却没有多少人在做。</p>
<p>也许很多学科都是这样吧，但是最让我迷惑的还是</p>
<p>你的学科究竟有什么用？</p>
<p>谁会对你的学科感兴趣？</p>
<p>也许是我的认知局限问题，我总是感觉，哪怕我们现在的各种各样的理想观测条件都达到了，我现在动动手指就能看到一个海湾里浮游植物的分布，不分白天黑夜，那这会有什么用呢？会有什么人去看呢？</p>
<p>感觉说来说去也不过就只有这两个地方，一个是渔业，一个是全球变化。 全球变化，真的有那么多人为之买单吗？</p>
<p>渔业，又能为SDG做到多少事情呢？我感觉目前的瓶颈明明不在观测上面，或者说模型上面，而是在执行上面。</p>
<p>观测能做到多少呢？</p>
<p>渔业，甚至说农业…</p>
<p>确实是人类最大的事情没错啦。</p>
<p>但是中国近海已经无鱼可捕。</p>
<p>我们再怎么研究，又能做到什么事情呢？</p>
<p>这也是为什么学院里养殖的人更多啦。</p>
<p>因为有更多的人感兴趣，有更多的经济来源和财政支持。</p>
<p>哪怕是搞研究，自己真的适合做研究吗？</p>
<p>自己其实不适合。</p>
<p>我真的觉得自己不适合。</p>
<p>自己也许只是会有很多想法，但是执行起来真的不太行。</p>
<p>自己这一年半过去，也没有做出来多少东西。</p>
<p>自己是有很多想法，而且自己也想把他们做出来，避免遗憾。</p>
<p>但是我真的觉得自己好不适合。</p>
<p>还是先别想了，看自己毕业论文吧。</p>
<p>努力。</p>
<h1 id="section-25">4.25</h1>
<p>今儿上午补了逃避可耻但有用新春SP。心情+1</p>
<p>下午来了实验室，看到老板今天居然也来了。</p>
<p>刷朋友圈，发现海大这个垃圾学校居然都搞非升即走了，我麻了。</p>
<p>还是看毕业论文能做成什么样吧，如果老板觉得能投出去就读。</p>
<p>都卷成麻花了。</p>
<p>承认吧，我并没有那么想做学术。</p>
<p>只想安安稳稳平平凡凡。</p>
<p>如果自己毕业论文能够达成下面三个点</p>
<ol type="1">
<li>anw的准确率能到R^2&gt;0.8</li>
<li>完成卫星实地验证，达到0.6</li>
<li>aph443准确率R^2能到0.7（现场数据）</li>
</ol>
<p>自己就读。</p>
<p>回家了先。</p>
<p>自己最近的状态有点差，晚上睡得太晚了，今天来了实验室还睡了两觉。</p>
<p>心情最终是0</p>
<h1 id="section-26">4.26</h1>
<p>今天终于开始认真干活了！</p>
<p>虽然结果也没有出来，但是总归心情还好。+1</p>
<p>另外晚上居然开始主动投了一下简历，心情继续+2</p>
<p>我感觉我自己有在变得有动力</p>
<p>最终心情+3</p>
<h1 id="section-27">4.27</h1>
<p>今天能很静下心来组织材料和思考问题了</p>
<p>心情为+4</p>
<h1 id="section-28">4.28</h1>
<p>名古屋的雨季要开始了</p>
<p>今天在实验室抓耳挠腮的想不出来，效率很低，总的干活时间也很少</p>
<p>心情-1</p>
<p>然后收到了老板的邮件，受宠若惊，但是其实不知道这算是心情好还是不好</p>
<p>0吧</p>
<h1 id="section-29">4.29</h1>
<p>早晨起来发了会呆</p>
<p>上午去帮同学搬家</p>
<p>下午Timi了一整天</p>
<p>晚上7点才开始整理PPT</p>
<p>感觉自己最近干活的时间太少了。</p>
<p>这两周都只有25小时。</p>
<p>感觉这一周出来的结论，又是跟前面的研究一模一样</p>
<p>感觉自己什么也没做</p>
<p>自己这一周只做了两天的内容</p>
<p>这周五六七感觉自己肯定也静不下心来</p>
<p>心情-1</p>
<h1 id="section-30">4.30</h1>
<p>老板还是那种很认真的跟我讨论，然后讲我需要做什么。</p>
<p>下午打了一下午游戏。</p>
<p>晚上本来想P图，后来就不想干了。</p>
<p>感觉没有兴致，不想去做这件事情。</p>
<p>一期一会吧。</p>
<p>希望下辈子能在哲学之道做一只小猫咪。</p>
<p>又一次有了自杀的想法。</p>
<p>什么都不想做。</p>
<p>心情-5.</p>
<p>朋友的邀约也不想去，感觉自己不想出门。</p>
<p>想在床上看会书，看不了两夜就看不心里去。</p>
<p>想找人一起出去溜达一会，问了一圈没人回复，也不知道要找谁。</p>
<p>两个人回复了，都是没空。</p>
<p>不知道做什么来消磨时间。</p>
<p>只想赶紧结束这一切。</p>
<p>樱花飞舞的四月也把我带走吧。</p>
<p>最近不知道做什么好，看电子产品看的眼睛疼</p>
<p>最近撸的频率也高了很多</p>
<p>每天都躺在床上不知道该做什么</p>
<p>樱花飞舞的四月，也请把我带走吧</p>
<p>躺在床上又哭了一会</p>
<p>十一点，出去买了点吃的，心情居然好了很多</p>
<p>十二点，感觉自己能够静下心来了</p>
<p>但是好困，要睡觉了</p>
<p>我似乎失去了做任何事情的动力</p>
<p>又是翻遍微信，翻遍QQ想找人说话找不到</p>
<p>想睡觉睡不着</p>
<p>只能自己哭着睡着的一个晚上</p>
<p>我还记得我刚来的时候是非常想交朋友的</p>
<p>但是找不到</p>
<p>我也不知道为什么</p>
<p>后来就逐渐习惯了，出去玩也都是自己一个人</p>
<p>甚至有人说想跟我一起去我还不习惯</p>
<h1 id="section-31">5.1</h1>
<p>早上起来跟xy打了会电话</p>
<p>大家怎么都这么惨呀</p>
<p>但是心情确实好了点哈哈哈</p>
<p>心情+5，本来觉得自己就在床上躺一天了</p>
<p>申请了阿玛棕的信用卡</p>
<p>出门买了吃的</p>
<p>甚至有了自己做饭吃的想法</p>
<h1 id="section-32">5.2</h1>
<p>今天虽然也没有干活，但是感觉状态好了很多。</p>
<p>收拾了厨房，清理了厕所，洗了衣服</p>
<p>自己做了饭</p>
<p>心情+3</p>
<p>毕业越来越近了</p>
<h1 id="section-33">5.3</h1>
<p>在家里就</p>
<p>太浪费时间了</p>
<p>今天一点才去干活</p>
<p>今天又自己做饭了！</p>
<p>稍微干了点活，屁股疼，坐不住</p>
<p>心情+3</p>
<p>为什么他们都有空出去玩</p>
<p>为什么他们都能找到人一起出去玩</p>
<p>为什么他们什么事情都能做的很好</p>
<p>而我活着都这么困难</p>
<p>以及为什么他们都能有女朋友啊SOS而我抑郁发作的时候都找不到人[裂开]最后只能找夏睿</p>
<p>心情-1</p>
<h1 id="section-34">5.4</h1>
<p>早晨起来看了X队六周年公演</p>
<p>心情+3</p>
<p>半摸鱼半墨迹的在家干活</p>
<p>在家里干活效率真的太低了</p>
<p>心情+1</p>
<p>看到了ky发的朋友圈</p>
<p>我真的好喜欢她呀</p>
<p>唉</p>
<p>来了日本两年也就遇见这么一个让我眼前一亮的女生</p>
<p>可能就是自己太心急了吧</p>
<p>急于达成关系</p>
<p>或者就是她跟我一样，也有个放不下的人</p>
<p>回头想想，如果有个我都不知道长什么样的男生像我对她一样对我，我也会在夜里无限的思念卢丹，然后慢慢拒绝她吧</p>
<p>大家都是成年人了</p>
<p>心情-2</p>
<p>又看到了一些国内的新闻</p>
<p>深深感受到个人的努力在时代潮流面前的无力</p>
<p>心情-3</p>
<p>之前咨询师跟我讲人际关系对我会有很大的影响，我还没察觉到，当时觉得很奇怪</p>
<p>后来我才慢慢发现了。</p>
<p>可能是因为我一直认为我不擅长社交，身边也没什么朋友，所以稍微有点进步，稍微被别人关心，或者发生一点点坏的事情</p>
<p>我的心情都会有很大的波动</p>
<p>都会对我的心情有很大的影响</p>
<p>我好想找个女朋友啊，说到这里。</p>
<p>我真的很少很少体会过被人关心过的感觉</p>
<p>所以那次咨询师跟我讲 让我千万不要伤害自己</p>
<p>我哭的撕心裂肺</p>
<p>不是伤心</p>
<p>而是在yk学姐离开之后，我终于又找到了一个关心我的人了</p>
<p>一个真正的关注我的想法，关心我这个人的人</p>
<p>Yk学姐回国之后，我就只在那天我抑郁情绪爆发的时候跟她打过电话</p>
<p>好久没打电话，我甚至都不知道开口说什么，一张嘴就要哭出来，又不敢在她面前哭出来</p>
<p>只能草草问候了几句挂了电话，然后她发觉了我不对劲，就像我大三在北京一样</p>
<p>他是我第一个主动发这篇日记网址的人</p>
<p>跟yk又提到了ld</p>
<p>我真的好怀念她</p>
<p>又哭了起来</p>
<p>也不知道是因为卢丹还是因为别的什么</p>
<p>因为我是在-3之后边敲这个边和刘雅坤聊天的</p>
<p>也许我就是觉得，活着真的好难</p>
<p>我觉得我似乎坚持不下去了</p>
<p>我真的能坚持下去 活着硕士毕业吗</p>
<p>我感觉我活着毕业真的好难</p>
<p>我感觉我似乎有一点坚持不下去了</p>
<p>我不知道我什么时候会再产生自杀的想法</p>
<p>心情-4</p>
<p>不知道为什么这周 反而心情特别差</p>
<p>也许是因为，没有跟咨询师聊天，自己的负面情绪无法得到一个舒缓，自己平时也没有什么负面情绪的出口</p>
<p>不敢跟别人讲，怕把别人也搞的很难受</p>
<p>没有什么朋友，没有什么知心朋友，没有什么可以分享负面情绪的朋友</p>
<p>牙碎了只敢往自己肚子里咽</p>
<p>之前这种情况还可以找聂颖</p>
<p>现在不知道是他真的状态差还是我惹到他了</p>
<p>唉</p>
<p>太子长琴，寡亲缘情缘，永生永世皆为孤独之命。</p>
<p>我身边的人，好像一直都没有好下场</p>
<h1 id="section-35">5.5</h1>
<p>早晨起来看朋友圈，ky还是没跟我回复</p>
<p>唉</p>
<p>也许我这人在人际关系上就容易想多吧</p>
<p>早晨起晚了又没赶上扔垃圾</p>
<p>心情-1</p>
<p>最近都睡得挺晚的，昨天两点多才睡着。</p>
<p>另外确实感觉自己早晨效率高一些</p>
<p>倒不是脑子好用，是心情平静，能够静下心来做事情</p>
<p>中午吃完饭又来了一发</p>
<p>唉</p>
<p>以后还是多去实验室吧</p>
<p>好歹在实验室自己不会动不动来一发</p>
<p>Fake it till you make it, 习惯成自然</p>
<p>下午和晚上因为要学一个新遇到的概念，推了公式</p>
<p>心情+3</p>
<h1 id="section-36">5.6</h1>
<blockquote>
<p>自己对于学术对于科研没有归属感。当认定自己在这个领域实现不了人生价值时也与自己的追求背道而驰时，放弃有何不可。</p>
<p>在我看来只有明确自己很爱研究，享受思考问题的人才适合。对于这样的人来说，世上并没有比科研更好的工作了。</p>
</blockquote>
<p>看到坏消息又不想读了h h h</p>
<p>人总是这么嬗变</p>
<p>下午发现自己能够静下心来写综述了！</p>
<p>心情+3</p>
<h1 id="section-37">5.7</h1>
<p>今天状态好到</p>
<p>跟老板讨论完不想休息 甚至又直接想起了下一步该怎么做</p>
<p>但还是主动强迫自己暂停干活，滚去打游戏了。</p>
<h1 id="section-38">5.10</h1>
<p>早晨起的好晚</p>
<p>自己要调整一下作息了</p>
<h1 id="section-39">5.11</h1>
<p>这两天心情都是0</p>
<h1 id="section-40">5.12</h1>
<p>今天因为搞出来的结果跟上次不一样心情烦躁，结果自己仔细检查之后发现是上次弄错了</p>
<p>烦躁的时候心情-3，后来弄出来就还好。</p>
<p>然后稍微尝试了下别的改进方法，发现结果还可以</p>
<p>心情+3，8小时。</p>
<h1 id="section-41">5.13</h1>
<p>怪不得会有人喜欢上自己的咨询师</p>
<p>怪不得会有人喜欢上自己的咨询师</p>
<p>怪不得会有人喜欢上自己的咨询师</p>
<p>怪不得会有人喜欢上自己的咨询师</p>
<h1 id="section-42">5.15</h1>
<p>昨天跟老板吵了一架</p>
<p>今天查看生物海洋学课的时候发现我上次给老板补交的作业老板没查看，我也懒得发邮件跟他讲了，0分就零分吧</p>
<p>真的很生气。</p>
<p>自己主动把咨询断了。</p>
<p>自己的情绪也许暂时也就没有出口了。</p>
<p>想找人吐槽我老板也不知道找谁。</p>
<p>就这样吧，不重要。</p>
<p>活着就行。</p>
<p>成全这首歌也好适合发在毕业的时候hhhh</p>
<h1 id="section-43">5.20</h1>
<p>自己这几天就没有再主动去记录自己的心情了。</p>
<p>同时今天也是自己的最后一次咨询了。</p>
<p>说实话，自己最近的心情💢真的非常差了</p>
<p>今天收到了老板催我论文的事情，然后也看到了教务入试出愿的消息。</p>
<p>心情真的还挺差的</p>
<p>最近刚刚想明白了未来的规划打算。</p>
<p>读博然后做科研相关的内容还真是自己的最优解。</p>
<p>因为我知道我自己喜欢的内容，我虽然这跟科研没有关系。</p>
<p>草 忽然想起来自己发给咨询师的忘记删去撸这件事了。</p>
<blockquote>
<p>知道自己选择的后果，愿意承担这个后果，并且坚持下去。</p>
<p>知道自己想要什么生活。</p>
</blockquote>
<p>我终于做到了。</p>
<p>但是世界好像在这个时候给我开了个玩笑。</p>
<p>回去随便找个活呗。</p>
<p>反正能毕业就行。</p>
<h1 id="section-44">5.21</h1>
<p>看到了朋友圈南理工今天（520）的图，心里一阵遗憾。</p>
<p>有的时候真的是一个决定能够影响自己一生</p>
<p>哪怕当时自己换专业学了数学，也会比现在过得好很多吧。</p>
<p>自己的下一个决定也要影响自己一生了。</p>
<p>自己要对自己负责了</p>
<p>不能再让别人替我做决定了</p>
<p>自己真的喜欢这个嘛</p>
<p>如果</p>
<h1 id="section-45">5.23</h1>
<p>今天又在想quit的问题https://www.zhihu.com/question/47045376</p>
<p>感觉大部分quit的人都是因为自己的老板https://zhuanlan.zhihu.com/p/25465778</p>
<p>博士只是一份工作，不要想太多</p>
<p>https://www.megoal.org/information_edu/910948.html</p>
<p>这个例子里和我好像https://instant.1point3acres.com/t/639137</p>
<p>这个劝退指南可太真实了https://www.douban.com/doulist/46560847/</p>
<p>有意义的从来都不是结果，而是过程</p>
<p>扔硬币吧</p>
<p>当你扔硬币的时候就知道自己想做什么选择了</p>
<p>做了选择之后就把他变成最好的选择</p>
<p>数字的那一面就读，花的那一面就不读。</p>
<p>https://www.1point3acres.com/bbs/thread-762401-1-1.html</p>
<p>扔了两次自己还没有做出选择</p>
<p>被自己笑死，扔了好几次硬币之后开始查转行游戏开发和前端</p>
<p>其实还是先干活吧</p>
<p>看自己能做到什么程度</p>
<p>不行就去考公务员事业单位</p>
<p>别想转行了</p>
<p>选择太多反而不好</p>
<p>Make your goal more clear</p>
<p>7.1号之前 如果结果做的不错，或者老板主动提</p>
<p>那就读</p>
<h1 id="section-46">5.28</h1>
<p>今天真的气死了</p>
<p>您为甚么不在我一开始用这个的时候就说呢？</p>
<h1 id="section-47">6.8</h1>
<p>最近几天心情有过好几次的黑暗时刻</p>
<p>但是也没写日记</p>
<p>这几天遇见了zyp 一个还挺可爱的女孩子</p>
<p>昨天跟老板讲了我读博士的事情</p>
<p>老板的回复还挺让我感动的</p>
<blockquote>
<p>I will try my best for finishing as early as possible if you enter, but I cannot guarantee.</p>
<p>I can be your extra supervisor and hep your research even I retire</p>
</blockquote>
<p>正在我感动的时候，今天早晨来到在🌰的群里讨论了一下</p>
<blockquote>
<p>笨的人才会在学术道路上坚持下去，是有reference的https://journals.biologists.com/jcs/article/121/11/1771/30038/The-importance-of-stupidity-in-scientific-research</p>
</blockquote>
<p>还有🌰的职业规划</p>
<blockquote>
<p>不不 DS只是为了身份 我真正想做的是 自己的App和产品</p>
<p>App比如自习室核心的东西拿出来打包成App 产品包括完善文书系列产品(课程、服务)+DS相关课程和服务</p>
<p>在我心中 最完美的工作不是去哪家公司赋予的 那个可以作为dayjob 但也就只是为了有个去处、稳定而已 我更看好副业的发展潜力</p>
</blockquote>
<p>被牵动的我又去查了查日本博士就业的情况，但是感觉自己似乎之前决定并不会在日本长留。</p>
<p>昨天看到了复旦的事情，心情更复杂了，国内屎一样的非升即走不知道会不会在这两年改善一下。</p>
<p>早晨来到实验室还没感动完，又收到了老板的邮件</p>
<blockquote>
<p>I was thinking about some basic problems.</p>
<p>Read carefully followings and should think how you proceed the analysis.</p>
<p>It is probably better to discuss more often.</p>
</blockquote>
<p>我都每周一次了 我天</p>
<p>这就是 读博要面对的生活吗</p>
<p>这种时候就脑子賊乱</p>
<p>老板给我的回复是啥</p>
<h1 id="section-48">6.9</h1>
<p>最近的脑子真的越来越乱</p>
<p>斜杠 有副业</p>
<p>自己哪儿有这东西</p>
<p>给zyp看了日记</p>
<p>他也不会真正的替自己考虑</p>
<p>自己的事情还是要自己来</p>
<p>孤独的自己来考虑</p>
<p>除了</p>
<h1 id="section-49">6.23</h1>
<p>跟老板讨论博士的题目，老板回复</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030623101616959.png" alt="image-00030623101616959"><figcaption aria-hidden="true">image-00030623101616959</figcaption>
</figure>
<p>心情忽然好了不少</p>
<blockquote>
<p>青衫磊落险峰行，玉壁月华明。 马疾香幽，崖高人远，微步縠纹生。</p>
<p>梦里真真语真幻。同一笑，到头万事俱空。糊涂醉，情长计短。解不了，名缰系嗔贪。却试问，几时把痴心断？</p>
</blockquote>
<p>也终于把这段话发了出来。</p>
<p>也许是机缘巧合，🌰的群里也在讨论转行的事情，榛子第二天还专门写了<span class="exturl" data-url="aHR0cHM6Ly90cmVsbG8uY29tL2Mva2d5bEhzV3YvNTY2LTIybmQtanVuZS0yNCVFNSVCMiU4MSVFOCVBRiVCQiVFNyVBQyVBQyVFNCVCQSU4QyVFNCVCOCVBQSVFNiU5QyVBQyVFNyVBNyU5MSVFRiVCQyU4QyVFNCVCOCU4RCVFNiU5OSU5QS1mdCVFNiVBNiU5QiVFNSVBRCU5MC0lRTglODclQUElRTQlQjklQTAlRTUlQUUlQTQlRTUlQkUlQUUlRTQlQkYlQTElRTclQkUlQTQlRTglQUUlQTglRTglQUUlQkE=">封面故事<i class="fa fa-external-link-alt"></i></span></p>
<blockquote>
<p>确实不晚，24岁，这对于“知道自己这辈子想做什么”来说时机太合适了。我觉得自己也是差不多24岁才大概知道自己要干嘛... 好像国内的教育对于这一块一直特别缺失 高考填志愿的时候，甚至没有很好的“职业规划师” 信息上真的很闭塞，大家都不知道各种工作和工种到底是在做什么的</p>
<p><strong>24岁找到此生想做的事 那意味着(平均寿命80的话)有56年可以实现它。</strong></p>
</blockquote>
<p>先专心写完修士毕业论文吧。</p>
<p>然后先回国，想明白自己想做什么。</p>
<p>或者随便找个班上。</p>
]]></content>
      <categories>
        <category>人生得意须尽欢</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>It is OK to quit your Ph.D</title>
    <url>/posts/722bb233.html</url>
    <content><![CDATA[<p>So I do not continue my Ph.D</p>
<a id="more"></a>
<blockquote>
<p>Your words “one of the difficulties for me is that I didn't find a question that I need to answer”</p>
<p>clearly indicate that you are not the point to apply Ph.D course.</p>
<p>I wrote that you need to grab Ph.D, but it is not something you find easy topic.</p>
<p>You need to have something you want to think and act for your life.</p>
<p>Of course, not all the Ph.D student is like this, but they usually have more time.</p>
<p>Again, I suggest you complete your master degree to find what is research for yourself.</p>
<p>Then you may be able to find your own direction.</p>
<p>I do not think you need to be hurry to finish your Ph.D with me.</p>
</blockquote>
<p>慢慢写吧。</p>
<p>上面是我老板写给我的关于博士申请的最终决定的邮件。</p>
<p>最终我还是决定不读了，因为自己并不能找到something I want to think and act for my life.</p>
<p>如果真让我选的话，我发自内心觉得更有意思的课题，可能反而是音乐，艺术，政治，哲学，社会学</p>
<p>我之前就写过一张单子</p>
<blockquote>
<p>我真感兴趣的话题，反而是音乐，偶像，女团和粉丝经济</p>
<p>别的我不敢说，这玩意我是真的感兴趣，脑子里早就有了各种乱七八糟的选题</p>
<p>比如流行音乐风格的地缘性与文化的关系（台湾的歌我一听就知道是台湾的，日本的歌我一听就知道是日本的）</p>
<p>偶像经济的兴衰与经济文化的关系（例如为什么日本是以早安少女团AKB作为偶像经济的开头，最近却变成了选秀韩团，国内传统偶像为什么不出圈，选秀为什么能让传统偶像出圈）</p>
<p>女团风格丰富度对于粉丝忠诚度，吸金能力，持久时间的影响（例如今年青你选出来的那个就是风格很丰富，从T系到妹系都有的团，还有一些基本全是妹系的日团韩团）</p>
<p>什么样风格的女团能有忠实的粉丝，忠实的粉丝占比高还是低的时候吸金能力高</p>
<p>一团多队的女团是一家独大吸金能力强还是各队平均吸金能力强</p>
<p>最重要的🧐CP和撕逼对于女团热度，吸粉和吸金的影响-基于塞纳河卡黄的案例研究🤓</p>
<p>加上二次元的话，其实还有其他一些很有趣的地方。</p>
<p>为什么啦啦和K-on！到了2020年还有粉丝，甚至还能形成粉丝经济，他们甚至都不是真实的偶像。那为啥依据真实偶像经历改编的AKB0048却极少见现有的粉丝</p>
<p>为什么vtuber会这么受欢迎，vtuber是不是证明了人设才是偶像最重要的一环</p>
<p>这些东西给我的感觉都比现在在做的研究有意思多了😂</p>
</blockquote>
<p>再来两张图</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/v2-a696f3afcf5bbff42c999300478b1b4f_720w.jpg" alt="一棵不完整的读博决策树"><figcaption aria-hidden="true">一棵不完整的读博决策树</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/142561624599331_.pic.jpg" alt="非升即走流程"><figcaption aria-hidden="true">非升即走流程</figcaption>
</figure>
<p>图上是现在非升即走的流程，最终的结论就是，大部分博后，都是要走的。</p>
<p>我不可能做出超出我认知之外的决定，也许之后高校生态会改善，但是我要根据我手上的信息作出有限信息下的决定了。</p>
<p>不带任何情感偏向，纯从利益考虑。</p>
<p>我决定暂时先退出了。</p>
<p>毕竟这行要跟全世界最聪明的脑子竞争。</p>
<p>而我 也没那么好的脑子了。</p>
<p>我真的好想提前安定下来呀。</p>
<p>这种一个人无根漂浮的感觉真的挺痛苦的，你掌控不了任何事情。</p>
<p>就像河里的浮萍。</p>
<p>两岸的风光确实很美丽。</p>
<p>但是你不知道你下一个转角之后会去哪里。</p>
<p>而你自己的努力也对前进的方向几乎毫无用处。</p>
<p>反正聪明的人比我多得多，比我厉害的人也多的多。</p>
<p>而他们很多人不也放弃了嘛？</p>
<p>做科研很有意思，但是以科研为职业却很痛苦。</p>
<p>也许以后还能回来，但是暂时，再见了。</p>
<p>这个网站里之前写的 会写完的坑，也就看心情了。</p>
<p>反正看了看Google analytics 的数据，除了我也没有太多别人看我的博客。</p>
<p>自己本科的时候问过在读博的学长学姐什么样的人适合读博，得到的结果众说纷纭，但是都包括 家庭条件好这一条</p>
<p>自己现在也明白了到底为什么有这一条。</p>
<p>自己家庭条件也不行啊。</p>
<p>总之 该放弃就放弃</p>
<h1 id="things-you-need-to-know-before-ph.d">Things you need to know before Ph.D</h1>
<p>The PhD Grind <span class="exturl" data-url="aHR0cHM6Ly93ZWIuYXJjaGl2ZS5vcmcvd2ViLzIwMjAwMzA1MDgyNzUyL2h0dHA6Ly9wZ2JvdmluZS5uZXQvUGhELW1lbW9pci9wZ3VvLVBoRC1ncmluZC5wZGY=">PDF<i class="fa fa-external-link-alt"></i></span>.</p>
<p>What My PhD Was Like <span class="exturl" data-url="aHR0cDovL2p4eXphYmMuYmxvZ3Nwb3QuY29tLzIwMTYvMDIvbXktcGhkLWFicmlkZ2VkLmh0bWw=">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>“博士这五年” <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNTA5OTYzOA==">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>A Survival Guide to a PhD <span class="exturl" data-url="aHR0cDovL2thcnBhdGh5LmdpdGh1Yi5pby8yMDE2LzA5LzA3L3BoZC8=">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>博士五年总结” <span class="exturl" data-url="aHR0cDovL3l1YW5kb25nLXRpYW4uY29tL2ZpdmVfeWVhcl9zdW1tYXJ5X29mX1BoRC5wZGY=">PDF<i class="fa fa-external-link-alt"></i></span>.</p>
<p>怎样完成自己的博士生涯？<span class="exturl" data-url="aHR0cHM6Ly93d3cuc29odS5jb20vYS8yNTM1NTQ3OTNfNDgxNzQxP19mPWluZGV4X2NoYW4yNW5ld3NfMTIz">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>The N=1 guide to grad school <span class="exturl" data-url="aHR0cDovL21hcmN1YS5uZXQvd3JpdGluZy9ncmFkc2Nob29sLWd1aWRlLw==">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>10 easy ways to fail a Ph.D. <span class="exturl" data-url="aHR0cDovL21hdHQubWlnaHQubmV0L2FydGljbGVzL3dheXMtdG8tZmFpbC1hLXBoZC8=">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p>So, you want to go to grad school? <span class="exturl" data-url="aHR0cDovL21hdHQtd2Vsc2guYmxvZ3Nwb3QubXkvMjAxMC8wOS9zby15b3Utd2FudC10by1nby10by1ncmFkLXNjaG9vbC5odG1s">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>I Loved Graduate School <span class="exturl" data-url="aHR0cDovL3d3dy5iYWlsaXMub3JnL2Jsb2cvaS1sb3ZlZC1ncmFkdWF0ZS1zY2hvb2wv">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>《A PhD is not enough》</p>
<p>How Do Professors Spend Their Time? <span class="exturl" data-url="aHR0cHM6Ly9qb25hdGhhbmFsZHJpY2guZ2l0aHViLmlvLzIwMTcvMTIvMjgvaG93LWRvLXByb2Zlc3NvcnMtc3BlbmQtdGhlaXItdGltZS1hLXBlcnNvbmFsLXBlcnNwZWN0aXZlLmh0bWw=">HTML<i class="fa fa-external-link-alt"></i></span></p>
<p>徐轶青<span class="exturl" data-url="aHR0cDovL3lpcWluZ3h1Lm9yZy9hcnRpY2xlcy8yMDE2MDUxNF9DTnBvbGl0aWNzX2ludGVydmlldy5wZGY=">《读博那些事儿》<i class="fa fa-external-link-alt"></i></span></p>
<p>Farewell to MIT <span class="exturl" data-url="aHR0cDovL3d3dy5ldmFuam9uZXMuY2EvZmFyZXdlbGwtbWl0Lmh0bWw=">HTML<i class="fa fa-external-link-alt"></i></span>.</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9mYXZvbmlhLm9yZy9hZHZpc2luZy5odG1s">Ph.D. Advising Statement<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ncmVhdHJlc2VhcmNoLm9yZy8yMDEzLzA4LzE0L21hbmFnaW5nLXlvdXItYWR2aXNvci8=">Managing Your Advisor<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY2VsbC5jb20vbmV1cm9uL2Z1bGx0ZXh0L1MwODk2LTYyNzMoMTMpMDA5MDctMA==">How to Pick a Graduate Advisor<i class="fa fa-external-link-alt"></i></span></p>
<p>最后</p>
<p><a href="https://lifeodyssey.github.io/posts/b5654816.html">My grind with depression.</a></p>
<p>在确定不读之后吗，自己的抑郁症状态也好转了不少。</p>
<p>至少最近晚上都睡得着了。</p>
<p>有缘再见。</p>
]]></content>
      <categories>
        <category>人生得意须尽欢</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>北京某遥感公司</title>
    <url>/posts/3593fd75.html</url>
    <content><![CDATA[<p>一个看起来专业很对口的北京公司</p>
<a id="more"></a>
<p>他们领导一开始出差迟到了，让我等了半个小时，然后还没来。</p>
<p>让我猜猜他们老板啥时候来。（35来的）。</p>
<p>趁这个时间写写他们公司。</p>
<p>他们公司写的工资是一万+，而且因为要求的很具体（类似XX系数反演）这种，我才试着投了投，不然我一点也不想去北京。</p>
<p>然后又查了眼，发现他们公司自己写的是在东四环，然后手底下一堆皮包公司，写的是北京但是不知道为啥大公司是山西。然后100人以下的民营小公司，智联上写的是朝九晚六周末双休。</p>
<p>他们没有开摄像头，面试稍微有点尴尬。</p>
<p>？？？他们居然知道l老师</p>
<p>？？？跟海大有合作</p>
<p>？？？碰见同行了</p>
<p>？？？？？？？？？？？？？？？？？</p>
<p><strong>后续更新，拿到了L老师的口头offer</strong></p>
]]></content>
      <categories>
        <category>成为社畜的路上</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>北京某遥感公司2</title>
    <url>/posts/3a8fa843.html</url>
    <content><![CDATA[<p>一个比上一个稍微大一点的公司</p>
<a id="more"></a>
<p>用钉钉面试 在周天面试 让我准备PPT感觉 很坑</p>
<p>这家公司就当积累面试经验了</p>
<p>不过这倒是提醒了我，如果当时面试第一个的时候，做了PPT，情况会不会更好些。</p>
<p>早该想到的唉，就是懒。</p>
<p>星期天大早晨打电话说面试提前了，垃圾公司。</p>
<p>他们老板还在车上。</p>
<p>我讲的东西他们都听不懂？？</p>
<p>这是专业技术面？？？</p>
<p>垃圾公司。</p>
<p>老板还在车上面试的。</p>
<p>真的垃圾。</p>
<p>他们还不开摄像头。</p>
]]></content>
      <categories>
        <category>成为社畜的路上</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>湖州某遥感公司</title>
    <url>/posts/c38ba18c.html</url>
    <content><![CDATA[<p>这个公司观感还不错。</p>
<p>其实查了一圈之后发现遥感除了事业单位就那么几个公司。</p>
<p>自己找的这些都是小公司。</p>
<p>除此之外就是清华那种的类似孵化基地的。</p>
<p>但是感觉，去这种公司，除非有很强的资源关系，否则还是不如进体制内。</p>
<p>毕竟体制内才是这个需求的提出者，查了查他们的经营关系特别是收入来源，大部分遥感的企业赚钱的方式一个是有自己卫星的卖数据，没自己卫星的接项目。我们做出来的算法产品，例如水质啦农业监测啦，真正对这个感兴趣的还是政府单位。</p>
<a id="more"></a>
<p>还好，他们自己开了摄像头。</p>
<p>而且时间安排在周五。</p>
<p>然后他们也听得懂我在讲什么，是个博士。</p>
<p>居然做的是海洋遥感和养殖筏架的监测，我说怎么对我做的这么清楚。</p>
<p>我猜他是不是和南信工那里有关系。</p>
<p>感觉这次挺顺利的。</p>
<p>就是回去之后要直接入职的那种了。</p>
]]></content>
      <categories>
        <category>成为社畜的路上</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>Write Thesis with Markdown</title>
    <url>/posts/4c54cf6c.html</url>
    <content><![CDATA[<p>因为office公式总是出问题，所以想着换一个来写论文，最后渲染出去</p>
<a id="more"></a>
<h1 id="initial-setup">Initial Setup</h1>
<p>这里参考的是<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xvd2VyY2FzZW5hbWUvZG9jZG93bi93aWtpL0luaXRpYWwtc2V0dXA=">这个<i class="fa fa-external-link-alt"></i></span>。</p>
<p>在装好zotero和Better BibTex之后，在文件那里选导出，格式选择<strong>BetterBibTeX JSON</strong>，除了Keep updated别的别选。我把他放在onedrive里面了。</p>
<p>然后去属性里打开Better BibTex,把Automatic export改成on change。</p>
<h1 id="cite-while-write">Cite while write</h1>
<p>这里需要<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RhdmVwd3NtaXRoL3pvdHBpY2stYXBwbGVzY3JpcHQ=">这个<i class="fa fa-external-link-alt"></i></span>，一个简单的方法是直接用vscode，我就直接用vscode然后把Citation Picker for Zotero下载下来就完事了。</p>
<p>然后按一下shift +option+z就可以呼唤出zotero</p>
<h1 id="pandoc">Pandoc</h1>
<p>还是直接在vscode里装好pandoc， 直接cmd+K+P完事</p>
<p>更详细的可以看<span class="exturl" data-url="aHR0cHM6Ly9jaHVob25nLmxpZmUvMDA3LW1hcmtkb3duLXRvLWRvY3gtcGRmLyNWU2NvZGUtJUU2JThGJTkyJUU1JTg1JUE1JUU1JUJDJTk1JUU2JTk2JTg3">这里<i class="fa fa-external-link-alt"></i></span></p>
<p>反正看完了这一圈之后，我感觉，就写个毕业论文，字数不多，暂时就没空改了。</p>
<p>等后面再写别的慢慢培养习惯。</p>
]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>Atmospheric Correction by He</title>
    <url>/posts/23b76a18.html</url>
    <content><![CDATA[<p>何老师在第二届水色遥感理论班的大气校正课程</p>
<a id="more"></a>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714150751457-00030714151728161.png" alt="image-00030714150751457"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714150939841-00030714151728504.png" alt="image-00030714150939841"></p>
<p>这个框架是现在水色遥感大气校正的标准算法，计算气溶胶是使用查找表的方式，因为辐射传输计算太花时间了。查找表是针对每个卫星生成的。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714151304935-00030714151728160.png" alt="image-00030714151304935"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714151408980-00030714151728422.png" alt="image-00030714151408980"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714151633347.png" alt="image-00030714151633347"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714151803215.png" alt="image-00030714151803215"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714151854497.png" alt="image-00030714151854497"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714152038809.png" alt="image-00030714152038809"></p>
<p>这个是之前的一个做法。对于非吸收性分子和气溶胶，不需要考虑垂向变化。在标准大气压下生成，实际使用时使用辅助观测气压数据校正。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714152608100.png" alt="image-00030714152608100"></p>
<p>瑞利散射的通用表已经做出来了，气溶胶的还比较难。</p>
<p>查找表在satco2上可以找到，读取的matlab代码也放在上面。紫外不实用因为光学厚度&gt;0.4</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714152743347.png" alt="image-00030714152743347"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714152843021.png" alt="image-00030714152843021"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714152900905.png" alt="image-00030714152900905"></p>
<p>白沫反射贡献比较小，估算不准影响也不大，可以直接拿风速来算。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>w</mi><mi>c</mi></mrow></msub><mo stretchy="false">(</mo><mi>λ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R_{wc}(\lambda)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">λ</span><span class="mclose">)</span></span></span></span>是根据风速和经验函数算出来的。高分辨率卫星可能影响比较大，百米千米级的水色卫星影响不大。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714153221071.png" alt="image-00030714153221071"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714153409064.png" alt="image-00030714153409064"></p>
<p>最难的就是这个气溶胶的，利用black pixel假设，这幅图是一类水里面的。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714153644456.png" alt="image-00030714153644456"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714153732628.png" alt="image-00030714153732628"></p>
<p>后面这个80种气溶胶模式是用粗模态和细模态，AERONET-OC统计出来的。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714153831140.png" alt="image-00030714153831140"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714154006856.png" alt="image-00030714154006856"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714154745753.png" alt="image-00030714154745753"></p>
<p>算完之后用辐射传输解出来</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714155301926.png" alt="image-00030714155301926"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714155518982.png" alt="image-00030714155518982"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714160101000.png" alt="image-00030714160101000"></p>
<p>被拉去帮了个忙，中间可能过了一些</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714160146582.png" alt="image-00030714160146582"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714160316876.png" alt="image-00030714160316876"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714160505057.png" alt="image-00030714160505057"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714160733681.png" alt="image-00030714160733681"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161121970.png" alt="image-00030714161121970"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161139931.png" alt="image-00030714161139931"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161336991.png" alt="image-00030714161336991"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161424435.png" alt="image-00030714161424435"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161624885.png" alt="image-00030714161624885"></p>
<p>校正到LT上面去</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161741793.png" alt="image-00030714161741793"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161753381.png" alt="image-00030714161753381"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714161852352.png" alt="image-00030714161852352"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714162146782.png" alt="image-00030714162146782"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714162437954.png" alt="image-00030714162437954"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714162644935.png" alt="image-00030714162644935"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714170049337.png" alt="image-00030714170049337"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714170106559.png" alt="image-00030714170106559"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714170319914.png" alt="image-00030714170319914"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714170432441.png" alt="image-00030714170432441"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714170558971.png" alt="image-00030714170558971"></p>
<p>终于到了我感兴趣的地方了</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714170630435.png" alt="image-00030714170630435"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714170734239.png" alt="image-00030714170734239"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714171104513.png" alt="image-00030714171104513"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714171343885.png" alt="image-00030714171343885"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714172456970.png" alt="image-00030714172456970"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714172612626.png" alt="image-00030714172612626"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714172721960.png" alt="image-00030714172721960"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714172913598.png" alt="image-00030714172913598"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714173207910.png" alt="image-00030714173207910"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714173737934.png" alt="image-00030714173737934"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714173849090.png" alt="image-00030714173849090"></p>
<p>分辨率可以达到25 我去</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174219987.png" alt="image-00030714174219987"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174249270.png" alt="image-00030714174249270"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174312920.png" alt="image-00030714174312920"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174405172.png" alt="image-00030714174405172"></p>
<p>这个应该就是Li hao的那个</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174651469.png" alt="image-00030714174651469"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174710201.png" alt="image-00030714174710201"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174740486.png" alt="image-00030714174740486"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174848723.png" alt="image-00030714174848723"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714174939288.png" alt="image-00030714174939288"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714175009007.png" alt="image-00030714175009007"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714175106875.png" alt="image-00030714175106875"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030714175136812.png" alt="image-00030714175136812"></p>
<p>就到这里就结束了。</p>
<p>笑死了，果然关心这个的最多。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Optics</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>Carbon flux by Bai</title>
    <url>/posts/149c7e00.html</url>
    <content><![CDATA[<p>白老师在第二届水色遥感理论班的碳循环课程，草草记了一点</p>
<a id="more"></a>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715150119832.png" alt="image-00030715150119832"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715153748887.png" alt="image-00030715153748887"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715153842811.png" alt="image-00030715153842811"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715155033902.png" alt="image-00030715155033902"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715155350237.png" alt="image-00030715155350237"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715155407175.png" alt="image-00030715155407175"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715155449393.png" alt="image-00030715155449393"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715155629933.png" alt="image-00030715155629933"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715155648818.png" alt="image-00030715155648818"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715161601448.png" alt="image-00030715161601448"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715161839220.png" alt="image-00030715161839220"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715161939071.png" alt="image-00030715161939071"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715162106225.png" alt="image-00030715162106225"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715162604043.png" alt="image-00030715162604043"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715162724736.png" alt="image-00030715162724736"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715162853499.png" alt="image-00030715162853499"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715163011176.png" alt="image-00030715163011176"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715163215808.png" alt="image-00030715163215808"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715163301960.png" alt="image-00030715163301960"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715165000743.png" alt="image-00030715165000743"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715165129011.png" alt="image-00030715165129011"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715165328243.png" alt="image-00030715165328243"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715165446094.png" alt="image-00030715165446094"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715165515863.png" alt="image-00030715165515863"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715165648773.png" alt="image-00030715165648773"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715170236710.png" alt="image-00030715170236710"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715170454221.png" alt="image-00030715170454221"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715170720242.png" alt="image-00030715170720242"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715170837208.png" alt="image-00030715170837208"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715171122648.png" alt="image-00030715171122648"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715171648486.png" alt="image-00030715171648486"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715172025267.png" alt="image-00030715172025267"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715172133762.png" alt="image-00030715172133762"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715172844108.png" alt="image-00030715172844108"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715173354680.png" alt="image-00030715173354680"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715173853759.png" alt="image-00030715173853759"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715174126328.png" alt="image-00030715174126328"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715174302587.png" alt="image-00030715174302587"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715174353026.png" alt="image-00030715174353026"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715174615750.png" alt="image-00030715174615750"></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030715174721072.png" alt="image-00030715174721072"></p>
<p>![image-00030715174923029](/Users/zhenjia/Library/Application Support/typora-user-images/image-00030715174923029.png)</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>秋招进程记录</title>
    <url>/posts/2cb8508a.html</url>
    <content><![CDATA[<p>8.2号就答辩了。</p>
<p>这几天都是睡在实验室里，也许答辩完或者写完最后的论文会再整理一点东西写出来吧。</p>
<p>忽然想起来，自己这个博客一开始也只想纯写技术型的东西，后来就慢慢地不得不加入了很多个人生活的东西。因为自己很难有别的地方去抒发这么长篇大论的感受。</p>
<a id="more"></a>
<h1 id="开始之前的个人牢骚"><a class="markdownIt-Anchor" href="#开始之前的个人牢骚"></a> 开始之前的个人牢骚</h1>
<p>今天早晨起来看到了一个化学转CS的[经历贴](- <span class="exturl" data-url="aHR0cHM6Ly93d3cuMXBvaW50M2FjcmVzLmNvbS9iYnMvdGhyZWFkLTc2NTkyNi0xLTEuaHRtbA==">https://www.1point3acres.com/bbs/thread-765926-1-1.html<i class="fa fa-external-link-alt"></i></span>)，关于他为什么要转CS，文里是这么写的</p>
<blockquote>
<p><strong>计算化学</strong>，我认为它是一条河流，这个河流连接的一端是严谨的物理的理论，另一端是可以定量的预测和解释化学反应和性质的能力。</p>
<p>这条河流分为三个部分，可以理解为一条河流的<strong>上游、中游和下游</strong>。</p>
<p>上游是用物理的方法去根据已有的物理定律去建立一个有效的模型，这个模型里面可能做了某些近似，那么我们需要根据化学的直觉以及扎实的物理基础来建立这些模型。</p>
<p>中游叫做算法，就是说建立一个模型之后，我们如何用一定的方法去求解这个模型，才能从这个模型中得出我们预测的结果。</p>
<p>下游是做应用，也就是说如何把模型用到一个有化学价值的体系里面。</p>
<p>那么这三个部分就也就决定了计算化学它要用到一些物理、应用数学以及计算机科学的知识。</p>
<p>因为我做了很多研究的项目，我在做这个项目的时候发现一个共同点：我在做这个研究的时候，好像关注的不是它背后有多么深刻的物理的原理，也没有去观察它能利用哪些化学直觉，然后做哪些化学的体系，而是更多的把精力放在了第二步，也就是说算法那一步。</p>
<p>如何去有效的求解这些模型是我最关心的，也是任何一个项目最使我感到有意思的一部分。</p>
<p>在这种情况下，我就逐渐的意识到，其实我计算化学之所以能做出一定的研究成果，并不是因为我对化学甚至物理有多大的兴趣，而是说我比较喜欢研究这些计算方面的方法，而这个东西本质上和我用到哪个学科里是没有关系的。</p>
<p>另一方面，我个人其实在写代码的时候是有一种比较独特的情感，我会觉得这种解决工程问题的过程中它有一种非常有意思的动手实践的感觉，它有一种及时的反馈；而我在思考一些更偏科学的问题的时候，我觉得我没有这种愉悦感。</p>
<p>所以说，这种表面的认同和实际经验中的快乐的区别是我在成长的过程中意识到的重要的一个心法，一种思考问题的方式。</p>
</blockquote>
<p>其实我的情况和这个差不多。</p>
<p>本科的时候能让我开心的从来不是生物的化学的知识，而是数学上清楚地推导。</p>
<p>现在能让我沉浸的也不是什么奇特的有趣的现象，而是物理光学之类的原理，和数学统计上的推导。</p>
<p>不同的是，可能我对算法并没有最关注，可能这三步我关注的点大概是442这样。</p>
<p>就是自己认识的太晚了，不过好歹自己没有盲目的继续去读博，否则会更痛苦。</p>
<p>所以我真的觉得，大学四年里，考多少分什么的，真的都不重要。</p>
<p>重要的是认识自己，而不是认识世界。</p>
<p>学会与自己相处永远是最重要的内容。</p>
<p>很遗憾自己迟来了两年，但也很庆幸自己只晚了两年。</p>
<p>希望我还能找个工作然后让我去学我喜欢的东西吧，推公式这种事情永远是让我最享受的。</p>
<p>可能这也是为啥我和我老板分歧比较严重，我老板可能是118的感觉。</p>
<h1 id="秋招进程"><a class="markdownIt-Anchor" href="#秋招进程"></a> 秋招进程</h1>
<p>秋招自己基本投的都是游戏厂商，目测是全军覆没的节奏hhhh</p>
<table>
<thead>
<tr>
<th>厂商</th>
<th>地点</th>
<th>职位</th>
<th>时间和进程</th>
<th>笔试</th>
</tr>
</thead>
<tbody>
<tr>
<td>网易互娱</td>
<td>游戏测试工程师/数值策划</td>
<td>游戏测试工程师/数值策划</td>
<td>7.16已投递</td>
<td></td>
</tr>
<tr>
<td>网易雷火</td>
<td>人工智能策划</td>
<td>杭州</td>
<td>7.19已投递</td>
<td></td>
</tr>
<tr>
<td>米哈游</td>
<td>关卡战斗策划</td>
<td>上海</td>
<td>7.28投递</td>
<td>8.11发来的通知。太变态了！居然是做Demo！感觉搞定了这个demo我都可以拿它投别的公司了！只能先放弃了。。。没办法，不过反正23才截止</td>
</tr>
<tr>
<td>网元圣唐</td>
<td>游戏策划（移动端数值方向）</td>
<td>上海</td>
<td>7.30投递</td>
<td></td>
</tr>
<tr>
<td>完美世界</td>
<td>数值策划/游戏测试</td>
<td>北京/上海</td>
<td>7.30投递</td>
<td></td>
</tr>
<tr>
<td>莉莉丝</td>
<td>游戏策划</td>
<td>上海</td>
<td>7.31投递</td>
<td>8.11笔试。笔试结束后感觉自己以后笔试面试前一定要看看他们家的产品，不然就会像这场一样，我明明知道莉莉丝有SLG游戏，却说不出来叫什么名字。唉。</td>
</tr>
</tbody>
</table>
<p>积攒下经验吧</p>
]]></content>
      <categories>
        <category>成为社畜的路上</category>
      </categories>
      <tags>
        <tag>日常记录</tag>
      </tags>
  </entry>
  <entry>
    <title>SGLI 官方工具</title>
    <url>/posts/46164445.html</url>
    <content><![CDATA[<p>日本第二代水色卫星SGLI提供的官方工具，在这个<span class="exturl" data-url="aHR0cHM6Ly9ncG9ydGFsLmpheGEuanAvZ3ByL2luZm9ybWF0aW9uL3Rvb2w/bGFuZz1lbiNHQ09NLUM=">网站<i class="fa fa-external-link-alt"></i></span>可以看到。</p>
<p>大概试试怎么使用</p>
<a id="more"></a>
<h1 id="sgli-map-projection-geotiff-conversion-toolver10"><a class="markdownIt-Anchor" href="#sgli-map-projection-geotiff-conversion-toolver10"></a> SGLI Map projection &amp; GeoTIFF conversion Tool(Ver.1.0)</h1>
<h1 id="sgli-user-tool-ver105"><a class="markdownIt-Anchor" href="#sgli-user-tool-ver105"></a> SGLI User Tool (Ver.1.05)</h1>
<h1 id="sgli-product-io-toolkit"><a class="markdownIt-Anchor" href="#sgli-product-io-toolkit"></a> SGLI Product I/O Toolkit</h1>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>在日本买笔记本</title>
    <url>/posts/6153578.html</url>
    <content><![CDATA[<p>因为快要离开日本了，需要买一个笔记本替换掉老板发的MBP16，也想消费掉自己的日元，于是记录了下自己买游戏本的情况。</p>
<p>时间为2021.8，后续情况可能不一样，包括汇率啥的。</p>
<p>后续更新：加入了苹果和其他一些笔记本的情况</p>
<a id="more"></a>
<h1 id="windows笔记本">windows笔记本</h1>
<p>先说结论，如果你是要来日本读书/工作，我建议你在国内买了再过来。</p>
<p>因为日式键盘很难用。</p>
<p>语言无法描述，就是 学过日语的应该都知道katakana和hiragana。对比一下就是，日本的键盘可以让你很方便的一口气打出来汉语的平上去入四声，直接指定你打出来的事平上去入的哪一种的那种。</p>
<p>对比起来，平时在国内用的英语键盘就很难用了。</p>
<p>附一张维基百科上日式键盘的图</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/1920px-KB_Japanese.svg.png" alt="KB Japanese.svg"><figcaption aria-hidden="true">KB Japanese.svg</figcaption>
</figure>
<p>如果像我一样不得不在日本买的话，这里推荐一个<span class="exturl" data-url="aHR0cHM6Ly9rYWtha3UuY29tL3BjL2dhbWluZy1ub3RlLw==">网站<i class="fa fa-external-link-alt"></i></span>。</p>
<p>可以很方便的像淘宝一样查各种型号配置之类的。</p>
<p>（也其实感觉也没啥查的必要，基本只有联想了-，-。）</p>
<p>日本联想和戴尔的都有中文客服，也很方便。</p>
<p>自己挑了半天之后决定还是联想了，于是就碰到了第二个问题。贵和慢</p>
<p>在没有各种活动的情况下，因为日本人不怎么玩PC游戏，日本游戏本领域不像国内竞争那么激烈，相应的定价也提高了。而且很多国际厂商例如戴尔，都是在国外制作好了再进来，在疫情的情况下这个速度慢如蜗牛，点进去一看两个月之后发货的都有。</p>
<p>以R9000P 1T版为例：</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00030803184504004.png" alt="image-00030803184504004"><figcaption aria-hidden="true">image-00030803184504004</figcaption>
</figure>
<p>这个加完税，再加一个一年里之内在日本用的三千块保修，是192,425日元，约合11392人民币，国内原价是9K不过原价的买不到罢了-，-对比国内的非官方现货大概贵了1000元左右。</p>
<p>再对比下，从国内运过来运费大概800元-，-就是，算起来基本一样了。</p>
<p>唯一的缺点，就只有日式键盘</p>
<p>Thinkpad的话是有全球联保的，而且可以更换英语键盘。</p>
<p>最终我决定还是在日本买了，一方面还真的挺不方便转运的，另一方面得把日元花掉，还有就是得在离开之前换掉，因为要转移数据资料。</p>
<p>以上。</p>
<h1 id="macos">MacOS</h1>
<p>价格和国内差不多，部分可以更换英式键盘。学校生协可能有优惠。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>在日本买手机和手机卡</title>
    <url>/posts/4321dd6d.html</url>
    <content><![CDATA[<p>写了<a href="https://lifeodyssey.github.io/posts/6153578.html">这个</a>之后，想着在离开日本之前尽量把自己脑子里还记得的这两年的记忆和经验总结一下，于是继续写了这个。</p>
<p>时间为2021.8，后续可能有变。</p>
<a id="more"></a>
<h1 id="安卓手机">安卓手机</h1>
<p>我过来的时候用的就是安卓手机，所以我就把这部分先放在前面了。</p>
<p>和上一篇的结论一样，我不推荐过来买手机，尤其是国内牌子的手机。</p>
<p>国内牌子的手机在日本很多都是阉割（例如888换成730）或者涨价（平均涨价1000RMB左右），而且本地维修服务和配件（手机壳/膜）很差，过来就算买到了，用的也不会像国内那么顺手。</p>
<p>如果真的要买国内牌子的手机，一个是可以去yodubashi，另一个是这个<span class="exturl" data-url="aHR0cHM6Ly93d3cuZXhwYW5zeXMuanAv">网站<i class="fa fa-external-link-alt"></i></span>。前者是日本本地的连锁电子商城，后者是将港版代运到海外。</p>
<p>如果不买国内牌子的手机，个人推荐买pixel 三星 sony，原因就是在国内也没得卖（或者贵），性价比差不多（逃）。</p>
<p>如果想把国内手机带过来，基本上全网通的都没有问题，不用担心频段的问题。</p>
<p>这里面华为要单独拿出来说一下。华为在2019年之后的国内机型不支持GMS（可以近似为谷歌），在这里无法下载和使用很多本地化服务，所以华为是我唯一一个不推荐在国内买了带过来的手机。</p>
<h1 id="苹果手机">苹果手机</h1>
<p>和之前笔记本一样，和国内价格差不多，生协学割可能有优惠，买了带过来或者过来再买都没啥问题。</p>
<h1 id="手机卡">手机卡</h1>
<p>不推荐中国移动的那个CMLINK。</p>
<p>对于穷学生来说，最好去Big camera或者类似的地方办格安卡。和网络一起办还会有优惠。</p>
<p>另外。。。千万别办soft bank air的无线网。</p>
<p>格安卡根据我个人的经历来看，会在两个地方收到限制。一个是在line成人认证的时候只有三大运营商的卡和line mobile可以进行认证。另一个是在追星注册移动会员俱乐部的时候，大部分只能三大运营商的卡来认证。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>樱花和桂花</title>
    <url>/posts/6fbb792.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="8241606fc2713f324928dd4b0ad3d1897231d5a08beab615635e01735a7bd7ff">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>梦里真真语真幻</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>某公司从零自学过笔试</title>
    <url>/posts/bc9381.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="92fb0f304fe76532a43fc489aca1ec6c745084fd56e0e2cb6240e80d19ddb609">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>成为社畜的路上</category>
      </categories>
      <tags>
        <tag>笔试</tag>
        <tag>游戏策划</tag>
      </tags>
  </entry>
</search>
