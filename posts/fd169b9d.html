<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"lifeodyssey.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.23.1","exturl":true,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"base16/tomorrow-night"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"style":"max"},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="开始炼丹的第二天">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow基础">
<meta property="og:url" content="https://lifeodyssey.github.io/posts/fd169b9d.html">
<meta property="og:site_name" content="乔克叔叔的床边故事">
<meta property="og:description" content="开始炼丹的第二天">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211438886.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211439263.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211439787.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211439438.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211851159.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202222229236.png">
<meta property="article:published_time" content="2022-01-04T02:43:02.000Z">
<meta property="article:modified_time" content="2025-06-29T02:33:38.518Z">
<meta property="article:author" content="周大侠">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Inversion">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211438886.png">


<link rel="canonical" href="https://lifeodyssey.github.io/posts/fd169b9d.html">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://lifeodyssey.github.io/posts/fd169b9d.html","path":"posts/fd169b9d.html","title":"tensorflow基础"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>tensorflow基础 | 乔克叔叔的床边故事</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-135697820-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-135697820-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js" defer></script>








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/bookmark.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.1/pdfobject.min.js","integrity":"sha256-jI72I8ZLVflVOisZIOaLvRew3tyvzeu6aZXFm7P7dEo="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js" defer></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":"forest","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.5.0/mermaid.min.js","integrity":"sha256-2obLuIPcceEhkE3G09G33hBdmE55ivVcZUlcKcGNHjU="}}</script>
  <script src="/js/third-party/tags/mermaid.js" defer></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="乔克叔叔的床边故事" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">乔克叔叔的床边故事</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B"><span class="nav-number">1.</span> <span class="nav-text">一个简单的神经网络搭建流程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92"><span class="nav-number">2.</span> <span class="nav-text">回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="nav-number">3.</span> <span class="nav-text">过拟合和欠拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="nav-number">3.1.</span> <span class="nav-text">训练过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98%E5%92%8C%E6%81%A2%E5%A4%8D%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">保存和恢复模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#checkpoint-%E5%9B%9E%E8%B0%83%E9%80%89%E9%A1%B9"><span class="nav-number">3.2.1.</span> <span class="nav-text">checkpoint 回调选项</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E4%BF%9D%E5%AD%98%E6%9D%83%E9%87%8D"><span class="nav-number">3.3.</span> <span class="nav-text">手动保存权重</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hdf5-%E6%A0%BC%E5%BC%8F"><span class="nav-number">3.3.1.</span> <span class="nav-text">HDF5 格式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%99%90%E5%88%B6"><span class="nav-number">3.3.1.1.</span> <span class="nav-text">限制</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%8A%82"><span class="nav-number">4.</span> <span class="nav-text">超参数调节</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.1.</span> <span class="nav-text">定义模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%B0%83%E8%8A%82%E5%99%A8%E5%B9%B6%E6%89%A7%E8%A1%8C%E8%B6%85%E8%B0%83"><span class="nav-number">4.2.</span> <span class="nav-text">实例化调节器并执行超调</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#finetune"><span class="nav-number">5.</span> <span class="nav-text">Finetune</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E5%88%9B%E5%BB%BA%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.1.</span> <span class="nav-text">从预训练卷积网络创建基础模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E5%88%B0%E6%88%91%E8%87%AA%E5%B7%B1%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8A"><span class="nav-number">6.</span> <span class="nav-text">回到我自己的问题上</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">周大侠</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">165</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">97</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lifeodyssey"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnpoZW5qaWF6aG91MDEyN0BnbWFpbC5jb20=" title="E-Mail → mailto:zhenjiazhou0127@gmail.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cucmVzZWFyY2hnYXRlLm5ldC9wcm9maWxlL1poZW5qaWFfWmhvdQ==" title="Researchgate → https:&#x2F;&#x2F;www.researchgate.net&#x2F;profile&#x2F;Zhenjia_Zhou"><i class="fa fa-researchgate fa-fw"></i>Researchgate</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cubGlua2VkaW4uY29tL2luL3poZW5qaWEtemhvdS8=" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhenjia-zhou&#x2F;"><i class="fa fa-Linkedin fa-fw"></i>Linkedin</span>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml" rel="noopener me"><i class="rss fa-fw"></i>RSS</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9lbg=="><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://lifeodyssey.github.io/posts/fd169b9d.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="周大侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="乔克叔叔的床边故事">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="tensorflow基础 | 乔克叔叔的床边故事">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          tensorflow基础
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-01-04 10:43:02" itemprop="dateCreated datePublished" datetime="2022-01-04T10:43:02+08:00">2022-01-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>5.8k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>21 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>开始炼丹的第二天</p>
<span id="more"></span>
<h1 id="一个简单的神经网络搭建流程">一个简单的神经网络搭建流程</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">model.evaluate(x_test,  y_test, verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>产出的结果</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/5</span><br><span class="line">1875/1875 [==============================] - 3s 2ms/step - loss: 0.2962 - accuracy: 0.9155</span><br><span class="line">Epoch 2/5</span><br><span class="line">1875/1875 [==============================] - 3s 2ms/step - loss: 0.1420 - accuracy: 0.9581</span><br><span class="line">Epoch 3/5</span><br><span class="line">1875/1875 [==============================] - 3s 2ms/step - loss: 0.1064 - accuracy: 0.9672</span><br><span class="line">Epoch 4/5</span><br><span class="line">1875/1875 [==============================] - 3s 2ms/step - loss: 0.0885 - accuracy: 0.9730</span><br><span class="line">Epoch 5/5</span><br><span class="line">1875/1875 [==============================] - 3s 2ms/step - loss: 0.0749 - accuracy: 0.9765</span><br><span class="line">313/313 - 0s - loss: 0.0748 - accuracy: 0.9778</span><br><span class="line">[0.07484959065914154, 0.9778000116348267]</span><br></pre></td></tr></table></figure>
<p>来看一下这个简单的神经网络的结构</p>
<p>x_train, x_test = x_train / 255.0, x_test / 255.0
是因为minist这个数据集是0-255的，做了规范化。</p>
<p>tf.keras.models.Sequential
则是一个计算的连接器，意思就是这个网络由下面这几步骤连接起来，按照顺序进行计算。</p>
<p>该网络的第一层 <code>tf.keras.layers.Flatten</code>
将图像格式从二维数组（28 x 28 像素）转换成一维数组（28 x 28 = 784
像素）。将该层视为图像中未堆叠的像素行并将其排列起来。该层没有要学习的参数，它只会重新格式化数据</p>
<p>展平像素后，网络会包括两个 <code>tf.keras.layers.Dense</code>
层的序列。它们是密集连接或全连接神经层。第一个 <code>Dense</code> 层有
128 个节点（或神经元）。第二个（也是最后一个）层会返回一个长度为 10 的
logits 数组。每个节点都包含一个得分，用来表示当前图像属于 10
个类中的哪一类。</p>
<p>这里面的Dropout则是一个正则化的trick，用来放置过拟合。Dropout的意思是：每次训练时随机忽略一部分神经元，这些神经元dropped-out了。换句话讲，这些神经元在正向传播时对下游的启动影响被忽略，反向传播时也不会更新权重。</p>
<p>神经网络的所谓“学习”是指，让各个神经元的权重符合需要的特性。不同的神经元组合后可以分辨数据的某个特征。每个神经元的邻居会依赖邻居的行为组成的特征，如果过度依赖，就会造成过拟合。如果每次随机拿走一部分神经元，那么剩下的神经元就需要补上消失神经元的功能，整个网络变成很多独立网络（对同一问题的不同解决方法）的合集。。意思就是在训练完第一个Dense之后，去掉20%的神经元来训练下一个Dense。相当于手动设置了一部分可能出错的神经元，用其他神经元来纠错。</p>
<p>model.compile(optimizer=‘adam’,
loss=‘sparse_categorical_crossentropy’, metrics=[‘accuracy’])</p>
<p>这个是模型的编译。需要添加三个东西。</p>
<ul>
<li><em>损失函数</em> -
用于测量模型在训练期间的准确率。您会希望最小化此函数，以便将模型“引导”到正确的方向上。</li>
<li><em>优化器</em> -
决定模型如何根据其看到的数据和自身的损失函数进行更新。</li>
<li><em>指标</em> -
用于监控训练和测试步骤。以下示例使用了<em>准确率</em>，即被正确分类的图像的比率</li>
</ul>
<p>损失函数和指标是两个因为目的不同而分开的东西。</p>
<p>损失函数存在的意义是在优化参数中需要最小化的一个函数，它存在的目的是优化模型的参数，当这个值最小的时候模型最好，一般需要求导或者做gradiant之类的。。而指标则是我们关心的评价。</p>
<p>举个例子，在回归中，MSE既可以是损失函数也可以是指标，但是R^2就不一定能作为损失函数使用，因为R2越大模型越好。</p>
<p>在分类问题中，我们可能只关注Accuracy（准确率Precision（精准率）Recall（召回率）ROC-AUC
P-R曲线里面的某一项指标，但是这些指标一个可能是算起来困难花费时间，另一个是可能和R2有同样地问题，所以我们用的是交叉熵之类的。</p>
<p>具体的可以看<span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8xMTY1MjYz">这里<i class="fa fa-external-link-alt"></i></span></p>
<p>后面就很熟悉了。唯一一个之前没见过的东西就是 verbose=2</p>
<ul>
<li><strong>verbose</strong>: ‘auto’, 0, 1, or 2. Verbosity mode. 0 =
silent, 1 = progress bar, 2 = one line per epoch. ‘auto’ defaults to 1
for most cases, but 2 when used with
<code>ParameterServerStrategy</code>. Note that the progress bar is not
particularly useful when logged to a file, so verbose=2 is recommended
when not running interactively (eg, in a production environment).</li>
</ul>
<p>所以看一眼输出</p>
<p>Epoch 5/5 1875/1875 [==============================] - 3s 2ms/step -
loss: 0.0749 - accuracy: 0.9765 313/313 - 0s - loss: 0.0748 - accuracy:
0.9778</p>
<p>这种类似的是因为我们verbose=2之后输出的在训练集上面的结果</p>
<p>[0.07484959065914154, 0.9778000116348267]这个则是在测试集上面的</p>
<h1 id="回归">回归</h1>
<p>大部分流程和前面一样，不再具体解释，例子来自于<span class="exturl" data-url="aHR0cHM6Ly90ZW5zb3JmbG93Lmdvb2dsZS5jbi90dXRvcmlhbHMva2VyYXMvcmVncmVzc2lvbg==">这里<i class="fa fa-external-link-alt"></i></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line">....<span class="comment">#做了一些数据的清洗之后 我直接跳到模型的构建那里</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_model</span>():</span><br><span class="line">  model = keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=[<span class="built_in">len</span>(train_dataset.keys())]),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>)</span><br><span class="line">  ])</span><br><span class="line"></span><br><span class="line">  optimizer = tf.keras.optimizers.RMSprop(<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">  model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,</span><br><span class="line">                optimizer=optimizer,</span><br><span class="line">                metrics=[<span class="string">&#x27;mae&#x27;</span>, <span class="string">&#x27;mse&#x27;</span>])</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line">model = build_model()</span><br></pre></td></tr></table></figure>
<p>因为输出的是单独一个值，所以最后一层只有一个神经元。这个build
model相当于一个生成model的函数。</p>
<p>在生成完模型之后可以看一下模型的简单描述</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model: <span class="string">&quot;sequential&quot;</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (<span class="built_in">type</span>)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">dense (Dense)                (None, 64)                640       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 64)                4160      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None, 1)                 65        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 4,865</span><br><span class="line">Trainable params: 4,865</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过为每个完成的时期打印一个点来显示训练进度</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PrintDot</span>(keras.callbacks.Callback):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">on_epoch_end</span>(<span class="params">self, epoch, logs</span>):</span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>: <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;.&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">  normed_train_data, train_labels,</span><br><span class="line">  epochs=EPOCHS, validation_split = <span class="number">0.2</span>, verbose=<span class="number">0</span>,</span><br><span class="line">  callbacks=[PrintDot()])</span><br></pre></td></tr></table></figure>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cudGVuc29yZmxvdy5vcmcvYXBpX2RvY3MvcHl0aG9uL3RmL2tlcmFzL2NhbGxiYWNrcy9DYWxsYmFjaw==">callbacks<i class="fa fa-external-link-alt"></i></span>是每个epochs结束的时候执行的函数。</p>
<p>validation则是搞一个交叉验证。</p>
<p>history对象则可以可视化模型的训练进度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_history</span>(<span class="params">history</span>):</span><br><span class="line">  hist = pd.DataFrame(history.history)</span><br><span class="line">  hist[<span class="string">&#x27;epoch&#x27;</span>] = history.epoch</span><br><span class="line"></span><br><span class="line">  plt.figure()</span><br><span class="line">  plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">  plt.ylabel(<span class="string">&#x27;Mean Abs Error [MPG]&#x27;</span>)</span><br><span class="line">  plt.plot(hist[<span class="string">&#x27;epoch&#x27;</span>], hist[<span class="string">&#x27;mae&#x27;</span>],</span><br><span class="line">           label=<span class="string">&#x27;Train Error&#x27;</span>)</span><br><span class="line">  plt.plot(hist[<span class="string">&#x27;epoch&#x27;</span>], hist[<span class="string">&#x27;val_mae&#x27;</span>],</span><br><span class="line">           label = <span class="string">&#x27;Val Error&#x27;</span>)</span><br><span class="line">  plt.ylim([<span class="number">0</span>,<span class="number">5</span>])</span><br><span class="line">  plt.legend()</span><br><span class="line"></span><br><span class="line">  plt.figure()</span><br><span class="line">  plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">  plt.ylabel(<span class="string">&#x27;Mean Square Error [$MPG^2$]&#x27;</span>)</span><br><span class="line">  plt.plot(hist[<span class="string">&#x27;epoch&#x27;</span>], hist[<span class="string">&#x27;mse&#x27;</span>],</span><br><span class="line">           label=<span class="string">&#x27;Train Error&#x27;</span>)</span><br><span class="line">  plt.plot(hist[<span class="string">&#x27;epoch&#x27;</span>], hist[<span class="string">&#x27;val_mse&#x27;</span>],</span><br><span class="line">           label = <span class="string">&#x27;Val Error&#x27;</span>)</span><br><span class="line">  plt.ylim([<span class="number">0</span>,<span class="number">20</span>])</span><br><span class="line">  plt.legend()</span><br><span class="line">  plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot_history(history)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211438886.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211439263.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>该图表显示在约100个 epochs 之后误差非但没有改进，反而出现恶化。
让我们更新 <code>model.fit</code>
调用，当验证值没有提高上是自动停止训练。 我们将使用一个
<em>EarlyStopping callback</em> 来测试每个 epoch
的训练条件。如果经过一定数量的 epochs 后没有改进，则自动停止训练。</p>
<p>你可以从<span class="exturl" data-url="aHR0cHM6Ly90ZW5zb3JmbG93Lmdvb2dsZS5jbi92ZXJzaW9ucy9tYXN0ZXIvYXBpX2RvY3MvcHl0aG9uL3RmL2tlcmFzL2NhbGxiYWNrcy9FYXJseVN0b3BwaW5n">这里<i class="fa fa-external-link-alt"></i></span>学习到更多的回调。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = build_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># patience 值用来检查改进 epochs 的数量</span></span><br><span class="line">early_stop = keras.callbacks.EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, patience=<span class="number">10</span>)</span><br><span class="line"><span class="comment">#即如果在10个训练后没有改进，就停止</span></span><br><span class="line">history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,</span><br><span class="line">                    validation_split = <span class="number">0.2</span>, verbose=<span class="number">0</span>, callbacks=[early_stop, PrintDot()])</span><br><span class="line"></span><br><span class="line">plot_history(history)</span><br></pre></td></tr></table></figure>
<h1 id="过拟合和欠拟合">过拟合和欠拟合</h1>
<p><span class="exturl" data-url="aHR0cHM6Ly90ZW5zb3JmbG93Lmdvb2dsZS5jbi90dXRvcmlhbHMva2VyYXMvb3ZlcmZpdF9hbmRfdW5kZXJmaXQ=">这一节<i class="fa fa-external-link-alt"></i></span>开始就是英语了</p>
<p>依然是省略了一些前期处理</p>
<p>防止过度拟合的最简单方法是以一个小模型开始。一个具有少量可学习参数的模型（由层数和每层的单元数决定）。在深度学习中，一个模型中的可学习参数的数量通常被称为模型的
“容量”。</p>
<p>直观地说，一个拥有更多参数的模型将拥有更多的
“记忆能力”，因此能够轻易地在训练样本和它们的目标之间学习一个完美的类似字典的映射，这种映射没有任何泛化能力，但在对以前未见过的数据进行预测时，这将毫无用处。</p>
<p>永远记住这一点：深度学习模型往往善于拟合训练数据，但真正的挑战是泛化，而不是拟合。</p>
<p>另一方面，如果网络的记忆资源有限，它将无法轻易学习映射。为了使其损失最小化，它将不得不学习具有更多预测能力的压缩表征。同时，如果你让你的模型太小，它将难以适应训练数据。在
“容量太大”和 “容量不足”之间存在着一种平衡。</p>
<p>不幸的是，没有神奇的公式来确定你的模型的正确大小或架构（就层数而言，或每层的正确大小）。你将不得不使用一系列不同的架构进行试验。</p>
<p>为了找到一个合适的模型大小，最好从相对较少的层和参数开始，然后开始增加层的大小或增加新的层，直到你看到验证损失的回报递减。</p>
<p>接下来将从一个只使用密集连接层（tf.keras.layer.Dense）的简单模型开始作为基线，然后创建更大的模型，并进行比较。</p>
<h2 id="训练过程">训练过程</h2>
<p>一般来说学习率越小效果越好,这个不难理解，我们可以利用<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers/schedules"><code>tf.keras.optimizers.schedules</code></a>来随着时间减少学习率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(</span><br><span class="line">  <span class="number">0.001</span>,</span><br><span class="line">  decay_steps=STEPS_PER_EPOCH*<span class="number">1000</span>,</span><br><span class="line">  decay_rate=<span class="number">1</span>,</span><br><span class="line">  staircase=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_optimizer</span>():</span><br><span class="line">  <span class="keyword">return</span> tf.keras.optimizers.Adam(lr_schedule)</span><br></pre></td></tr></table></figure>
<p>这个函数会双曲线的来减少学习率，比如，第1000epochs会降低到一半，两千会到1/3。具体的公式是</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.optimizers.schedules.InverseTimeDecay(</span><br><span class="line">    initial_learning_rate, decay_steps, decay_rate, staircase=<span class="literal">False</span>, name=<span class="literal">None</span></span><br><span class="line">)<span class="comment">#这是参数</span></span><br><span class="line"><span class="comment">#这是默认的函数（staircase=False）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">decayed_learning_rate</span>(<span class="params">step</span>):</span><br><span class="line">  <span class="keyword">return</span> initial_learning_rate / (<span class="number">1</span> + decay_rate * step / decay_step)</span><br><span class="line">  <span class="comment">#这是另一个函数（staircase=True）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">decayed_learning_rate</span>(<span class="params">step</span>):</span><br><span class="line">  <span class="keyword">return</span> initial_learning_rate / (<span class="number">1</span> + decay_rate * floor(step / decay_step))</span><br></pre></td></tr></table></figure>
<p>下一步则是加入<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping"><code>tf.keras.callbacks.EarlyStopping</code></a>来避免训练太久。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_callbacks</span>(<span class="params">name</span>):</span><br><span class="line">  <span class="keyword">return</span> [</span><br><span class="line">    tfdocs.modeling.EpochDots(),</span><br><span class="line">    tf.keras.callbacks.EarlyStopping(monitor=<span class="string">&#x27;val_binary_crossentropy&#x27;</span>, patience=<span class="number">200</span>),</span><br><span class="line">    tf.keras.callbacks.TensorBoard(logdir/name),</span><br><span class="line">  ]</span><br></pre></td></tr></table></figure>
<p>这里EarlyStopping关注的是val_binary_crossentropy，而不是val_loss，区别在后面会讲到。</p>
<p>tf.keras.callbacks.TensorBoard则会直接显示一些定义好的metrics给你看，就像这样，具体的等后面看一下。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211439787.png" alt="How to use Keras TensorBoard callback for grid search - Stack Overflow">
<figcaption aria-hidden="true">How to use Keras TensorBoard callback for
grid search - Stack Overflow</figcaption>
</figure>
<p>然后利用Model.compile和Model.fit来构建一个网络。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compile_and_fit</span>(<span class="params">model, name, optimizer=<span class="literal">None</span>, max_epochs=<span class="number">10000</span></span>):</span><br><span class="line">  <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    optimizer = get_optimizer()</span><br><span class="line">  model.<span class="built_in">compile</span>(optimizer=optimizer,</span><br><span class="line">                loss=tf.keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                metrics=[</span><br><span class="line">                  tf.keras.losses.BinaryCrossentropy(</span><br><span class="line">                      from_logits=<span class="literal">True</span>, name=<span class="string">&#x27;binary_crossentropy&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  model.summary()</span><br><span class="line"></span><br><span class="line">  history = model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epoch = STEPS_PER_EPOCH,</span><br><span class="line">    epochs=max_epochs,</span><br><span class="line">    validation_data=validate_ds,</span><br><span class="line">    callbacks=get_callbacks(name),</span><br><span class="line">    verbose=<span class="number">0</span>)</span><br><span class="line">  <span class="keyword">return</span> history</span><br></pre></td></tr></table></figure>
<p>我们从一个小模型来开始训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tiny_model = tf.keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;elu&#x27;</span>, input_shape=(FEATURES,)),</span><br><span class="line">    layers.Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br><span class="line">size_histories = &#123;&#125;</span><br><span class="line">size_histories[<span class="string">&#x27;Tiny&#x27;</span>] = compile_and_fit(tiny_model, <span class="string">&#x27;sizes/Tiny&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>输出为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">Model: <span class="string">&quot;sequential&quot;</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line"> Layer (<span class="built_in">type</span>)                Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line"> dense (Dense)               (None, 16)                464       </span><br><span class="line">                                                                 </span><br><span class="line"> dense_1 (Dense)             (None, 1)                 17        </span><br><span class="line">                                                                 </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 481</span><br><span class="line">Trainable params: 481</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br><span class="line"></span><br><span class="line">Epoch: 0, accuracy:0.4896,  binary_crossentropy:0.8395,  loss:0.8395,  val_accuracy:0.5070,  val_binary_crossentropy:0.7700,  val_loss:0.7700,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 100, accuracy:0.6016,  binary_crossentropy:0.6240,  loss:0.6240,  val_accuracy:0.5910,  val_binary_crossentropy:0.6256,  val_loss:0.6256,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 200, accuracy:0.6269,  binary_crossentropy:0.6103,  loss:0.6103,  val_accuracy:0.6110,  val_binary_crossentropy:0.6151,  val_loss:0.6151,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 300, accuracy:0.6484,  binary_crossentropy:0.5984,  loss:0.5984,  val_accuracy:0.6340,  val_binary_crossentropy:0.6038,  val_loss:0.6038,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 400, accuracy:0.6584,  binary_crossentropy:0.5905,  loss:0.5905,  val_accuracy:0.6340,  val_binary_crossentropy:0.5993,  val_loss:0.5993,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 500, accuracy:0.6694,  binary_crossentropy:0.5860,  loss:0.5860,  val_accuracy:0.6410,  val_binary_crossentropy:0.5979,  val_loss:0.5979,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 600, accuracy:0.6684,  binary_crossentropy:0.5831,  loss:0.5831,  val_accuracy:0.6550,  val_binary_crossentropy:0.5960,  val_loss:0.5960,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 700, accuracy:0.6748,  binary_crossentropy:0.5810,  loss:0.5810,  val_accuracy:0.6510,  val_binary_crossentropy:0.5967,  val_loss:0.5967,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 800, accuracy:0.6707,  binary_crossentropy:0.5795,  loss:0.5795,  val_accuracy:0.6580,  val_binary_crossentropy:0.5965,  val_loss:0.5965,  </span><br><span class="line">...........................</span><br></pre></td></tr></table></figure>
<p>我们来画一下train test plot</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plotter = tfdocs.plots.HistoryPlotter(metric = <span class="string">&#x27;binary_crossentropy&#x27;</span>, smoothing_std=<span class="number">10</span>)</span><br><span class="line">plotter.plot(size_histories)</span><br><span class="line">plt.ylim([<span class="number">0.5</span>, <span class="number">0.7</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(0.5, 0.7)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211439438.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>接着我们来换一个更大一点的模型来看看会不会好一点</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">small_model = tf.keras.Sequential([</span><br><span class="line">    <span class="comment"># `input_shape` is only required here so that `.summary` works.</span></span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;elu&#x27;</span>, input_shape=(FEATURES,)),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;elu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br><span class="line">size_histories[<span class="string">&#x27;Small&#x27;</span>] = compile_and_fit(small_model, <span class="string">&#x27;sizes/Small&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Model: <span class="string">&quot;sequential_1&quot;</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line"> Layer (<span class="built_in">type</span>)                Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line"> dense_2 (Dense)             (None, 16)                464       </span><br><span class="line">                                                                 </span><br><span class="line"> dense_3 (Dense)             (None, 16)                272       </span><br><span class="line">                                                                 </span><br><span class="line"> dense_4 (Dense)             (None, 1)                 17        </span><br><span class="line">                                                                 </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 753</span><br><span class="line">Trainable params: 753</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br><span class="line"></span><br><span class="line">Epoch: 0, accuracy:0.4877,  binary_crossentropy:0.7209,  loss:0.7209,  val_accuracy:0.4860,  val_binary_crossentropy:0.7025,  val_loss:0.7025,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 100, accuracy:0.6212,  binary_crossentropy:0.6148,  loss:0.6148,  val_accuracy:0.6200,  val_binary_crossentropy:0.6184,  val_loss:0.6184,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 200, accuracy:0.6657,  binary_crossentropy:0.5853,  loss:0.5853,  val_accuracy:0.6570,  val_binary_crossentropy:0.5949,  val_loss:0.5949,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 300, accuracy:0.6774,  binary_crossentropy:0.5750,  loss:0.5750,  val_accuracy:0.6720,  val_binary_crossentropy:0.5868,  val_loss:0.5868,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 400, accuracy:0.6838,  binary_crossentropy:0.5683,  loss:0.5683,  val_accuracy:0.6760,  val_binary_crossentropy:0.5859,  val_loss:0.5859,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 500, accuracy:0.6897,  binary_crossentropy:0.5632,  loss:0.5632,  val_accuracy:0.6720,  val_binary_crossentropy:0.5863,  val_loss:0.5863,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 600, accuracy:0.6946,  binary_crossentropy:0.5593,  loss:0.5593,  val_accuracy:0.6670,  val_binary_crossentropy:0.5883,  val_loss:0.5883,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 700, accuracy:0.6963,  binary_crossentropy:0.5558,  loss:0.5558,  val_accuracy:0.6730,  val_binary_crossentropy:0.5869,  val_loss:0.5869,  </span><br><span class="line">....................................................................................................</span><br><span class="line">Epoch: 800, accuracy:0.7006,  binary_crossentropy:0.5531,  loss:0.5531,  val_accuracy:0.6620,  val_binary_crossentropy:0.5894,  val_loss:0.5894,  </span><br><span class="line">.........................</span><br></pre></td></tr></table></figure>
<p>他还尝试了大的 更大的 最大的 来看Loss的图</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202211851159.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>在notebook里面可以查看TensorBoard</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docs_infra: no_execute</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the TensorBoard notebook extension</span></span><br><span class="line">%load_ext tensorboard</span><br><span class="line"></span><br><span class="line"><span class="comment"># Open an embedded TensorBoard viewer</span></span><br><span class="line">%tensorboard --logdir &#123;logdir&#125;/sizes</span><br><span class="line"></span><br><span class="line">display.IFrame(</span><br><span class="line">    src=<span class="string">&quot;https://tensorboard.dev/experiment/vW7jmmF9TmKmy3rbheMQpw/#scalars&amp;_smoothingWeight=0.97&quot;</span>,</span><br><span class="line">    width=<span class="string">&quot;100%&quot;</span>, height=<span class="string">&quot;800px&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>具体效果看着挺不错的，不放图了。</p>
<h2 id="保存和恢复模型">保存和恢复模型</h2>
<p>我去 居然是拿hdf5格式保存的 怪不得 OC-SMART是这个格式</p>
<p>那或许我可以试着读取一下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pip install pyyaml h5py  <span class="comment"># Required to save models in HDF5 format</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tf.version.VERSION)</span><br><span class="line"><span class="comment">#省略一部分</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在训练期间保存模型的话，用的是tf.keras.callbacks.ModelCheckpoint</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">checkpoint_path = <span class="string">&quot;training_1/cp.ckpt&quot;</span></span><br><span class="line">checkpoint_dir = os.path.dirname(checkpoint_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a callback that saves the model&#x27;s weights</span></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model with the new callback</span></span><br><span class="line">model.fit(train_images, </span><br><span class="line">          train_labels,  </span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">          validation_data=(test_images, test_labels),</span><br><span class="line">          callbacks=[cp_callback])  <span class="comment"># Pass callback to training</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This may generate warnings related to saving the state of the optimizer.</span></span><br><span class="line"><span class="comment"># These warnings (and similar warnings throughout this notebook)</span></span><br><span class="line"><span class="comment"># are in place to discourage outdated usage, and can be ignored.</span></span><br></pre></td></tr></table></figure>
<p>这将创建一个 TensorFlow checkpoint 文件集合，这些文件在每个 epoch
结束时更新.</p>
<p>只要两个模型共享相同的架构，您就可以在它们之间共享权重。因此，当从仅权重恢复模型时，创建一个与原始模型具有相同架构的模型，然后设置其权重。</p>
<p>读取的方式则是</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a basic model instance</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate the model</span></span><br><span class="line">loss, acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Untrained model, accuracy: &#123;:5.2f&#125;%&quot;</span>.<span class="built_in">format</span>(<span class="number">100</span> * acc))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loads the weights</span></span><br><span class="line">model.load_weights(checkpoint_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Re-evaluate the model</span></span><br><span class="line">loss, acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Restored model, accuracy: &#123;:5.2f&#125;%&quot;</span>.<span class="built_in">format</span>(<span class="number">100</span> * acc))</span><br></pre></td></tr></table></figure>
<h3 id="checkpoint-回调选项">checkpoint 回调选项</h3>
<p>回调提供了几个选项，为 checkpoint 提供唯一名称并调整 checkpoint
频率。</p>
<p>训练一个新模型，每五个 epochs 保存一次唯一命名的 checkpoint ：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Include the epoch in the file name (uses `str.format`)</span></span><br><span class="line">checkpoint_path = <span class="string">&quot;training_2/cp-&#123;epoch:04d&#125;.ckpt&quot;</span></span><br><span class="line">checkpoint_dir = os.path.dirname(checkpoint_path)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a callback that saves the model&#x27;s weights every 5 epochs</span></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(</span><br><span class="line">    filepath=checkpoint_path, </span><br><span class="line">    verbose=<span class="number">1</span>, </span><br><span class="line">    save_weights_only=<span class="literal">True</span>,</span><br><span class="line">    save_freq=<span class="number">5</span>*batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new model instance</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the weights using the `checkpoint_path` format</span></span><br><span class="line">model.save_weights(checkpoint_path.<span class="built_in">format</span>(epoch=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model with the new callback</span></span><br><span class="line">model.fit(train_images, </span><br><span class="line">          train_labels,</span><br><span class="line">          epochs=<span class="number">50</span>, </span><br><span class="line">          batch_size=batch_size, </span><br><span class="line">          callbacks=[cp_callback],</span><br><span class="line">          validation_data=(test_images, test_labels),</span><br><span class="line">          verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="手动保存权重">手动保存权重</h2>
<p>使用 <code>Model.save_weights</code>
方法手动保存权重。默认情况下，<code>tf.keras</code>（尤其是
<code>save_weights</code>）使用扩展名为 <code>.ckpt</code> 的 TensorFlow
<span class="exturl" data-url="aHR0cHM6Ly93d3cudGVuc29yZmxvdy5vcmcvZ3VpZGUvY2hlY2twb2ludD9obD16aF9jbg==">检查点<i class="fa fa-external-link-alt"></i></span>格式（保存在扩展名为
<code>.h5</code> 的 <span class="exturl" data-url="aHR0cHM6Ly9qcy50ZW5zb3JmbG93Lm9yZy90dXRvcmlhbHMvaW1wb3J0LWtlcmFzLmh0bWw/aGw9emhfY24=">HDF5<i class="fa fa-external-link-alt"></i></span>
中，<span class="exturl" data-url="aHR0cHM6Ly93d3cudGVuc29yZmxvdy5vcmcvZ3VpZGUva2VyYXMvc2F2ZV9hbmRfc2VyaWFsaXplP2hsPXpoX2NuI3dlaWdodHMtb25seV9zYXZpbmdfaW5fc2F2ZWRtb2RlbF9mb3JtYXQ=">保存和序列化模型<i class="fa fa-external-link-alt"></i></span>指南中会讲到这一点）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save the weights</span></span><br><span class="line">model.save_weights(<span class="string">&#x27;./checkpoints/my_checkpoint&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new model instance</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Restore the weights</span></span><br><span class="line">model.load_weights(<span class="string">&#x27;./checkpoints/my_checkpoint&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate the model</span></span><br><span class="line">loss, acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Restored model, accuracy: &#123;:5.2f&#125;%&quot;</span>.<span class="built_in">format</span>(<span class="number">100</span> * acc))</span><br></pre></td></tr></table></figure>
<h3 id="hdf5-格式">HDF5 格式</h3>
<p>Keras使用 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvSGllcmFyY2hpY2FsX0RhdGFfRm9ybWF0">HDF5<i class="fa fa-external-link-alt"></i></span>
标准提供了一种基本的保存格式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create and train a new model instance.</span></span><br><span class="line">model = create_model()</span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the entire model to a HDF5 file.</span></span><br><span class="line"><span class="comment"># The &#x27;.h5&#x27; extension indicates that the model should be saved to HDF5.</span></span><br><span class="line">model.save(<span class="string">&#x27;my_model.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>现在，从该文件重新创建模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Recreate the exact same model, including its weights and the optimizer</span></span><br><span class="line">new_model = tf.keras.models.load_model(<span class="string">&#x27;my_model.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the model architecture</span></span><br><span class="line">new_model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss, acc = new_model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Restored model, accuracy: &#123;:5.2f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * acc))</span><br></pre></td></tr></table></figure>
<h4 id="限制">限制</h4>
<p>与 SavedModel 格式相比，H5 文件不包括以下两方面内容：</p>
<ul>
<li>通过 <code>model.add_loss()</code> 和
<code>model.add_metric()</code>
添加的<strong>外部损失和指标</strong>不会被保存（这与 SavedModel
不同）。如果您的模型有此类损失和指标且您想要恢复训练，则您需要在加载模型后自行重新添加这些损失。请注意，这不适用于通过
<code>self.add_loss()</code> 和 <code>self.add_metric()</code>
在层<em>内</em>创建的损失/指标。只要该层被加载，这些损失和指标就会被保留，因为它们是该层
<code>call</code> 方法的一部分。</li>
<li>已保存的文件中不包含<strong>自定义对象（如自定义层）的计算图</strong>。在加载时，Keras
需要访问这些对象的 Python 类/函数以重建模型。请参阅<span class="exturl" data-url="aHR0cHM6Ly93d3cudGVuc29yZmxvdy5vcmcvZ3VpZGUva2VyYXMvc2F2ZV9hbmRfc2VyaWFsaXplP2hsPXpoX2NuI2N1c3RvbS1vYmplY3Rz">自定义对象<i class="fa fa-external-link-alt"></i></span>。</li>
</ul>
<h1 id="超参数调节">超参数调节</h1>
<p>Keras Tuner 是一个库，可帮助您为 TensorFlow
程序选择最佳的超参数集。为您的机器学习 (ML)
应用选择正确的超参数集，这一过程称为<em>超参数调节</em>或<em>超调</em>。</p>
<p>超参数是控制训练过程和 ML
模型拓扑的变量。这些变量在训练过程中保持不变，并会直接影响 ML
程序的性能。超参数有两种类型：</p>
<ol type="1">
<li><strong>模型超参数</strong>：影响模型的选择，例如隐藏层的数量和宽度</li>
<li><strong>算法超参数</strong>：影响学习算法的速度和质量，例如随机梯度下降
(SGD) 的学习率以及 k 近邻 (KNN) 分类器的近邻数</li>
</ol>
<p>在本教程中，您将使用 Keras Tuner 对图像分类应用执行超调。</p>
<p>直接跳过一堆</p>
<h2 id="定义模型">定义模型</h2>
<p>构建用于超调的模型时，除了模型架构之外，还要定义超参数搜索空间。您为超调设置的模型称为<em>超模型</em>。</p>
<p>您可以通过两种方式定义超模型：</p>
<ul>
<li>使用模型构建工具函数</li>
<li>将 Keras Tuner API 的 <code>HyperModel</code> 类子类化</li>
</ul>
<p>您还可以将两个预定义的 <code>HyperModel</code> 类（<span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy10ZWFtLmdpdGh1Yi5pby9rZXJhcy10dW5lci9kb2N1bWVudGF0aW9uL2h5cGVybW9kZWxzLyNoeXBlcnhjZXB0aW9uLWNsYXNz">HyperXception<i class="fa fa-external-link-alt"></i></span>
和 <span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy10ZWFtLmdpdGh1Yi5pby9rZXJhcy10dW5lci9kb2N1bWVudGF0aW9uL2h5cGVybW9kZWxzLyNoeXBlcnJlc25ldC1jbGFzcw==">HyperResNet<i class="fa fa-external-link-alt"></i></span>）用于计算机视觉应用。</p>
<p>在本教程中，您将使用模型构建工具函数来定义图像分类模型。模型构建工具函数将返回已编译的模型，并使用您以内嵌方式定义的超参数对模型进行超调。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model_builder</span>(<span class="params">hp</span>):</span><br><span class="line">  model = keras.Sequential()</span><br><span class="line">  model.add(keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Tune the number of units in the first Dense layer</span></span><br><span class="line">  <span class="comment"># Choose an optimal value between 32-512</span></span><br><span class="line">  hp_units = hp.Int(<span class="string">&#x27;units&#x27;</span>, min_value=<span class="number">32</span>, max_value=<span class="number">512</span>, step=<span class="number">32</span>)</span><br><span class="line">  model.add(keras.layers.Dense(units=hp_units, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">  model.add(keras.layers.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Tune the learning rate for the optimizer</span></span><br><span class="line">  <span class="comment"># Choose an optimal value from 0.01, 0.001, or 0.0001</span></span><br><span class="line">  hp_learning_rate = hp.Choice(<span class="string">&#x27;learning_rate&#x27;</span>, values=[<span class="number">1e-2</span>, <span class="number">1e-3</span>, <span class="number">1e-4</span>])</span><br><span class="line"></span><br><span class="line">  model.<span class="built_in">compile</span>(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),</span><br><span class="line">                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="实例化调节器并执行超调">实例化调节器并执行超调</h2>
<p>实例化调节器以执行超调。Keras Tuner
提供了四种调节器：<code>RandomSearch</code>、<code>Hyperband</code>、<code>BayesianOptimization</code>
和 <code>Sklearn</code>。在本教程中，您将使用 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE2MDMuMDY1NjAucGRm">Hyperband<i class="fa fa-external-link-alt"></i></span> 调节器。</p>
<p>要实例化 Hyperband 调节器，必须指定超模型、要优化的
<code>objective</code> 和要训练的最大周期数
(<code>max_epochs</code>)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tuner = kt.Hyperband(model_builder,</span><br><span class="line">                     objective=<span class="string">&#x27;val_accuracy&#x27;</span>,</span><br><span class="line">                     max_epochs=<span class="number">10</span>,</span><br><span class="line">                     factor=<span class="number">3</span>,</span><br><span class="line">                     directory=<span class="string">&#x27;my_dir&#x27;</span>,</span><br><span class="line">                     project_name=<span class="string">&#x27;intro_to_kt&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="finetune">Finetune</h1>
<p>在本教程中，您将学习如何使用迁移学习通过预训练网络对猫和狗的图像进行分类。</p>
<p>预训练模型是一个之前基于大型数据集（通常是大型图像分类任务）训练的已保存网络。您可以按原样使用预训练模型，也可以使用迁移学习针对给定任务自定义此模型。</p>
<p>用于图像分类的迁移学习背后的理念是，如果一个模型是基于足够大且通用的数据集训练的，那么该模型将有效地充当视觉世界的通用模型。随后，您可以利用这些学习到的特征映射，而不必通过基于大型数据集训练大型模型而从头开始。</p>
<p>在此笔记本中，您将尝试通过以下两种方式来自定义预训练模型：</p>
<ol type="1">
<li>特征提取：使用先前网络学习的表示从新样本中提取有意义的特征。您只需在预训练模型上添加一个将从头开始训练的新分类器，这样便可重复利用先前针对数据集学习的特征映射。</li>
</ol>
<p>您无需（重新）训练整个模型。基础卷积网络已经包含通常用于图片分类的特征。但是，预训练模型的最终分类部分特定于原始分类任务，随后特定于训练模型所使用的类集。</p>
<ol type="1">
<li>微调：解冻已冻结模型库的一些顶层，并共同训练新添加的分类器层和基础模型的最后几层。这样，我们便能“微调”基础模型中的高阶特征表示，以使其与特定任务更相关。</li>
</ol>
<p>您将遵循通用的机器学习工作流。</p>
<ol type="1">
<li>检查并理解数据</li>
<li>构建输入流水线，在本例中使用 Keras ImageDataGenerator</li>
<li>构成模型
<ul>
<li>加载预训练的基础模型（和预训练权重）</li>
<li>将分类层堆叠在顶部</li>
</ul></li>
<li>训练模型</li>
<li>评估模型</li>
</ol>
<p>忽略一堆</p>
<h2 id="从预训练卷积网络创建基础模型">从预训练卷积网络创建基础模型</h2>
<p>您将根据 Google 开发的 <strong>MobileNet V2</strong>
模型来创建基础模型。此模型已基于 ImageNet 数据集进行预训练，ImageNet
数据集是一个包含 140 万个图像和 1000 个类的大型数据集。ImageNet
是一个研究训练数据集，具有各种各样的类别，例如 <code>jackfruit</code> 和
<code>syringe</code>。此知识库将帮助我们对特定数据集中的猫和狗进行分类。</p>
<p>首先，您需要选择将 MobileNet V2
的哪一层用于特征提取。最后的分类层（在“顶部”，因为大多数机器学习模型的图表是从下到上的）不是很有用。相反，您将按照常见做法依赖于展平操作之前的最后一层。此层被称为“瓶颈层”。与最后一层/顶层相比，瓶颈层的特征保留了更多的通用性。</p>
<p>首先，实例化一个已预加载基于 ImageNet 训练的权重的 MobileNet V2
模型。通过指定 <strong>include_top=False</strong>
参数，可以加载不包括顶部分类层的网络，这对于特征提取十分理想</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the base model from the pre-trained model MobileNet V2</span></span><br><span class="line">IMG_SHAPE = IMG_SIZE + (<span class="number">3</span>,)</span><br><span class="line">base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,</span><br><span class="line">                                               include_top=<span class="literal">False</span>,</span><br><span class="line">                                               weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="回到我自己的问题上">回到我自己的问题上</h1>
<p>我现在是属于要用H5的那个，那么 首先我需要自己重新创建一个模型。</p>
<p>先补一下<span class="exturl" data-url="aHR0cDovL3poLmQybC5haS9jaGFwdGVyX211bHRpbGF5ZXItcGVyY2VwdHJvbnMvbWxwLmh0bWw=">MLP<i class="fa fa-external-link-alt"></i></span></p>
<p>然后我也手动测试出了模型结构 下一个问题就是
怎么给Weight和Bias赋值</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image.202202222229236.png" alt="image-20220222222953159">
<figcaption aria-hidden="true">image-20220222222953159</figcaption>
</figure>
<p>好简单。。。只要肯查源码，什么都不是问题</p>
<p>这么写的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Fmodel.add(Dense(<span class="number">100</span>, input_shape=(<span class="number">7</span>,),activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                 kernel_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer1&#x27;</span>])),</span><br><span class="line">                bias_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer1&#x27;</span>]))))</span><br><span class="line"></span><br><span class="line">Fmodel.add(Dense(<span class="number">75</span>, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                 kernel_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer2&#x27;</span>])),</span><br><span class="line">                bias_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer2&#x27;</span>]))))</span><br><span class="line">Fmodel.add(Dense(<span class="number">50</span>, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                 kernel_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer3&#x27;</span>])),</span><br><span class="line">                bias_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer3&#x27;</span>]))))</span><br><span class="line">Fmodel.add(Dense(<span class="number">25</span>, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                 kernel_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer4&#x27;</span>])),</span><br><span class="line">                bias_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer4&#x27;</span>]))))</span><br><span class="line"></span><br><span class="line">Fmodel.add(Dense(<span class="number">7</span>, activation=<span class="string">&#x27;linear&#x27;</span>,</span><br><span class="line">                 kernel_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer5&#x27;</span>])),</span><br><span class="line">                bias_initializer=keras.initializers.Constant(np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer5&#x27;</span>]))))</span><br></pre></td></tr></table></figure>
<p>为什么他们结果不太一样呢</p>
<p>自己一开始是把activation写错了 写成了relu
就是上面那个，后面改成了tanh 应该一样了啊</p>
<p>再次开启debug，然后发现从第一层开始就有问题了。</p>
<p>所以这个dense tanh到底是怎么计算的呢</p>
<p><code>Dense</code> implements the operation:
<code>output = activation(dot(input, kernel) + bias)</code> where
<code>activation</code> is the element-wise activation function passed
as the <code>activation</code> argument, <code>kernel</code> is a
weights matrix created by the layer, and <code>bias</code> is a bias
vector created by the layer (only applicable if <code>use_bias</code> is
<code>True</code>). These are all attributes of <code>Dense</code>.</p>
<p>对于原来的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lastlayer=np.tanh(np.matmul(aphnn_weights[i],aphinput.transpose())+aphnn_bias[i])</span><br></pre></td></tr></table></figure>
<p>np.matmul和dot都是一样的，矩阵乘法</p>
<p>啊搞定了</p>
<p>因为keras.initializers.Constant只能给所有的weight和bias赋一样的值，所以会有差别。</p>
<p>新的写法改成了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Fmodel.add(Dense(<span class="number">100</span>, input_shape=(<span class="number">7</span>,),activation=<span class="string">&#x27;tanh&#x27;</span>,use_bias=<span class="literal">True</span>))</span><br><span class="line">Fmodel.layers[<span class="number">0</span>].set_weights([np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer1&#x27;</span>]).T,np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer1&#x27;</span>]).flatten()])</span><br><span class="line">Fmodel.add(Dense(<span class="number">75</span>, activation=<span class="string">&#x27;tanh&#x27;</span>,use_bias=<span class="literal">True</span>)</span><br><span class="line">Fmodel.layers[<span class="number">1</span>].set_weights([np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer2&#x27;</span>]).T,np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer2&#x27;</span>]).flatten()])</span><br><span class="line">Fmodel.add(Dense(<span class="number">50</span>, activation=<span class="string">&#x27;tanh&#x27;</span>,use_bias=<span class="literal">True</span>)</span><br><span class="line">Fmodel.layers[<span class="number">2</span>].set_weights([np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer3&#x27;</span>]).T,np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer3&#x27;</span>]).flatten()])</span><br><span class="line">Fmodel.add(Dense(<span class="number">25</span>, activation=<span class="string">&#x27;tanh&#x27;</span>,,use_bias=<span class="literal">True</span>)</span><br><span class="line">Fmodel.layers[<span class="number">3</span>].set_weights([np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer4&#x27;</span>]).T,np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer4&#x27;</span>]).flatten()])</span><br><span class="line">Fmodel.add(Dense(<span class="number">7</span>, activation=<span class="string">&#x27;linear&#x27;</span>,use_bias=<span class="literal">True</span>,use_bias=<span class="literal">True</span>)</span><br><span class="line">Fmodel.layers[<span class="number">4</span>].set_weights([np.array(f[<span class="string">&#x27;Weights&#x27;</span>][<span class="string">&#x27;Layer5&#x27;</span>]).T,np.array(f[<span class="string">&#x27;Bias&#x27;</span>][<span class="string">&#x27;Layer5&#x27;</span>]).flatten()])</span><br></pre></td></tr></table></figure>
<p>终于搞定了 后面做个finetune就可以了</p>
<p>https://www.kaggle.com/c/tensorflow-great-barrier-reef</p>
<p>https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay</p>
<p>https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc</p>
<p>https://vimsky.com/examples/usage/python-tf.keras.layers.Dropout-tf.html</p>
<p>https://cnbeining.github.io/deep-learning-with-python-cn/4-advanced-multi-layer-perceptrons-and-keras/ch16-reduce-overfitting-with-dropout-regularization.html</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>周大侠
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://lifeodyssey.github.io/posts/fd169b9d.html" title="tensorflow基础">https://lifeodyssey.github.io/posts/fd169b9d.html</a>
  </li>
  <li class="post-copyright-license">
      <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9lbg=="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/Inversion/" rel="tag"># Inversion</a>
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/fee729e7.html" rel="prev" title="PyTorch基础">
                  <i class="fa fa-angle-left"></i> PyTorch基础
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/661d51c5.html" rel="next" title="人生は最高の暇つぶし">
                  人生は最高の暇つぶし <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2016 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">周大侠</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">275k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">16:39</span>
  </span>
</div>
  <div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9taXN0Lw==">NexT.Mist</span>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
