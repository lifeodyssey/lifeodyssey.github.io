<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  
  <link rel="stylesheet" href="/lib/animate-css/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lifeodyssey.github.io","root":"/","scheme":"Mist","version":"8.0.0-rc.5","exturl":true,"sidebar":{"position":"right","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"path":"search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="之前在IOP的那篇论文里提到过，反演问题的数学本质是一个病态问题。而机器学习和深度学习本质上解决的都是分类和回归问题，并不能直接解决病态问题。最近重新查看一些论文，终于想起了之前看过的一些东西。">
<meta property="og:type" content="article">
<meta property="og:title" content="Mixture Density Network">
<meta property="og:url" content="https://lifeodyssey.github.io/posts/fbd0b1b0.html">
<meta property="og:site_name" content="乔克叔叔的床边故事">
<meta property="og:description" content="之前在IOP的那篇论文里提到过，反演问题的数学本质是一个病态问题。而机器学习和深度学习本质上解决的都是分类和回归问题，并不能直接解决病态问题。最近重新查看一些论文，终于想起了之前看过的一些东西。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewin1-s2.0-S0034425719306248-gr3.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinclip_image002.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinfrsen-01-623678-g004.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinfrsen-01-623678-g005.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinfrsen-01-623678-g006.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinclip_image003.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewin202112302311329.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewin202112302311329.png">
<meta property="article:published_time" content="2021-12-28T05:23:00.000Z">
<meta property="article:modified_time" content="2022-01-28T06:12:03.603Z">
<meta property="article:author" content="周大侠">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Inversion">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewin1-s2.0-S0034425719306248-gr3.jpg">

<link rel="canonical" href="https://lifeodyssey.github.io/posts/fbd0b1b0.html">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Mixture Density Network | 乔克叔叔的床边故事</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-135697820-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-135697820-1');
      }
    </script>






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="乔克叔叔的床边故事" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">乔克叔叔的床边故事</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%87%A0%E7%AF%87%E8%AE%BA%E6%96%87"><span class="nav-number">1.</span> <span class="nav-text">几篇论文、</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#seamless-retrievals-of-chlorophyll-a-from-sentinel-2-msi-and-sentinel-3-olci-in-inland-and-coastal-waters-a-machine-learning-approach"><span class="nav-number">1.1.</span> <span class="nav-text">Seamless retrievals of chlorophyll-a from Sentinel-2 (MSI) and Sentinel-3 (OLCI) in inland and coastal waters: A machine-learning approach</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="nav-number">1.1.1.</span> <span class="nav-text">训练过程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#robust-algorithm-for-estimating-total-suspended-solids-tss-in-inland-and-nearshore-coastal-waters"><span class="nav-number">1.2.</span> <span class="nav-text">Robust algorithm for estimating total suspended solids (TSS) in inland and nearshore coastal waters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hyperspectral-retrievals-of-phytoplankton-absorption-and-chlorophyll-a-in-inland-and-nearshore-coastal-waters"><span class="nav-number">1.3.</span> <span class="nav-text">Hyperspectral retrievals of phytoplankton absorption and chlorophyll-a in inland and nearshore coastal waters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#a-chlorophyll-a-algorithm-for-landsat-8-based-on-mixture-density-networks"><span class="nav-number">1.4.</span> <span class="nav-text">A Chlorophyll-a Algorithm for Landsat-8 Based on Mixture Density Networks</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9C%8B%E6%BA%90%E4%BB%A3%E7%A0%81%E4%B9%8B%E5%89%8D%E8%A1%A5%E5%85%85%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86"><span class="nav-number">2.</span> <span class="nav-text">看源代码之前补充一些知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B1%BB%E7%9A%84%E7%BB%A7%E6%89%BF%E5%92%8C%E5%A4%9A%E6%80%81"><span class="nav-number">2.0.1.</span> <span class="nav-text">类的继承和多态</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#iterator"><span class="nav-number">2.0.2.</span> <span class="nav-text">iterator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BF%E9%97%AE%E9%99%90%E5%88%B6"><span class="nav-number">2.0.3.</span> <span class="nav-text">访问限制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9D%97%E7%9A%84%E8%B0%83%E7%94%A8"><span class="nav-number">2.0.4.</span> <span class="nav-text">模块的调用</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#mdn%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.</span> <span class="nav-text">MDN的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98"><span class="nav-number">3.1.</span> <span class="nav-text">一个问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensorflow_probability"><span class="nav-number">3.2.</span> <span class="nav-text">tensorflow_probability</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%8D%E6%9D%A5%E8%A1%A5%E4%B8%AA%E8%AF%BE"><span class="nav-number">3.3.</span> <span class="nav-text">再来补个课</span></a></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">周大侠</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">121</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">76</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lifeodyssey"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnpoZW5qaWF6aG91MDEyN0BnbWFpbC5jb20=" title="E-Mail → mailto:zhenjiazhou0127@gmail.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cucmVzZWFyY2hnYXRlLm5ldC9wcm9maWxlL1poZW5qaWFfWmhvdQ==" title="Researchgate → https:&#x2F;&#x2F;www.researchgate.net&#x2F;profile&#x2F;Zhenjia_Zhou"><i class="fa fa-researchgate fa-fw"></i>Researchgate</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cubGlua2VkaW4uY29tL2luLyVFNiU4QyVBRiVFNCVCRCVCMy0lRTUlOTElQTgtODMyNmI0MTU1Lw==" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;%E6%8C%AF%E4%BD%B3-%E5%91%A8-8326b4155&#x2F;"><i class="fa fa-Linkedin fa-fw"></i>Linkedin</span>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="rss fa-fw"></i>RSS</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9lbg=="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>



      </section>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>

<noscript>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


      <div class="main-inner">
        

        <div class="content post posts-expand">
          

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://lifeodyssey.github.io/posts/fbd0b1b0.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="周大侠">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="乔克叔叔的床边故事">
    </span>

    
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Mixture Density Network
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-28 13:23:00" itemprop="dateCreated datePublished" datetime="2021-12-28T13:23:00+08:00">2021-12-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-28 14:12:03" itemprop="dateModified" datetime="2022-01-28T14:12:03+08:00">2022-01-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>33k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>30 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>之前在IOP的那篇论文里提到过，反演问题的数学本质是一个病态问题。而机器学习和深度学习本质上解决的都是分类和回归问题，并不能直接解决病态问题。最近重新查看一些论文，终于想起了之前看过的一些东西。 <a id="more"></a></p>
<h1 id="几篇论文">几篇论文、</h1>
<ul>
<li>"Seamless retrievals of chlorophyll-a from Sentinel-2 (MSI) and Sentinel-3 (OLCI) in inland and coastal waters: A machine-learning approach". N. Pahlevan, et al. (2020). Remote Sensing of Environment. 111604. 10.1016/j.rse.2019.111604.</li>
<li>"Robust algorithm for estimating total suspended solids (TSS) in inland and nearshore coastal waters". S.V. Balasubramanian, et al. (2020). Remote Sensing of Environment. 111768. 10.1016/j.rse.2020.111768. Code.</li>
<li>"Hyperspectral retrievals of phytoplankton absorption and chlorophyll-a in inland and nearshore coastal waters". N. Pahlevan, et al. (2021). Remote Sensing of Environment. 112200. 10.1016/j.rse.2020.112200.</li>
<li>"A Chlorophyll-a Algorithm for Landsat-8 Based on Mixture Density Networks". B. Smith, et al. (2021). Frontiers in Remote Sensing. 623678. 10.3389/frsen.2020.623678.</li>
</ul>
<p>这几篇论文都是Pahlevan搞的，代码都放在https://github.com/BrandonSmithJ/MDN，但是跟怕别人偷走一样，对于怎么重新应用只口不提。</p>
<p>一篇篇来看吧</p>
<h2 id="seamless-retrievals-of-chlorophyll-a-from-sentinel-2-msi-and-sentinel-3-olci-in-inland-and-coastal-waters-a-machine-learning-approach">Seamless retrievals of chlorophyll-a from Sentinel-2 (MSI) and Sentinel-3 (OLCI) in inland and coastal waters: A machine-learning approach</h2>
<p>这篇论文是Pahlevan搞得第一篇，重点来看看他的这个网络是怎么做的，MDN的原理回合后面实现一起讲</p>
<h3 id="训练过程">训练过程</h3>
<p>因为他们的数据足够多，所以只用了1/3，大概1000个数据来训练。</p>
<p>输入数据只有400-800的Rrs.</p>
<p>所有的feature都log-transformed, normalized based on median centering and interquartile scaling, and then scaled to the range (0,1);</p>
<p>这个步骤是咋做的呢，我去翻了翻他们的源代码，对于传进来的data，会利用from .transformers import TransformerPipeline, generate_scalers 这个scalers来做变换。</p>
<p>然后</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line">args.x_scalers = [</span><br><span class="line">          serialize(preprocessing.RobustScaler),</span><br><span class="line">    ]</span><br><span class="line"> args.y_scalers = [</span><br><span class="line">        serialize(LogTransformer),</span><br><span class="line">        serialize(preprocessing.MinMaxScaler, [(-<span class="number">1</span>, <span class="number">1</span>)]),</span><br><span class="line"> ]</span><br></pre></td></tr></table></figure>
<p>?不是说的0-1吗？</p>
<p>具体用的应该是这一个https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html，然后对y做的就是MinMaxScaler了。</p>
<p>然后应该是把这个参数存下来，等到后面在做的时候重新来弄，不然一个单独的数哪儿来的IQR。</p>
<p>等到后面具体实现的时候可以认真看下。</p>
<p>输出的数据output variables are subject to the same normalization method</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewin1-s2.0-S0034425719306248-gr3.jpg" alt="Fig. 3"><figcaption aria-hidden="true">Fig. 3</figcaption>
</figure>
<p>然后放了这么一张图上来。</p>
<p>不是，我也没见你哪里有做feature engineering啊。</p>
<p>再看后面几个论文的时候发现把feature engineering给去掉了hhh，果然顶刊也是很容易出问题的啊。</p>
<p>然后对于调参</p>
<blockquote>
<p>These choices appear to be fairly robust to changes within the current implementation, especially with regard to the MDN-specific parameters. Following experimenting with several architectures, we found that the model is very robust to changes in various hyperparameters.</p>
</blockquote>
<p>在这种情况下他们就只用了一个a five-layer neural network with 100 neurons per layer, which is trained to output the parameters of five Gaussians.</p>
<p>The median estimates from the MDN model taken over ten trials of random network initializations are the predicted Chl<em>a</em> for a given *R**rs* spectrum. Here, the same training data are used for all trials.</p>
<p>这篇论文关于网络的部分基本就这么结了，看下一个</p>
<h2 id="robust-algorithm-for-estimating-total-suspended-solids-tss-in-inland-and-nearshore-coastal-waters">Robust algorithm for estimating total suspended solids (TSS) in inland and nearshore coastal waters</h2>
<p>直接跳到训练过程</p>
<p>其实有点想吐槽，这么直接的复制粘贴，好多地方都一样，真的不会被判抄袭吗，这篇论文有意思的地方是结合了MDN，QAA，水体光学分类，来做TSS。</p>
<p>和上一篇论文不同的地方只有</p>
<blockquote>
<p>. The current default model uses a five-layer neural network with 25 neurons per layer, which is trained to output the parameters of five Gaussians. From this mixture model, the overall estimate is selected via the Gaussian with the maximum prior likelihood. The described model is trained a number of times with random initializations of the underlying neural network, in order to ensure a stable final output of the estimates. The median estimate is taken as the final result of these trials, with convergence occurring within some small margin of error after approximately ten trials</p>
</blockquote>
<h2 id="hyperspectral-retrievals-of-phytoplankton-absorption-and-chlorophyll-a-in-inland-and-nearshore-coastal-waters">Hyperspectral retrievals of phytoplankton absorption and chlorophyll-a in inland and nearshore coastal waters</h2>
<p>没有任何其他的区别。</p>
<p>真要说的话就是他们训练了俩模型，也不太懂为什么要训练俩。</p>
<h2 id="a-chlorophyll-a-algorithm-for-landsat-8-based-on-mixture-density-networks">A Chlorophyll-a Algorithm for Landsat-8 Based on Mixture Density Networks</h2>
<p>这个是这么说的</p>
<blockquote>
<p>. All models examined in this study have simply used ‘reasonable’ default values for their hyperparameters (Glorot and Bengio 2010; Hinton 1990; Kingma and Ba 2014) namely: a five layer neural network with 100 nodes per layer, learning a mixture of five gaussians; a learning rate, L2 normalization rate, and <img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinclip_image002.png" alt="img"> value all set to 0.001; and with training performed via Adam optimization over a set of 10,000 stochastic mini-batch iterations, using a mini-batch size of 128 samples.</p>
</blockquote>
<p>这篇论文其实很有意思。</p>
<p>这篇论文的一个主要目的是证明MDN这个专门针对反演问题的网络架构和其他的神经网络架构相比的优越性。具体结果可以看这几张图。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinfrsen-01-623678-g004.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinfrsen-01-623678-g005.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinfrsen-01-623678-g006.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>还比较了我之前想试着用的cao 2020用过的XGBoost</p>
<p>这篇论文的补充材料里的讨论也写的贼有意思，感觉这个讨论是用来怼某个审稿人的。我来翻译一下这个讨论。</p>
<p>审稿人问：你为啥不改你模型的参数啊</p>
<blockquote>
<p>While no hyperparameter optimization has taken place over the course of this work, it is an important step to ensure optimal performance and generality.</p>
<p>These choices are mostly arbitrary, as the goal of this study was to present the feasibility and theoretical backing of the MDN model</p>
<p>These choices are mostly arbitrary, as the goal of this study was to present the feasibility and theoretical backing of the MDN model. A full optimality demonstration, on the other hand, would require a significantly longer study than already presented.</p>
</blockquote>
<p>回答：第一，重点不在这，第二，没空，先水一个论文再说。</p>
<p>审稿人：不行，你得证明你这个模型参数不重要。</p>
<blockquote>
<p>Nevertheless, we would be remiss to exclude any discussion which examines the hyperparameter choices, and so what follows is a (very) brief look at how select parameters affect performance.</p>
</blockquote>
<p>回答：行吧，既然你不懂，我们就稍微给你讲一下，而且我们觉得你听不懂，我们给你们讲个最简单的。</p>
<blockquote>
<p>First, some terminology must be defined in order to make it clear what is being examined. Normally in hyperparameter optimization, and machine learning in general, the dataset is split into three parts: training, validation, and testing. The training set is of course used to train the model on; the validation set is used to optimize the model using data unseen during training; and the testing set is used only at the end, in order to benchmark performance.</p>
</blockquote>
<p>回答：爷来给你们讲一下定义。</p>
<blockquote>
<p>As mentioned, no explicit hyperparameter optimizations have taken place thus far in the study. Default values were chosen based on those commonly used in literature and in available libraries (e.g. scikit-learn), and as will be seen, do not represent the optimal values for our specific data. As such, no separate validation set was set aside for the purposes of such an exercise.</p>
</blockquote>
<p>因为我们没有做一个精确的超参数调整，所以我们就没做val那一部分的数据集，只做了train test</p>
<blockquote>
<p>One of the main questions any reader may have is, “how large is the model?”.</p>
</blockquote>
<p>我知道你们不是这行的，提不出来啥专业问题，我来提一个。</p>
<p>然后给了两张图看layer和node的影响</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewinclip_image003.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>接着给看了learning curve</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewin202112302311329.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/gamewin202112302311329.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>怼的真的很好哈哈哈</p>
<h1 id="看源代码之前补充一些知识">看源代码之前补充一些知识</h1>
<p>不想看可以直接跳过</p>
<p>###　class的一些知识补充</p>
<p>自己之前逃的课都会以另一种方式回来，面向对象，这不就又来了。</p>
<p>类包括同时包括valuable 和function，前者是类的属性，后者是类的方法。</p>
<p>比如一个人的身高和体重就是属性，说话吃饭是他的方法</p>
<p>定义的方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassName</span>:</span></span><br><span class="line">   <span class="string">&#x27;类的帮助信息&#x27;</span>   <span class="comment">#类文档字符串</span></span><br><span class="line">   class_suite  <span class="comment">#类体</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 一个例子</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span>:</span></span><br><span class="line">   <span class="string">&#x27;所有员工的基类&#x27;</span></span><br><span class="line">   empCount = <span class="number">0</span><span class="comment"># 属性</span></span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, salary</span>):</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.salary = salary</span><br><span class="line">      Employee.empCount += <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayCount</span>(<span class="params">self</span>):</span><span class="comment">#方法</span></span><br><span class="line">     <span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayEmployee</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;Name : &quot;</span>, self.name,  <span class="string">&quot;, Salary: &quot;</span>, self.salary</span><br></pre></td></tr></table></figure>
<p>在这里面呢，empCount变量是一个类变量，这个值在所有的实例之间共享，访问方法为Employee.empCount</p>
<p>第一种方法 <strong>init</strong>() 方法是一种特殊的方法，被称为类的构造函数或初始化方法，当创建了这个类的实例时就会调用该方法。意思就是每次创建一个类的实例，就会给name和salary赋值，然后Employee.empCount+1</p>
<p>这里面self代表的是实例，意思比如你定义了一个李华进去，这个self就代表了李华，可以理解为你定义一个fun(x,y,z),然后调用的时候用的是fun(a,b,c), self只是他在类内部的名字而已，调用的使用不需要传入相应的参数。</p>
<p>这就是类和函数一个特别的区别，类必须由一个额外的第一个参数名称。</p>
<p>更具体一点的区别可以看这里</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prt</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(self)</span><br><span class="line">        <span class="built_in">print</span>(self.__class__)</span><br><span class="line">t = Test()</span><br><span class="line">t.prt()</span><br></pre></td></tr></table></figure>
<p>执行结果为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;__main__.Test instance at 0x10d066878&gt;</span><br><span class="line">__main__.Test</span><br></pre></td></tr></table></figure>
<p>第一行输出的是instance，代表一个实例，第二行是这个类本身。</p>
<p>self不是关键词，可以改成akb48。</p>
<p>想要调用必须创建一个实例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#&quot;创建 Employee 类的第一个对象&quot;</span></span><br><span class="line">emp1 = Employee(<span class="string">&quot;Zara&quot;</span>, <span class="number">2000</span>)</span><br><span class="line"><span class="comment">#&quot;创建 Employee 类的第二个对象&quot;</span></span><br><span class="line">emp2 = Employee(<span class="string">&quot;Manni&quot;</span>, <span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<p>这些参数是通过init来接收的</p>
<p>和函数很类似，可以修改和访问实例里面的属性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">emp1.displayEmployee()</span><br><span class="line">emp2.displayEmployee()</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br></pre></td></tr></table></figure>
<p>这个结果是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Name :  Zara ,Salary:  2000</span><br><span class="line">Name :  Manni ,Salary:  5000</span><br><span class="line">Total Employee 2</span><br></pre></td></tr></table></figure>
<p>同时也可以添加、删除、修改类的属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">emp1.age = <span class="number">7</span>  <span class="comment"># 添加一个 &#x27;age&#x27; 属性</span></span><br><span class="line">emp1.age = <span class="number">8</span>  <span class="comment"># 修改 &#x27;age&#x27; 属性</span></span><br><span class="line"><span class="keyword">del</span> emp1.age  <span class="comment"># 删除 &#x27;age&#x27; 属性</span></span><br></pre></td></tr></table></figure>
<p>也可以使用这些函数来访问属性</p>
<ul>
<li><strong>getattr(obj, name[, default]) : 访问对象的属性。</strong></li>
<li><strong>hasattr(obj,name) : 检查是否存在一个属性。</strong></li>
<li><strong>setattr(obj,name,value) : 设置一个属性。如果属性不存在，会创建一个新属性。</strong></li>
<li><strong>delattr(obj, name) : 删除属性</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hasattr</span>(emp1, <span class="string">&#x27;age&#x27;</span>)    <span class="comment"># 如果存在 &#x27;age&#x27; 属性返回 True。</span></span><br><span class="line"><span class="built_in">getattr</span>(emp1, <span class="string">&#x27;age&#x27;</span>)    <span class="comment"># 返回 &#x27;age&#x27; 属性的值</span></span><br><span class="line"><span class="built_in">setattr</span>(emp1, <span class="string">&#x27;age&#x27;</span>, <span class="number">8</span>) <span class="comment"># 添加属性 &#x27;age&#x27; 值为 8</span></span><br><span class="line"><span class="built_in">delattr</span>(empl, <span class="string">&#x27;age&#x27;</span>)    <span class="comment"># 删除属性 &#x27;age&#x27;</span></span><br></pre></td></tr></table></figure>
<p>python有一些内置的类属性，意思是你创建这个类的时候就有这些属性。包括：</p>
<ul>
<li><strong>dict</strong> : 类的属性（包含一个字典，由类的数据属性组成）</li>
<li><strong>doc</strong> :类的文档字符串</li>
<li><strong>name</strong>: 类名</li>
<li><strong>module</strong>: 类定义所在的模块（类的全名是'<strong>main</strong>.className'，如果类位于一个导入模块 mymod 中，那么 className.__module__ 等于 mymod）</li>
<li><strong>bases</strong> : 类的所有父类构成元素（包含了以个由所有父类组成的元组）</li>
</ul>
<p>调用方式为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span>:</span></span><br><span class="line">   <span class="string">&#x27;所有员工的基类&#x27;</span></span><br><span class="line">   empCount = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, salary</span>):</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.salary = salary</span><br><span class="line">      Employee.empCount += <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayCount</span>(<span class="params">self</span>):</span></span><br><span class="line">     <span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayEmployee</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;Name : &quot;</span>, self.name,  <span class="string">&quot;, Salary: &quot;</span>, self.salary</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__doc__:&quot;</span>, Employee.__doc__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__name__:&quot;</span>, Employee.__name__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__module__:&quot;</span>, Employee.__module__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__bases__:&quot;</span>, Employee.__bases__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__dict__:&quot;</span>, Employee.__dict__</span><br></pre></td></tr></table></figure>
<p>这个输出的结果是</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Employee.__doc__: 所有员工的基类</span><br><span class="line">Employee.__name__: Employee</span><br><span class="line">Employee.__module__: __main__</span><br><span class="line">Employee.__bases__: ()</span><br><span class="line">Employee.__dict__: &#123;<span class="string">&#x27;__module__&#x27;</span>: <span class="string">&#x27;__main__&#x27;</span>, <span class="string">&#x27;displayCount&#x27;</span>: &lt;<span class="keyword">function</span> displayCount at 0x10a939c80&gt;, <span class="string">&#x27;empCount&#x27;</span>: 0, <span class="string">&#x27;displayEmployee&#x27;</span>: &lt;<span class="keyword">function</span> displayEmployee at 0x10a93caa0&gt;, <span class="string">&#x27;__doc__&#x27;</span>: <span class="string">&#x27;\xe6\x89\x80\xe6\x9c\x89\xe5\x91\x98\xe5\xb7\xa5\xe7\x9a\x84\xe5\x9f\xba\xe7\xb1\xbb&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>: &lt;<span class="keyword">function</span> __init__ at 0x10a939578&gt;&#125;</span><br></pre></td></tr></table></figure>
<h3 id="类的继承和多态">类的继承和多态</h3>
<p>面向对象最大的好处是代码的重用。</p>
<p>还是看代码更容易理解一些</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent</span>:</span>        <span class="comment"># 定义父类</span></span><br><span class="line">   parentAttr = <span class="number">100</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;调用父类构造函数&quot;</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">parentMethod</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&#x27;调用父类方法&#x27;</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">setAttr</span>(<span class="params">self, attr</span>):</span></span><br><span class="line">      Parent.parentAttr = attr</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">getAttr</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;父类属性 :&quot;</span>, Parent.parentAttr</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child</span>(<span class="params">Parent</span>):</span> <span class="comment"># 定义子类</span></span><br><span class="line">    <span class="comment"># class 派生类名（基类名）</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;调用子类构造方法&quot;</span></span><br><span class="line"><span class="comment"># 需要专门调用init方法</span></span><br><span class="line"><span class="comment"># 这个构造函数可以被重写，比如</span></span><br><span class="line"><span class="comment">#      def__init__(self,name,sex,mother,father):</span></span><br><span class="line"><span class="comment">#     self.name = name</span></span><br><span class="line"><span class="comment">#     self.sex = sex</span></span><br><span class="line"><span class="comment">#     self.mother = mother</span></span><br><span class="line"><span class="comment">#     self.father = father</span></span><br><span class="line"><span class="comment"># 如果父类的属性太多，也可以重写这个方法，和下面讲到的多态一样</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">childMethod</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&#x27;调用子类方法 child method&#x27;</span></span><br><span class="line"></span><br><span class="line">c = Child()          <span class="comment"># 实例化子类</span></span><br><span class="line">c.childMethod()      <span class="comment"># 调用子类的方法</span></span><br><span class="line">c.parentMethod()     <span class="comment"># 调用父类方法</span></span><br><span class="line">c.setAttr(<span class="number">200</span>)       <span class="comment"># 再次调用父类的方法</span></span><br><span class="line">c.getAttr()          <span class="comment"># 再次调用父类的方法</span></span><br></pre></td></tr></table></figure>
<p>父类只去定义一些最基本的属性和方法</p>
<p>多态是比如果说，我们在员工里增加这么一个方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span>:</span></span><br><span class="line">   <span class="string">&#x27;所有员工的基类&#x27;</span></span><br><span class="line">   empCount = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, salary</span>):</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.salary = salary</span><br><span class="line">      Employee.empCount += <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayCount</span>(<span class="params">self</span>):</span></span><br><span class="line">     <span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_title</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.sex == <span class="string">&quot;male&quot;</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;man&quot;</span>)</span><br><span class="line">        <span class="keyword">elif</span> self.sex == <span class="string">&quot;female&quot;</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;woman&quot;</span>)</span><br><span class="line">        </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayEmployee</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;Name : &quot;</span>, self.name,  <span class="string">&quot;, Salary: &quot;</span>, self.salary     </span><br></pre></td></tr></table></figure>
<p>现在我我们想雇佣童工了，就可以把新的子类写为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">child</span>(<span class="params">Employee</span>):</span></span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">print_title</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.sex == <span class="string">&quot;male&quot;</span>:</span><br><span class="line">             <span class="built_in">print</span>(<span class="string">&quot;boy&quot;</span>)</span><br><span class="line">         <span class="keyword">elif</span> self.sex == <span class="string">&quot;female&quot;</span>:</span><br><span class="line">             <span class="built_in">print</span>(<span class="string">&quot;girl&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>当子类和父类都存在相同的 print_title()方法时，子类的 print_title() 覆盖了父类的 print_title()，在代码运行时，会调用子类的 print_title()</p>
<p>多态的好处就是，当我们需要传入更多的子类，例如新增 Teenagers、Grownups 等时，我们只需要继承 Person 类型就可以了，而print_title()方法既可以直不重写（即使用Person的），也可以重写一个特有的。这就是多态的意思。调用方只管调用，不管细节，而当我们新增一种Person的子类时，只要确保新方法编写正确，而不用管原来的代码。这就是著名的“开闭”原则：</p>
<h3 id="iterator">iterator</h3>
<p>讲什么样的类才能循环，我感觉暂时用不到</p>
<h3 id="访问限制">访问限制</h3>
<p>如果我们不想让某个属性被外界访问到，可以增加访问限制，就像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JustCounter</span>:</span></span><br><span class="line"> __secretCount = <span class="number">0</span>  <span class="comment"># 私有变量</span></span><br><span class="line">    publicCount = <span class="number">0</span>    <span class="comment"># 公开变量</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">count</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.__secretCount += <span class="number">1</span></span><br><span class="line">       self.publicCount += <span class="number">1</span></span><br><span class="line">     <span class="built_in">print</span> self.__secretCount</span><br><span class="line"></span><br><span class="line">counter = JustCounter()</span><br><span class="line">counter.count()</span><br><span class="line">counter.count()</span><br><span class="line"><span class="built_in">print</span> counter.publicCount</span><br><span class="line"><span class="built_in">print</span> counter.__secretCount  <span class="comment"># 报错，实例不能访问私有变量</span></span><br></pre></td></tr></table></figure>
<h3 id="模块的调用">模块的调用</h3>
<p>Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。</p>
<p>意思就是，我们可以把类也放到模块里，跟函数一样去调用。</p>
<h1 id="mdn的实现">MDN的实现</h1>
<p>说了这么多，啥是MDN呢</p>
<p>打算结合<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hhcmRtYXJ1L3B5dG9yY2hfbm90ZWJvb2tz">这个<i class="fa fa-external-link-alt"></i></span>里面来讲。</p>
<p>重点来看他们是怎么实现MDN的，然后对比一下论文的源代码。最后再去讲原理。</p>
<p>在看这个之前，请先把<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvYmFzaWNzL3RlbnNvcnFzX3R1dG9yaWFsLmh0bWw=">这个<i class="fa fa-external-link-alt"></i></span>看完来补补课</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MDN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_hidden, n_gaussians</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MDN, self).__init__()</span><br><span class="line">        self.z_h = nn.Sequential(<span class="comment"># 这个是连续处理的意思，就是先做线性变换再做tanh变换</span></span><br><span class="line">            nn.Linear(<span class="number">1</span>, n_hidden),<span class="comment">#这里是做了Linear transformation</span></span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line">        self.z_pi = nn.Linear(n_hidden, n_gaussians)</span><br><span class="line">        self.z_sigma = nn.Linear(n_hidden, n_gaussians)</span><br><span class="line">        self.z_mu = nn.Linear(n_hidden, n_gaussians)  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        z_h = self.z_h(x)</span><br><span class="line">        pi = nn.functional.softmax(self.z_pi(z_h), -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># re scale to [0,1]</span></span><br><span class="line">        sigma = torch.exp(self.z_sigma(z_h))</span><br><span class="line">        <span class="comment">#做exp运算</span></span><br><span class="line">        mu = self.z_mu(z_h)</span><br><span class="line">        <span class="keyword">return</span> pi, sigma, mu</span><br></pre></td></tr></table></figure>
<p>让我们详细说一下这个MDN是怎么构造的</p>
<p>对于每一个输入的x，我们预测的是y的分布</p>
<p><span class="math inline">\(P(y|x) = \sum_{k}^{K} \Pi_{k}(x) \phi(y, \mu_{k}(x), \sigma_{k}(x))\)</span></p>
<ul>
<li><span class="math inline">\(k\)</span> is an index describing which Gaussian we are referencing. There are <span class="math inline">\(K\)</span> Gaussians total.</li>
<li><span class="math inline">\(\sum_{k}^{K}\)</span> is the summation operator. We sum every <span class="math inline">\(k\)</span> Gaussian across all <span class="math inline">\(K\)</span>. You might also see <span class="math inline">\(\sum_{k=0}^{K-1}\)</span> or <span class="math inline">\(\sum_{k=1}^{K}\)</span> depending on whether an author is using zero-based numbering or not.</li>
<li><span class="math inline">\(\Pi_k\)</span> acts as a weight, or multiplier, for mixing every <span class="math inline">\(k\)</span> Gaussian. It is a function of the input <span class="math inline">\(x\)</span>: <span class="math inline">\(\Pi_k(x)\)</span></li>
<li><span class="math inline">\(\phi\)</span> is the Gaussian function and returns the at <span class="math inline">\(y\)</span> for a given mean and standard deviation.</li>
<li><span class="math inline">\(\mu_k\)</span> and <span class="math inline">\(\sigma_k\)</span> are the parameters for the <span class="math inline">\(k\)</span> Gaussian: mean <span class="math inline">\(\mu_k\)</span> and standard deviation <span class="math inline">\(\sigma_k\)</span>. Instead of being fixed for each Gaussian, they are also functions of the input <span class="math inline">\(x\)</span>: <span class="math inline">\(\mu_k(x)\)</span> and <span class="math inline">\(\sigma_k(x)\)</span></li>
</ul>
<p>All of <span class="math inline">\(\sigma_{k}\)</span> are positive, and all of the weights <span class="math inline">\(\Pi\)</span> sum to one:</p>
<p><span class="math inline">\(\sum_{k}^{K} \Pi_{k} = 1\)</span></p>
<p>First our network must learn the functions <span class="math inline">\(\Pi_{k}(x), \mu_{k}(x), \sigma_{k}(x)\)</span> for every <span class="math inline">\(k\)</span> Gaussian. Then these functions can be used to generate individual parameters <span class="math inline">\(\mu_k, \sigma_k, \Pi_k\)</span> for a given input <span class="math inline">\(x\)</span>. These parameters will be used to generate our pdf <span class="math inline">\(P(y|x)\)</span>. Finally, to make a prediction, we will need to sample (pick a value) from this pdf.</p>
<p>In our implementation, we will use a neural network of one hidden layer with 20 nodes. This will feed into another layer that generates the parameters for 5 mixtures: with 3 parameters <span class="math inline">\(\Pi_k\)</span>, <span class="math inline">\(\mu_k\)</span>, <span class="math inline">\(\sigma_k\)</span> for each Gaussian <span class="math inline">\(k\)</span>.</p>
<p>Our definition will be split into three parts.</p>
<p>First we will compute 20 hidden values <span class="math inline">\(z_h\)</span> from our input <span class="math inline">\(x\)</span>.</p>
<p><span class="math inline">\(z_h(x) = \tanh( W_{in} x + b_{in})\)</span></p>
<p>Second, we will use these hidden values <span class="math inline">\(z_h\)</span> to compute our three sets of parameters <span class="math inline">\(\Pi, \sigma, \mu\)</span>:</p>
<p>$ z_= W_{} z_h + b_{}\ z_= W_{} z_h + b_{}\ z_= W_{} z_h + b_{} $</p>
<p>Third, we will use the output of these layers to determine the parameters of the Gaussians.</p>
<p>$ = \ = (z_{})\ = z_{} $</p>
<ul>
<li><span class="math inline">\(\exp(x)\)</span> is the exponential function also written as <span class="math inline">\(e^x\)</span></li>
</ul>
<p>We use a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Softmax_function"><em>softmax</em></a> operator to ensure that <span class="math inline">\(\Pi\)</span> sums to one across all <span class="math inline">\(k\)</span>, and the exponential function ensures that each weight <span class="math inline">\(\Pi_k\)</span> is positive. We also use the exponential function to ensure that every <span class="math inline">\(\sigma_k\)</span> is positive.</p>
<p>懂了，这个构造的方式其实是利用MDN预测了高斯混合网络的几个参数，再从整个PDF里面取值作为预测值。</p>
<p>然后再来看看论文的源代码.</p>
<p>写的好长...而且是用tensorflow写的..自己这不是得重写了...</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MDN</span>:</span></span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27; Mixture Density Network which handles multi-output, full (symmetric) covariance.</span></span><br><span class="line"><span class="string">  Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    n_mix : int, optional (default=5)</span></span><br><span class="line"><span class="string">     Number of mixtures used in the gaussian mixture model.</span></span><br><span class="line"><span class="string">    hidden : list, optional (default=[100, 100, 100, 100, 100])</span></span><br><span class="line"><span class="string">       Number of layers and hidden units per layer in the neural network.</span></span><br><span class="line"><span class="string">    lr : float, optional (default=1e-3)</span></span><br><span class="line"><span class="string">       Learning rate for the model.</span></span><br><span class="line"><span class="string">  l2 : float, optional (default=1e-3)</span></span><br><span class="line"><span class="string">       L2 regularization scale for the model weights.</span></span><br><span class="line"><span class="string">    n_iter : int, optional (default=1e4)</span></span><br><span class="line"><span class="string">      Number of iterations to train the model for </span></span><br><span class="line"><span class="string">  batch : int, optional (default=128)</span></span><br><span class="line"><span class="string">       Size of the minibatches for stochastic optimization.</span></span><br><span class="line"><span class="string">  imputations : int, optional (default=5)</span></span><br><span class="line"><span class="string">       Number of samples used in multiple imputation when handling NaN</span></span><br><span class="line"><span class="string">       target values during training. More samples results in a higher</span></span><br><span class="line"><span class="string">       accuracy for the likelihood estimate, but takes longer and may</span></span><br><span class="line"><span class="string">        result in overfitting. Assumption is that any missing data is </span></span><br><span class="line"><span class="string">        MAR / MCAR, in order to allow a multiple imputation approach.</span></span><br><span class="line"><span class="string"> epsilon : float, optional (default=1e-3)</span></span><br><span class="line"><span class="string">      Normalization constant added to diagonal of the covariance matrix.</span></span><br><span class="line"><span class="string">    activation : str, optional (default=relu)</span></span><br><span class="line"><span class="string">     Activation function applied to hidden layers.</span></span><br><span class="line"><span class="string"> scalerx : transformer, optional (default=IdentityTransformer)</span></span><br><span class="line"><span class="string">     Transformer which has fit, transform, and inverse_transform methods</span></span><br><span class="line"><span class="string">       (i.e. follows the format of sklearn transformers). Scales the x </span></span><br><span class="line"><span class="string">      values prior to training / prediction. Stored along with the saved</span></span><br><span class="line"><span class="string">        model in order to have consistent inputs to the model.</span></span><br><span class="line"><span class="string">    scalery : transformer, optional (default=IdentityTransformer)</span></span><br><span class="line"><span class="string">     Transformer which has fit, transform, and inverse_transform methods</span></span><br><span class="line"><span class="string">       (i.e. follows the format of sklearn transformers). Scales the y </span></span><br><span class="line"><span class="string">      values prior to training, and the output values after prediction. </span></span><br><span class="line"><span class="string">        Stored along with the saved model in order to have consistent </span></span><br><span class="line"><span class="string">        outputs from the model.</span></span><br><span class="line"><span class="string">   model_path : pathlib.Path, optional (default=./Weights)</span></span><br><span class="line"><span class="string">       Folder location to store saved models.</span></span><br><span class="line"><span class="string">    model_name : str, optional (default=MDN)</span></span><br><span class="line"><span class="string">      Name to assign to the model. </span></span><br><span class="line"><span class="string"> no_load : bool, optional (default=False)</span></span><br><span class="line"><span class="string">      If true, train a new model rather than loading a previously </span></span><br><span class="line"><span class="string">      trained one.</span></span><br><span class="line"><span class="string">  no_save : bool, optional (default=False)</span></span><br><span class="line"><span class="string">      If true, do not save the model when training is completed.</span></span><br><span class="line"><span class="string">    seed : int, optional (default=None)</span></span><br><span class="line"><span class="string">       Random seed. If set, ensure consistent output.</span></span><br><span class="line"><span class="string">    verbose : bool, optional (default=False)</span></span><br><span class="line"><span class="string">      If true, print various information while loading / training.</span></span><br><span class="line"><span class="string">  debug : bool, optional (default=False)</span></span><br><span class="line"><span class="string">        If true, use control flow dependencies to determine where NaN</span></span><br><span class="line"><span class="string">     values are entering the model. Model runs slower with this </span></span><br><span class="line"><span class="string">       parameter set to true.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"> distribution = <span class="string">&#x27;MultivariateNormalTriL&#x27;</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_mix=<span class="number">5</span>, hidden=[<span class="number">100</span>]*<span class="number">5</span>, lr=<span class="number">1e-3</span>, l2=<span class="number">1e-3</span>, n_iter=<span class="number">1e4</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                batch=<span class="number">128</span>, imputations=<span class="number">5</span>, epsilon=<span class="number">1e-3</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 activation=<span class="string">&#x27;relu&#x27;</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                scalerx=<span class="literal">None</span>, scalery=<span class="literal">None</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">              model_path=<span class="string">&#x27;Weights&#x27;</span>, model_name=<span class="string">&#x27;MDN&#x27;</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 no_load=<span class="literal">False</span>, no_save=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 seed=<span class="literal">None</span>, verbose=<span class="literal">False</span>, debug=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">     config = initialize_random_states(seed)</span><br><span class="line">       config.update(&#123;</span><br><span class="line">          <span class="string">&#x27;n_mix&#x27;</span>        : n_mix,</span><br><span class="line">         <span class="string">&#x27;hidden&#x27;</span>       : <span class="built_in">list</span>(np.atleast_1d(hidden)),</span><br><span class="line">         <span class="string">&#x27;lr&#x27;</span>           : lr,</span><br><span class="line">            <span class="string">&#x27;l2&#x27;</span>           : l2,</span><br><span class="line">            <span class="string">&#x27;n_iter&#x27;</span>       : n_iter,</span><br><span class="line">            <span class="string">&#x27;batch&#x27;</span>        : batch,</span><br><span class="line">         <span class="string">&#x27;imputations&#x27;</span>  : imputations,</span><br><span class="line">           <span class="string">&#x27;epsilon&#x27;</span>      : epsilon,</span><br><span class="line">           <span class="string">&#x27;activation&#x27;</span>   : activation,</span><br><span class="line">            <span class="string">&#x27;scalerx&#x27;</span>      : scalerx <span class="keyword">if</span> scalerx <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> IdentityTransformer(),</span><br><span class="line">            <span class="string">&#x27;scalery&#x27;</span>      : scalery <span class="keyword">if</span> scalery <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> IdentityTransformer(),</span><br><span class="line">            <span class="string">&#x27;model_path&#x27;</span>   : Path(model_path),</span><br><span class="line">          <span class="string">&#x27;model_name&#x27;</span>   : model_name,</span><br><span class="line">            <span class="string">&#x27;no_load&#x27;</span>      : no_load,</span><br><span class="line">           <span class="string">&#x27;no_save&#x27;</span>      : no_save,</span><br><span class="line">           <span class="string">&#x27;seed&#x27;</span>         : seed,</span><br><span class="line">          <span class="string">&#x27;verbose&#x27;</span>      : verbose,</span><br><span class="line">           <span class="string">&#x27;debug&#x27;</span>        : debug,</span><br><span class="line">     &#125;)</span><br><span class="line">       self.set_config(config)</span><br><span class="line"><span class="comment">#前面 构造函数 定义变量</span></span><br><span class="line">       <span class="keyword">for</span> k <span class="keyword">in</span> kwargs: </span><br><span class="line">           warnings.warn(<span class="string">f&#x27;Unused keyword given to MDN: &quot;<span class="subst">&#123;k&#125;</span>&quot;&#x27;</span>, UserWarning)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_predict_chunk</span>(<span class="params">self, X, return_coefs=<span class="literal">False</span>, use_gpu=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line">     <span class="string">&#x27;&#x27;&#x27; Generates estimates for the given set. X may be only a subset of the full</span></span><br><span class="line"><span class="string">         data, which speeds up the prediction process and limits memory consumption.</span></span><br><span class="line"><span class="string">       </span></span><br><span class="line"><span class="string">          use_gpu : bool, optional (default=False)</span></span><br><span class="line"><span class="string">              Use the GPU to generate estimates if True, otherwise use the CPU.</span></span><br><span class="line"><span class="string">          &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:0&#x27;</span> <span class="keyword">if</span> use_gpu <span class="keyword">else</span> <span class="string">&#x27;/cpu:0&#x27;</span>):</span><br><span class="line"><span class="comment">#确定位置</span></span><br><span class="line">         model_out = self.model( self.scalerx.transform(ensure_format(X)) )</span><br><span class="line">    <span class="comment">#先处理成一样的类型</span></span><br><span class="line">           coefs_out = self.get_coefs(model_out)<span class="comment">#解析模型输出</span></span><br><span class="line">         outputs   = self.extract_predictions(coefs_out, **kwargs)</span><br><span class="line"> <span class="comment"># 这个是得到最后的输出，</span></span><br><span class="line">            <span class="keyword">if</span> return_coefs: </span><br><span class="line">                <span class="keyword">return</span> outputs, [c.numpy() <span class="keyword">for</span> c <span class="keyword">in</span> coefs_out]</span><br><span class="line">         <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @ignore_warnings</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X, chunk_size=<span class="number">1e5</span>, return_coefs=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="comment">#这个是预测的主函数</span></span><br><span class="line">       <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">       Top level interface to get predictions for a given dataset, which wraps _predict_chunk </span></span><br><span class="line"><span class="string">       to generate estimates in smaller chunks. See the docstring of extract_predictions() for </span></span><br><span class="line"><span class="string">      a description of other keyword parameters that can be given. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">      chunk_size : int, optional (default=1e5)</span></span><br><span class="line"><span class="string">          Controls the size of chunks which are estimated by the model. If None is passed,</span></span><br><span class="line"><span class="string">          chunking is not used and the model is given all of the X dataset at once. </span></span><br><span class="line"><span class="string">        return_coefs : bool, optional (default=False)</span></span><br><span class="line"><span class="string">         If True, return the estimated coefficients (prior, mu, sigma) along with the </span></span><br><span class="line"><span class="string">         other requested outputs. Note that rescaling the coefficients using scalerx/y</span></span><br><span class="line"><span class="string">         is left up to the user, as calculations involving sigma must be performed in </span></span><br><span class="line"><span class="string">         the basis learned by the model.</span></span><br><span class="line"><span class="string">       &#x27;&#x27;&#x27;</span></span><br><span class="line">     chunk_size    = <span class="built_in">int</span>(chunk_size <span class="keyword">or</span> <span class="built_in">len</span>(X))</span><br><span class="line">        partial_coefs = []</span><br><span class="line">        partial_estim = []</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> trange(<span class="number">0</span>, <span class="built_in">len</span>(X), chunk_size, disable=<span class="keyword">not</span> self.verbose):</span><br><span class="line">            chunk_est, chunk_coef = self._predict_chunk(X[i:i+chunk_size], return_coefs=<span class="literal">True</span>, **kwargs)</span><br><span class="line">            <span class="comment"># 把总的数据分成好几块来进行预测</span></span><br><span class="line">            <span class="comment">#每个小块都是在predict_chunk里预测的</span></span><br><span class="line">          partial_coefs.append(chunk_coef)</span><br><span class="line">          partial_estim.append( np.array(chunk_est, ndmin=<span class="number">3</span>) )</span><br><span class="line"></span><br><span class="line">        coefs = [np.vstack(c) <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">zip</span>(*partial_coefs)]</span><br><span class="line">       preds = np.hstack(partial_estim)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> return_coefs:</span><br><span class="line">         <span class="keyword">return</span> preds, coefs </span><br><span class="line">     <span class="keyword">return</span> preds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">extract_predictions</span>(<span class="params">self, coefs, confidence_interval=<span class="literal">None</span>, threshold=<span class="literal">None</span>, avg_est=<span class="literal">False</span></span>):</span></span><br><span class="line">       <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">       Function used to extract model predictions from the given set of </span></span><br><span class="line"><span class="string">     coefficients. Users should call the predict() method instead, if</span></span><br><span class="line"><span class="string">      predictions from input data are needed. </span></span><br><span class="line"><span class="string">      confidence_interval : float, optional (default=None)</span></span><br><span class="line"><span class="string">          If a confidence interval value is given, then this function</span></span><br><span class="line"><span class="string">           returns (along with the predictions) the upper and lower </span></span><br><span class="line"><span class="string">         &#123;confidence_interval*100&#125;% confidence bounds around the prediction.</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">      threshold : float, optional (default=None)</span></span><br><span class="line"><span class="string">            If set, the model outputs the maximum prior estimate when the prior</span></span><br><span class="line"><span class="string">           probability is above this threshold; and outputs the average estimate</span></span><br><span class="line"><span class="string">         when below the threshold. Any passed value should be in the range (0, 1],</span></span><br><span class="line"><span class="string">         though the sign of the threshold can be negative in order to switch the</span></span><br><span class="line"><span class="string">           estimates (i.e. negative threshold would output average estimate when prior</span></span><br><span class="line"><span class="string">           is greater than the (absolute) value).  </span></span><br><span class="line"><span class="string">      avg_est : bool, optional (default=False)</span></span><br><span class="line"><span class="string">          If true, model outputs the prior probability weighted mean as the</span></span><br><span class="line"><span class="string">         estimate. Otherwise, model outputs the maximum prior estimate.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">     <span class="keyword">assert</span>(confidence_interval <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> (<span class="number">0</span> &lt; confidence_interval &lt; <span class="number">1</span>)), <span class="string">&#x27;confidence_interval must be in the range (0,1)&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span>(threshold <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> (<span class="number">0</span> &lt; threshold &lt;= <span class="number">1</span>)), <span class="string">&#x27;threshold must be in the range (0,1]&#x27;</span></span><br><span class="line"><span class="comment">#检查是不是在0-1</span></span><br><span class="line">        target = (<span class="string">&#x27;avg&#x27;</span> <span class="keyword">if</span> avg_est <span class="keyword">else</span> <span class="string">&#x27;top&#x27;</span>) <span class="keyword">if</span> threshold <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&#x27;threshold&#x27;</span><span class="comment"># 选一个方式来处理模型的输出，比如avg</span></span><br><span class="line">        output = <span class="built_in">getattr</span>(self, <span class="string">f&#x27;_get_<span class="subst">&#123;target&#125;</span>_estimate&#x27;</span>)(coefs)</span><br><span class="line">        <span class="comment">#然后处理输出</span></span><br><span class="line">       scale  = <span class="keyword">lambda</span> x: self.scalery.inverse_transform(x.numpy())</span><br><span class="line">     </span><br><span class="line">      <span class="keyword">if</span> confidence_interval <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">           <span class="keyword">assert</span>(threshold <span class="keyword">is</span> <span class="literal">None</span>), <span class="string">f&#x27;Cannot calculate confidence on thresholded estimates&#x27;</span></span><br><span class="line">           confidence = <span class="built_in">getattr</span>(self, <span class="string">f&#x27;_get_<span class="subst">&#123;target&#125;</span>_confidence&#x27;</span>)(coefs, confidence_interval)</span><br><span class="line">          upper_bar  = output + confidence</span><br><span class="line">          lower_bar  = output - confidence</span><br><span class="line">          <span class="keyword">return</span> scale(output), scale(upper_bar), scale(lower_bar)</span><br><span class="line">        <span class="comment">#k</span></span><br><span class="line">        <span class="keyword">return</span> scale(output)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @ignore_warnings</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, Y, output_slices=<span class="literal">None</span>, **kwargs</span>):</span></span><br><span class="line">     <span class="keyword">with</span> get_device(self.config):<span class="comment">#数据放在CPU还是GPU </span></span><br><span class="line">         checkpoint = self.model_path.joinpath(<span class="string">&#x27;checkpoint&#x27;</span>)</span><br><span class="line"><span class="comment">#加载模型文件</span></span><br><span class="line">           <span class="keyword">if</span> checkpoint.exists() <span class="keyword">and</span> <span class="keyword">not</span> self.no_load:</span><br><span class="line">               <span class="keyword">if</span> self.verbose: <span class="built_in">print</span>(<span class="string">f&#x27;Restoring model weights from <span class="subst">&#123;checkpoint&#125;</span>&#x27;</span>)</span><br><span class="line">                self.load()</span><br><span class="line"><span class="comment">#如果模型存在的话，就加载，不存在的话就不加载</span></span><br><span class="line">         <span class="keyword">elif</span> self.no_load <span class="keyword">and</span> X <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">              <span class="keyword">raise</span> Exception(<span class="string">&#x27;Model exists, but no_load is set and no training data was given.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">elif</span> X <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> Y <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:   </span><br><span class="line">              self.scalerx.fit( ensure_format(X), ensure_format(Y) )</span><br><span class="line">                self.scalery.fit( ensure_format(Y) )</span><br><span class="line"><span class="comment"># 对数据做一下预处理，看是不是符合要求，转换函数在前面有定义，在product_estimation里面自定义的</span></span><br><span class="line">              <span class="comment"># Gather all data (train, validation, test, ...) into singular object</span></span><br><span class="line">                datasets = kwargs[<span class="string">&#x27;datasets&#x27;</span>] = kwargs.get(<span class="string">&#x27;datasets&#x27;</span>, &#123;&#125;)</span><br><span class="line">              datasets.update(&#123;<span class="string">&#x27;train&#x27;</span>: &#123;<span class="string">&#x27;x&#x27;</span> : X, <span class="string">&#x27;y&#x27;</span>: Y&#125;&#125;)</span><br><span class="line"><span class="comment"># 分训练集和测试机</span></span><br><span class="line">              <span class="keyword">for</span> key, data <span class="keyword">in</span> datasets.items(): </span><br><span class="line">                 <span class="keyword">if</span> data[<span class="string">&#x27;x&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                       datasets[key].update(&#123;</span><br><span class="line">                           <span class="string">&#x27;x_t&#x27;</span> : self.scalerx.transform( ensure_format(data[<span class="string">&#x27;x&#x27;</span>]) ),</span><br><span class="line">                           <span class="string">&#x27;y_t&#x27;</span> : self.scalery.transform( ensure_format(data[<span class="string">&#x27;y&#x27;</span>]) ),</span><br><span class="line">                       &#125;)</span><br><span class="line"><span class="comment">#再次转换</span></span><br><span class="line"><span class="keyword">assert</span>(np.isfinite(datasets[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;x_t&#x27;</span>]).<span class="built_in">all</span>()), <span class="string">&#x27;NaN values found in X training data&#x27;</span></span><br><span class="line"><span class="comment">#数据检查</span></span><br><span class="line">              self.update_config(&#123;</span><br><span class="line">                 <span class="string">&#x27;output_slices&#x27;</span> : output_slices <span class="keyword">or</span> &#123;<span class="string">&#x27;&#x27;</span>: <span class="built_in">slice</span>(<span class="literal">None</span>)&#125;,</span><br><span class="line">                   <span class="string">&#x27;n_inputs&#x27;</span>      : datasets[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;x_t&#x27;</span>].shape[<span class="number">1</span>],</span><br><span class="line">                    <span class="string">&#x27;n_targets&#x27;</span>     : datasets[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;y_t&#x27;</span>].shape[<span class="number">1</span>],</span><br><span class="line">                &#125;)</span><br><span class="line">               self.build()</span><br><span class="line"></span><br><span class="line">                callbacks = []</span><br><span class="line">                model_kws = &#123;</span><br><span class="line">                    <span class="string">&#x27;batch_size&#x27;</span> : self.batch, </span><br><span class="line">                 <span class="string">&#x27;epochs&#x27;</span>     : <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">int</span>(self.n_iter / <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">len</span>(X) / self.batch))),</span><br><span class="line">                  <span class="string">&#x27;verbose&#x27;</span>    : <span class="number">0</span>, </span><br><span class="line">                  <span class="string">&#x27;callbacks&#x27;</span>  : callbacks,</span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">              <span class="keyword">if</span> self.verbose:</span><br><span class="line">                 callbacks.append( TqdmCallback(model_kws[<span class="string">&#x27;epochs&#x27;</span>], data_size=<span class="built_in">len</span>(X), batch_size=self.batch) )</span><br><span class="line"></span><br><span class="line">              <span class="keyword">if</span> self.debug:</span><br><span class="line">                   callbacks.append( tf.keras.callbacks.TensorBoard(histogram_freq=<span class="number">1</span>, profile_batch=(<span class="number">2</span>,<span class="number">60</span>)) )</span><br><span class="line"></span><br><span class="line">              <span class="keyword">if</span> <span class="string">&#x27;args&#x27;</span> <span class="keyword">in</span> kwargs:</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">getattr</span>(kwargs[<span class="string">&#x27;args&#x27;</span>], <span class="string">&#x27;plot_loss&#x27;</span>, <span class="literal">False</span>):</span><br><span class="line">                       callbacks.append( PlottingCallback(kwargs[<span class="string">&#x27;args&#x27;</span>], datasets, self) )</span><br><span class="line"></span><br><span class="line">                  <span class="keyword">if</span> <span class="built_in">getattr</span>(kwargs[<span class="string">&#x27;args&#x27;</span>], <span class="string">&#x27;save_stats&#x27;</span>, <span class="literal">False</span>):</span><br><span class="line">                      callbacks.append( StatsCallback(kwargs[<span class="string">&#x27;args&#x27;</span>], datasets, self) )</span><br><span class="line"></span><br><span class="line">                 <span class="keyword">if</span> <span class="built_in">getattr</span>(kwargs[<span class="string">&#x27;args&#x27;</span>], <span class="string">&#x27;best_epoch&#x27;</span>, <span class="literal">False</span>):</span><br><span class="line">                      <span class="keyword">if</span> <span class="string">&#x27;valid&#x27;</span> <span class="keyword">in</span> datasets <span class="keyword">and</span> <span class="string">&#x27;x_t&#x27;</span> <span class="keyword">in</span> datasets[<span class="string">&#x27;valid&#x27;</span>]:</span><br><span class="line">                          model_kws[<span class="string">&#x27;validation_data&#x27;</span>] = (datasets[<span class="string">&#x27;valid&#x27;</span>][<span class="string">&#x27;x_t&#x27;</span>], datasets[<span class="string">&#x27;valid&#x27;</span>][<span class="string">&#x27;y_t&#x27;</span>])</span><br><span class="line">                         callbacks.append( ModelCheckpoint(self.model_path) )</span><br><span class="line"></span><br><span class="line">                self.model.fit(datasets[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;x_t&#x27;</span>], datasets[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;y_t&#x27;</span>], **model_kws)</span><br><span class="line"></span><br><span class="line">             <span class="keyword">if</span> <span class="keyword">not</span> self.no_save:</span><br><span class="line">                    self.save()</span><br><span class="line"></span><br><span class="line">         <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">f&quot;No trained model exists at: \n<span class="subst">&#123;self.model_path&#125;</span>&quot;</span>)</span><br><span class="line">           <span class="keyword">return</span> self </span><br><span class="line"></span><br><span class="line"><span class="comment"># 网络构建的部分在这里</span></span><br><span class="line"><span class="comment">#全连接 输入层 隐藏层 激活函数 输出层</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self</span>):</span></span><br><span class="line">        layer_kwargs = &#123;</span><br><span class="line">         <span class="string">&#x27;activation&#x27;</span>         : self.activation,<span class="comment">#激活函数</span></span><br><span class="line">           <span class="string">&#x27;kernel_regularizer&#x27;</span> : tf.keras.regularizers.l2(self.l2),<span class="comment">#一个正则项</span></span><br><span class="line">            <span class="string">&#x27;bias_regularizer&#x27;</span>   : tf.keras.regularizers.l2(self.l2),<span class="comment">#另一个正则项</span></span><br><span class="line">           <span class="comment"># &#x27;kernel_initializer&#x27; : tf.keras.initializers.LecunNormal(),</span></span><br><span class="line">          <span class="comment"># &#x27;bias_initializer&#x27;   : tf.keras.initializers.LecunNormal(),</span></span><br><span class="line">      &#125;</span><br><span class="line">        mixture_kwargs = &#123;</span><br><span class="line">           <span class="string">&#x27;n_mix&#x27;</span>     : self.n_mix,<span class="comment">#整个模型输出几个高斯参数</span></span><br><span class="line">         <span class="string">&#x27;n_targets&#x27;</span> : self.n_targets,<span class="comment">#在前面都定义过</span></span><br><span class="line">          <span class="string">&#x27;epsilon&#x27;</span>   : self.epsilon,</span><br><span class="line">     &#125;</span><br><span class="line">        mixture_kwargs.update(layer_kwargs)</span><br><span class="line">       <span class="comment">#字典添加到上面</span></span><br><span class="line">     create_layer = <span class="keyword">lambda</span> inp, out: tf.keras.layers.Dense(out, input_shape=(inp,), **layer_kwargs)<span class="comment"># 第一层的全连接的方式，</span></span><br><span class="line">     model_layers = [create_layer(inp, out) <span class="keyword">for</span> inp, out <span class="keyword">in</span> <span class="built_in">zip</span>([self.n_inputs] + self.hidden[:-<span class="number">1</span>], self.hidden)]<span class="comment">#把第一层全连接组合起来，</span></span><br><span class="line">        output_layer = MixtureLayer(**mixture_kwargs)<span class="comment">#搭建混合密度网络</span></span><br><span class="line">       <span class="comment">#做初始化</span></span><br><span class="line">        <span class="comment"># Define yscaler.inverse_transform as a tensorflow function, and estimate extraction from outputs</span></span><br><span class="line">        <span class="comment"># yscaler_a   = self.scalery.scalers[-1].min_</span></span><br><span class="line">        <span class="comment"># yscaler_b   = self.scalery.scalers[-1].scale_</span></span><br><span class="line">      <span class="comment"># inv_scaler  = lambda y: tf.math.exp((tf.reshape(y, shape=[-1]) - yscaler_a) / yscaler_b) </span></span><br><span class="line">      <span class="comment"># extract_est = lambda z: self._get_top_estimate( self._parse_outputs(z) )</span></span><br><span class="line">       </span><br><span class="line">      optimizer  = tf.keras.optimizers.Adam(self.lr)<span class="comment">#优化器</span></span><br><span class="line">       self.model = tf.keras.Sequential(model_layers + [output_layer], name=self.model_name)<span class="comment">#网络组合起来</span></span><br><span class="line">     self.model.<span class="built_in">compile</span>(loss=self.loss, optimizer=optimizer, metrics=[])<span class="comment">#[MSA(extract_est, inv_scaler)])#和前面的模型叠加进行训练</span></span><br><span class="line">       </span><br><span class="line"></span><br><span class="line"><span class="meta"> @tf.function</span></span><br><span class="line">    </span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, y, output</span>):</span></span><br><span class="line">      prior, mu, scale = self._parse_outputs(output) </span><br><span class="line">        <span class="comment">#对输出做解析</span></span><br><span class="line">     dist  = <span class="built_in">getattr</span>(tfp.distributions, self.distribution)(mu, scale)</span><br><span class="line">        <span class="comment">#选出来正态分布</span></span><br><span class="line">     prob  = tfp.distributions.Categorical(probs=prior)</span><br><span class="line">        <span class="comment">#类别分布</span></span><br><span class="line">        mix   = tfp.distributions.MixtureSameFamily(prob, dist)</span><br><span class="line">       <span class="comment">#把五个分布结合起来变成一个新的分布</span></span><br><span class="line">       <span class="function"><span class="keyword">def</span> <span class="title">impute</span>(<span class="params">mix, y, N</span>):</span></span><br><span class="line">          <span class="comment"># summation  = tf.zeros(tf.shape(y)[0])</span></span><br><span class="line">          <span class="comment"># imputation = lambda i, s: [i+1, tf.add(s, mix.log_prob(tf.where(tf.math.is_nan(y), mix.sample(), y)))]</span></span><br><span class="line">         <span class="comment"># return tf.while_loop(lambda i, x: i &lt; N, imputation, (0, summation), maximum_iterations=N, parallel_iterations=N)[1] / N</span></span><br><span class="line">            <span class="keyword">return</span> tf.reduce_mean([</span><br><span class="line">              mix.log_prob( tf.where(tf.math.is_nan(y), mix.sample(), y) )</span><br><span class="line">                <span class="comment">#把y从一个数转换为一个分布</span></span><br><span class="line">         <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(N)], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Much slower due to cond executing both branches regardless of the conditional</span></span><br><span class="line">      <span class="comment"># likelihood = tf.cond(tf.reduce_any(tf.math.is_nan(y)), lambda: impute(mix, y, self.imputations), lambda: mix.log_prob(y))</span></span><br><span class="line">      likelihood = mix.log_prob(y)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> tf.reduce_mean(-likelihood) + tf.add_n([<span class="number">0.</span>] + self.model.losses)<span class="comment">#计算这两个分布的相似性</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">     <span class="keyword">return</span> self.model(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="keyword">return</span> self.config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">set_config</span>(<span class="params">self, config, *args, **kwargs</span>):</span></span><br><span class="line">      self.config = &#123;&#125; </span><br><span class="line">       self.update_config(config, *args, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">update_config</span>(<span class="params">self, config, keys=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> keys <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          config = &#123;k:v <span class="keyword">for</span> k,v <span class="keyword">in</span> config.items() <span class="keyword">if</span> k <span class="keyword">in</span> keys <span class="keyword">or</span> k <span class="keyword">not</span> <span class="keyword">in</span> self.config&#125;</span><br><span class="line">        </span><br><span class="line">      self.config.update(config)</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> config.items():</span><br><span class="line">         <span class="built_in">setattr</span>(self, k, v)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">save</span>(<span class="params">self</span>):</span></span><br><span class="line">     self.model_path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">      store_pkl(self.model_path.joinpath(<span class="string">&#x27;config.pkl&#x27;</span>), self.get_config())</span><br><span class="line">        self.model.save_weights(self.model_path.joinpath(<span class="string">&#x27;checkpoint&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">self</span>):</span></span><br><span class="line">     self.update_config(read_pkl(self.model_path.joinpath(<span class="string">&#x27;config.pkl&#x27;</span>)), [<span class="string">&#x27;scalerx&#x27;</span>, <span class="string">&#x27;scalery&#x27;</span>, <span class="string">&#x27;tf_random&#x27;</span>, <span class="string">&#x27;np_random&#x27;</span>])</span><br><span class="line">      tf.random.set_global_generator(self.tf_random)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;model&#x27;</span>): self.build()</span><br><span class="line">     self.model.load_weights(self.model_path.joinpath(<span class="string">&#x27;checkpoint&#x27;</span>)).expect_partial()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_coefs</span>(<span class="params">self, output</span>):</span></span><br><span class="line">        prior, mu, scale = self._parse_outputs(output)</span><br><span class="line">        <span class="keyword">return</span> prior, mu, self._covariance(scale)</span><br><span class="line">        <span class="comment">#scale做了协方差</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_parse_outputs</span>(<span class="params">self, output</span>):</span></span><br><span class="line">       prior, mu, scale = tf.split(output, [self.n_mix, self.n_mix * self.n_targets, -<span class="number">1</span>], axis=<span class="number">1</span>)</span><br><span class="line">        prior = tf.reshape(prior, shape=[-<span class="number">1</span>, self.n_mix])</span><br><span class="line">     mu    = tf.reshape(mu,    shape=[-<span class="number">1</span>, self.n_mix, self.n_targets])</span><br><span class="line">     scale = tf.reshape(scale, shape=[-<span class="number">1</span>, self.n_mix, self.n_targets, self.n_targets])</span><br><span class="line">     <span class="keyword">return</span> prior, mu, scale</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_covariance</span>(<span class="params">self, scale</span>):</span></span><br><span class="line">       <span class="keyword">return</span> tf.einsum(<span class="string">&#x27;abij,abjk-&gt;abik&#x27;</span>, tf.transpose(scale, perm=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>]), scale)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">   Estimate Generation</span></span><br><span class="line"><span class="string">   &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#不同的估计方式</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_calculate_top</span>(<span class="params">self, prior, values</span>):</span></span><br><span class="line">        vals, idxs  = tf.nn.top_k(prior, k=<span class="number">1</span>)</span><br><span class="line">     idxs = tf.stack([tf.<span class="built_in">range</span>(tf.shape(idxs)[<span class="number">0</span>]), tf.reshape(idxs, [-<span class="number">1</span>])], axis=-<span class="number">1</span>)</span><br><span class="line">     <span class="keyword">return</span> tf.gather_nd(values, idxs)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_get_top_estimate</span>(<span class="params">self, coefs, **kwargs</span>):</span></span><br><span class="line">       prior, mu, _ = coefs</span><br><span class="line">      <span class="keyword">return</span> self._calculate_top(prior, mu)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_get_avg_estimate</span>(<span class="params">self, coefs, **kwargs</span>):</span></span><br><span class="line">       prior, mu, _ = coefs</span><br><span class="line">      <span class="keyword">return</span> tf.reduce_sum(mu * tf.expand_dims(prior, -<span class="number">1</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_threshold_estimate</span>(<span class="params">self, coefs, threshold=<span class="number">0.5</span></span>):</span></span><br><span class="line">        top_estimate = self.get_top_estimate(coefs)</span><br><span class="line">       avg_estimate = self.get_avg_estimate(coefs)</span><br><span class="line">       prior, _, _  = coefs</span><br><span class="line">      <span class="keyword">return</span> tf.compat.v2.where(tf.expand_dims(tf.math.greater(tf.reduce_max(prior, <span class="number">1</span>) / threshold, tf.math.sign(threshold)), -<span class="number">1</span>), top_estimate, avg_estimate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">   Confidence Estimation</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">_calculate_confidence</span>(<span class="params">self, sigma, level=<span class="number">0.9</span></span>):</span></span><br><span class="line">      <span class="comment"># For a given confidence level probability p (0&lt;p&lt;1), and number of dimensions d, rho is the error bar coefficient: rho=sqrt(2)*erfinv(p ** (1/d))</span></span><br><span class="line">     <span class="comment"># https://faculty.ucmerced.edu/mcarreira-perpinan/papers/cs-99-03.pdf</span></span><br><span class="line">        s, u, v = tf.linalg.svd(sigma)</span><br><span class="line">        rho = <span class="number">2</span>**<span class="number">0.5</span> * tf.math.erfinv(level ** (<span class="number">1.</span>/self.n_targets)) </span><br><span class="line">      <span class="keyword">return</span> tf.cast(rho, tf.float32) * <span class="number">2</span> * s ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">_get_top_confidence</span>(<span class="params">self, coefs, level=<span class="number">0.9</span></span>):</span></span><br><span class="line">        prior, mu, sigma = coefs</span><br><span class="line">      top_sigma = self._calculate_top(prior, sigma)</span><br><span class="line">     <span class="keyword">return</span> self._calculate_confidence(top_sigma, level)        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_avg_confidence</span>(<span class="params">self, coefs, level=<span class="number">0.9</span></span>):</span></span><br><span class="line">        prior, mu, sigma = coefs</span><br><span class="line">      avg_estim = self.get_avg_estimate(coefs)</span><br><span class="line">      avg_sigma = tf.reduce_sum(tf.expand_dims(tf.expand_dims(prior, -<span class="number">1</span>), -<span class="number">1</span>) * </span><br><span class="line">                        (sigma + tf.matmul(tf.transpose(mu - tf.expand_dims(avg_estim, <span class="number">1</span>), (<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)), </span><br><span class="line">                                                     mu - tf.expand_dims(avg_estim, <span class="number">1</span>))), axis=<span class="number">1</span>)</span><br><span class="line">      <span class="keyword">return</span> self._calculate_confidence(avg_sigma, level)        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MixtureLayer</span>(<span class="params">tf.keras.layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_mix, n_targets, epsilon, **layer_kwargs</span>):</span></span><br><span class="line">      <span class="built_in">super</span>(MixtureLayer, self).__init__()</span><br><span class="line">        layer_kwargs.pop(<span class="string">&#x27;activation&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">     self.n_mix     = n_mix </span><br><span class="line">       self.n_targets = n_targets </span><br><span class="line">       self.epsilon   = tf.constant(epsilon)</span><br><span class="line">     self._layer    = tf.keras.layers.Dense(self.n_outputs, **layer_kwargs)</span><br><span class="line">        <span class="comment">#前面的参数直接传过来</span></span><br><span class="line"><span class="meta">   @property </span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">layer_sizes</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="string">&#x27;&#x27;&#x27; Sizes of the prior, mu, and (lower triangle) scale matrix outputs &#x27;&#x27;&#x27;</span></span><br><span class="line">       sizes = [<span class="number">1</span>, self.n_targets, (self.n_targets * (self.n_targets + <span class="number">1</span>)) // <span class="number">2</span>]</span><br><span class="line">     <span class="keyword">return</span> self.n_mix * np.array(sizes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">   @property </span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">n_outputs</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Total output size of the layer object &#x27;&#x27;&#x27;</span></span><br><span class="line">       <span class="keyword">return</span> <span class="built_in">sum</span>(self.layer_sizes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="comment"># @tf.function(experimental_compile=True)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        <span class="comment">#这里是前向传播</span></span><br><span class="line">        <span class="comment">#整个输入分为三个部分</span></span><br><span class="line">        prior, mu, scale = tf.split(self._layer(inputs), self.layer_sizes, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      prior = tf.nn.softmax(prior, axis=-<span class="number">1</span>) + tf.constant(<span class="number">1e-9</span>)</span><br><span class="line">        <span class="comment">#softmax激活，为了不为0加了个常数</span></span><br><span class="line">     mu    = tf.stack(tf.split(mu, self.n_mix, <span class="number">1</span>), <span class="number">1</span>) </span><br><span class="line">     scale = tf.stack(tf.split(scale, self.n_mix, <span class="number">1</span>), <span class="number">1</span>) </span><br><span class="line">      scale = tfp.math.fill_triangular(scale, upper=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 变成一个上三角矩阵</span></span><br><span class="line">       norm  = tf.linalg.diag(tf.ones((<span class="number">1</span>, <span class="number">1</span>, self.n_targets)))</span><br><span class="line">        <span class="comment"># 取出来对角线的值</span></span><br><span class="line">      sigma = tf.einsum(<span class="string">&#x27;abij,abjk-&gt;abik&#x27;</span>, tf.transpose(scale, perm=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>]), scale)</span><br><span class="line">        <span class="comment">#矩阵乘法</span></span><br><span class="line">     sigma+= self.epsilon * norm</span><br><span class="line">       scale = tf.linalg.cholesky(sigma)</span><br><span class="line"> <span class="comment">#乘出来一个分布</span></span><br><span class="line">     <span class="keyword">return</span> tf.keras.layers.concatenate([</span><br><span class="line">         tf.reshape(prior, shape=[-<span class="number">1</span>, self.n_mix]),</span><br><span class="line">            tf.reshape(mu,    shape=[-<span class="number">1</span>, self.n_mix * self.n_targets]),</span><br><span class="line">           tf.reshape(scale, shape=[-<span class="number">1</span>, self.n_mix * self.n_targets ** <span class="number">2</span>]),</span><br><span class="line">      ])</span><br><span class="line">    <span class="comment">#三个矩阵压缩到同一个矩阵里进行输出</span></span><br></pre></td></tr></table></figure>
<p>看完这个代码发现了这个论文的另一个特殊的地方，就是他的loss。</p>
<p>虽然最后输出的是只输出一个数，但是他在训练这个网络的时候，用了pdf和pdf的极大似然值来做loss</p>
<p>差不多就到这里，后续等我把他实现一下。</p>
<h2 id="一个问题">一个问题</h2>
<p>看完之后有一个很有意思的问题</p>
<p>就是原本的论文是假设输出是由一个由五个正态分布组合成的分布，但是我们得到的y只有一个单独的数。</p>
<p>怎么样才能把我们的y和预测出来的y进行对比得到loss用来训练呢</p>
<p>这就要看这个loss function了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, y, output</span>):</span></span><br><span class="line">    prior, mu, scale = self._parse_outputs(output) </span><br><span class="line">    dist  = <span class="built_in">getattr</span>(tfp.distributions, self.distribution)(mu, scale)</span><br><span class="line">    prob  = tfp.distributions.Categorical(probs=prior)</span><br><span class="line">    mix   = tfp.distributions.MixtureSameFamily(prob, dist)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">impute</span>(<span class="params">mix, y, N</span>):</span></span><br><span class="line">        <span class="comment"># summation  = tf.zeros(tf.shape(y)[0])</span></span><br><span class="line">        <span class="comment"># imputation = lambda i, s: [i+1, tf.add(s, mix.log_prob(tf.where(tf.math.is_nan(y), mix.sample(), y)))]</span></span><br><span class="line">        <span class="comment"># return tf.while_loop(lambda i, x: i &lt; N, imputation, (0, summation), maximum_iterations=N, parallel_iterations=N)[1] / N</span></span><br><span class="line">        <span class="keyword">return</span> tf.reduce_mean([</span><br><span class="line">            mix.log_prob( tf.where(tf.math.is_nan(y), mix.sample(), y) )</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(N)], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Much slower due to cond executing both branches regardless of the conditional</span></span><br><span class="line">    <span class="comment"># likelihood = tf.cond(tf.reduce_any(tf.math.is_nan(y)), lambda: impute(mix, y, self.imputations), lambda: mix.log_prob(y))</span></span><br><span class="line">    likelihood = mix.log_prob(y)</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(-likelihood) + tf.add_n([<span class="number">0.</span>] + self.model.losses)</span><br></pre></td></tr></table></figure>
<p>返回值是tf.reduce_mean(-likelihood) + tf.add_n([0.] + self.model.losses)</p>
<p>impute这个函数似乎一直都没有用到</p>
<p>计算张量的各个维度上的元素的平均值.</p>
<p>而这里计算的是likelihood，计算方式是mix.log_prob(y)</p>
<p>mix这个类来自于tfp.distributions.MixtureSameFamily(prob, dist), prob和dist来自output</p>
<p>tfp这个东西来自于tensorflow_probability</p>
<h2 id="tensorflow_probability">tensorflow_probability</h2>
<p>又跑去扒了源码，看的我头疼，这里用到了里面的两个类，一个MixtureSameFamily，一个categorical,太长了新开一篇</p>
<h2 id="再来补个课">再来补个课</h2>
<p>这么多函数前面都带_，这玩意到底是干嘛的</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>周大侠
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://lifeodyssey.github.io/posts/fbd0b1b0.html" title="Mixture Density Network">https://lifeodyssey.github.io/posts/fbd0b1b0.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9lbg=="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/Inversion/" rel="tag"># Inversion</a>
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/posts/760defdb.html" rel="prev" title="Tree Family in Machine learning and XGBoost">
      <i class="fa fa-chevron-left"></i> Tree Family in Machine learning and XGBoost
    </a></div>
      <div class="post-nav-item">
    <a href="/posts/a23e5172.html" rel="next" title="2021年终总结">
      2021年终总结 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



        </div>
        

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">周大侠</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">763k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">11:33</span>
</div>
  <div class="powered-by">Powered by <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9taXN0Lw==">NexT.Mist</span>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>


  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      const script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
