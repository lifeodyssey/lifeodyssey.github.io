<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  
  <link rel="stylesheet" href="/lib/animate-css/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lifeodyssey.github.io","root":"/","scheme":"Mist","version":"8.0.0-rc.5","exturl":true,"sidebar":{"position":"right","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"path":"search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="There are five main data fusion approaches according to &#39;Spatio-temporal fusion for remote sensing data: an overview and new benchmark&#39;. Here I will read the STARFM.">
<meta property="og:type" content="article">
<meta property="og:title" content="Data fusion series note 1">
<meta property="og:url" content="https://lifeodyssey.github.io/posts/bd7e58b0.html">
<meta property="og:site_name" content="乔克叔叔的床边故事">
<meta property="og:description" content="There are five main data fusion approaches according to &#39;Spatio-temporal fusion for remote sensing data: an overview and new benchmark&#39;. Here I will read the STARFM.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://lifeodyssey.github.io/posts/Users/zhenjia/AppData/Roaming/Typora/typora-user-images/image-20220207140829822.png">
<meta property="article:published_time" content="2020-07-15T14:52:41.000Z">
<meta property="article:modified_time" content="2022-02-18T06:46:57.000Z">
<meta property="article:author" content="周大侠">
<meta property="article:tag" content="Data Fusion">
<meta property="article:tag" content="Research Basis">
<meta property="article:tag" content="paper reading">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lifeodyssey.github.io/posts/Users/zhenjia/AppData/Roaming/Typora/typora-user-images/image-20220207140829822.png">

<link rel="canonical" href="https://lifeodyssey.github.io/posts/bd7e58b0.html">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Data fusion series note 1 | 乔克叔叔的床边故事</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-135697820-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-135697820-1');
      }
    </script>






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="乔克叔叔的床边故事" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">乔克叔叔的床边故事</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#weight-function-based-methods-starfm"><span class="nav-number">1.</span> <span class="nav-text">Weight function-based methods: STARFM</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#data-requirement"><span class="nav-number">1.1.</span> <span class="nav-text">Data Requirement</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#performance"><span class="nav-number">1.2.</span> <span class="nav-text">Performance</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#theoretical-basis"><span class="nav-number">1.3.</span> <span class="nav-text">Theoretical Basis</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#basic-equations"><span class="nav-number">1.3.1.</span> <span class="nav-text">Basic Equations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#implementation-considerations"><span class="nav-number">1.4.</span> <span class="nav-text">Implementation Considerations</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#how-to-weight-spatial-information"><span class="nav-number">1.4.1.</span> <span class="nav-text">How to weight spatial information</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#spectrally-similar-neighbor-pixels"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">Spectrally Similar Neighbor Pixels</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#combined-weighting-function"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">Combined Weighting Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sample-filtering"><span class="nav-number">1.4.1.3.</span> <span class="nav-text">Sample Filtering</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#following-methods"><span class="nav-number">1.5.</span> <span class="nav-text">Following methods</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#fsdaf"><span class="nav-number">2.</span> <span class="nav-text">FSDAF</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#fine-resolution-classification"><span class="nav-number">2.1.</span> <span class="nav-text">1. Fine Resolution Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%AF%8F%E4%B8%80%E7%B1%BB%E7%9A%84%E6%97%B6%E9%97%B4%E5%8F%98%E5%8C%96"><span class="nav-number">2.2.</span> <span class="nav-text">2.计算每一类的时间变化</span></a></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">周大侠</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">141</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">88</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lifeodyssey"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnpoZW5qaWF6aG91MDEyN0BnbWFpbC5jb20=" title="E-Mail → mailto:zhenjiazhou0127@gmail.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cucmVzZWFyY2hnYXRlLm5ldC9wcm9maWxlL1poZW5qaWFfWmhvdQ==" title="Researchgate → https:&#x2F;&#x2F;www.researchgate.net&#x2F;profile&#x2F;Zhenjia_Zhou"><i class="fa fa-researchgate fa-fw"></i>Researchgate</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cubGlua2VkaW4uY29tL2luLyVFNiU4QyVBRiVFNCVCRCVCMy0lRTUlOTElQTgtODMyNmI0MTU1Lw==" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;%E6%8C%AF%E4%BD%B3-%E5%91%A8-8326b4155&#x2F;"><i class="fa fa-Linkedin fa-fw"></i>Linkedin</span>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="rss fa-fw"></i>RSS</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9lbg=="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>



      </section>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>

<noscript>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


      <div class="main-inner">
        

        <div class="content post posts-expand">
          

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://lifeodyssey.github.io/posts/bd7e58b0.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="周大侠">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="乔克叔叔的床边故事">
    </span>

    
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Data fusion series note 1
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-15 22:52:41" itemprop="dateCreated datePublished" datetime="2020-07-15T22:52:41+08:00">2020-07-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-02-18 14:46:57" itemprop="dateModified" datetime="2022-02-18T14:46:57+08:00">2022-02-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>9 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>There are five main data fusion approaches according to 'Spatio-temporal fusion for remote sensing data: an overview and new benchmark'. Here I will read the STARFM.</p>
<a id="more"></a>
<h1 id="weight-function-based-methods-starfm">Weight function-based methods: STARFM</h1>
<p>The spatial and temporal adaptive reflectance fusion model (STARFM) is the first weight function-based STF method developed in the literature. This method first assumes that all the pixels in the coarse images are pure. It uses a weighted strategy to add the reflectance changes between two coarse images to the prior fine image so as to predict the target image. STARFM has been shown to be able to capture phenological changes. However, its performance in highly heterogeneous landscapes and in the task of capturing land-cover changes is limited.</p>
<h2 id="data-requirement">Data Requirement</h2>
<p>(MODIS and Landsat)Their orbital parameters are equal, and as such the viewing (near-nadir) and solar geometries are close to those of the corresponding Landsat acquisition.</p>
<h2 id="performance">Performance</h2>
<p>The STARFM has been tested over forested areas, cropland regions, and heterogeneous mixtures of crop and forest. Results show that the STARFM can capture phenology changes precisely, although the accuracy depends on the characteristic patch size of the landscape.</p>
<h2 id="theoretical-basis">Theoretical Basis</h2>
<p>Assumptions</p>
<ol type="1">
<li>Neglecting geolocation errors and differences in atmospheric correction</li>
<li>MODIS surface reflectance <span class="math inline">\(M(x_i,y_j,t_k)\)</span> has been previously georeferenced and super sampled to the resolution and bounds of the Landsat surface reflectance image $L(x_i,y_j,t_k) $and thus shares the same image size, pixel size, and coordinate system.</li>
<li>if MODIS and Landsat surface reflectance are equal at a given time, then these values should be equal for the prediction date.</li>
<li>If the MODIS surface reflectance is constant over time, then the Landsat surface reflectance should not change as well.</li>
</ol>
<h3 id="basic-equations">Basic Equations</h3>
<p>Assumption 1</p>
<p>A heterogeneous coarse-resolution pixel at date <em>t</em> and surface reflectance (<span class="math inline">\(C_t\)</span>) can be aggregated from finer resolution homogeneous pixels of surface reflectance <span class="math inline">\(F^i_t\)</span> and percentage coverage <span class="math inline">\(A^i_t\)</span> according to <span class="math display">\[
C_t=\sum(F^i_t*A^i_t)\tag{1}
\]</span></p>
<p>where <span class="math inline">\(i\)</span> refers to the spatial index (location) of the fine- resolution pixel.</p>
<p>The key to finding an approximate solution is to find spectrally similar homogeneous neighboring pixels.</p>
<p>For a homogenous pixel at a coarser MODIS resolution, the surface reflectance measured by Landsat data can be ex- pressed as <span class="math display">\[
L(x_i,y_i,t_k)=M(x_i,y_i,t_i)+\varepsilon_k \tag{2}
\]</span> where <span class="math inline">\((x_i,y_j)\)</span> is a given pixel location for both Landsat and MODIS images, <span class="math inline">\(t_k\)</span> is the acquisition date for both MODIS and Landsat data, and <span class="math inline">\(ε_k\)</span> represents the difference between observed MODIS and Landsat surface reflectance (caused by differing bandwidth and solar geometry).</p>
<p>Assumption 2</p>
<p>Suppose we have n pairs input of $L(x_i,y_j,t_k) $and <span class="math inline">\(M(x_i,y_j,t_k)\)</span> and each pair is acquired on the same date, where <span class="math inline">\(k ∈ [1,n]\)</span>. The daily MODIS surface reflectance <span class="math inline">\(M(x_i,y_j,t_0)\)</span> at date <span class="math inline">\(t_0\)</span> is also a known value among inputs, then the predicted Landsat surface reflectance at date <span class="math inline">\(t_0\)</span> is <span class="math display">\[
L(x_i,y_j,t_0)= M(x_i,y_j,t_0)+ ε_0. \tag{3}
\]</span> Suppose the ground coverage type and system errors at pixel<span class="math inline">\((x_i,y_j)\)</span> does not change over prediction date <span class="math inline">\(t_0\)</span> and the date <span class="math inline">\(t_k\)</span>, we will have <span class="math inline">\(ε_0 = ε_k\)</span> and thus <span class="math display">\[
L(x_i,y_j,t_0)= M(x_i,y_j,t_0)+ L(x_i,y_j,t_k) −M(x_i,y_j,t_k).\tag{4}
\]</span> Such ideal situation cannot be satisfied from MODIS and Landsat observations. Their relationships are complicated by several factors:</p>
<ol type="1">
<li>MODIS observation is not a homogeneous pixel and may include mixed land-cover types when considered at Landsat spatial resolution</li>
<li>Land cover may change from one type to another type during the prediction period</li>
<li>Land-cover status (phenology) and solar geometry bidirectional reflectance distribution function (BRDF) changes will alter the reflectance from prediction date <span class="math inline">\(t_0\)</span> to date <span class="math inline">\(t_k\)</span>.</li>
</ol>
<p>By introducing additional information from neighboring pixels, we compute the surface reflectance for the central pixel at date t0 with a weighting function <span class="math display">\[
L (x_{w/2},y_{w/2},t_0) = \sum_{i=1}^{w} \sum_{j=1}^{w} \sum_{k=1}^{w}
W_{ijk}×(M(x_i,y_j,t_0)+ L(x_i,y_j,t_k) −M(x_i,y_j,t_k))\tag{5}
\]</span> where <span class="math inline">\(w\)</span> is the searching window size and <span class="math inline">\((x_{w/2},y_{w/2})\)</span> is the central pixel of this moving window.</p>
<p>To ensure that the right information from neighbor pixels is used, only spectrally similar (i.e., from the same spectral class) and cloud-free pixels from Landsat surface reflectance within the moving window are used to compute the reflectance.</p>
<p>The weight <span class="math inline">\(W_{ijk}\)</span> determines how much each neighboring pixel contributes to the estimated reflectance of the central pixel. It is very important and is determined by three measures as follows.</p>
<ol type="1">
<li><p>Spectral difference between MODIS and ETM+ data at a given location is <span class="math display">\[
S_{ijk} = |L(x_i,y_j,t_k) −M(x_i,y_j,t_k)| .\tag{6}
\]</span> A smaller value of <span class="math inline">\(S_{ijk}\)</span> implies that the fine spatial resolution pixel has closer spectral features to the averaged surrounding pixels; thus, the change at fine resolution should be comparable to that of the averaged surrounding pixels. Therefore, the pixel’s reflectance should be assigned a higher weight in (5).</p>
<p>A3</p></li>
<li><p>Temporal difference between the input and the predicted MODIS data is <span class="math display">\[
T_{ijk} = |M(x_i,y_j,t_k) −M(x_i,y_j,t_0)|\tag{7}
\]</span> This metric measures changes occurring between the prediction and the acquisition dates. A smaller <span class="math inline">\(T_{ijk}\)</span> means less vegetation change between time <span class="math inline">\(t_k\)</span> and <span class="math inline">\(t_0\)</span>; thus, the pixel should be assigned a higher weight.</p>
<p>A4</p>
<p>if changes are too subtle to be detected by the MODIS observation, this algorithm will not be able to predict any change when synthesizing the fine resolution imagery. Also, there may be situations where the STARFM algorithm cannot detect changes when two contradicting changes occur within a coarse-resolution pixel simultaneously and compensate for each other.</p></li>
<li><p>Location distance between central pixel <span class="math inline">\((x_{w/2},y_{w/2})\)</span> and candidate pixel <span class="math inline">\((x_i,y_j)\)</span> at date <span class="math inline">\(t_k\)</span> is <span class="math display">\[
d_{ijk} = \sqrt{(x_{w/2} − x_i )^2 + (y_{w/2} − y_j)^2}
\]</span> The spatial similarity is normally better for a closer pixel; thus, the closer candidate should be assigned a higher weight.</p></li>
</ol>
<h2 id="implementation-considerations">Implementation Considerations</h2>
<h3 id="how-to-weight-spatial-information">How to weight spatial information</h3>
<h4 id="spectrally-similar-neighbor-pixels">Spectrally Similar Neighbor Pixels</h4>
<p>The spectral similarity ensures that the correct spectral information is used from fine-resolution neighboring pixels: Unsupervised classification and using thresholds in surface reflectance directly. STARFM use the second approach.</p>
<p>"the purpose of the search process is to find pixels within the local moving window that are spectrally similar to the central pixel. Each central pixel becomes the center of the class, and the rules used to determine spectral similarity become local rules and thus vary from pixel to pixel. In contrast to the traditional classification, which applies the same classification rules over the whole region, our search process (second approach) will not be able to produce a unique classification map over the study area."</p>
<h4 id="combined-weighting-function">Combined Weighting Function</h4>
<p>Based one these assumptions:</p>
<ol type="1">
<li>coarse-resolution homogeneous pixels provide identical temporal changes as fine-resolution observations from the same spectral class</li>
<li>observations with less change from the prediction date provide better information for the prediction date</li>
<li>more proximal neighboring pixels normally provide better information for prediction.</li>
</ol>
<p>The final step is to combine these independent factors to create an ideal weight function that blends both temporal and spatial information</p>
<p>First, convert the actual distance to a relative distance through the function <span class="math display">\[
D_{ijk} =1.0+ d_{ijk}/A\tag{9}
\]</span> where <span class="math inline">\(A\)</span> is a constant that defines the relative importance of the spatial distance to the spectral and temporal distance.</p>
<p>The relative distance <span class="math inline">\(D_ijk\)</span> within searching area “<span class="math inline">\(w\)</span>” changes from 1to <span class="math inline">\([1 + (1/ \sqrt2) ∗ (w/A)]\)</span>. A smaller value of <span class="math inline">\(A\)</span> gives a larger dynamic range of <span class="math inline">\(D_{ijk}\)</span>.</p>
<p>The combined spectral, temporal, and spatial distance can be computed with <span class="math display">\[
C_{ijk} = S_{ijk} ∗ T_{ijk} ∗ D_{ijk}\tag{10}
\]</span> or in a logistic formula to make it less sensitive to the spectral differences <span class="math display">\[
C_{ijk} =ln(S_{ijk} ∗ B +1) ∗ ln(T_{ijk} ∗ B +1) ∗ D_{ijk}\tag{11}
\]</span> where <span class="math inline">\(B\)</span> is a scale factor (equal to 10 000 when using MODIS or LEDAPS reflectance products, which linearly scale reflectance from 0 to 10 000).</p>
<p>We use a normalized reverse distance as the weight function</p>
<p><span class="math display">\[
W_{ijk} =(1/C_{ijk}) /\sum_{i=1}^{w}\sum_{j=1}^{w}\sum_{k=1}^{n}(1/C_{ijk}).\tag{12}
\]</span></p>
<p>If the MODIS surface reflectance does not change, we have <span class="math inline">\(M(x_i,y_j,t_k)= M(x_i,y_j,t_0)\)</span>, then <span class="math inline">\(T_{ijk} =0\)</span> and <span class="math inline">\(C_{ijk} =0\)</span>, and weight <span class="math inline">\(W_{ijk}\)</span> is set to the maximum value. The predicted surface reflectance for central pixel of the moving window is then</p>
<p><span class="math display">\[
L (x_{w/2},y_{w/2},t_0) = M(x_i,y_j,t_0).
\]</span></p>
<p>This satisfies our other basic assumption: if MODIS and Landsat surface reflectance are equal at date <span class="math inline">\(t_k\)</span>, then they should be equal at date$ t_0$</p>
<h4 id="sample-filtering">Sample Filtering</h4>
<p>Additional filtering processes will then be applied to the candidates to remove poor- quality observations.</p>
<ol type="1">
<li><p>All poor-quality data are excluded from candidates according to the QA layer in the Landsat and MODIS surface reflectance products</p></li>
<li><p>Neighbor pixels are filtered out if they cannot provide better spectral and spatial information than the central pixel of the moving window</p>
<p>A good candidate should satisfy the following condition: <span class="math display">\[
S_{ijk} &lt; max (|L(x_{w/2},y_{w/2},t_k) −M(x_{w/2},y_{w/2},t_k)|)\tag{13}
\]</span> and <span class="math display">\[
T_{ijk} &lt; max(|M(x_{w/2},y_{w/2},t_k) −M(x_{w/2},y_{w/2},t_0)|) \tag{14}
\]</span></p></li>
</ol>
<p>Suppose we know that the uncertainties from Landsat and MODIS surface reflectance are <span class="math inline">\(\sigma_l\)</span> and <span class="math inline">\(\sigma_m\)</span>, respectively. All surface reflectance measurements are independent. The uncertainty for the spectral difference (6) between MODIS and ETM+ is <span class="math display">\[
\sigma_{lm} = \sqrt{\sigma_l^2+\sigma_m^2}
\]</span> The uncertainty for temporal difference (7) between two MODIS inputs is <span class="math display">\[
\sigma_{mm} = \sqrt{\sigma_m^2+\sigma_m^2}=\sqrt{2}*\sigma_m
\]</span> Considering the uncertainties in the candidate selection, (12)can be revised as</p>
<p><span class="math display">\[
S_{ijk}&lt; max(|{L(x_{w/2},y_{w/2},t_k)−M(x_{w/2},y_{w/2},t_k)}
+σ_{lm}\tag{15}
\]</span></p>
<p>and(13)can be revised as</p>
<p><span class="math display">\[
T_{ijk} &lt;max(|M(x_{w/2},y_{w/2},t_{k}−M(x_{w/2},y_{w/2},t_0) + \sigma_{mm}\tag{16}
\]</span></p>
<h2 id="following-methods">Following methods</h2>
<p>http://www.chen-lab.club/?page_id=11432</p>
<p>ESTARFM,IFSDAF,cuFSDAD</p>
<h1 id="fsdaf">FSDAF</h1>
<p>最后选用的是这个算法，也懒得去重新写ISFDAF的代码了。有GPU的话可以使用cuFSDAF。更好的选择是IFSDAF或者FSDAF 2.0 但是都是IDL的代码 我不会IDL.jpg</p>
<p>代码在https://xiaolinzhu.weebly.com/open-source-code.html可以找到</p>
<p>流程</p>
<figure>
<img src="/posts/Users/zhenjia/AppData/Roaming/Typora/typora-user-images/image-20220207140829822.png" alt="image-20220207140829822"><figcaption aria-hidden="true">image-20220207140829822</figcaption>
</figure>
<p>简单看下这个代码吧，看看需要改哪里的参数之类的</p>
<p>基本都在FSDAF.py里</p>
<p>没啥需要改的参数 就是用起来挺麻烦的.</p>
<p>关于参数的设置</p>
<p>软件中涉及到的融合参数没有标准答案。最近一项研究中（Zhou et al., 2021）中的设置可作为初始尝试：</p>
<ol type="1">
<li><p>Number of Classes 表示影像中土地覆盖类型数量，一般设置为5-7（STARFM可设置更多数量，如25）；</p></li>
<li><p>Number of Similar Pixels 表示算法中搜索周边相似像元的数量，与粗分辨率与细分辨率的比值为相关（假设为R），一般设置为Ｒ*1.5再向上取整。如MODIS-Landsat分辨率比值为8，则该值取12</p></li>
<li><p>Windows size(half width) 表示相似像元的搜索窗口，与粗分辨率与细分辨率的比值为相关（假设为R），一般设置为（R*1.5）/2再向上取整. 如MODIS-Landsat分辨率比值为8，则该值取6</p></li>
<li><p>Min/Max value表示融合数据的最大值和最小值，根据你的数据格式取值，如0-1或者0-255等 Zhou J., Chen J., Chen X.*, Zhu X., Qiu, Y., Song, H., Rao, Y., Zhang C., Cao X., Cui X. (2021).Sensitivity of six typical spatiotemporal fusion methods to different influential factors:A comparative study for a normalized difference vegetation index time series reconstruction. Remote Sensing of Environment .252, 112130. doi.org: 10.1016/j.rse.2020.112130</p></li>
</ol>
<p>摁跑了之后发现没啥结果，还是要认真看步骤找一下结果</p>
<h2 id="fine-resolution-classification">1. Fine Resolution Classification</h2>
<p>第一步是先把高分辨率的做一个分类，这里用的是ISODATA。</p>
<p>做完之后可以得到在一个粗分辨率像素中不同类的比例 <span class="math display">\[
f_{c}(x_i,y_i)=N_C(x_i,y_i)/m
\]</span> Nc是在粗分辨率xi,yi处属于c类的像素数量</p>
<h2 id="计算每一类的时间变化">2.计算每一类的时间变化</h2>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>周大侠
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://lifeodyssey.github.io/posts/bd7e58b0.html" title="Data fusion series note 1">https://lifeodyssey.github.io/posts/bd7e58b0.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9lbg=="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Data-Fusion/" rel="tag"># Data Fusion</a>
              <a href="/tags/Research-Basis/" rel="tag"># Research Basis</a>
              <a href="/tags/paper-reading/" rel="tag"># paper reading</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/posts/eaba55e.html" rel="prev" title="How to follow the research progress in your field?">
      <i class="fa fa-chevron-left"></i> How to follow the research progress in your field?
    </a></div>
      <div class="post-nav-item">
    <a href="/posts/5ab69b8e.html" rel="next" title="book reading note 4">
      book reading note 4 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



        </div>
        

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">周大侠</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">910k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">13:48</span>
</div>
  <div class="powered-by">Powered by <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9taXN0Lw==">NexT.Mist</span>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>


  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      const script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
